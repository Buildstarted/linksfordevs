<?xml version="1.0" encoding="utf-16"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <atom:link rel="self" type="application/rss+xml" href="https://linksfor.dev/" />
    <title>linksfor.dev(s)</title>
    <link>https://linksfor.dev/</link>
    <description>Curated links for devs</description>
    <language>en</language>
    <item>
      <title>AI Tools Are Wrecking Junior Developers! – Dev Leader Weekly 70</title>
      <link>https://www.devleader.ca/2024/11/16/ai-tools-are-wrecking-junior-developers-dev-leader-weekly-70/</link>
      <description>Welcome to another issue of Dev Leader Weekly! In this issue, I discuss my take on AI tools and getting started as a software developer.</description>
      <author> (https://www.facebook.com/devleaderca)</author>
      <guid>https://www.devleader.ca/2024/11/16/ai-tools-are-wrecking-junior-developers-dev-leader-weekly-70/</guid>
      <pubDate>Sat, 16 Nov 2024 14:01:12 GMT</pubDate>
    </item>
    <item>
      <title>Stop Making Me Memorize The Borrow Checker</title>
      <link>https://erikmcclure.com/blog/stop-making-me-memorize-borrow-checker/</link>
      <description>I started learning Rust about 3 or 4 years ago. I am now knee-deep in several very complex Rust projects that keep slamming into the limitations of the Rust compiler. One of the most common and obnoxious problems is hitting a situation the borrow-checker can’t deal with and realizing that I need to completely re-architect how my program works, because lifetimes are “contagious” the same way async is. Naturally, Rust has both!</description>
      <author> (Erik McClure)</author>
      <guid>https://erikmcclure.com/blog/stop-making-me-memorize-borrow-checker/</guid>
      <pubDate>Sat, 16 Nov 2024 11:01:39 GMT</pubDate>
    </item>
    <item>
      <title>D: Design Specifics 2 (Category Compilation) #09～#18</title>
      <link>https://youtube.com/watch?v=AhD9HhmZ8wY</link>
      <description>In Category D: Design Specifics, I talk in-depth about systems and mechanics used in games. There&amp;#39;s some occasional crossover with the Planning &amp;amp; Game Design category, but I tend to examine the topics here in greater detail.

[Index]
0:00 Opening
0:11 D-09 Maps Are Game Screens, Too
2:35 D-10 Unexpected Results
6:36 D-11 Flick Input
9:01 D-12 Teaching Players How to Play
11:17 D-13 Randomness Spices Games Up
15:09 D-14 Handicap Systems
18:45 D-15 Average and Mediocre Are the Same Thing
22:20 D-16 Online Updates
26:15 D-17 Speedy Screen Transitions
28:53 D-18 What Happens When You Shift the Center of Gravity?

[Playlist D: Design Specifics]
https://www.youtube.com/playlist?list=PLgKCjZ2WsVLQUWyKv2-ee6ds7uxtFiZeO</description>
      <author> (Masahiro Sakurai on Creating Games)</author>
      <guid>https://youtube.com/watch?v=AhD9HhmZ8wY</guid>
      <pubDate>Sat, 16 Nov 2024 11:01:30 GMT</pubDate>
    </item>
    <item>
      <title>Biological Miracle - Gates Of The Arctic National Park &amp;amp; Preserve (U.S. National Park Service)</title>
      <link>https://www.nps.gov/gaar/learn/nature/wood-frog-page-2.htm</link>
      <description>Wood Frog page 2</description>
      <author> ()</author>
      <guid>https://www.nps.gov/gaar/learn/nature/wood-frog-page-2.htm</guid>
      <pubDate>Sat, 16 Nov 2024 05:01:35 GMT</pubDate>
    </item>
    <item>
      <title>What To Use Instead of PGP - Dhole Moments</title>
      <link>https://soatok.blog/2024/11/15/what-to-use-instead-of-pgp/</link>
      <description>It’s been more than five years since The PGP Problem was published, and I still hear from people who believe that using PGP (whether GnuPG or another OpenPGP implementation) is a thing they s…</description>
      <author> ()</author>
      <guid>https://soatok.blog/2024/11/15/what-to-use-instead-of-pgp/</guid>
      <pubDate>Sat, 16 Nov 2024 04:01:53 GMT</pubDate>
    </item>
    <item>
      <title>.NET Data Community Standup - EF Core 9: Release extravaganza</title>
      <link>https://youtube.com/watch?v=wG8D5HJMzjA</link>
      <description>EF Core 9 was just released. Join us in this special session talking with industry experts about all topic EF Core.

Featuring: Jiri Cincura, Julie Lerman, Diego Vega, Erik Ejlskov Jensen, Chris Klug

#EFCore #chat #features</description>
      <author> (dotnet)</author>
      <guid>https://youtube.com/watch?v=wG8D5HJMzjA</guid>
      <pubDate>Sat, 16 Nov 2024 02:01:34 GMT</pubDate>
    </item>
    <item>
      <title>Half-Life 2 Anniversary Update</title>
      <link>https://www.half-life.com/en/halflife2/20th</link>
      <description>Experience Half-Life 2 all over again, with a brand-new commentary mode, improved graphics and gameplay options, Steam Workshop support, and more. We&amp;#39;re also bringing back the art book, and have a new documentary featuring the original development team.</description>
      <author> ()</author>
      <guid>https://www.half-life.com/en/halflife2/20th</guid>
      <pubDate>Sat, 16 Nov 2024 01:01:40 GMT</pubDate>
    </item>
    <item>
      <title>HybridCache in ASP.NET Core - New Caching Library</title>
      <link>https://www.milanjovanovic.tech/blog/hybrid-cache-in-aspnetcore-new-caching-library</link>
      <description>HybridCache in .NET 9 combines fast in-memory caching with distributed caching, solving common problems like cache stampede while adding features like tag-based invalidation. This guide shows you how to use HybridCache in your applications, from basic setup to real-world usage patterns with Entity Framework Core and minimal APIs.</description>
      <author> ()</author>
      <guid>https://www.milanjovanovic.tech/blog/hybrid-cache-in-aspnetcore-new-caching-library</guid>
      <pubDate>Sat, 16 Nov 2024 01:01:37 GMT</pubDate>
    </item>
    <item>
      <title>Maybe Bluesky has “won”</title>
      <link>https://anderegg.ca/2024/11/15/maybe-bluesky-has-won</link>
      <description>November has sucked so far. One upside of the terrible nonsense is that more people are fleeing X. Many are choosing Bluesky. I’ve seen a bunch of takes about this recently, but I keep seeing things I disagree with. I figure that’s a good enough excuse to write more about this weird-assed social network.</description>
      <author> ()</author>
      <guid>https://anderegg.ca/2024/11/15/maybe-bluesky-has-won</guid>
      <pubDate>Sat, 16 Nov 2024 01:01:35 GMT</pubDate>
    </item>
    <item>
      <title>Boosting WPF Performance - Upcoming Improvements</title>
      <link>https://youtube.com/watch?v=U_dwd0FbhkA</link>
      <description>This talk will focus on performance improvements in WPF DataGrid and other areas in WPF. We will be exploring the work in progress and improvements lined up in WPF for upcoming .NET releases. Join us to learn how to take full advantage of the performance enhancements in WPF and deliver responsive, high-performing applications.

Featuring: Ashish Kumar Singh

Connect with .NET: 
Blog:  https://aka.ms/dotnet/blog
Twitter: https://aka.ms/dotnet/twitter
TikTok:  https://aka.ms/dotnet/tiktok
Mastodon:  https://aka.ms/dotnet/mastodon
LinkedIn:  https://aka.ms/dotnet/linkedin
Facebook:  https://aka.ms/dotnet/facebook
Docs: https://learn.microsoft.com/dotnet
Forums: https://aka.ms/dotnet/forums
&amp;#128587;‍♀️Q&amp;amp;A: https://aka.ms/dotnet-qa
&amp;#128104;‍&amp;#127891;Microsoft Learn: https://aka.ms/learndotnet

#dotnet</description>
      <author> (dotnet)</author>
      <guid>https://youtube.com/watch?v=U_dwd0FbhkA</guid>
      <pubDate>Sat, 16 Nov 2024 01:01:30 GMT</pubDate>
    </item>
    <item>
      <title>How Fidelity uses .NET MAUI for Cross-platform desktop</title>
      <link>https://youtube.com/watch?v=kn-nmFsaMHc</link>
      <description>Kevin and Matthew join us from Fidelity to share their experiences and successes using .NET MAUI to power the next generation of their Active Trader Pro desktop client. We&amp;#39;ll get into:

Optimizing UI Dispatch for MAUI Applications
WebView Pooling and Optimizations for OSX and Windows
MDI multi-window desktop interfaces
Controlled Initialization and Shutdown sequences for MAUI
Dynamic Context Menus

Featuring: David Ortinau, Matthew Faust, Kevin Bieri

Connect with .NET: 
Blog:  https://aka.ms/dotnet/blog
Twitter: https://aka.ms/dotnet/twitter
TikTok:  https://aka.ms/dotnet/tiktok
Mastodon:  https://aka.ms/dotnet/mastodon
LinkedIn:  https://aka.ms/dotnet/linkedin
Facebook:  https://aka.ms/dotnet/facebook
Docs: https://learn.microsoft.com/dotnet
Forums: https://aka.ms/dotnet/forums
&amp;#128587;‍♀️Q&amp;amp;A: https://aka.ms/dotnet-qa
&amp;#128104;‍&amp;#127891;Microsoft Learn: https://aka.ms/learndotnet

#dotnet #maui #dotnetconf</description>
      <author> (dotnet)</author>
      <guid>https://youtube.com/watch?v=kn-nmFsaMHc</guid>
      <pubDate>Sat, 16 Nov 2024 00:01:39 GMT</pubDate>
    </item>
    <item>
      <title>GitHub - epasveer/seer: Seer - a gui frontend to gdb</title>
      <link>https://github.com/epasveer/seer</link>
      <description>Seer - a gui frontend to gdb. Contribute to epasveer/seer development by creating an account on GitHub.</description>
      <author> ()</author>
      <guid>https://github.com/epasveer/seer</guid>
      <pubDate>Fri, 15 Nov 2024 23:01:37 GMT</pubDate>
    </item>
    <item>
      <title>Infuse AI in your Windows apps with .NET</title>
      <link>https://youtube.com/watch?v=J0MJDLEm1AQ</link>
      <description>Join us for a demo packed session where you will learn what you can do with AI on Windows and how to add AI based features to your Windows apps to delight and empower your users. With Windows Copilot Runtime, developers can leverage APIs backed by on-device models such as Phi Silica and use frameworks and tools to leverage the latest open source or proprietary models locally within their apps.

Featuring: Nikola Metulev, Alexandre Zollinger Chohfi

Connect with .NET: 
Blog:  https://aka.ms/dotnet/blog
Twitter: https://aka.ms/dotnet/twitter
TikTok:  https://aka.ms/dotnet/tiktok
Mastodon:  https://aka.ms/dotnet/mastodon
LinkedIn:  https://aka.ms/dotnet/linkedin
Facebook:  https://aka.ms/dotnet/facebook
Docs: https://learn.microsoft.com/dotnet
Forums: https://aka.ms/dotnet/forums
&amp;#128587;‍♀️Q&amp;amp;A: https://aka.ms/dotnet-qa
&amp;#128104;‍&amp;#127891;Microsoft Learn: https://aka.ms/learndotnet

#dotnet</description>
      <author> (dotnet)</author>
      <guid>https://youtube.com/watch?v=J0MJDLEm1AQ</guid>
      <pubDate>Fri, 15 Nov 2024 23:01:33 GMT</pubDate>
    </item>
    <item>
      <title>The fallacies of distributed systems</title>
      <link>https://newsletter.francofernando.com/p/the-fallacies-of-distributed-systems</link>
      <description>Eight distributed systems fallacies that are underrated during system design.</description>
      <author> ()</author>
      <guid>https://newsletter.francofernando.com/p/the-fallacies-of-distributed-systems</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:56 GMT</pubDate>
    </item>
    <item>
      <title>Switching away from Pocket - Marcel Kapfer</title>
      <link>https://mmk2410.org/2024/11/13/switching-away-from-pocket</link>
      <description>After using Pocket for many years I needed to switch.</description>
      <author> ()</author>
      <guid>https://mmk2410.org/2024/11/13/switching-away-from-pocket</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:56 GMT</pubDate>
    </item>
    <item>
      <title>Wireguard + SSH</title>
      <link>https://rair.dev/wireguard-ssh/</link>
      <description>When COVID arrived in 2020, I lost my job as a scuba diving instructor. Now I’m writing articles about self-hosted applications to continue teaching.</description>
      <author> ()</author>
      <guid>https://rair.dev/wireguard-ssh/</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:55 GMT</pubDate>
    </item>
    <item>
      <title>Why didn’t we get GPT-2 in 2005?</title>
      <link>https://dynomight.net/gpt-2/</link>
      <description>We probably could have</description>
      <author> ()</author>
      <guid>https://dynomight.net/gpt-2/</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:54 GMT</pubDate>
    </item>
    <item>
      <title>5 ways to reduce the risk and impact of LLM hallucinations</title>
      <link>https://chrislovejoy.me/reduce-hallucinations</link>
      <description>I’ve been building apps powered by LLMs for the past 2 years - mostly in healthcare where the stakes are high.</description>
      <author> ()</author>
      <guid>https://chrislovejoy.me/reduce-hallucinations</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:53 GMT</pubDate>
    </item>
    <item>
      <title>You zag when others zig | Pavlina Papashimova</title>
      <link>https://www.pavlina.me/you-zag-when-others-zig/</link>
      <description>You’re not just one thing. Not only a professional, or only a partner, or only a parent. Not only someone who works, or someone who runs, or someone who paints in their free time.</description>
      <author> ()</author>
      <guid>https://www.pavlina.me/you-zag-when-others-zig/</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:52 GMT</pubDate>
    </item>
    <item>
      <title>Grafana as proxy</title>
      <link>https://ceesbos.nl/posts/20241108-grafana-as-proxy/</link>
      <description>Your local development of a Grafana plugin or dashboard may lack representative data. Connecting to production data sources may be impossible, but there are other ways to connect. Read more to find out how to use Grafana as a proxy to access the data.</description>
      <author> ()</author>
      <guid>https://ceesbos.nl/posts/20241108-grafana-as-proxy/</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:52 GMT</pubDate>
    </item>
    <item>
      <title>Guaranteed Fastest Way to Fix Bugs</title>
      <link>https://mattsgarlata.com/2024/11/14/guaranteed-fastest-way-to-fix-bugs/</link>
      <description>This is going to sound a little trite, but bear with me for a few sentences here. The fastest way to fix a bug is to not fix it. Before you roll your eyes and write this off as stupid or obvious, l…</description>
      <author> ()</author>
      <guid>https://mattsgarlata.com/2024/11/14/guaranteed-fastest-way-to-fix-bugs/</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:51 GMT</pubDate>
    </item>
    <item>
      <title>At-will employment</title>
      <link>https://www.kcoleman.me/2024/10/31/at-will.html</link>
      <description>Before I joined Grab, USA’s At-will employment system left me uncomfortable. When I was impacted by layoffs, I simultaneous balanced the emotional disruption establishing a new identity (“I was no longer Kevin that works at ___”, but “fUnemployed Kevin”) and the need to re-evaluate my finances and healthcare. A 30-day or 60-day notice would have given me a softer landing while I rebuild myself. But my experiences as a hiring manager at an international company shift my perspective on what is actually best for the employee (and the employer). As a hiring manager, I’ve hired and said good-bye to co-workers and directs from India, Malaysia, and the USA countries in contract employment and at-will roles. At-will in the USA In late 2020, I wanted to leave Yelp as soon as possible. When I got a job offer from Grab, I provided Yelp the standard 2 weeks notice, last day being Friday and then Grab started me the following Monday. This rapid change had perfect timing, because my new-hire grant was priced about 40% below our IPO price a year later. Coworkers that joined during the pre-ipo period (7 months after I did) had their shares valued at ~$10 IPO price (currently trading at $4.10/ea). Most of the time, Start your vesting as soon as possible is the best strategy. Contracted termination in Singapore When I got my first big project at Grab, I was assigned a product manager that halfway through the project put in her 60 day notice to leave Grab. During those 60 days, you’re expected to perform your full job duties until the day you leave. Because the project was schedule to end 2 weeks before her last day, her manager didn’t bother transitioning her responsibilities to another person. Unfortunately for me, she was visibly disengaged with her work. I wasn’t able to get the answers I needed at the rate I needed them, and thus couldn’t deliver the project on time. She effectively had 2 months of part-time labor for full time pay with her coworkers paying the price with their own careers. Hiring in India A coworker give a 60 day notice to leave the company. He stayed engaged until his last week, which everyone appreciated, but hiring a backfill was a hot mess. I don’t know if internal book keeping delayed searching for a backfill, but it wasn’t 2 months after he left did we find a replacement. Unfortunately, this replacement also had a 60 day notice they needed to give their current employer. Our group made due with a hole in our group for 4 months (2 months hiring + 2 months waiting for them to join + 1.5 months of training). 10 days before their start date, the new hire messaged the company saying their current employer gave them a raise once they saw Grab’s offer and would not be joining. With the role being potentially vacant for an additional 4 months, the manager ended up just losing the headcount. Hiring in Malaysia A team member in India informed me they wanted to leave the company and put in their 60 day notice. I negotiated with People Operations and my manager to terminate him immediately (but keep him on payroll for 60 days to meet the contract obligations). After my experience with the lady in singapore, I thought a visible hole on my team would be less painful than trying to get someone that doesn’t want to be here to complete there work. I communicated to other teams that we didn’t have the bandwidth to deliver on our project commitments because he was gone. I opted to backfill the role in Malaysia, for various reasons. After 2 months of interviewing, we found a great candidate. Unfortunately, this person also had a 2 month contract that they needed to complete, resulting in a 5 month hole on my team between one person leaving and another person coming in. Hire and Fire With contract employment, there is a probation period ranging from 3-6 months. During this time, the employment is practically “at-will” where the employer can terminate an employee instantly without the 60 day notice period. This system incentizes companies with teams of many redundent employees (for exmaple call centers) to “hire and fire” during that period if anything smells wrong, because if they just wait 1 day, they could be stuck with an underperformer for months. As difficult as at-will employment might feel sometimes, it is much more efficient for the employee and the employer if they are able to leave the job when they want to leave the job. Employees maximize their engagement (and career growth) if they are able to shift onto their next chapter faster and employers can better manage</description>
      <author> ()</author>
      <guid>https://www.kcoleman.me/2024/10/31/at-will.html</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:51 GMT</pubDate>
    </item>
    <item>
      <title>A World Without Engineering Managers?</title>
      <link>https://www.ebiester.com/agile/2024/03/31/a-world-without-engineering-managers.html</link>
      <description>There is a recurring complaint about the uselessness of software development (or engineering) managers in tech. At best, they’re considered a necessary evil. At worst, they’re incompetent programmers (or non-programmers1) who, through political means, weaseled into positions of power, became micromanagers, and actively impede the mission of getting software to customers. For some, they shouldn’t even exist. That said, I do think all software development managers should have experience as a senior developers or QE. Even with technical support, it is hard to add value as a manager without such a base.&amp;#160;↩</description>
      <author> ()</author>
      <guid>https://www.ebiester.com/agile/2024/03/31/a-world-without-engineering-managers.html</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:51 GMT</pubDate>
    </item>
    <item>
      <title>We don’t need to use what we make</title>
      <link>https://sive.rs/salt</link>
      <description>For many years, I was a touring musician, performing live on stage every week.
	But I didn’t like attending concerts.
	I liked making music more than listening to music.
	I felt I must be in the wrong line of work, creating something that I don’t consume.
	I never reconciled this feeling.</description>
      <author> ()</author>
      <guid>https://sive.rs/salt</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:51 GMT</pubDate>
    </item>
    <item>
      <title>Exploring LLM performance on the ARC training dataset</title>
      <link>https://lewish.io/posts/exploring-and-tagging-the-arc-training-dataset</link>
      <description>A quick write-up on tagging and describing the ARC training dataset tasks, merging it with evaluation data for some LLMs, doing some analysis on it, and putting it all on a site so you can explore it.</description>
      <author> ()</author>
      <guid>https://lewish.io/posts/exploring-and-tagging-the-arc-training-dataset</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:51 GMT</pubDate>
    </item>
    <item>
      <title>fulfillment and capitalism</title>
      <link>https://vivekn.dev/blog/fulfillment-capitalism</link>
      <description>viveknathani - blog</description>
      <author> ()</author>
      <guid>https://vivekn.dev/blog/fulfillment-capitalism</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:51 GMT</pubDate>
    </item>
    <item>
      <title>Tiny GraphRAG (Part 2)</title>
      <link>https://www.stephendiehl.com/posts/graphrag2/</link>
      <description>Personal Blog</description>
      <author> ()</author>
      <guid>https://www.stephendiehl.com/posts/graphrag2/</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:51 GMT</pubDate>
    </item>
    <item>
      <title>Finding my QA Automation Job in Bulgaria 2024</title>
      <link>https://www.pavlinbg.com/posts/finding-my-qa-automation-job-in-bulgaria-2024</link>
      <description>My journey navigating the Bulgarian job market in 2024 as Automation QA. From application strategies and interview experiences to insights on market challenges, learn what it takes to succeed in this competitive landscape</description>
      <author> ()</author>
      <guid>https://www.pavlinbg.com/posts/finding-my-qa-automation-job-in-bulgaria-2024</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:50 GMT</pubDate>
    </item>
    <item>
      <title>CMTOPS.DEV</title>
      <link>https://cmtops.dev/posts/building-observability-with-clickhouse/</link>
      <description>Tim&amp;#39;s internet corner. You will find occasional articles related to Linux, other Unix-like systems, and DevOps here.</description>
      <author> ()</author>
      <guid>https://cmtops.dev/posts/building-observability-with-clickhouse/</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:48 GMT</pubDate>
    </item>
    <item>
      <title>Open Source When We Say So</title>
      <link>https://writing.kemitchell.com/2024/11/14/OSI-AI</link>
      <description>still stronger claims of self-authority in OSI’s new AI “definition”</description>
      <author> ()</author>
      <guid>https://writing.kemitchell.com/2024/11/14/OSI-AI</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:48 GMT</pubDate>
    </item>
    <item>
      <title>‘Reflections on Trusting Trust’, but completely by accident this time</title>
      <link>https://secret.club/2024/10/21/unnecessarily-exhaustice-rca.html</link>
      <description>Compilers are complicated. You just won’t believe how vastly, hugely, mind-bogglingly complicated they are. I mean, you may think C build systems are painful, but they’re just peanuts to compilers. - Douglas Adams, probably This blog post assumes you have some knowledge of LLVM internals - I’ll try to fill in some of the lesser-known gaps but there are likely some other, better resources out there for learning about that. I have only one other post on this blog at the time of writing. It describes a somewhat boring, easily-explained missed optimization in one of the core components of LLVM with some actual, real-world implications. This blog post, although it follows roughly the same format, is the exact opposite: An exhaustive analysis of a miscompilation that impacted basically no-one Introduction &amp;amp; disclaimer Is all the complexity in modern-day optimizing compilers warranted? Probably not. Take LLVM, for example - once you get to the backends it might as well be 200 compilers in a trench coat. Picture this: it’s two in the morning and you’ve figured out exactly what went wrong after several weeks of debugging. You’re on your fifth coffee and have an idea for a target-independent patch. There’s just one small problem - you’d have to reach out to other overworked people from other companies, convince them that giving you some of their extremely limited time is worthwhile, wait for a bit, address any and all potential concerns, wait a bit more, and Lord help you if something breaks on a piece of hardware you don’t have access to. Alternatively, you could just add another if statement, ping a coworker to fast-track code review since the change is restricted to your little llvm/lib/Target sandbox, and be on your merry way. Repeat a few times a day and now your Modular™ framework ends up with a bunch of duplicated, convoluted, unnecessarily target-dependent code generation logic. Yes, quite a bit of the complexity is the result of Conway’s Law and the inevitable bitrot of a decades-old codebase. That being said, there is still an incredible amount of inherent messiness when targeting dozens of architectures in a (mostly) correct and performant way. Nobody is ever going to have a full, deep view of the entire system at once, and even if they did it would be out of date by the next Revert &amp;quot;[NFC] ...&amp;quot; commit. Every computer on the planet is a compiler fuzzer We tame the combinatorial explosion of potentially-buggy interactions through the kind of extraordinarily exhaustive testing only possible in the information age. Even a simple “Hello, world!” is a reliability test of the compiler, the linker, the runtime, the operating system, the terminal, any rendering middleware (which might also be running LLVM to compile shaders!), display drivers, the underlying hardware itself, and all software used in the process of building any of that. As such, you can be reasonably confident that release versions of production compilers, when using the flags and target architectures everyone else does, will probably not break anything. That’s not to say stuff doesn’t get through the cracks - yarpgen, alive2, Csmith, and similar tools would not have a long list of trophies otherwise - but those tools are also now just a part of this testing process too. A direct corollary of this is that bugs are regularly introduced in mainline branches, even by seasoned developers, and fixed whenever this exhaustive testing happens and people actually care about fixing them. Anyway, take a look at this commit: https://github.com/llvm/llvm-project/commit/c6e01627acf8591830ee1d211cff4d5388095f3d It is extremely important to emphasize: This committer knows what they’re doing! They’re good at their job! It’s just the nature of compilers and llvm-project/main; shit happens. The miscompile was found and fixed in roughly a week, and if this is all there was to it then we wouldn’t be here. The funniest compiler bug Here’s a bug. https://issues.chromium.org/issues/336399264 Credits to @dougall. As a summary, here’s what happened. Compile clang with the commit right before the fix above - This is generally called a “stage 1” build Bootstrap clang with the newly-compiled clang - This is a “stage 2” build Build the repro script attached with ASAN and fuzzing harnesses on when targeting AArch64 Get a miscompile in the output. Due to the Clang version being known-buggy and swapped out pretty much immediately, the stage 2 miscompile was noticed by pretty much nobody except people employed at companies that pay them to look at this stuff. This is the system working as intended! Unfortunately, I am a complete sucker for bugs like this but do not get paid to look at them. I wanted to figure out what went wrong here because it’s such a great example of the emergent complexity that comes with modern-day compilers. hear that? it’s the sound of my free time going down the drain for the next week. fwsssssssshhhhhhhhhhhhhhhhhhhhhhhh There’s some good news: this is a bug in the loop vectorizer, meaning our stage2 compiler is probably not going to be broken in the impossible-to-debug some-target-specific-register-allocation-thing-is-cooked-somehow way. That may not always be the case (especially if undef/poison are involved) but it seems like we’re going to get a nice, deterministic problem in the mostly-sorta-target-independent part of the pipeline. undef and poison are, roughly, LLVM’s way of modelling the set of all possible values and a deferred form of undefined behavior. I will not be explaining how this is formalized or what the implications for compiler transforms are. It gets weird. Please do not ask. Unfortunately, there is also some bad news: this is a bug in the loop vectorizer. The vectorizer is probably the single most per-target-tuned pass in the entirety of the generic optimization pipeline. That means we’re probably going to have some trouble convincing the compiler to deliberately emit the wrong instruction sequence on platforms without cross-compiling. Cross-compiling is not fun. I do not want to cross-compile, so I would like to try to coax the compiler into emitting the right (wrong?) code on X86 if possible. Foreshadowing is a narrative device in which- Reproducing the bug with somewhat-helpful debugging information For now, it’s important to just reproduce the original bug with the aforementioned stage1/stage2 executables in exact the same build environment. While we’re at it, let’s tack on some useful debugging options that will hopefully help us down the line: -print-after=loop-vectorize lets us print out a textual dump of the IR whenever the loop vectorizer pass has finished -ir-dump-directory lets us redirect this output to a folder somewhere This is going to generate a lot of text files. That’s okay, though, because computers are really fast and it doesn’t impact the build times in any meaningful way if we use an SSD. Simply run this easy-to-remember set of CMake incantations for the stage1 and stage2 builds: LLVM_DIR=$(pwd) cmake -S llvm -B build/stage1 -G Ninja -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=clang -DLLVM_TARGETS_TO_BUILD=AArch64 cmake --build build/stage1 cmake -S llvm -B build/stage2 -G Ninja -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=clang -DLLVM_TARGETS_TO_BUILD=AArch64 -DCMAKE_C_COMPILER=&amp;quot;$(realpath build/stage1/bin)/clang&amp;quot; -DCMAKE_CXX_COMPILER=&amp;quot;$(realpath build/stage1/bin)/clang++&amp;quot; -DCMAKE_C_FLAGS=&amp;quot;-mllvm -print-after=loop-vectorize -mllvm -ir-dump-directory=$LLVM_DIR/build/stage2/ir_dump&amp;quot; -DCMAKE_CXX_FLAGS=&amp;quot;-mllvm -print-after=loop-vectorize -mllvm -ir-dump-directory=$LLVM_DIR/build/stage2/ir_dump&amp;quot; cmake --build build/stage2 Unfortunately, I do not have an Apple device – as such, I would like to thank an anonymous friend with an M3 laptop for taking the time to help me with this. Time to test. $ ./build/stage1/bin/clang++ --target=arm64-apple-macos -O2 -fsanitize=fuzzer-no-link -fsanitize=address repro.cc -S -o - | sha256sum b8dd73117741b08fddb6065fb9289f861f9375b63ebab3ee67edf547ecb0c17a - $ ./build/stage2/bin/clang++ --target=arm64-apple-macos -O2 -fsanitize=fuzzer-no-link -fsanitize=address repro.cc -S -o - | sha256sum cf9f89efb0549051409d2559441404b1e627c73f11e763c975be20fcd7fcda34 - Okay, we’ve successfully reproduced the bug! We’re not really interested in why this code specifically breaks at runtime - it’s just a minimized reproducer - we just wanted to make sure we could catch it at all. With a repro in hand, we immediately notice some funky changes: Output difference &amp;lt; .section __TEXT,__literal16,16byte_literals &amp;lt; .p2align 4, 0x0 ; -- Begin function _ZN3re28Compiler9PostVisitEPNS_6RegexpENS_4FragES3_PS3_i &amp;lt; lCPI1_0: &amp;lt; .byte 255 ; 0xff &amp;lt; .byte 255 ; 0xff &amp;lt; .byte 255 ; 0xff &amp;lt; .byte 255 ; 0xff &amp;lt; .byte 255 ; 0xff &amp;lt; .byte 255 ; 0xff &amp;lt; .byte 255 ; 0xff &amp;lt; .byte 255 ; 0xff &amp;lt; .byte 8 ; 0x8 &amp;lt; .byte 9 ; 0x9 &amp;lt; .byte 10 ; 0xa &amp;lt; .byte 11 ; 0xb &amp;lt; .byte 12 ; 0xc &amp;lt; .byte 255 ; 0xff &amp;lt; .byte 255 ; 0xff &amp;lt; .byte 255 ; 0xff &amp;lt; lCPI1_1: &amp;lt; .byte 16 ; 0x10 &amp;lt; .byte 17 ; 0x11 &amp;lt; .byte 18 ; 0x12 &amp;lt; .byte 19 ; 0x13 &amp;lt; .byte 20 ; 0x14 &amp;lt; .byte 21 ; 0x15 &amp;lt; .byte 22 ; 0x16 &amp;lt; .byte 23 ; 0x17 &amp;lt; .byte 8 ; 0x8 &amp;lt; .byte 9 ; 0x9 &amp;lt; .byte 10 ; 0xa &amp;lt; .byte 11 ; 0xb &amp;lt; .byte 12 ; 0xc &amp;lt; .byte 29 ; 0x1d &amp;lt; .byte 30 ; 0x1e &amp;lt; .byte 31 ; 0x1f &amp;lt; .section __TEXT,__text,regular,pure_instructions &amp;lt; .globl __ZN3re28Compiler9PostVisitEPNS_6RegexpENS_4FragES3_PS3_i --- &amp;gt; .globl __ZN3re28Compiler9PostVisitEPNS_6RegexpENS_4FragES3_PS3_i ; -- Begin function _ZN3re28Compiler9PostVisitEPNS_6RegexpENS_4FragES3_PS3_i 63,71c26,34 &amp;lt; sub sp, sp, #192 [...] &amp;lt; ldr q0, [x8, lCPI1_1@PAGEOFF] &amp;lt; str q0, [sp] ; 16-byte Folded Spill &amp;lt; adrp x28, l___sancov_gen_.2@PAGE+5 &amp;lt; add x8, sp, #48 &amp;lt; ld1.2d { v1, v2 }, [x8] ; 32-byte Folded Reload --- &amp;gt; mov w22, #4 ; =0x4 &amp;gt; mov w27, #2 ; =0x2 &amp;gt; movi.2d v0, #0000000000000000 &amp;gt; mov.d x8, v0[1] &amp;gt; str x8, [sp] [...] Something quite fishy has happened here: we’ve lost a whole bunch of data that looks a lot like some sort of vector mask. Good to know! Since we’re diagnosing a miscompile in the stage2 build of Clang, we should also grab a known-good version of the textual IR of the compiler in the meantime. This just involves running the same set of commands with the fixed (Revert &amp;quot;...&amp;quot;) commit. In the end, we have two sets of folders full of IR files, most of which are the same: $ du -sh * 2.5G ir_dump_bad 2.5G ir_dump_good All of this will be useful later; let’s table it for now and try to avoid using someone else’s computer, since nagging someone else to recompile LLVM constantly is painful for both parties. It gets better Okay, now that we’ve successfully captured at least some debugging info, let’s try this the easy way first despite knowing full-well God is laughing his ass off. This would mean compiling on X86 Windows to X86 windows and testing. Ideally, I wouldn’t need to do anything weird to get it to work. Ha, Nope. Same output in both cases. Alright, let’s try WSL2. System-V is a bit closer to AAPCS and maybe there’s some weird ABI stuff going on. # (on X86-64 via WSL) $ ./build/stage1/bin/clang++ --target=arm64-apple-macos -O2 -fsanitize=fuzzer-no-link -fsanitize=address repro.cc -S -o - | sha256sum b8dd73117741b08fddb6065fb9289f861f9375b63ebab3ee67edf547ecb0c17a - $ ./build/stage2/bin/clang++ --target=arm64-apple-macos -O2 -fsanitize=fuzzer-no-link -fsanitize=address repro.cc -S -o - | sha256sum b8dd73117741b08fddb6065fb9289f861f9375b63ebab3ee67edf547ecb0c17a - Nope. Maybe the STL is involved - some change between libstdc++ and libc++. $ ./build/stage2_lcxx/bin/clang++ --target=arm64-apple-macos -O2 -fsanitize=fuzzer-no-link -fsanitize=address repro.cc -S -o - | sha256sum b8dd73117741b08fddb6065fb9289f861f9375b63ebab3ee67edf547ecb0c17a - Great. No taking the easy way out. Fuck it, just cross-compile the thing Alternate title: We live in a /usr/include/hell-gnueabihfelmnop of our own creation C build systems are not fun. One might go so far as to say they’re really, really, really not fun. This is true for a variety of reasons, but one painfully obvious example is cross-compilation. Here’s how you compile Clang to target AArch64 on Linux with the useful IR debug information, assuming you have an AArch64 sysroot installed and an appropriate CMake toolchain file: cmake -S llvm -B build/stage2 -DCMAKE_TOOLCHAIN_FILE=/home/user/aarch64.cmake -DLLVM_ENABLE_THREADS=OFF -DCMAKE_BUILD_TYPE=Release -DLLVM_USE_LINKER=lld -DLLVM_HOST_TRIPLE=aarch64-linux-gnu -DLLVM_ENABLE_PROJECTS=clang -DLLVM_TARGETS_TO_BUILD=AArch64 -DCMAKE_C_COMPILER=&amp;quot;$(realpath build/stage1/bin)/clang&amp;quot; -DCMAKE_CXX_COMPILER=&amp;quot;$(realpath build/stage1/bin)/clang++&amp;quot; -DCMAKE_C_FLAGS=&amp;quot;-fPIC -fuse-ld=lld --target=aarch64-linux-gnu -mllvm -print-after=loop-vectorize -mllvm -ir-dump-directory=$(realpath build/stage2/ir_dump)&amp;quot; -DCMAKE_CXX_FLAGS=&amp;quot;-fPIC -fuse-ld=lld --target=aarch64-linux-gnu -mllvm -print-after=loop-vectorize -mllvm -ir-dump-directory=$(realpath build/stage2/ir_dump)&amp;quot; -DCMAKE_ASM_FLAGS=&amp;quot;-fPIC --target=aarch64-linux-gnu&amp;quot; -G Ninja Yes, the --target options are necessary despite the AArch64 toolchain. Yes, -fuse-ld=lld is necessary despite -DLLVM_USE_LINKER=lld. There is no reason that this should be as complicated as it is today. None. Zero. No other language pulls shit like this and gets away with it. Too much time later: $ qemu-aarch64 ./build/stage2/bin/clang --target=arm64-apple-macos -O2 repro.cc -S -o - | sha256sum cf9f89efb0549051409d2559441404b1e627c73f11e763c975be20fcd7fcda34 - Success! I think I would’ve started to question my life choices if the stage2 compiler target had to be Apple-specific. To summarize: Compile clang with the commit right before the fix above Bootstrap clang with the newly-compiled clang &amp;lt;– AND TARGET AARCH64 Build the repro script attached with ASAN and fuzzing harnesses on when targeting AArch64 There may be some contrived way to convince the vectorizer to miscompile this on X86 by tweaking profitability heuristics but this is good enough for now. Back to bug hunting! In which approximately 29,000 lines of textual IR diffs are checked by hand and we get extremely lucky $ diff ir_dump_bad ir_dump_good &amp;gt; yeouch.diff $ ls -lh yeouch.diff -rw-r--r-- 1 user user 1.6M Sep 25 21:43 yeouch.diff There’s a lot going on in there. I’m going to optimistically assume that there’s nothing fishy going on in the Clang frontend, which slashes a significant portion off. After this we manually go through anything remaining, find any suspicious differences, and then check the IR dumps by hand for the function names since those aren’t in the diff itself. It would’ve also been pretty easy to check if the problem was actually in clang by using -emit-llvm and checking whether the two stages emit something different. I can retroactively say here that they don’t. Eventually, close to the bottom, we find that SelectionDAG::getVectorShuffle has been messed with in some way: ; *** IR Dump After LoopVectorizePass on *ZN4llvm12SelectionDAG16getVectorShuffleENS_3EVTERKNS_5SDLocENS_7SDValueES5_NS_8ArrayRefIiEE *** ; Function Attrs: mustprogress nounwind ssp uwtable(sync) define [2 x i64] @_ZN4llvm12SelectionDAG16getVectorShuffleENS_3EVTERKNS_5SDLocENS_7SDValueES5_NS_8ArrayRefIiEE [...] &amp;lt; %306 = phi i64 [ 0, %300 ], [ %323, %305 ] &amp;lt; %307 = phi &amp;lt;16 x i64&amp;gt; [ &amp;lt;i64 0, i64 1, i64 2, i64 3, i64 4, i64 5, i64 6, i64 7, i64 8, i64 9, i64 10, i64 11, i64 12, i64 13, i64 14, i64 15&amp;gt;, %300 ], [ %324, %305 ] &amp;lt; %308 = phi &amp;lt;16 x i1&amp;gt; [ zeroinitializer, %300 ], [ %319, %305 ] &amp;lt; %309 = phi &amp;lt;16 x i1&amp;gt; [ zeroinitializer, %300 ], [ %322, %305 ] --- &amp;gt; %306 = phi i64 [ 0, %300 ], [ %321, %305 ] &amp;gt; %307 = phi &amp;lt;16 x i64&amp;gt; [ &amp;lt;i64 0, i64 1, i64 2, i64 3, i64 4, i64 5, i64 6, i64 7, i64 8, i64 9, i64 10, i64 11, i64 12, i64 13, i64 14, i64 15&amp;gt;, %300 ], [ %322, %305 ] &amp;gt; %308 = phi &amp;lt;16 x i1&amp;gt; [ &amp;lt;i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true&amp;gt;, %300 ], [ %318, %305 ] &amp;gt; %309 = phi &amp;lt;16 x i1&amp;gt; [ &amp;lt;i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true, i1 true&amp;gt;, %300 ], [ %320, %305 ] [...] … Okay, but what is the SelectionDAG? On the subject of the SelectionDAG You can skip the section explaining the SelectionDAG if you know what the SelectionDAG is. LLVM IR, at this point, has been very well-documented elsewhere. The same is not true for the SelectionDAG. When lowering instructions to machine code, LLVM will by default use an intermediate representation known internally as the SelectionDAG. As the name suggests, it’s an acyclic graph-based intermediate representation designed to be useful for instruction selection. Each basic block has gets own SelectionDAG. This is not very helpful without a concrete visualization. Luckily, LLVM provides some visualization tools for us. There are a lot of different passes that the SelectionDAG goes through before being passed through the instruction selection system, but we’re going to completely ignore most of them for the sake of this explanation. Take the following code and compile it: // ./build/stage1_debug/bin/clang -mllvm -view-isel-dags -mllvm -view-dag-combine1-dags -O2 -m32 test2.c void test(int *b, long long *c) { *c = *b * 2345; } You’ll notice we’re compiling for x86_32 - this is important. Note that LLVM will try to start graphviz or some other dotfile viewer. The reader may find this useful but WSL doesn’t seem to play nicely with them. Solution: apt uninstall graphviz There are three distinct DAGs that are important to demonstrate roughly what the SelectionDAG does and how. They are quite large, but hopefully don’t mess the flow of this blog post up too much. The first one we’re going to look at is what LLVM IR initially gets translated to: dotfile There are multiple things you’ll notice about the SelectionDAG, but the most important takeaway is that the SelectionDAG is a dataflow graph that represents all dependencies of any given node as edges in an acyclic graph. To read the graph, consider GraphRoot the end of the block and go up. This makes intuitive sense, as we are essentially saying that the terminator instruction (a return in our case) depends on the results of the previous computations, including memory state. This is very helpful for instruction selection, as you get all valid orderings of instructions right off the bat. Memory dependencies are normally implicit in LLVM IR. There is an analysis framework that bolts on explicit memory dependency information on top of LLVM IR. It’s very useful but notably not a core part of the intermediate representation. In order for this to work, an explicit “state” edge must be added to all nodes that in some way manipulate memory. The way the SelectionDAG represents that is through the Chain operand, labeled ch in the graphs. Dependencies between blocks are modeled as stores to virtual registers with appropriate Chain operands. Note that the chain is marked in dotted blue lines. You’ll also notice that the chain is not fully sequential, meaning we can also represent non-volatile loads and stores that do not alias each other. There is another “special” form of node called Glue. We are not going to be talking about Glue. You’ll also notice that there’s already a target specific (X86ISD::) node in here. This is useful since it lets backends handle intrinsics or other wonky target-specific nonsense. One other notable difference compared to LLVM IR is that SelectionDAG nodes can have multiple returns. This is used, for example, so that load instructions can return both the loaded value and the new Chain. It’s also used in cases like X86’s div instruction, as div simultaneously computes the quotient and the remainder. With that being said, there’s a problem here: We’re doing 64-bit stores on a 32-bit platform! That’s not going to work. This is where the next phase of the SelectionDAG comes in: legalization. We need to turn the graph above into something that can map down to actual instructions on the hardware. Backends specify a list of legal operations, and all illegal operations are removed by the DAG “legalizer.” Once that’s done, we get output like this: dotfile A lot more stuff is happening in this graph, but it’s stuff that actually maps down to something in the hardware. Notably, the 64-bit store has been completely removed and replaced with two (reorderable!) 32-bit stores. TokenFactor nodes just merge separate state edges together, which is important if we have something like a store that potentially depends on two independent loads. In between these two graphs, we’ve also run the DAGCombiner. This is essentially just a patently absurd amount of pattern matching, both target-independent and not. After we’ve legalized the DAG and done some other transforms, we’re ready to do the initial instruction selection. This involves a bunch more stuff, including a TableGen-generated bytecode machine which I haven’t seen documented anywhere but is ridiculously cool to me, but we don’t have the space for that. Once that’s done, we get a graph that looks like this: dotfile Instruction selection (what instructions) now stops and instruction scheduling (where do they go) begins. From here, we use one of multiple different schedulers to map the SelectionDAG down to sequential code. That pretty much sums it up! Much of the target-dependent optimization, legalization, and other logic is queried through the inherited TargetLowering classes, which are generally implemented in the *ILselLowering.cpp files. Fun fact: X86IselLowering.cpp is big enough that GitHub refuses to render it. There is a very low-level explanation of the SelectionDAG on the LLVM website if you’re curious about more implementation specifics. GlobalIsel eta 2045 every day I’m shufflin’ After some cranial percussive maintenance analysis of the LLVM IR, we find that one specific location has changed: SelectionDAG::getVectorShuffle SDValue SelectionDAG::getVectorShuffle(EVT VT, const SDLoc &amp;amp;dl, SDValue N1, SDValue N2, ArrayRef&amp;lt;int&amp;gt; Mask) { // [...] // !!! THIS CODE CHANGED SOMEHOW !!! bool Identity = true, AllSame = true; for (int i = 0; i != NElts; ++i) { if (MaskVec[i] &amp;gt;= 0 &amp;amp;&amp;amp; MaskVec[i] != i) Identity = false; if (MaskVec[i] != MaskVec[0]) AllSame = false; } if (Identity &amp;amp;&amp;amp; NElts) return N1; // [...] } Note that at this point we’re not quite sure what the behavioral differences are here; I am not quite ready to read through dozens of lines of vectorized IR to figure out exactly what went wrong here. That doesn’t really matter, though; alarm bells are already going off in my head since the check in the resulting condition (Identity) is short-circuiting emission of a vector shuffle, which would generate data blobs like those removed completely in the miscompiled assembly. In addition, the code that was changed looks suspiciously like the reproducer in the GitHub issue, which also erroneously returns true. This is a neat coincidence – the original bug is in the loop vectorizer and seems to manifest itself as an entirely separate issue in vectorized code generated in a constructor for vector shuffles. yo dawg Let’s make sure we’re not jumping to conclusions first, though. Actually Doing the Thing Remember that cross-compilation nightmare? We’re not done yet! After building Clang once and testing some minor changes to SelectionDAG.cpp I realized that, to my horror, CMake marked the entire cross-compile build as stale and started the whole thing from scratch. This happened with both the default and Ninja generators. Turns out there’s a bug.. somewhere, that causes includes to constantly be marked as dirty under certain scenarios when using clang. Cool. tl;dr - sudo ln -s /usr/include /include Now that we’re not rebuilding the entirety of clang every time, it’s pretty easy to test whether our earlier hypothesis was correct. We can get rid of vectorization for this loop see whether anything changes: - for (int i = 0; i != NElts; ++i) + for (volatile int i = 0; i != NElts; ++i) $ qemu-aarch64 ./build/stage2/bin/clang --target=arm64-apple-macos -O2 -fsanitize=fuzzer-no-link -fsanitize=address repro.cc -S -o - | sha256sum b8dd73117741b08fddb6065fb9289f861f9375b63ebab3ee67edf547ecb0c17a - Great! Bug gone, which confirms exactly what’s being miscompiled in the compiler. Less debug info We’re generating way too much textual IR every time we compile. Let’s use -filter-print-funcs, another useful debugging flag, to fix that: -mllvm -filter-print-funcs=_ZN4llvm12SelectionDAG16getVectorShuffleENS_3EVTERKNS_5SDLocENS_7SDValueES5_NS_8ArrayRefIiEE Definitely a mouthful, but helpful nonetheless. While we’re at it, we should enable lld as well for full end-to-end testing. For those keeping track, our CMake configure script now looks roughly like this: cmake -S llvm -B build/stage2 -DCMAKE_TOOLCHAIN_FILE=/home/user/aarch64.cmake -DLLVM_ENABLE_THREADS=OFF -DCMAKE_BUILD_TYPE=Release -DLLVM_USE_LINKER=lld -DLLVM_HOST_TRIPLE=aarch64-linux-gnu -DLLVM_ENABLE_PROJECTS=&amp;quot;clang;lld&amp;quot; -DLLVM_TARGETS_TO_BUILD=AArch64 -DCMAKE_C_COMPILER=&amp;quot;$(realpath build/stage1/bin)/clang&amp;quot; -DCMAKE_CXX_COMPILER=&amp;quot;$(realpath build/stage1/bin)/clang++&amp;quot; -DCMAKE_C_FLAGS=&amp;quot;-fPIC -fuse-ld=lld --target=aarch64-linux-gnu -mllvm -print-after=loop-vectorize -mllvm -ir-dump-directory=$(realpath build/stage2/ir_dump) -mllvm -filter-print-funcs=_ZN4llvm12SelectionDAG16getVectorShuffleENS_3EVTERKNS_5SDLocENS_7SDValueES5_NS_8ArrayRefIiEE&amp;quot; -DCMAKE_CXX_FLAGS=&amp;quot;-fPIC -fuse-ld=lld --target=aarch64-linux-gnu -mllvm -print-after=loop-vectorize -mllvm -ir-dump-directory=$(realpath build/stage2/ir_dump) -mllvm -filter-print-funcs=_ZN4llvm12SelectionDAG16getVectorShuffleENS_3EVTERKNS_5SDLocENS_7SDValueES5_NS_8ArrayRefIiEE&amp;quot; -DCMAKE_ASM_FLAGS=&amp;quot;-fPIC --target=aarch64-linux-gnu&amp;quot; -G Ninja Side-note: brute-force testing only works for code, not command-line options I’d like to take a moment to point out that -filter-print-funcs did not actually work when combined with -ir-dump-directory until I was diagnosing this miscompile and submitted the only useful contribution of this [TOO LONG] word blog post. When I say that you will be fine if you use the flags that everyone else does, this is what I mean. These options work fine on their own, when combined they caused an extremely trivial crash, and that’s a normal Tuesday afternoon because nobody had ever bothered to try and do that. More debug info Let’s use the world’s best form of debugging to get some useful info about what’s going on here. + printf(&amp;quot;identity: %d, nelts: %d
&amp;quot;, (int)Identity, NElts); # Bad run: identity: 1, nelts: 20 identity: 0, nelts: 16 identity: 1, nelts: 16 identity: 1, nelts: 20 identity: 0, nelts: 16 identity: 1, nelts: 16 identity: 0, nelts: 16 # Good run: identity: 0, nelts: 20 identity: 0, nelts: 16 identity: 0, nelts: 16 identity: 0, nelts: 16 identity: 1, nelts: 16 identity: 0, nelts: 20 identity: 0, nelts: 16 identity: 0, nelts: 16 identity: 0, nelts: 16 identity: 1, nelts: 16 identity: 0, nelts: 16 All we’ve done here is add volatile and we’re even getting changes in how often the function is being called. The good news is that this confirms our hypothesis that Identity is erroneously being set to true in certain cases. The fact that these cases involve the number of vector elements being 20 is also important for later, but we’ll get to that. Let’s go ahead and also print out all the elements of the vector: + for (int i = 0; i != NElts; ++i) + printf(&amp;quot;[%08X] &amp;quot;, MaskVec[i]); As a reminder, the Identity boolean is set to true if all elements of the vector are either less than zero or equal to their indices in the vector itself. For example, [0, 1, -1, 3] would return true and [0, 0, 0, 0] would return false. $ qemu-aarch64 ./build/stage2/bin/clang --target=arm64-apple-macos -O2 -fsanitize=fuzzer-no-link -fsanitize=address repro.cc -S -o - [FFFFFFFF] [FFFFFFFF] [FFFFFFFF] [FFFFFFFF] [FFFFFFFF] [FFFFFFFF] [FFFFFFFF] [FFFFFFFF] [00000000] [00000001] [00000002] [00000003] [00000004] [FFFFFFFF] [FFFFFFFF] [FFFFFFFF] [FFFFFFFF] [FFFFFFFF] [FFFFFFFF] [FFFFFFFF] -&amp;gt; identity: 1, nelts: 20 [...] Now, I’m not exactly a mathematician… Reproducing the vectorizer oopsie We require a reasonably-representative reliable reproducer to avoid regular recompilation of clang. After a bit of tinkering with the runtime data we have, here’s a small piece of code that demonstrates the issue: Reproducer #include &amp;lt;cstdio&amp;gt; int testarr[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16 // index 16 (17th element!) }; void do_the_thing(int *mask_vec, int n_elts) { asm volatile(&amp;quot;&amp;quot;:&amp;quot;+r&amp;quot;(mask_vec),&amp;quot;+r&amp;quot;(n_elts)); // optimization barrier for good luck bool identity = true; for (int i = 0; i != n_elts; ++i) { if (mask_vec[i] != i) identity = false; } printf(&amp;quot;identity: %d, nelts: %d
&amp;quot;, (int)identity, n_elts); } int main() { do_the_thing(testarr, sizeof(testarr) / sizeof(testarr[0])); } $ ./build/stage1/bin/clang --target=aarch64-linux-gnu -O2 test.cpp -fuse-ld=lld -o test.out $ qemu-aarch64 test.out identity: 1, nelts: 17 Nifty. What’s going on internally, though? We can view the CFG of the output LLVM IR using the opt tool to find out. Rembember how I said I was not ready to read through dozens of lines of vectorized IR? Well, so, uh, ./build/stage1/bin/clang --target=aarch64-linux-gnu -O2 test.cpp -fuse-ld=lld -emit-llvm -S -o test.ll ./build/stage1/bin/opt -passes=-view-cfg test.ll The original dotfile is here. A rendered version is located here for your viewing displeasure. It’s big enough that I’d rather not embed it in-line, so you should open it in a second window somewhere to follow along. If you squint hard enough, you’ll notice a 16-wide vector loop, an 8-wide vector loop, and a scalar loop. Really quickly, let’s take a look at some of the trickery that’s happened already. Here’s an annotated and shortened version of the 16-wide vector loop: loop_block: %bool_phi = phi &amp;lt;16 x i1&amp;gt; [ zeroinitializer, %entry ], [ %bool_vec, %loop_block ] %idx_list = phi &amp;lt;16 x i32&amp;gt; [ ... ] %current_block_ptr = getelementptr inbounds ... %current_block = load &amp;lt;16 x i32&amp;gt;, ptr %current_block_ptr %cmp_result = icmp ne &amp;lt;16 x i32&amp;gt; %idx_list, %loaded_values %bool_vec = or &amp;lt;16 x i1&amp;gt; %bool_phi, %cmp_result s/”shortened version of”/”deliberate lie about what’s in”/ If you’re paying really close attention, you’ll notice that the meaning of cmp_result has actually been inverted compared to identity! Now any element of bool_vec being true would mean that identity is false, rather than requiring all elements of bool_vec to be true in order for identity to be true. I hope that made sense. This inversion means it’s possible to use a simple comparison against zero to check whether our condition was satisfied, rather than needing to load -1 in various places afterwards. Neat, huh? The phi node results of the 16-wide vector loop are, depending on whether we want to execute the 8-wide vector loop or not, are– Wait a minute. COMPUTER, ENHANCE! 27: ; preds = %14 %28 = bitcast &amp;lt;16 x i1&amp;gt; %23 to i16 %29 = icmp eq i16 %28, 0 %30 = icmp eq i64 %13, %8 br i1 %30, label %64, label %31 31: ; preds = %27 %32 = and i64 %8, 8 %33 = icmp eq i64 %32, 0 br i1 %33, label %61, label %34 61: ; preds = %7, %31, %57 %62 = phi i64 [ 0, %7 ], [ %13, %31 ], [ %38, %57 ] %63 = phi i1 [ true, %7 ], [ true, %31 ], [ %59, %57 ] br label %70 Let’s annotate this a bit. Block %27 is executed immediately after %14 (the 16-wide loop) is done, %57 is executed immediately after the 8-wide loop, %13 is the current loop iteration index (i.e. how many iterations of the original operation the 16-wide loop has completed), and %8 is the required total iteration count. ; Executed immediately after 16-wide vector loop 27: ; preds = %14 ; %29 is set to whether 0 if all vector elements are false; i.e. the check in the vector loop always fails. Not shown: the vectorizer has inverted our condition from equality to inequality. %28 = bitcast &amp;lt;16 x i1&amp;gt; %23 to i16 %29 = icmp eq i16 %28, 0 ; Check whether we&amp;#39;ve iterated through the entire loop %30 = icmp eq i64 %big_loop_trip_count, %req_trip_count br i1 %30, label %64, label %31 ; We have not, check whether we should execute 8-wide vector loop 31: ; preds = %27 %32 = and i64 %req_trip_count, 8 %33 = icmp eq i64 %32, 0 br i1 %33, label %61, label %34 ; Do not want to execute 8-wide loop 61: ; preds = %7, %31, %57 ; Iteration count after vectorized loops %62 = phi i64 [ 0, %7 ], [ %big_loop_trip_count, %31 ], [ %38, %57 ] ; PHI node representing current status of `identity`. Always `true` after the entry block, `true` after block `%31`, dependent on `%59` after block `%57` (8-wide loop). %63 = phi i1 [ true, %7 ], [ true, %31 ], [ %59, %57 ] br label %70 true after block %31? That’s not good. It seems like, if the second vector loop is not executed and we go to the scalar loop, the results of the first vector loop are just.. ignored! We can test this out pretty easily: int testarr[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, - 16 + 16, 17, 18, 19, 20, 21, 22, 23 }; $ qemu-aarch64 test.out identity: 0, nelts: 24 Then let’s try deliberately executing the scalar loop and the second vector loop: int testarr[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, - 16 + 16, 17, 18, 19, 20, 21, 22, 23, 24 }; $ qemu-aarch64 test.out identity: 0, nelts: 25 Great! Or, well, not great, but we’ve successfully narrowed down the root cause of the stage2 bug. To be clear, to trigger this bug the vectorizer has to generate a very specific type of operation at compile time and at runtime we have to have somewhere between 17 and 23 total iterations done. Fun. … How are these vectors generated, anyway? What would generate a twenty-element vector? Let’s take a look at the original reproducer and try to find anything useful in the LLVM IR: $ qemu-aarch64 ./build/stage2/bin/clang --target=arm64-apple-macos -O2 -fsanitize=fuzzer-no-link -fsanitize=address repro.cc -S -emit-llvm -o - | grep &amp;quot;20 x &amp;quot; $ Okay, so this has to be something done after all of the IR passes then. Fantastic. Let’s just print out everything with -debug and- $ ./build/stage1/bin/clang --target=arm64-apple-macos -O2 -fsanitize=fuzzer-no-link -fsanitize=address -S repro.cc -mllvm -debug clang (LLVM option parsing): Unknown command line argument &amp;#39;-debug&amp;#39;. Try: &amp;#39;clang (LLVM option parsing) --help&amp;#39; Oh. Right. We didn’t compile Clang in debug mode. Time to kick off yet another from-scratch LLVM build. sigh [more than one minute later] $ ./build/stage1_debug/bin/clang --target=arm64-apple-macos -O2 -fsanitize=fuzzer-no-link -fsanitize=address -S repro.cc -mllvm -debug [...] Creating new node: t76: v20i8 = concat_vectors t74, undef:v5i8, undef:v5i8, undef:v5i8 I’m not even going to question why or how a vector with five elements is being generated for now - what’s important is that the 20-element vector is being created during instruction selection. The &amp;lt;5 x i8&amp;gt; vectors exist before instruction selection in the form of operands to vector shuffles, which is good: ;./build/stage1/bin/clang --target=aarch64-linux-gnu -O2 repro.cc -fsanitize=fuzzer-no-link -fsanitize=address -emit-llvm -S -o - ; ... %133 = bitcast i40 %ref.tmp.sroa.4.0.extract.trunc to &amp;lt;5 x i8&amp;gt; %retval.sroa.0.8.vec.expand62 = shufflevector &amp;lt;5 x i8&amp;gt; %133, &amp;lt;5 x i8&amp;gt; poison, ... ; ... The fact that these vectors are in the IR emitted by -emit-llvm means we can assume they’ll be passed directly to the initial SelectionDAG builder, so we should take a look at that now. well, not always :( Passes after -emit-llvm but before instruction selection can absolutely trash your code if you’re not careful. Here’s something absolutely diabolical - the summary is that the WinEHPrepare pass will detect blocks with specific types of malformed call instructions AND COMPLETELY NUKE THE BASIC BLOCK. No less than three people (the author of that issue, a friend of mine, and I) have run into this to-date. If you develop for LLVM and there is ONE thing you take away from this post, it should be to be careful about inserting calls when funclet pads are involved!!! Under complex macroarchitectural conditions… Let’s take a look at SelectionDAGBuilder::visitShuffleVector: SelectionDAGBuilder::visitShuffleVector void SelectionDAGBuilder::visitShuffleVector(const User &amp;amp;I) { // ... // Normalize the shuffle vector since mask and vector length don&amp;#39;t match. if (SrcNumElts &amp;lt; MaskNumElts) { // ... unsigned PaddedMaskNumElts = alignTo(MaskNumElts, SrcNumElts); unsigned NumConcat = PaddedMaskNumElts / SrcNumElts; // Pad both vectors with undefs to make them the same length as the mask. SDValue UndefVal = DAG.getUNDEF(SrcVT); SmallVector&amp;lt;SDValue, 8&amp;gt; MOps1(NumConcat, UndefVal); SmallVector&amp;lt;SDValue, 8&amp;gt; MOps2(NumConcat, UndefVal); MOps1[0] = Src1; MOps2[0] = Src2; Src1 = DAG.getNode(ISD::CONCAT_VECTORS, DL, PaddedVT, MOps1); Src2 = DAG.getNode(ISD::CONCAT_VECTORS, DL, PaddedVT, MOps2); // Readjust mask for new input vector length. SmallVector&amp;lt;int, 8&amp;gt; MappedOps(PaddedMaskNumElts, -1); // ... SDValue Result = DAG.getVectorShuffle(PaddedVT, DL, Src1, Src2, MappedOps); // ... } As a reminder, our source vector size is 5 and our mask vector size is 16. The SelectionDAG builder wants to normalize the source and mask vectors, such that: The resulting output mask is a multiple of the number of elements in the source vector. Not quite sure why. All vectors passed to getVectorShuffle are the same size as the mask. This means that we get undef-padded 20-element vectors and multiple -1s at the end of the mask. Those -1s then get passed to getVectorShuffle, which then causes the miscompile as mentioned before. Neat. Time to look a little at how that 5-element vector was generated. Looking for &amp;lt;5 x i8&amp;gt; in the debug logs tell us a bit more about what’s going on here: rewriting [8,13) slice #8 Begin:(8, 13) NewBegin:(8, 13) NewAllocaBegin:(0, 16) original: store i40 %f1.sroa.5.0.extract.trunc.peel, ptr %9, align 8 shuffle: %retval.sroa.0.8.vec.expand = shufflevector &amp;lt;5 x i8&amp;gt; %10, ... blend: %retval.sroa.0.8.vecblend = select &amp;lt;16 x i1&amp;gt; ... SROA is a pass designed to optimize away (“promote”) alloca instructions and turn the values they reference directly into SSA registers. We can see SROA turning a store of a 40-bit integer(????) into a mess of shuffles. I’m not going to go through this bit line-by-line as, frankly, there isn’t anything particularly unique about how this part of the bug manifests itself. There are plenty of other ways in which weird-length vectors are generated - &amp;lt;20 x i8&amp;gt; and &amp;lt;5 x i8&amp;gt; show up a bunch of times in the test-cases. Here’s a great overview of some of the passes in the LLVM mid-end optimization pipeline. As an expedited summary, SROA runs, then a bunch of passes run, then SROA runs again and turns some stores into those i40 stores, then some other passes run, then SROA runs again and turns those stores into 5-element vector shuffles as seen above. Going through exactly why this happens would involve sifting through a bunch of implementation details with nothing much to say other than “this is what it does.” I don’t find that particularly engaging when nothing else is involved, and this post is long enough as-is. The code works as intended. The fact of the matter is that all modern-day compiler bugs have root cause chains this deep - one pass happens to generate some code which happens to cause another pass to generate some other code, and so on and so forth. If you’d like, you can see the full diff here. Conclusion It’s entirely unnecessary for compiler engineers to go into this amount of detail about why something went wrong from start to finish. All that’s needed is what was given at the very start: Correct IR, buggy IR. Fix bug, add test-case, done. The underlying root cause of this bug was fixed a while ago – it’s very unlikely that anyone was ever concretely impacted by it outside of a few hours of type 2 fun. With that being said, this silly bug will probably hold a special place in my heart for a while. The potential for a buggy bootstrapped compiler has always existed. In practice, however, it’s incredibly rare, and I didn’t think I’d ever actually see a real-world example. I hope whoever read to the end learned something. It’s a fantastic example of how things can go wrong in ridiculous, unexpected ways when so many moving parts are involved. I love shit like this.</description>
      <author> ()</author>
      <guid>https://secret.club/2024/10/21/unnecessarily-exhaustice-rca.html</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:47 GMT</pubDate>
    </item>
    <item>
      <title>The force is strong in LLMs - building an open source Star Wars inspired copilot in .NET</title>
      <link>https://youtube.com/watch?v=orYbN8990dA</link>
      <description>In the Star Wars universe, many pilots have an astromech copilot. Luke had R2-D2 in the back of his X-Wing for example. As developers, we too have copilots. Although these are not as cool as R2, and don’t help us blow up the Death Star, they do help us with our day to day tasks like writing code.

Whilst copilots can be boring, Jim thought it would be fun to create one inspired by Star Wars to help him with important tasks, such as describing his Lego collection (Star Wars Lego of course), and helping him write code, all done in the style of a Jedi.

In this session, Jim will walk you through the steps to build your own copilot, using the Pieces .NET SDK. By leveraging this SDK, your copilot can not only access an LLM of your choice from a range of cloud and on-device models such as Microsoft Phi and OpenAI GPT-4o, but you can also add assets to your chat’s context, such as code, documents, and plans for the Death Star. And just like a Jedi can sense the living force, this copilot can sense your presence and answer questions without needing additional documentation, such as summarizing your research on Wookiepedia. And best of all, reply like Yoda, it can!

By the end of this session, you will be able to complete your apprenticeship and build your own open source AI copilot.

Featuring: Jim Bennett

Connect with .NET: 
Blog:  https://aka.ms/dotnet/blog
Twitter: https://aka.ms/dotnet/twitter
TikTok:  https://aka.ms/dotnet/tiktok
Mastodon:  https://aka.ms/dotnet/mastodon
LinkedIn:  https://aka.ms/dotnet/linkedin
Facebook:  https://aka.ms/dotnet/facebook
Docs: https://learn.microsoft.com/dotnet
Forums: https://aka.ms/dotnet/forums
&amp;#128587;‍♀️Q&amp;amp;A: https://aka.ms/dotnet-qa
&amp;#128104;‍&amp;#127891;Microsoft Learn: https://aka.ms/learndotnet

#dotnet</description>
      <author> (dotnet)</author>
      <guid>https://youtube.com/watch?v=orYbN8990dA</guid>
      <pubDate>Fri, 15 Nov 2024 22:01:29 GMT</pubDate>
    </item>
    <item>
      <title>The Day Has Finally Come: Junior Devs Only Know ChatGPT!</title>
      <link>https://youtube.com/watch?v=-Y5NwCwAT2o</link>
      <description>We knew this day was coming. They warned us. There was nothing we could do.

Junior developers are joining the job market and they can&amp;#39;t code! They can only speak to LLMs!

... Or is that really true?

Let&amp;#39;s jump over to this Reddit thread and see how a software engineer is perceiving this as junior developers join their team!

----
&amp;#128273; Membership &amp;amp; Subscriptions:
- &amp;#128232; Weekly Newsletter: https://weekly.devleader.ca
- &amp;#127960;️ Private Discord Community: https://sidestack.io/devleader

&amp;#129504; Courses:
- All Courses: https://www.devleader.ca/courses
- Get Promoted As A Software Engineer: https://dometrain.com/course/career-getting-promoted-as-a-software-engineer/?ref=nick-cosentino
- Nailing The Behavioral Interview: https://dometrain.com/course/career-nailing-the-behavioral-interview/?ref=nick-cosentino
- Getting Started with C#: https://dometrain.com/course/getting-started-csharp?ref=nick-cosentino
- Deep dive C#: https://dometrain.com/course/deep-dive-csharp?ref=nick-cosentino
- C# Zero to Hero BUNDLE: https://dometrain.com/bundle/from-zero-to-hero-csharp/?ref=nick-cosentino
- Reflection in .NET: https://dometrain.com/course/from-zero-to-hero-reflection-in-dotnet/?ref=nick-cosentino
- Refactoring For C# Devs: https://dometrain.com/course/from-zero-to-hero-refactoring-for-csharp-developers?ref=nick-cosentino
- [FREE] Intro to Software Development: https://www.youtube.com/playlist?list=PLzATctVhnsggb3lj53T8fJSK6LJQFUyKS

&amp;#128483;️ Social Media &amp;amp; Links:
- All My Links: https://linktr.ee/devleader
- Vlogs:  @DevLeaderBTS @CodeCommute 
- Blog: https://www.devleader.ca/
- TikTok: https://www.tiktok.com/@devleader
- LinkedIn: https://www.linkedin.com/in/nickcosentino
- Threads: https://threads.net/@dev.leader
- Twitter: https://twitter.com/DevLeaderCa
- Facebook: https://www.facebook.com/DevLeaderCa
- Instagram: https://www.instagram.com/dev.leader
- GitHub: https://github.com/ncosentino/
- Twitch: https://twitch.tv/devleaderca
- YouTube: https://youtube.com/@DevLeader?sub_confirmation=1

❤️ Affiliations &amp;amp; Products/Services That I Love:
- @BrandGhostAI for all of my content creation: https://brandghost.ai
- AI shorts helper Opus Clip: https://opus.pro/?via=2f9e97
- VPS hosting from RackNerd: https://my.racknerd.com/aff.php?aff=9013
- VPS hosting from Contabo: https://www.jdoqocy.com/click-101028632-12454592
- Newsletter platform ConvertKit: https://convertkit.com/?lmref=c5X7KQ
- Newsletter referral system SparkLoop: https://dash.sparkloop.app/signup?aff=9fe76c8b
----

#softwareengineering #softwaredeveloper #softwareengineer</description>
      <author> (Dev Leader)</author>
      <guid>https://youtube.com/watch?v=-Y5NwCwAT2o</guid>
      <pubDate>Fri, 15 Nov 2024 20:01:44 GMT</pubDate>
    </item>
    <item>
      <title>How we chose the right UI framework for DevToys</title>
      <link>https://youtube.com/watch?v=W1DFK0wawwM</link>
      <description>Choosing the right UI framework in .NET can be daunting with options like .NET MAUI, Uno Platform, Blazor Hybrid, and many more. Each framework offers unique strengths; the optimal choice depends on your project goals. We&amp;#39;ll use https://devtoys.app as a case study to explore these frameworks.

Featuring: Etienne Baudoux

Connect with .NET: 
Blog:  https://aka.ms/dotnet/blog
Twitter: https://aka.ms/dotnet/twitter
TikTok:  https://aka.ms/dotnet/tiktok
Mastodon:  https://aka.ms/dotnet/mastodon
LinkedIn:  https://aka.ms/dotnet/linkedin
Facebook:  https://aka.ms/dotnet/facebook
Docs: https://learn.microsoft.com/dotnet
Forums: https://aka.ms/dotnet/forums
&amp;#128587;‍♀️Q&amp;amp;A: https://aka.ms/dotnet-qa
&amp;#128104;‍&amp;#127891;Microsoft Learn: https://aka.ms/learndotnet

#dotnet</description>
      <author> (dotnet)</author>
      <guid>https://youtube.com/watch?v=W1DFK0wawwM</guid>
      <pubDate>Fri, 15 Nov 2024 20:01:44 GMT</pubDate>
    </item>
    <item>
      <title>Deep dive on native AOT</title>
      <link>https://youtube.com/watch?v=Gmn-4mVSjq4</link>
      <description>Native AOT has been part of .NET since .NET 7. With each release we&amp;#39;re extending the areas where it can be used. From console apps in .NET 7, through ASP.NET web APIs in .NET 8, to MAUI in .NET 9. It is your best bet if you need your .NET app to start fast and use as little memory as possible.

But how does native AOT actually work? Why does it start so fast? How can we fit an entire .NET runtime, the base class libraries, and your code in a 1 MB executable file?

In this talk we&amp;#39;ll peek into the internal workings of native AOT compilation and look at what it does at run time.

Featuring: Michal Strehovsk&amp;#253;

Connect with .NET: 
Blog:  https://aka.ms/dotnet/blog
Twitter: https://aka.ms/dotnet/twitter
TikTok:  https://aka.ms/dotnet/tiktok
Mastodon:  https://aka.ms/dotnet/mastodon
LinkedIn:  https://aka.ms/dotnet/linkedin
Facebook:  https://aka.ms/dotnet/facebook
Docs: https://learn.microsoft.com/dotnet
Forums: https://aka.ms/dotnet/forums
&amp;#128587;‍♀️Q&amp;amp;A: https://aka.ms/dotnet-qa
&amp;#128104;‍&amp;#127891;Microsoft Learn: https://aka.ms/learndotnet

#dotnet #dotnetconf #dotnet9</description>
      <author> (dotnet)</author>
      <guid>https://youtube.com/watch?v=Gmn-4mVSjq4</guid>
      <pubDate>Fri, 15 Nov 2024 19:01:29 GMT</pubDate>
    </item>
    <item>
      <title>The Future of Orion</title>
      <link>https://xkcd.com/3012/</link>
      <description></description>
      <author> ()</author>
      <guid>https://xkcd.com/3012/</guid>
      <pubDate>Fri, 15 Nov 2024 18:01:38 GMT</pubDate>
    </item>
  </channel>
</rss>