<?xml version="1.0" encoding="utf-16"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <atom:link rel="self" type="application/rss+xml" href="https://linksfor.dev/" />
    <title>linksfor.dev(s)</title>
    <link>https://linksfor.dev/</link>
    <description>Curated links for devs</description>
    <language>en</language>
    <item>
      <title>GUIDs are globally unique, but substrings of GUIDs aren't | The Old New Thing</title>
      <link>https://devblogs.microsoft.com/oldnewthing/20080627-00/?p=21823</link>
      <description>A customer needed to generate an 8-byte unique value, and their initial idea was to generate a GUID and throw away the second half, keeping the first eight bytes. They wanted to know if this was a good idea. No, it’s not a good idea.</description>
      <author> (Raymond Chen  Follow)</author>
      <guid>https://devblogs.microsoft.com/oldnewthing/20080627-00/?p=21823</guid>
      <pubDate>Fri, 21 Aug 2020 17:03:35 GMT</pubDate>
    </item>
    <item>
      <title>Introducing the new Azure SDKs</title>
      <link>https://www.youtube.com/watch?v=38RYIx7a2M4</link>
      <description>Azure SDK Website: https://aka.ms/azsdk
Azure SDK Twitter: https://twitter.com/@AzureSDK
Azure SDK Blog: https://aka.ms/azsdk/blog
Azure SDK Releases: https://aka.ms/azsdk/releases
Azure SDK Guidelines: https://aka.ms/azsdk/guide
Azure SDK Code: https://aka.ms/azsdk/github
Azure SDK Intro Video: https://aka.ms/azsdk/intro
Azure SDK Intro Video Deck: https://aka.ms/azsdk/intro/deck

Introducing the new Azure SDKs

Before we introduced the new Azure SDKs in July of 2019, each Azure Service team independently created their own SDKs in disparate repositories, had their own CI process, and had varying levels of authentication, language, OS, and package support.  

With the new Azure SDKs we have established a set of common design guidelines, a centralized engineering system, centralized open-source repositories, as well as consistent authentication, language, and OS support. We also deliver packages to the most popular package managers for each language.

We currently provide libraries in .NET, Java, Python, and JavaScript/TypeScript with more languages coming soon. 

https://aka.ms/azsdk will lead you to the Azure SDK website, which a great landing spot with links to our packages, guidelines, documentation, and blog.

Developer productivity is the primary driver for the new Azure SDK effort.

We know that you will be most productive when your experience feels natural for whatever language you code in and when you can easily download the libraries from package managers that you use every day.

Consistency is also key, with the new Azure SDKs, navigating amongst the services doesn’t require you to learn a new API paradigm.  

Being approachable, diagnosable, and dependable are all pillars that go into building libraries, so we are investing heavily in these areas as well. Including ramping up our documentation efforts, integrating with standard logging frameworks, and holding API board reviews for all new libraries.

You can find all these guidelines detailed at https://aka.ms/azsdk/guide. We’ll continue to evolve these guidelines, so please review them, and provide us with feedback or suggestions via GitHub

We released our first GA libraries in the fall of 2019 and continue to release monthly.  

In GA, we currently have Storage, Key Vault, Event Hubs, App Config, Cosmos for JavaScript/TypeScript, Python and Java. Cognitive Services Text Analytics. Azure.Identity and Azure.Core which implement a consistent authentication and request/response pipeline for all libraries.


And in Preview, we have Cosmos for .NET. Cognitive Services Form Recognizer, Cognitive Search, Service Bus, and the Azure SDK for Embedded C

We’ll eventually GA libraries for all Azure services, but next up on the list is Tables, Cognitive services Anomaly Detector, Azure Synapse Analytics, and the new Resource Management libraries.

You can find the full list of libraries with links to packages, code, and docs at https://aka.ms/azsdk/releases. 

You can find the code for all the new Azure SDKs at https://aka.ms/azsdk/github. That will take you to our central repo which has links to all the other language specific repos and houses our common design guidelines. It’s a great place to file architecture board suggestions and questions or issues that cut across all the SDKs. The overriding theme here is everything in the open on GitHub, with an engaged engineering team to help you through any issues you discover as you build your Azure solutions.


We’d like to encourage you to start using the new Azure SDKs and contributing to them by submitting issues or pull-requests on GitHub. You can follow us on Twitter https://twitter.com/@AzureSDK and subscribe to our blog at https://aka.ms/azsdk/blog.</description>
      <author> (Jon Gallant)</author>
      <guid>https://www.youtube.com/watch?v=38RYIx7a2M4</guid>
      <pubDate>Fri, 21 Aug 2020 16:03:46 GMT</pubDate>
    </item>
    <item>
      <title>Azure SDK Latest Releases | Azure SDKs</title>
      <link>https://azure.github.io/azure-sdk/</link>
      <description />
      <author> ()</author>
      <guid>https://azure.github.io/azure-sdk/</guid>
      <pubDate>Fri, 21 Aug 2020 16:03:45 GMT</pubDate>
    </item>
    <item>
      <title>Approximate results may vary</title>
      <link>https://ericlippert.com/2020/08/21/approximate-results-may-vary/</link>
      <description>Part 33 of my ongoing series is coming but I did not get all the code written that I wanted to this week, so it will be delayed. In the meanwhile: Living in Canada as a child, of course I grew up l…</description>
      <author> ()</author>
      <guid>https://ericlippert.com/2020/08/21/approximate-results-may-vary/</guid>
      <pubDate>Fri, 21 Aug 2020 16:03:43 GMT</pubDate>
    </item>
    <item>
      <title>reMarkable microSD</title>
      <link>http://www.davisr.me/projects/remarkable-microsd/</link>
      <description>This page discusses how I added a microSD card to my reMarkable tablet. I did this because I want to develop software for my rM without wearing out the internal eMMC. I chose an external card because I want to be able to swap them easily; it also makes backups faster.</description>
      <author> ()</author>
      <guid>http://www.davisr.me/projects/remarkable-microsd/</guid>
      <pubDate>Fri, 21 Aug 2020 16:03:41 GMT</pubDate>
    </item>
    <item>
      <title>The Brussels Choice - Numberphile</title>
      <link>https://www.youtube.com/watch?v=AeqK96UX3rA</link>
      <description>Neil Sloane from the OEIS discusses the Choix de Bruxelles.
Check out Brilliant (get 20% off their premium service): https://brilliant.org/numberphile (sponsor)

More links &amp; stuff in full description below ↓↓↓ 

Neil Sloane founded the runs the OEIS: https://oeis.org/
Brussels Choice on the OEIS: https://oeis.org/A323454
Neil Sloane playlist on Numberphile: http://bit.ly/Sloane_Numberphile
Neil Sloane on the Numberphile podcast: https://youtu.be/mNk_MfFKnuY

Numberphile is supported by the Mathematical Sciences Research Institute (MSRI): http://bit.ly/MSRINumberphile

We are also supported by Science Sandbox, a Simons Foundation initiative dedicated to engaging everyone with the process of science. https://www.simonsfoundation.org/outreach/science-sandbox/

And support from Math For America - https://www.mathforamerica.org/

NUMBERPHILE
Website: http://www.numberphile.com/
Numberphile on Facebook: http://www.facebook.com/numberphile
Numberphile tweets: https://twitter.com/numberphile
Subscribe: http://bit.ly/Numberphile_Sub

Video by Brady Haran and Pete McPartlan

Patreon: http://www.patreon.com/numberphile

Numberphile T-Shirts and Merch: https://teespring.com/stores/numberphile

Brady's videos subreddit: http://www.reddit.com/r/BradyHaran/

Brady's latest videos across all channels: http://www.bradyharanblog.com/

Sign up for (occasional) emails: http://eepurl.com/YdjL9</description>
      <author> (Numberphile)</author>
      <guid>https://www.youtube.com/watch?v=AeqK96UX3rA</guid>
      <pubDate>Fri, 21 Aug 2020 15:03:41 GMT</pubDate>
    </item>
    <item>
      <title>First thoughts on Rust vs OCaml</title>
      <link>https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/</link>
      <description>I'm about two weeks into Rust now, so this feels like a good time to write a critique, before I get Stockholm Syndrome'd. My main motivation in learning Rust is that I have to maintain some of Dark's Rust code. There was a recent outage related to that code, and</description>
      <author> (Paul Biggar)</author>
      <guid>https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/</guid>
      <pubDate>Fri, 21 Aug 2020 15:03:40 GMT</pubDate>
    </item>
    <item>
      <title>Chromium’s impact on root DNS traffic | APNIC Blog</title>
      <link>https://blog.apnic.net/2020/08/21/chromiums-impact-on-root-dns-traffic/</link>
      <description>Guest Post: With 70% of market share, Chromium has had a significant impact on the total root DNS traffic.</description>
      <author> (Geoff Huston)</author>
      <guid>https://blog.apnic.net/2020/08/21/chromiums-impact-on-root-dns-traffic/</guid>
      <pubDate>Fri, 21 Aug 2020 14:03:55 GMT</pubDate>
    </item>
    <item>
      <title>Why Did Mozilla Remove XUL Add-ons?</title>
      <link>https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/</link>
      <description>During the past few days, I&amp;rsquo;ve been chatting with Firefox users, trying to separate fact from rumor regarding the consequences of the August 2020 Mozilla layoffs. One of the topics that came back a few times was the removal of XUL-based add-ons during the move to Firefox Quantum. I was very surprised to see that, years after it happened, some community members still felt hurt by this choice.
And then, as someone pointed out on reddit, I realized that we still haven&amp;rsquo;t taken the time to explain in-depth why we had no choice but to remove XUL-based add-ons.
So, if you&amp;rsquo;re ready for a dive into some of the internals of add-ons and Gecko, I&amp;rsquo;d like to take this opportunity to try and give you a bit more detail.
</description>
      <author> (David Teller)</author>
      <guid>https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/</guid>
      <pubDate>Fri, 21 Aug 2020 12:03:39 GMT</pubDate>
    </item>
    <item>
      <title>Weekly Update 204</title>
      <link>https://www.youtube.com/watch?v=CItROiNKnn0&amp;hss_channel=tw-2925438791</link>
      <description></description>
      <author> (Troy Hunt)</author>
      <guid>https://www.youtube.com/watch?v=CItROiNKnn0&amp;hss_channel=tw-2925438791</guid>
      <pubDate>Fri, 21 Aug 2020 11:03:49 GMT</pubDate>
    </item>
    <item>
      <title>Fullstack Vulnerability Management | Cyber Attack Prevention</title>
      <link>https://www.edgescan.com/</link>
      <description>edgescan Fullstack Vulnerability Management™. Award winning &amp; internationally accredited cyber attack prevention. Continuous security testing.</description>
      <author> ()</author>
      <guid>https://www.edgescan.com/</guid>
      <pubDate>Fri, 21 Aug 2020 11:03:48 GMT</pubDate>
    </item>
    <item>
      <title>https://media.defense.gov/2020/Aug/13/2002476465/-1/-1/0/CSA_DROVORUB_RUSSIAN_GRU_MALWARE_AUG_2020.PDF</title>
      <link>https://media.defense.gov/2020/Aug/13/2002476465/-1/-1/0/CSA_DROVORUB_RUSSIAN_GRU_MALWARE_AUG_2020.PDF</link>
      <description />
      <author> ()</author>
      <guid>https://media.defense.gov/2020/Aug/13/2002476465/-1/-1/0/CSA_DROVORUB_RUSSIAN_GRU_MALWARE_AUG_2020.PDF</guid>
      <pubDate>Fri, 21 Aug 2020 10:03:39 GMT</pubDate>
    </item>
    <item>
      <title>Building a Second Brain: The Illustrated Notes</title>
      <link>https://maggieappleton.com/basb/</link>
      <description>Maggie Appleton is an art director, anthropologist, and metaphor-making illustrator. This is her digital garden for growing visual explanations about technology, culture, and programming</description>
      <author> ()</author>
      <guid>https://maggieappleton.com/basb/</guid>
      <pubDate>Fri, 21 Aug 2020 06:15:04 GMT</pubDate>
    </item>
    <item>
      <title>Building a Second Brain</title>
      <link>https://www.buildingasecondbrain.com/</link>
      <description>An online bootcamp on leveraging digital tools to enhance your creativity, productivity, and learning, by Tiago Forte</description>
      <author> ()</author>
      <guid>https://www.buildingasecondbrain.com/</guid>
      <pubDate>Fri, 21 Aug 2020 06:07:23 GMT</pubDate>
    </item>
    <item>
      <title>Lightroom App Update Wipes Users' Photos and Presets, Adobe Says they are 'Not Recoverable'</title>
      <link>https://petapixel.com/2020/08/20/lightroom-app-update-wipes-users-photos-and-presets-adobe-says-they-are-not-recoverable/</link>
      <description>This morning, multiple readers wrote in to alert us to a major Adobe gaff. It seems the latest update to the Lightroom app for iPhone and iPad</description>
      <author> ()</author>
      <guid>https://petapixel.com/2020/08/20/lightroom-app-update-wipes-users-photos-and-presets-adobe-says-they-are-not-recoverable/</guid>
      <pubDate>Fri, 21 Aug 2020 06:03:54 GMT</pubDate>
    </item>
    <item>
      <title>Development quotes of the week [LWN.net]</title>
      <link>https://lwn.net/Articles/829123/</link>
      <description>Posted Aug 19, 2020 22:57 UTC (Wed) by flussence (subscriber, #85566)
         In reply to: Development quotes of the week by mathstuf
        Parent article: Development quotes of the week</description>
      <author> ()</author>
      <guid>https://lwn.net/Articles/829123/</guid>
      <pubDate>Fri, 21 Aug 2020 06:03:44 GMT</pubDate>
    </item>
    <item>
      <title>How Shopify Reduced Storefront Response Times with a Rewrite</title>
      <link>https://engineering.shopify.com/blogs/engineering/how-shopify-reduced-storefront-response-times-rewrite</link>
      <description>In January 2019, we set out to rewrite the critical software that powers all online storefronts on Shopify’s platform to offer the fastest online shopping experience possible, entirely from scratch and without downtime.
The Storefront Renderer is a server-side application that loads a Shopify merchant's storefront Liquid theme, along with the data required to serve the request (for example product data, collection data, inventory information, and images), and returns the HTML response back to your browser. Shaving milliseconds off response time leads to big results for merchants on the platform as buyers increasingly expect pages to load quickly, and failing to deliver on performance can hinder sales, not to mention other important signals like SEO.
The previous storefront implementation‘s development, started over 15 years ago when Tobi launched Snowdevil, lived within Shopify’s Ruby on Rails monolith. Over the years, we realized that the “storefront” part of Shopify is quite different from the other parts of the monolith: it has much stricter performance requirements and can accept more complexity implementation-wise to improve performance, whereas other components (such as payment processing) need to favour correctness and readability.
In addition to this difference in paradigm, storefront requests progressively became slower to compute as we saw more storefront traffic on the platform. This performance decline led to a direct impact on our merchant storefronts’ performance, where time-to-first-byte metrics from Shopify servers slowly crept up as time went on.
Here’s how the previous architecture looked:
Old Storefront Implementation 
Before, the Rails monolith handled almost all kinds of traffic: checkout, admin, APIs, and storefront.
With the new implementation, traffic routing looks like this:
New Storefront Implementation 
The Rails monolith still handles checkout, admin, and API traffic, but storefront traffic is handled by the new implementation.
Designing the new storefront implementation from the ground up allowed us to think about the guarantees we could provide: we took the opportunity of this evergreen project to set us up on strong primitives that can be extended in the future, which would have been much more difficult to retrofit in the legacy implementation. An example of these foundations is the decision to design the new implementation on top of an active-active replication setup. As a result, the new implementation always reads from dedicated read replicas, improving performance and reducing load on the primary writers.
Similarly, by rebuilding and extracting the storefront-related code in a dedicated application, we took the opportunity to think about building the best developer experience possible: great debugging tools, simple onboarding setup, welcoming documentation, and so on.
Finally, with improving performance as a priority, we work to increase resilience and capacity in high load scenarios (think flash sales: events where a large number of buyers suddenly start shopping on a specific online storefront), and invest in the future of storefront development at Shopify. The end result is a fast, resilient, single-purpose application that serves high-throughput online storefront traffic for merchants on the Shopify platform as quickly as possible.
Defining Our Success Criteria
Once we clearly outlined the problem we’re trying to solve and scoped out the project, we defined three main success criteria:


Establishing feature parity: for a given input, both implementations generate the same output.

Improving performance: the new implementation runs on active-active replication setup and minimizes server response times.

Improving resilience and capacity: in high-load scenarios, the new implementation generally sustains traffic without causing errors.

Building A Verifier Mechanism
Before building the new implementation, we needed a way to make sure that whatever we built would behave the same way as the existing implementation. So, we built a verifier mechanism that compares the output of both implementations and returns a positive or negative result depending on the outcome of the comparison.
This verification mechanism runs on storefront traffic in production, and it keeps track of verification results so we can identify differences in output that need fixing. Running the verifier mechanism on production traffic (in addition to comparing the implementations locally through a formal specification and a test suite) lets us identify the most impactful areas to work on when fixing issues, and keeps us focused on the prize: reaching feature parity as quickly as possible. It’s desirable for multiple reasons:

giving us an idea of progress and spreading the risk over a large amount of time
shortening the period of time that developers at Shopify work with two concurrent implementations at once
providing value to Shopify merchants as soon as possible.

There are two parts to the entire verifier mechanism implementation:

A verifier service (implemented in Ruby) compares the two responses we provide and returns a positive or negative result depending on the verification outcome. Similar to a `diff` tool, it lets us identify differences between the new and legacy implementations.
A custom nginx routing module (implemented in Lua on top of OpenResty) sends a sample of production traffic to the verifier service for verification. This module acts as a router depending on the result of the verifications for subsequent requests.

The following diagram shows how each part interacts with the rest of the architecture:
Legacy implementation and new implementation at the same conceptual layer
The legacy implementation (the Rails monolith) still exists, and the new implementation (including the Verifier service) is introduced at the same conceptual layer. Both implementations are placed behind a custom routing module that decides where to route traffic based on the request attributes and the verification data for this request type. Let’s look at an example.
When a buyer’s device sends an initial request for a given storefront page (for example, a product page from shop XYZ), the request is sent to Shopify’s infrastructure, at which point an nginx instance handles it. The routing module considers the request attributes to determine if other shop XYZ product page requests have previously passed verification.
First request routed to Legacy implementation
Since this is the first request of this kind in our example, the routing module sends the request to the legacy implementation to get a baseline reference that it will use for subsequent shop XYZ product page requests.
Routing module sends original request and legacy implementation’s response to the new implementation
Once the response comes back from the legacy implementation, the Lua routing module sends that response to the buyer. In the background, the Lua routing module also sends both the original request and the legacy implementation’s response to the new implementation. The new implementation computes a response to the original request and feeds both its response and the forwarded legacy implementation’s response to the verifier service. This is done asynchronously to make sure we’re not adding latency to responses we send to buyers, who don’t notice anything different.
At this point, the verifier service received the responses from both the legacy and new implementations and is ready to compare them. Of course, the legacy implementation is assumed to be correct as it’s been running in production for years now (it acts as our reference point). We keep track of differences between the two implementations’ responses so we can debug and fix them later. The verifier service looks at both responses’ status code, headers, and body, ensuring they’re equivalent. This lets us identify any differences in the responses so we make sure our new implementation behaves like the legacy one.
Time-related and randomness-related exceptions make it impossible to have exactly byte-equal responses, so we ignore certain patterns in the verifier service to relax the equivalence criteria. The verifier service uses a fixed time value during the comparison process and sets any random values to a known value so we reliably compare the outputs containing time-based and randomness-based differences.
The verifier service sends comparison result back to the Lua module
The verifier service sends the outcome of the comparison back to the Lua module, which keeps track of that comparison outcome for subsequent requests of the same kind.
Dynamically Routing Requests To the New Implementation
Once we had verified our new approach, we tested rendering a page using the new implementation instead of the legacy one. We iterated upon our verification mechanism to allow us to route traffic to the new implementation after a given number of successful verifications. Here’s how it works.
Just like when we only verified traffic, a request arrives from a client device and hits Shopify’s architecture. The request is sent to both implementations, and both outputs are forwarded to the verifier service for comparison. The comparison result is sent back to the Lua routing module, which keeps track of it for future requests.
When a subsequent storefront request arrives from a buyer and reaches the Lua routing module, it decides where to send it based on the previous verification results for requests similar to the current one (based on the request attributes
For subsequent storefront requests, the Lua routing module decides where to send it
If the request was verified multiple times in the past, and nearly all outcomes from the verifier service were “Pass”, then we consider the request safe to be served by the new implementation.
If most verifier service results are “Pass”, then it uses the new implementation
If, on the other hand, some verifications failed for this kind of request, we’ll play it safe and send the request to the legacy implementation.
If most verifier service results are “Fail”, then it uses the old implementation
Successfully Rendering In Production
With the verifier mechanism and the dynamic router in place, our first goal was to render one of the simplest storefront pages that exists on the Shopify platform: the password page that protects a storefront before the merchant makes it available to the public.
Once we reached full parity for a single shop’s password page, we tested our implementation in production (for the first time) by routing traffic for this password page to the new implementation for a couple of minutes to test it out.
Success! The new implementation worked in production. It was time to start implementing everything else.
Increasing Feature Parity
After our success with the password page, we tackled the most frequently accessed storefront pages on the platform (product pages, collection pages, etc). Diff by diff, endpoint by endpoint, we slowly increased the parity rate between the legacy and new implementations.
Having both implementations running at the same time gave us a safety net to work with so that if we introduced a regression, requests would easily be routed to the legacy implementation instead. Conversely, whenever we shipped a change to the new implementation that would fix a gap in feature parity, the verifier service starts to report verification successes, and our custom routing module in nginx automatically starts sending traffic to the new implementation after a predetermined time threshold.
Defining “Good” Performance with Apdex Scores
We collected Apdex (Application Performance Index) scores on server-side processing time for both the new and legacy implementations to compare them.
To calculate Apdex scores, we defined a parameter for a satisfactory threshold response time (this is the Apdex’s “T” parameter). Our threshold response time to define a frustrating experience would then be “above 4T” (defined by Apdex).
We defined our “T” parameter as 200ms, which lines up with Google’s PageSpeed Insights recommendation for server response times. We consider server processing time below 200ms as satisfying and a server processing time of 800ms or more as frustrating. Anything in between is tolerated.
From there, calculating the Apdex score for a given implementation consists of setting a time frame, and counting three values:

N, the total number of responses in the defined time frame
S, the number of satisfying responses (faster than 200ms) in the time frame
T, the number of tolerated responses (between 200ms and 800ms) in the time frame

Then, we calculate the Apdex score: 

$$\frac{s + t/2}{n}$$
By calculating Apdex scores for both the legacy and new implementations using the same T parameter, we had common ground to compare their performance.
Methods to Improve Server-side Storefront Performance
We want all Shopify storefronts to be fast, and this new implementation aims to speed up what a performance-conscious theme developer can’t by optimizing data access patterns, reducing memory allocations, and implementing efficient caching layers.
Optimizing Data Access Patterns
The new implementation uses optimized, handcrafted SQL multi-select statements maximizing the amount of data transferred in a single round trip. We carefully vet what we eager-load depending on the type of request and we optimize towards reducing instances of N+1 queries.
Reducing Memory Allocations
We reduce the number of memory allocations as much as possible so Ruby spends less time in garbage collection. We use methods that apply modifications in place (such as #map!) rather than those that allocate more memory space (like #map). This kind of performance-oriented Ruby paradigm sometimes leads to code that’s not as simple as idiomatic Ruby, but paired with proper testing and verification, this tradeoff provides big performance gains. It may not seem like much, but those memory allocations add up quickly, and considering the amount of storefront traffic Shopify handles, every optimization counts.
Implementing Efficient Caching Layers
We implemented various layers of caching throughout the application to reduce expensive calls. Frequent database queries are partitioned and cached to optimize for subsequent reads in a key-value store, and in the case of extremely frequent queries, those are cached directly in application memory to reduce I/O latency. Finally, the results of full page renders are cached too, so we can simply serve a full HTTP response directly from cache if possible.
Measuring Performance Improvement Successes
Once we could measure the performance of both implementations and reach a high enough level of verified feature parity, we started migrating merchant shops. Here are some of the improvements we’re seeing with our new implementation:

Across all shops, average server response times for requests served by the new implementation are 4x to 6x faster than the legacy implementation. This is huge!
When migrating a storefront to the new implementation, we see that the Apdex score for server-side processing time improves by +0.11 on average.
When only considering cache misses (requests that can’t be served directly from the cache and need to be computed from scratch), the new implementation increases the Apdex score for server-side processing time by a full +0.20 on average compared to the previous implementation.
We heard back from merchants mentioning a 500ms improvement in time-to-first-byte metrics when the new implementation was rolled out to their storefront.

So another success! We improved store performance in production.
Now how do we make sure this translates to our third success criteria?
Improving Resilience and Capacity
While working on the new implementation, the Verifier service identified potential parity gaps, which helped tremendously. However, a few times we shipped code to production that broke in exceedingly rare edge cases that it couldn’t catch.
As a safety mechanism, we made it so that whenever the new implementation would fail to successfully render a given request, we’d fall back to the legacy implementation. The response would be slower, but at least it was working properly. We used circuit breakers in our custom nginx routing module so that we’d open the circuit and start sending traffic to the legacy implementation if the new implementation was having trouble responding successfully. Read more on tuning circuit breakers in this blog post by my teammate Damian Polan.
Increase Capacity in High-load Scenarios
To ensure that the new implementation responds well to flash sales, we implemented and tweaked two mechanisms. The first one is an automatic scaling mechanism that adds or remove computing capacity in response to the amount of load on the current swarm of computers that serve traffic. If load increases as a result of an increase in traffic, the autoscaler will detect this increase and start provisioning more compute capacity to handle it.
Additionally, we introduced in-memory cache to reduce load on external data stores for storefronts that put a lot of pressure on the platform’s resources. This provides a buffer that reduces load on very-high traffic shops.
Failing Fast
When an external data store isn’t available, we don’t want to serve buyers an error page. If possible, we’ll try to gracefully fall back to a safe way to serve the request. It may not be as fast, or as complete as a normal, healthy response, but it’s definitely better than serving a sad error page.
We implemented circuit breakers on external datastores using Semian, a Shopify-developed Ruby gem that controls access to slow or unresponsive external services, avoiding cascading failures and making the new implementation more resilient to failure.
Similarly, if a cache store isn’t available, we’ll quickly consider the timeout as a cache miss, so instead of failing the entire request because the cache store wasn’t available, we’ll simply fetch the data from the canonical data store instead. It may take longer, but at least there’s a successful response to serve back to the buyer.
Testing Failure Scenarios and the Limits of the New Implementation
Finally, as a way to identify potential resilience issues, the new implementation uses Toxiproxy to generate test cases where various resources are made available or not, on demand, to generate problematic scenarios.
As we put these resilience and capacity mechanisms in place, we regularly ran load tests using internal tooling to see how the new implementation behaves in the face of a large amount of traffic. As time went on, we increased the new implementation’s resilience and capacity significantly, removing errors and exceptions almost completely even in high-load scenarios. With BFCM 2020 coming soon (which we consider as an organic, large-scale load test), we’re excited to see how the new implementation behaves.
Where We’re at Currently
We’re currently in the process of rolling out the new implementation to all online storefronts on the platform. This process happens automatically, without the need for any intervention from Shopify merchants. While we do this, we’re adding more features to the new implementation to bring it to full parity with the legacy implementation. The new implementation is currently at 90%+ feature parity with the legacy one, and we’re increasing that figure every day with the goal of reaching 100% parity to retire the legacy implementation.
As we roll out the new implementation to storefronts we are continuing to see and measure performance improvements as well. On average, server response times for the new implementation are 4x faster than the legacy implementation. Rhone Apparel, a Shopify Plus merchant, started using the new implementation in April 2020 and saw dramatic improvements in server-side performance over the previous month.
We learned a lot during the process of rewriting this critical piece of software. The strong foundations of this new implementation make it possible to deploy it around the world, closer to buyers everywhere, to reduce network latency involved in cross-continental networking, and we continue to explore ways to make it even faster while providing the best developer experience possible to set us up for the future.

We're always on the lookout for talent and we’d love to hear from you. Visit our Engineering career page to find out about our open positions.</description>
      <author> (Maxime Vaillancourt)</author>
      <guid>https://engineering.shopify.com/blogs/engineering/how-shopify-reduced-storefront-response-times-rewrite</guid>
      <pubDate>Fri, 21 Aug 2020 06:03:41 GMT</pubDate>
    </item>
    <item>
      <title>Upgrade to .NET 5 by davidfowl · Pull Request #96 · davidfowl/BedrockFramework</title>
      <link>https://github.com/davidfowl/BedrockFramework/pull/96/files</link>
      <description />
      <author> (davidfowl)</author>
      <guid>https://github.com/davidfowl/BedrockFramework/pull/96/files</guid>
      <pubDate>Fri, 21 Aug 2020 05:03:44 GMT</pubDate>
    </item>
    <item>
      <title>Guess a GUID</title>
      <link>http://guessaguid.secretgeek.net/</link>
      <description>Guess A Guid. The fun guid guessing game.</description>
      <author> ()</author>
      <guid>http://guessaguid.secretgeek.net/</guid>
      <pubDate>Fri, 21 Aug 2020 05:03:41 GMT</pubDate>
    </item>
    <item>
      <title>WSL 2 Support is coming to Windows 10 Versions 1903 and 1909 | Windows Command Line</title>
      <link>https://devblogs.microsoft.com/commandline/wsl-2-support-is-coming-to-windows-10-versions-1903-and-1909/</link>
      <description>Support for Windows Subsystem for Linux (WSL) 2 distros is being backported to Windows 10 version 1903, and 1909!</description>
      <author> (Tyler Citrin Program Manager Follow)</author>
      <guid>https://devblogs.microsoft.com/commandline/wsl-2-support-is-coming-to-windows-10-versions-1903-and-1909/</guid>
      <pubDate>Fri, 21 Aug 2020 02:03:37 GMT</pubDate>
    </item>
    <item>
      <title>Docker Desktop &amp; WSL 2 - Backport Update - Docker Blog</title>
      <link>https://www.docker.com/blog/docker-desktop-wsl-2-backport-update/</link>
      <description>Learn from Docker experts to simplify and advance your app development and management with Docker. Stay up to date on Docker events and new version announcements!</description>
      <author> ()</author>
      <guid>https://www.docker.com/blog/docker-desktop-wsl-2-backport-update/</guid>
      <pubDate>Fri, 21 Aug 2020 01:03:42 GMT</pubDate>
    </item>
    <item>
      <title>Why Sudan's Remarkable Ancient Civilization Has Been Overlooked by History</title>
      <link>https://www.smithsonianmag.com/travel/sudan-land-kush-meroe-ancient-civilization-overlooked-180975498/</link>
      <description>The African nation's pyramids and other archaeological sites are only now emerging from the shadow of its more storied neighbor to the north</description>
      <author> (Isma'il Kushkush,Matt Stirn)</author>
      <guid>https://www.smithsonianmag.com/travel/sudan-land-kush-meroe-ancient-civilization-overlooked-180975498/</guid>
      <pubDate>Fri, 21 Aug 2020 00:03:52 GMT</pubDate>
    </item>
    <item>
      <title>Add enhancement to default behavior of client reconnection by barahonajm · Pull Request #24992 · dotnet/aspnetcore</title>
      <link>https://github.com/dotnet/aspnetcore/pull/24992</link>
      <description>Summary
These changes are to improve the default reconnection behavior of the client

 Match the reconnection time with server side
 Add indicator to know at which reconnection attempt we currently...</description>
      <author> (dotnet)</author>
      <guid>https://github.com/dotnet/aspnetcore/pull/24992</guid>
      <pubDate>Thu, 20 Aug 2020 22:03:45 GMT</pubDate>
    </item>
    <item>
      <title>The Temporality of Media</title>
      <link>https://snufk.in/blog/temporality.html</link>
      <description>&lt;p&gt;Temporality is a bit of a contentious topic, here I will explore the idea that temporality in the media we consume is key.&lt;/p&gt;</description>
      <author> ()</author>
      <guid>https://snufk.in/blog/temporality.html</guid>
      <pubDate>Thu, 20 Aug 2020 21:04:32 GMT</pubDate>
    </item>
    <item>
      <title>Who to ignore (3 bullshit filters)</title>
      <link>https://ernest.oppet.it/2020/08/14/who-to-ignore/</link>
      <description>By Gabriel and Ernest Oppetit Unforseen shit happens. 9/11, the 2008 crash, Brexit, Trump, COVID-19… you know the story.  These events surprised us because our information diets are domi…</description>
      <author> (Ernest Oppetit)</author>
      <guid>https://ernest.oppet.it/2020/08/14/who-to-ignore/</guid>
      <pubDate>Thu, 20 Aug 2020 21:04:27 GMT</pubDate>
    </item>
    <item>
      <title>The Ebb and the Flow of Product Development</title>
      <link>https://giansegato.com/essays/the-ebb-and-the-flow-of-product-development/</link>
      <description>Founders want speed. Devs want careful planning. The tension can be looked as a variation of the exploration-exploitation trade-off, and its mathematical solution shows an Ebb and a Flow of Product Development in early stage startups.</description>
      <author> (https://giansegato.com/about/)</author>
      <guid>https://giansegato.com/essays/the-ebb-and-the-flow-of-product-development/</guid>
      <pubDate>Thu, 20 Aug 2020 21:04:25 GMT</pubDate>
    </item>
    <item>
      <title>Is Sapiens Worth Reading? — mattswain.co.uk</title>
      <link>https://www.mattswain.co.uk/blog/is-sapiens-worth-reading</link>
      <description>Pretty much everyone recommends reading Sapiens: A Brief History of Humankind. Tim Ferris's podcast interviewee's often say that Sapiens is the book they gift the most and Amazon's 20,000 ratings give it 4.6 stars. But, with over 400 pages of dense content, is it actually worth reading? Or is it jus</description>
      <author> (Aug 20
            
            Written By Matt S)</author>
      <guid>https://www.mattswain.co.uk/blog/is-sapiens-worth-reading</guid>
      <pubDate>Thu, 20 Aug 2020 21:04:21 GMT</pubDate>
    </item>
    <item>
      <title>How to Initiate Contact With a Mentor | Daniel Miessler</title>
      <link>https://danielmiessler.com/blog/how-to-initiate-first-contact-with-a-mentor/</link>
      <description>I’ve been in security for over 20 years now and have received thousands of emails asking for help or mentorship. And throughout that time I’ve also</description>
      <author> ()</author>
      <guid>https://danielmiessler.com/blog/how-to-initiate-first-contact-with-a-mentor/</guid>
      <pubDate>Thu, 20 Aug 2020 21:04:18 GMT</pubDate>
    </item>
    <item>
      <title>Angel Investing: Check Sizes</title>
      <link>http://ilya.sukhar.com/blog/angel-investing-check-sizes.html</link>
      <description>If I were to go back in time and give myself advice on starting out as an angel investor, perhaps the first thing I’d say is: “pick a check size and stick with it.”</description>
      <author> ()</author>
      <guid>http://ilya.sukhar.com/blog/angel-investing-check-sizes.html</guid>
      <pubDate>Thu, 20 Aug 2020 21:04:15 GMT</pubDate>
    </item>
    <item>
      <title>Citibank's $900 Million Blunder</title>
      <link>https://finshots.in/archive/citibank-billion-dollar-blunder/</link>
      <description>An explainer on Citi's $1 billion blunder.</description>
      <author> ()</author>
      <guid>https://finshots.in/archive/citibank-billion-dollar-blunder/</guid>
      <pubDate>Thu, 20 Aug 2020 21:04:13 GMT</pubDate>
    </item>
    <item>
      <title>Transfer a Software Project - Lessons Learned - dcaulfield</title>
      <link>http://www.dcaulfield.com/transfer-a-software-project-lessons-learned/</link>
      <description>Transferring a software project (or indeed any project) to your team from another team is a daunting task. For the purpose of this article, let’s call the giving teams the “Throwers” and the receiving teams the “Catchers”. To transfer a project, the Throwers dump their brains and give their thoughts to the Catchers hoping most …</description>
      <author> (David Caulfield)</author>
      <guid>http://www.dcaulfield.com/transfer-a-software-project-lessons-learned/</guid>
      <pubDate>Thu, 20 Aug 2020 21:04:09 GMT</pubDate>
    </item>
    <item>
      <title>The sandpaper learning method</title>
      <link>https://dangoldin.com/2020/08/18/the-sandpaper-learning-method/</link>
      <description>Rather than jump straight to the answer it's important to struggle so once you get the answer it has a place to nest.</description>
      <author> (Dan Goldin)</author>
      <guid>https://dangoldin.com/2020/08/18/the-sandpaper-learning-method/</guid>
      <pubDate>Thu, 20 Aug 2020 21:04:00 GMT</pubDate>
    </item>
    <item>
      <title>Pascal’s Scam - Second Breakfast</title>
      <link>https://secondbreakfast.co/pascal-s-scam</link>
      <description>Bertrand Russell imagined what he’d say if he found himself on the wrong side of Pascal’s Wager: “But Lord, you did not give us enough evidence!”1</description>
      <author> ()</author>
      <guid>https://secondbreakfast.co/pascal-s-scam</guid>
      <pubDate>Thu, 20 Aug 2020 21:03:57 GMT</pubDate>
    </item>
    <item>
      <title>The Impostor's Advantage</title>
      <link>https://www.zainrizvi.io/blog/the-impostors-advantage/</link>
      <description>My heart was racing. My palms sweating. I was going to be fired. Performance reviews had just ended, and it was time to meet my manager and be told my results. Except I knew what it would say. How else do you rate a programmer who doesn’t code? As</description>
      <author> ()</author>
      <guid>https://www.zainrizvi.io/blog/the-impostors-advantage/</guid>
      <pubDate>Thu, 20 Aug 2020 21:03:55 GMT</pubDate>
    </item>
    <item>
      <title>Announcing TypeScript 4.0 | TypeScript</title>
      <link>https://devblogs.microsoft.com/typescript/announcing-typescript-4-0/</link>
      <description>Today we are thrilled to announce the availability of TypeScript 4.0! This version of the language represents our next generation of TypeScript releases, as we dive deeper into expressivity, productivity, and scalability. If you’re not familiar with TypeScript, it’s a language that builds on top of JavaScript by adding syntax for static types.</description>
      <author> (Daniel Rosenwasser Program Manager, TypeScript Follow)</author>
      <guid>https://devblogs.microsoft.com/typescript/announcing-typescript-4-0/</guid>
      <pubDate>Thu, 20 Aug 2020 20:03:38 GMT</pubDate>
    </item>
    <item>
      <title>Hoppscotch</title>
      <link>https://hoppscotch.io/</link>
      <description>A free, fast and beautiful API request builder</description>
      <author> (liyasthomas)</author>
      <guid>https://hoppscotch.io/</guid>
      <pubDate>Thu, 20 Aug 2020 19:23:25 GMT</pubDate>
    </item>
    <item>
      <title>Rideshare operations are being suspended in California</title>
      <link>https://www.lyft.com/blog/posts/ca-operations-update</link>
      <description>At 11:59PM PT today our rideshare operations in California will be suspended. This is not something we wanted to do, as we know millions of Californians depend on Lyft for daily, essential trips. We’re personally reaching out to riders and drivers to share more about why this is happening, what you can do about it, and to provide some transportation alternatives</description>
      <author> (Lyft, Inc.)</author>
      <guid>https://www.lyft.com/blog/posts/ca-operations-update</guid>
      <pubDate>Thu, 20 Aug 2020 19:03:48 GMT</pubDate>
    </item>
    <item>
      <title>.NET Tooling Community Standup - August 20th 2020 - Chat with the NuGet team!</title>
      <link>https://www.youtube.com/watch?v=fijQkqWssn0</link>
      <description>Come learn about new improvements in NuGet with PMs: Jiachen Jiang and Christopher Gill.

Featuring: Jiachen Jiang, Christopher Gill</description>
      <author> (.NET Foundation)</author>
      <guid>https://www.youtube.com/watch?v=fijQkqWssn0</guid>
      <pubDate>Thu, 20 Aug 2020 18:03:38 GMT</pubDate>
    </item>
  </channel>
</rss>