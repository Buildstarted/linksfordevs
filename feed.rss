<?xml version="1.0" encoding="utf-16"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <atom:link rel="self" type="application/rss+xml" href="https://linksfor.dev/" />
    <title>linksfor.dev(s)</title>
    <link>https://linksfor.dev/</link>
    <description>Curated links for devs</description>
    <language>en</language>
    <item>
      <title>LiveAuctioneers data breach: Millions of cracked passwords for sale, say researchers</title>
      <link>https://portswigger.net/daily-swig/liveauctioneers-data-breach-millions-of-cracked-passwords-for-sale-say-researchers</link>
      <description>Antiques marketplace blames breach on data processing partner LiveAuctioneers, an online antiques marketplace, has revealed that it suffered a data breach that security researchers have claimed includ</description>
      <author> (Adam Bannister
        
    
        
            @Ad_Nauseum74)</author>
      <guid>https://portswigger.net/daily-swig/liveauctioneers-data-breach-millions-of-cracked-passwords-for-sale-say-researchers</guid>
      <pubDate>Sat, 22 Aug 2020 05:03:50 GMT</pubDate>
    </item>
    <item>
      <title>July 11, 2020 - LiveAuctioneers Account Security</title>
      <link>https://help.liveauctioneers.com/article/496-july-11-2020-liveauctioneers-account-security</link>
      <description>Last Update: August 3, 2020 @ 9:55am ET We take the protection of member information very seriously. We are deeply sorry for any concern or inconvenience this m</description>
      <author> (LiveAuctioneers)</author>
      <guid>https://help.liveauctioneers.com/article/496-july-11-2020-liveauctioneers-account-security</guid>
      <pubDate>Sat, 22 Aug 2020 05:03:45 GMT</pubDate>
    </item>
    <item>
      <title>AI Slays Top F-16 Pilot In DARPA Dogfight Simulation</title>
      <link>https://breakingdefense.com/2020/08/ai-slays-top-f-16-pilot-in-darpa-dogfight-simulation/</link>
      <description>"It's a giant leap," said DARPA's Justin (call sign "Glock") Mock.</description>
      <author> (Theresa Hitchens)</author>
      <guid>https://breakingdefense.com/2020/08/ai-slays-top-f-16-pilot-in-darpa-dogfight-simulation/</guid>
      <pubDate>Sat, 22 Aug 2020 04:04:04 GMT</pubDate>
    </item>
    <item>
      <title>.NET Dev Summit 2020 - Virtual Conference - Bengaluru</title>
      <link>https://bdotnet.in/dotnet-dev-summit-2020/</link>
      <description>.NET Dev Summit 2020 is a free, virtual developer conference co-organized by the Bangalore DotNet UG (BDotNet), XHackers Xamarin community and Microsoft | Bengaluru, IN | AUG 29 2020</description>
      <author> ()</author>
      <guid>https://bdotnet.in/dotnet-dev-summit-2020/</guid>
      <pubDate>Sat, 22 Aug 2020 04:03:59 GMT</pubDate>
    </item>
    <item>
      <title>Use Project Tye to simplify your .NET microservice development experience (part 1)</title>
      <link>https://daveabrock.com/2020/08/19/microservices-with-tye-1</link>
      <description>In this post, we explore Project Tye, a new developer tool that simplifies developing .NET microservices and distributed applications.</description>
      <author> (Dave Brock)</author>
      <guid>https://daveabrock.com/2020/08/19/microservices-with-tye-1</guid>
      <pubDate>Sat, 22 Aug 2020 04:03:56 GMT</pubDate>
    </item>
    <item>
      <title>6FigureDev - Twitch</title>
      <link>https://www.twitch.tv/6figuredev</link>
      <description>Twitch is the world's leading video platform and community for gamers.</description>
      <author> ()</author>
      <guid>https://www.twitch.tv/6figuredev</guid>
      <pubDate>Sat, 22 Aug 2020 04:03:53 GMT</pubDate>
    </item>
    <item>
      <title>Ride Through a German Village on 'The Flying Train' in Incredibly Clear Footage from 1902</title>
      <link>https://www.thisiscolossal.com/2020/08/the-flying-train-moma/</link>
      <description>﻿

Shot in 1902, "The Flying Train" takes viewers on an uncommonly crisp journey aboard a suspended railcar. Throughout the two-minute video, riders see Wuppertal residents walking across pedestrian bridges and down dirt roadways more than a century ago. The city is known still today for its schwe</description>
      <author> (Grace Ebert)</author>
      <guid>https://www.thisiscolossal.com/2020/08/the-flying-train-moma/</guid>
      <pubDate>Sat, 22 Aug 2020 03:03:44 GMT</pubDate>
    </item>
    <item>
      <title>What's new in the Windows Store client</title>
      <link>https://docs.microsoft.com/en-us/windows-server/remote/remote-desktop-services/clients/windows-whatsnew#updates-for-version-1021519-insider</link>
      <description>Learn about recent changes to the Remote Desktop client for Windows Store</description>
      <author> (Heidilohr)</author>
      <guid>https://docs.microsoft.com/en-us/windows-server/remote/remote-desktop-services/clients/windows-whatsnew#updates-for-version-1021519-insider</guid>
      <pubDate>Sat, 22 Aug 2020 02:03:52 GMT</pubDate>
    </item>
    <item>
      <title>Get Microsoft Remote Desktop - Microsoft Store en-CA</title>
      <link>https://www.microsoft.com/en-ca/p/microsoft-remote-desktop/9wzdncrfj3ps</link>
      <description>Download this app from Microsoft Store for Windows 10, Windows 8.1, Windows 10 Mobile, Windows Phone 8.1, Windows 10 Team (Surface Hub), HoloLens. See screenshots, read the latest customer reviews, and compare ratings for Microsoft Remote Desktop. </description>
      <author> ()</author>
      <guid>https://www.microsoft.com/en-ca/p/microsoft-remote-desktop/9wzdncrfj3ps</guid>
      <pubDate>Sat, 22 Aug 2020 02:03:49 GMT</pubDate>
    </item>
    <item>
      <title>Why write ADRs</title>
      <link>https://github.blog/2020-08-13-why-write-adrs/</link>
      <description>How architecture decision records can help your team.</description>
      <author> ()</author>
      <guid>https://github.blog/2020-08-13-why-write-adrs/</guid>
      <pubDate>Sat, 22 Aug 2020 00:47:03 GMT</pubDate>
    </item>
    <item>
      <title>nTopology jobs</title>
      <link>https://jobs.lever.co/ntopology</link>
      <description>Job openings at nTopology</description>
      <author> ()</author>
      <guid>https://jobs.lever.co/ntopology</guid>
      <pubDate>Sat, 22 Aug 2020 00:03:51 GMT</pubDate>
    </item>
    <item>
      <title>Leaked Palantir S-1 shows $579M loss in 2019 – TechCrunch</title>
      <link>https://techcrunch.com/2020/08/21/leaked-s-1-screenshots-show-palantir-losing-579m-in-2019/</link>
      <description>Palantir filed an S-1 confidentially to the SEC in early July, but we have so far been waiting for the final document to be published for weeks now with nary a murmur. Now, thanks to some leaked screenshots to TechCrunch from a Palantir shareholder, we might have some top-line numbers. Full-year re…</description>
      <author> (Danny Crichton@dannycrichton / 8:20 am PDT•August 21, 2020comment Comment)</author>
      <guid>https://techcrunch.com/2020/08/21/leaked-s-1-screenshots-show-palantir-losing-579m-in-2019/</guid>
      <pubDate>Fri, 21 Aug 2020 23:04:02 GMT</pubDate>
    </item>
    <item>
      <title>Exclude code that follows [DoesNotReturn] from code coverage (per #898) by kevin-montrose · Pull Request #904 · coverlet-coverage/coverlet</title>
      <link>https://github.com/coverlet-coverage/coverlet/pull/904</link>
      <description>Per #898
Implementing reachability analysis, which will allow instructions that follow calls to methods that never return to be excluded from coverage metrics.
Determines what methods will return w...</description>
      <author> (coverlet-coverage)</author>
      <guid>https://github.com/coverlet-coverage/coverlet/pull/904</guid>
      <pubDate>Fri, 21 Aug 2020 23:03:55 GMT</pubDate>
    </item>
    <item>
      <title>Kids Trap (Collection 1-15)</title>
      <link>https://open.spotify.com/playlist/4BDJsVcxauiyDxpO5pTAxt?si=J2G2L-O-SI6M0Q3seq1yfg</link>
      <description>oman546 · Playlist · 149 songs · 3.1K likes</description>
      <author> ()</author>
      <guid>https://open.spotify.com/playlist/4BDJsVcxauiyDxpO5pTAxt?si=J2G2L-O-SI6M0Q3seq1yfg</guid>
      <pubDate>Fri, 21 Aug 2020 23:03:51 GMT</pubDate>
    </item>
    <item>
      <title>This is your one shot</title>
      <link>https://neoslash.net/this-is-your-one-shot?guid=none</link>
      <description>I've worked in IT consulting for over 10 years in various roles. My current job includes meeting with prospects and discussing our IT services and how they fit into their business. This has been the first position I've held where I deal with a lot mo...</description>
      <author> (David GaliataPublished on May 3, 20203 min read)</author>
      <guid>https://neoslash.net/this-is-your-one-shot?guid=none</guid>
      <pubDate>Fri, 21 Aug 2020 22:04:21 GMT</pubDate>
    </item>
    <item>
      <title>fast.ai releases new deep learning course, four libraries, and 600-page book</title>
      <link>https://www.fast.ai/2020/08/21/fastai2-launch/</link>
      <description>We're releasing Practical Deep Learning for Coders (2020), fastai v2, fastcore, fastscript, and fastgpu.</description>
      <author> ()</author>
      <guid>https://www.fast.ai/2020/08/21/fastai2-launch/</guid>
      <pubDate>Fri, 21 Aug 2020 22:04:18 GMT</pubDate>
    </item>
    <item>
      <title>Generating Sales from YouTube micro-influencers</title>
      <link>https://austinrepp.com/youtubemicro/</link>
      <description>Explore the numbers of my YouTube marketing campaign for Discord Bot Studio.</description>
      <author> ()</author>
      <guid>https://austinrepp.com/youtubemicro/</guid>
      <pubDate>Fri, 21 Aug 2020 22:04:16 GMT</pubDate>
    </item>
    <item>
      <title>Weekly Update 205</title>
      <link>https://www.troyhunt.com/weekly-update-205/</link>
      <description>Between still feeling a little groggy after hitting the water hard on an early wake boarding session then my camera overheating and shutting down towards the end of the live stream, this wasn't the smoothest of weekly updates, I still got across everything I needed to. I'm especially excited about</description>
      <author> (https://www.facebook.com/troyahunt)</author>
      <guid>https://www.troyhunt.com/weekly-update-205/</guid>
      <pubDate>Fri, 21 Aug 2020 22:04:14 GMT</pubDate>
    </item>
    <item>
      <title>You don’t always have to be productive - WEEB TRASH LIFE</title>
      <link>https://weebtrash.ga/2020/08/21/you-dont-always-have-to-be-productive/</link>
      <description>Did you know that being constantly stuck in the productivity trap isn’t really healthy? Now you do. Wanna’ get out of it? Read these tips.</description>
      <author> ()</author>
      <guid>https://weebtrash.ga/2020/08/21/you-dont-always-have-to-be-productive/</guid>
      <pubDate>Fri, 21 Aug 2020 22:04:12 GMT</pubDate>
    </item>
    <item>
      <title>Tom Spark Talks with Troy Hunt - Owner of HaveIBeenPwned!</title>
      <link>https://www.youtube.com/watch?v=KZ195OCgH_Y</link>
      <description>I talked with Troy Hunt about his website and about general privacy online. 

►Privacy Review/tier list website with all ratings: https://vpntierlist.com/

Favorite VPN provider : TorGuard VPN http://bit.ly/tomsparkTorGuard 
Favorite browser: http://brave.com/tom352

Want to see what my favorite products are? https://www.vpntierlist.com/tom-spark-favorite-products/

Discord community: https://discord.gg/9YkDAJU
Join the subreddit! https://www.reddit.com/r/virtualprivatenetwork/

Disclaimer: This video and all my videos are solely my opinion, to provide educational content and to entertain my audience, and thus are protected by the first amendment in the USA, as well as the Consumer Review Fairness Act which protects my right to write reviews. 

I am affiliated, but not sponsored by any VPN. This means I do make money when you click on the links provided, but keep my own opinion to be legit and truthful without bias. I do not host sponsored content on this channel, which means I am not paid to promote VPNs in a positive manner. All of my opinions on this channel are strictly my own!</description>
      <author> (Tom Spark Reviews)</author>
      <guid>https://www.youtube.com/watch?v=KZ195OCgH_Y</guid>
      <pubDate>Fri, 21 Aug 2020 22:04:06 GMT</pubDate>
    </item>
    <item>
      <title>Toward a Zoom agreement</title>
      <link>https://seths.blog/2020/08/toward-a-zoom-agreement/</link>
      <description>If you promise not to check your email while we’re talking, we promise to not waste your time. If you agree to look me in the eye and try to absorb the gist of what I’m saying, I agree …</description>
      <author> (August 21, 2020)</author>
      <guid>https://seths.blog/2020/08/toward-a-zoom-agreement/</guid>
      <pubDate>Fri, 21 Aug 2020 22:04:05 GMT</pubDate>
    </item>
    <item>
      <title>Hand washing stations</title>
      <link>https://casita-colibri.blog/2020/08/20/hand-washing-stations/</link>
      <description>If you are out, about, and going to the mercados in Oaxaca in the last couple of months, you may have seen a clever contraption like the one below set up outside the Independencia entrance to Merca…</description>
      <author> ()</author>
      <guid>https://casita-colibri.blog/2020/08/20/hand-washing-stations/</guid>
      <pubDate>Fri, 21 Aug 2020 22:04:02 GMT</pubDate>
    </item>
    <item>
      <title>Why I Started Experimental Cooking — A Pursuit of Joy</title>
      <link>https://knowledgeartist.org/articles/51b7b831-515b-4ad0-ad4d-616cbbe180c1/why-i-started-experimental-cooking-a-pursuit-of-joy</link>
      <description>Cooking to me is not about creating the best tasting dish in the world. Rather, it is an outlet of expression, a means to evoke sensations.</description>
      <author> ()</author>
      <guid>https://knowledgeartist.org/articles/51b7b831-515b-4ad0-ad4d-616cbbe180c1/why-i-started-experimental-cooking-a-pursuit-of-joy</guid>
      <pubDate>Fri, 21 Aug 2020 22:03:59 GMT</pubDate>
    </item>
    <item>
      <title>Why Do Technical Recruiters Even Exist? - Scott Turman</title>
      <link>https://scottturman.com/why-do-technical-recruiters-even-exist/</link>
      <description>We’re all familiar with the suited snakes that spend every 8-to-10-hour workday calling to convince us to leave our current, steady jobs for nothing more than a few bucks more and criminally bad insurance. With that said then, why do recruiters even exist?</description>
      <author> (Scott Turman)</author>
      <guid>https://scottturman.com/why-do-technical-recruiters-even-exist/</guid>
      <pubDate>Fri, 21 Aug 2020 22:03:55 GMT</pubDate>
    </item>
    <item>
      <title>Port 5432 is open: introducing the Splitgraph Data Delivery Network</title>
      <link>https://www.splitgraph.com/blog/data-delivery-network-launch</link>
      <description>We launch the Splitgraph Data Delivery Network: a single endpoint that lets any PostgreSQL application, client or BI tool to connect and query over 40,000 public datasets hosted or proxied by Splitgraph.</description>
      <author> (AuthorsArtjoms Iškovs, Miles Richardson)</author>
      <guid>https://www.splitgraph.com/blog/data-delivery-network-launch</guid>
      <pubDate>Fri, 21 Aug 2020 21:03:46 GMT</pubDate>
    </item>
    <item>
      <title>Why efficiency is dangerous and slowing down makes life better | Psyche Ideas</title>
      <link>https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better</link>
      <description>The urge to do everything faster and better is risky. Far wiser to do what’s good enough for the range of possible futures</description>
      <author> (by Anna Greenburgh)</author>
      <guid>https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better</guid>
      <pubDate>Fri, 21 Aug 2020 21:03:43 GMT</pubDate>
    </item>
    <item>
      <title>Ignoring mass reformatting commits with git blame – Rob Allen's DevNotes</title>
      <link>https://akrabat.com/ignoring-revisions-with-git-blame/</link>
      <description>I’ve recently merged a PR by Stephen to rst2df that reformats the entire codebase to align with PEP 8. As rst2pdf is over a decade old, this has resulted in a lot of changes to the files which now have Stephen’s name attached. This affects git blame.</description>
      <author> ()</author>
      <guid>https://akrabat.com/ignoring-revisions-with-git-blame/</guid>
      <pubDate>Fri, 21 Aug 2020 20:03:39 GMT</pubDate>
    </item>
    <item>
      <title>An Update on MDN Web Docs – Mozilla Hacks - the Web developer blog</title>
      <link>https://hacks.mozilla.org/2020/08/an-update-on-mdn-web-docs/</link>
      <description>Last week, Mozilla announced some general changes in our investments and we would like to outline how they will impact our MDN platform efforts moving forward. It hurts to make ...</description>
      <author> (By
                                        rjensen)</author>
      <guid>https://hacks.mozilla.org/2020/08/an-update-on-mdn-web-docs/</guid>
      <pubDate>Fri, 21 Aug 2020 19:03:42 GMT</pubDate>
    </item>
    <item>
      <title>Developer Advocate, Careers At EDB </title>
      <link>https://enterprisedb.hrmdirect.com/employment/job-opening.php?req=1370410&amp;cust_sort1=-1&amp;nohd=#job</link>
      <description>Developer Advocate Remote preferred  The world loves Postgres If you work with developers or data scientists or anyone wrangling data youll probably see a sticker with the tusks and trunk of the Postgres elephant on the lid of a nearby laptop EDB has a lot to do with that Weve been major contributors to Postgres since the beginning and we are proud to call thousands of boundary pushing customers our partners Proud though we are we are not resting on our laurels Theres plenty of work to do The good news is that everything we do will impact Postgres which is to say that it will impact the world No pressure As a Developer Advocate you will join a team of user experience and software development professionals on a mission to make working with Postgres easier for developers data scientists data wranglers operators and the ever expanding ecosystem of technologists who rely on Postgres to innovate at speed What youll do Make Postgres easier identify points of friction in Postgres and EDB products develop approaches to address them Contribute Postgres expertise to a number of communities including Nodejs Python and Go Identify and engage with new communities which stand to benefit from Postgres Publish code and content that will help others get started with and get more out of Postgres Share feedback to development teams across our portfolio Collaborate with product engineering and marketing teams Talk to Postgres users and EDB customers and listen for not only their needs but also their ideas for the future of Postgres What were looking for A strong communicator A robust online portfolio featuring code and technical content including READMEs Ideally experience working on a technical advocacy team Facility with modern communication collaboration and development tools; eg Slack Github Stack Overflow VSCode Jira Experience with agile methodologies Willingness to analyze understand and extend existing cultural and technical systems Developer Advocates will report to the Director of Developer Advocacy in the CXO organization</description>
      <author> ()</author>
      <guid>https://enterprisedb.hrmdirect.com/employment/job-opening.php?req=1370410&amp;cust_sort1=-1&amp;nohd=#job</guid>
      <pubDate>Fri, 21 Aug 2020 19:03:40 GMT</pubDate>
    </item>
    <item>
      <title>Inside the Microsoft STL: The std::exception_ptr | The Old New Thing</title>
      <link>https://devblogs.microsoft.com/oldnewthing/20200820-00/?p=104097</link>
      <description>When debugging, you may find yourself staring at a std::exception_ptr and want to know what exception is inside it. What you see in the MSVC header file is that a std::exception_ptr is a class that consists of two pointers enigmatically named _Data1 and _Data2.</description>
      <author> (Raymond Chen  Follow)</author>
      <guid>https://devblogs.microsoft.com/oldnewthing/20200820-00/?p=104097</guid>
      <pubDate>Fri, 21 Aug 2020 18:03:59 GMT</pubDate>
    </item>
    <item>
      <title>My Stream Timer</title>
      <link>http://www.mystreamtimer.com/</link>
      <description>A cool app to count up or down that writes text to file for streamers</description>
      <author> ()</author>
      <guid>http://www.mystreamtimer.com/</guid>
      <pubDate>Fri, 21 Aug 2020 18:03:56 GMT</pubDate>
    </item>
    <item>
      <title>.NET Productivity Tips and Tricks</title>
      <link>https://www.youtube.com/watch?v=NXbpIMOJzNE</link>
      <description>The .NET Productivity team (a.k.a. Roslyn) is constantly thinking of new ways to make .NET developers more productive. Roslyn PM Mika Dumont shows a number of the latest features that make your coding life better, including her favorite (IntelliSense completion in DateTime and TimeSpan string literals). 

See the .NET blog post at https://devblogs.microsoft.com/dotnet/learn-about-the-latest-net-productivity-features/ for more details.</description>
      <author> (Microsoft Visual Studio)</author>
      <guid>https://www.youtube.com/watch?v=NXbpIMOJzNE</guid>
      <pubDate>Fri, 21 Aug 2020 18:03:54 GMT</pubDate>
    </item>
    <item>
      <title>Recognizing different types of exception objects that Windows platform libraries can throw | The Old New Thing</title>
      <link>https://devblogs.microsoft.com/oldnewthing/20200821-00/?p=104112</link>
      <description>Last time, we saw how to dig the exception object out of a std::exception_ptr. But what kind of exception objects might there be? For C++/CX code, you are probably going to get a Platform::Exception^. 0:007&gt; ?? p class std::exception_ptr   +0x000 _Data1      : 0x08a5885c Void   +0x004 _Data2      : 0x08a58850 Void  We learned that the _Data1 points to an EXCEPTION_RECORD¹</description>
      <author> (Raymond Chen  Follow)</author>
      <guid>https://devblogs.microsoft.com/oldnewthing/20200821-00/?p=104112</guid>
      <pubDate>Fri, 21 Aug 2020 18:03:54 GMT</pubDate>
    </item>
    <item>
      <title>How NAT traversal works</title>
      <link>https://tailscale.com/blog/how-nat-traversal-works/</link>
      <description>In this post, we'll talk about how to establish a peer-to-peer connection between two machines, in spite of all the obstacles in the way.</description>
      <author> (Tailscale)</author>
      <guid>https://tailscale.com/blog/how-nat-traversal-works/</guid>
      <pubDate>Fri, 21 Aug 2020 18:03:52 GMT</pubDate>
    </item>
    <item>
      <title>Productivity Tips and Tricks</title>
      <link>https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/Productivity-Tips-and-Tricks</link>
      <description>The .NET Productivity team (a.k.a. Roslyn) is constantly thinking of new ways to make .NET developers more productive. Roslyn PM Mika Dumont shows a number of the latest features that make your coding</description>
      <author> (by Robert Green, Leslie Richardson [MSFT])</author>
      <guid>https://channel9.msdn.com/Shows/Visual-Studio-Toolbox/Productivity-Tips-and-Tricks</guid>
      <pubDate>Fri, 21 Aug 2020 18:03:48 GMT</pubDate>
    </item>
    <item>
      <title>Saturday Morning Breakfast Cereal - Funding</title>
      <link>https://www.smbc-comics.com/comic/funding</link>
      <description>Saturday Morning Breakfast Cereal - Funding</description>
      <author> (sirPangur)</author>
      <guid>https://www.smbc-comics.com/comic/funding</guid>
      <pubDate>Fri, 21 Aug 2020 17:41:33 GMT</pubDate>
    </item>
    <item>
      <title>When U.S. air force discovered the flaw of averages</title>
      <link>https://www.thestar.com/news/insight/2016/01/16/when-us-air-force-discovered-the-flaw-of-averages.html</link>
      <description>In the early 1950s, a young lieutenant realized the fatal flaw in the cockpit design of U.S. air force jets. Todd Rose explains in an excerpt from his...</description>
      <author> (TRBy Todd RoseSat., Jan. 16, 2016timer11 min. read)</author>
      <guid>https://www.thestar.com/news/insight/2016/01/16/when-us-air-force-discovered-the-flaw-of-averages.html</guid>
      <pubDate>Fri, 21 Aug 2020 17:13:26 GMT</pubDate>
    </item>
    <item>
      <title>GUIDs are globally unique, but substrings of GUIDs aren't | The Old New Thing</title>
      <link>https://devblogs.microsoft.com/oldnewthing/20080627-00/?p=21823</link>
      <description>A customer needed to generate an 8-byte unique value, and their initial idea was to generate a GUID and throw away the second half, keeping the first eight bytes. They wanted to know if this was a good idea. No, it’s not a good idea.</description>
      <author> (Raymond Chen  Follow)</author>
      <guid>https://devblogs.microsoft.com/oldnewthing/20080627-00/?p=21823</guid>
      <pubDate>Fri, 21 Aug 2020 17:03:35 GMT</pubDate>
    </item>
    <item>
      <title>Introducing the new Azure SDKs</title>
      <link>https://www.youtube.com/watch?v=38RYIx7a2M4</link>
      <description>Azure SDK Website: https://aka.ms/azsdk
Azure SDK Twitter: https://twitter.com/@AzureSDK
Azure SDK Blog: https://aka.ms/azsdk/blog
Azure SDK Releases: https://aka.ms/azsdk/releases
Azure SDK Guidelines: https://aka.ms/azsdk/guide
Azure SDK Code: https://aka.ms/azsdk/github
Azure SDK Intro Video: https://aka.ms/azsdk/intro
Azure SDK Intro Video Deck: https://aka.ms/azsdk/intro/deck

Introducing the new Azure SDKs

Before we introduced the new Azure SDKs in July of 2019, each Azure Service team independently created their own SDKs in disparate repositories, had their own CI process, and had varying levels of authentication, language, OS, and package support.  

With the new Azure SDKs we have established a set of common design guidelines, a centralized engineering system, centralized open-source repositories, as well as consistent authentication, language, and OS support. We also deliver packages to the most popular package managers for each language.

We currently provide libraries in .NET, Java, Python, and JavaScript/TypeScript with more languages coming soon. 

https://aka.ms/azsdk will lead you to the Azure SDK website, which a great landing spot with links to our packages, guidelines, documentation, and blog.

Developer productivity is the primary driver for the new Azure SDK effort.

We know that you will be most productive when your experience feels natural for whatever language you code in and when you can easily download the libraries from package managers that you use every day.

Consistency is also key, with the new Azure SDKs, navigating amongst the services doesn’t require you to learn a new API paradigm.  

Being approachable, diagnosable, and dependable are all pillars that go into building libraries, so we are investing heavily in these areas as well. Including ramping up our documentation efforts, integrating with standard logging frameworks, and holding API board reviews for all new libraries.

You can find all these guidelines detailed at https://aka.ms/azsdk/guide. We’ll continue to evolve these guidelines, so please review them, and provide us with feedback or suggestions via GitHub

We released our first GA libraries in the fall of 2019 and continue to release monthly.  

In GA, we currently have Storage, Key Vault, Event Hubs, App Config, Cosmos for JavaScript/TypeScript, Python and Java. Cognitive Services Text Analytics. Azure.Identity and Azure.Core which implement a consistent authentication and request/response pipeline for all libraries.


And in Preview, we have Cosmos for .NET. Cognitive Services Form Recognizer, Cognitive Search, Service Bus, and the Azure SDK for Embedded C

We’ll eventually GA libraries for all Azure services, but next up on the list is Tables, Cognitive services Anomaly Detector, Azure Synapse Analytics, and the new Resource Management libraries.

You can find the full list of libraries with links to packages, code, and docs at https://aka.ms/azsdk/releases. 

You can find the code for all the new Azure SDKs at https://aka.ms/azsdk/github. That will take you to our central repo which has links to all the other language specific repos and houses our common design guidelines. It’s a great place to file architecture board suggestions and questions or issues that cut across all the SDKs. The overriding theme here is everything in the open on GitHub, with an engaged engineering team to help you through any issues you discover as you build your Azure solutions.


We’d like to encourage you to start using the new Azure SDKs and contributing to them by submitting issues or pull-requests on GitHub. You can follow us on Twitter https://twitter.com/@AzureSDK and subscribe to our blog at https://aka.ms/azsdk/blog.</description>
      <author> (Jon Gallant)</author>
      <guid>https://www.youtube.com/watch?v=38RYIx7a2M4</guid>
      <pubDate>Fri, 21 Aug 2020 16:03:46 GMT</pubDate>
    </item>
    <item>
      <title>Azure SDK Latest Releases | Azure SDKs</title>
      <link>https://azure.github.io/azure-sdk/</link>
      <description />
      <author> ()</author>
      <guid>https://azure.github.io/azure-sdk/</guid>
      <pubDate>Fri, 21 Aug 2020 16:03:45 GMT</pubDate>
    </item>
    <item>
      <title>Approximate results may vary</title>
      <link>https://ericlippert.com/2020/08/21/approximate-results-may-vary/</link>
      <description>Part 33 of my ongoing series is coming but I did not get all the code written that I wanted to this week, so it will be delayed. In the meanwhile: Living in Canada as a child, of course I grew up l…</description>
      <author> ()</author>
      <guid>https://ericlippert.com/2020/08/21/approximate-results-may-vary/</guid>
      <pubDate>Fri, 21 Aug 2020 16:03:43 GMT</pubDate>
    </item>
    <item>
      <title>reMarkable microSD</title>
      <link>http://www.davisr.me/projects/remarkable-microsd/</link>
      <description>This page discusses how I added a microSD card to my reMarkable tablet. I did this because I want to develop software for my rM without wearing out the internal eMMC. I chose an external card because I want to be able to swap them easily; it also makes backups faster.</description>
      <author> ()</author>
      <guid>http://www.davisr.me/projects/remarkable-microsd/</guid>
      <pubDate>Fri, 21 Aug 2020 16:03:41 GMT</pubDate>
    </item>
    <item>
      <title>The Brussels Choice - Numberphile</title>
      <link>https://www.youtube.com/watch?v=AeqK96UX3rA</link>
      <description>Neil Sloane from the OEIS discusses the Choix de Bruxelles.
Check out Brilliant (get 20% off their premium service): https://brilliant.org/numberphile (sponsor)

More links &amp; stuff in full description below ↓↓↓ 

Neil Sloane founded the runs the OEIS: https://oeis.org/
Brussels Choice on the OEIS: https://oeis.org/A323454
Neil Sloane playlist on Numberphile: http://bit.ly/Sloane_Numberphile
Neil Sloane on the Numberphile podcast: https://youtu.be/mNk_MfFKnuY

Numberphile is supported by the Mathematical Sciences Research Institute (MSRI): http://bit.ly/MSRINumberphile

We are also supported by Science Sandbox, a Simons Foundation initiative dedicated to engaging everyone with the process of science. https://www.simonsfoundation.org/outreach/science-sandbox/

And support from Math For America - https://www.mathforamerica.org/

NUMBERPHILE
Website: http://www.numberphile.com/
Numberphile on Facebook: http://www.facebook.com/numberphile
Numberphile tweets: https://twitter.com/numberphile
Subscribe: http://bit.ly/Numberphile_Sub

Video by Brady Haran and Pete McPartlan

Patreon: http://www.patreon.com/numberphile

Numberphile T-Shirts and Merch: https://teespring.com/stores/numberphile

Brady's videos subreddit: http://www.reddit.com/r/BradyHaran/

Brady's latest videos across all channels: http://www.bradyharanblog.com/

Sign up for (occasional) emails: http://eepurl.com/YdjL9</description>
      <author> (Numberphile)</author>
      <guid>https://www.youtube.com/watch?v=AeqK96UX3rA</guid>
      <pubDate>Fri, 21 Aug 2020 15:03:41 GMT</pubDate>
    </item>
    <item>
      <title>First thoughts on Rust vs OCaml</title>
      <link>https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/</link>
      <description>I'm about two weeks into Rust now, so this feels like a good time to write a critique, before I get Stockholm Syndrome'd. My main motivation in learning Rust is that I have to maintain some of Dark's Rust code. There was a recent outage related to that code, and</description>
      <author> (Paul Biggar)</author>
      <guid>https://blog.darklang.com/first-thoughts-on-rust-vs-ocaml/</guid>
      <pubDate>Fri, 21 Aug 2020 15:03:40 GMT</pubDate>
    </item>
    <item>
      <title>Chromium’s impact on root DNS traffic | APNIC Blog</title>
      <link>https://blog.apnic.net/2020/08/21/chromiums-impact-on-root-dns-traffic/</link>
      <description>Guest Post: With 70% of market share, Chromium has had a significant impact on the total root DNS traffic.</description>
      <author> (Geoff Huston)</author>
      <guid>https://blog.apnic.net/2020/08/21/chromiums-impact-on-root-dns-traffic/</guid>
      <pubDate>Fri, 21 Aug 2020 14:03:55 GMT</pubDate>
    </item>
    <item>
      <title>Why Did Mozilla Remove XUL Add-ons?</title>
      <link>https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/</link>
      <description>During the past few days, I&amp;rsquo;ve been chatting with Firefox users, trying to separate fact from rumor regarding the consequences of the August 2020 Mozilla layoffs. One of the topics that came back a few times was the removal of XUL-based add-ons during the move to Firefox Quantum. I was very surprised to see that, years after it happened, some community members still felt hurt by this choice.
And then, as someone pointed out on reddit, I realized that we still haven&amp;rsquo;t taken the time to explain in-depth why we had no choice but to remove XUL-based add-ons.
So, if you&amp;rsquo;re ready for a dive into some of the internals of add-ons and Gecko, I&amp;rsquo;d like to take this opportunity to try and give you a bit more detail.
</description>
      <author> (David Teller)</author>
      <guid>https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/</guid>
      <pubDate>Fri, 21 Aug 2020 12:03:39 GMT</pubDate>
    </item>
    <item>
      <title>Weekly Update 204</title>
      <link>https://www.youtube.com/watch?v=CItROiNKnn0&amp;hss_channel=tw-2925438791</link>
      <description></description>
      <author> (Troy Hunt)</author>
      <guid>https://www.youtube.com/watch?v=CItROiNKnn0&amp;hss_channel=tw-2925438791</guid>
      <pubDate>Fri, 21 Aug 2020 11:03:49 GMT</pubDate>
    </item>
    <item>
      <title>Fullstack Vulnerability Management | Cyber Attack Prevention</title>
      <link>https://www.edgescan.com/</link>
      <description>edgescan Fullstack Vulnerability Management™. Award winning &amp; internationally accredited cyber attack prevention. Continuous security testing.</description>
      <author> ()</author>
      <guid>https://www.edgescan.com/</guid>
      <pubDate>Fri, 21 Aug 2020 11:03:48 GMT</pubDate>
    </item>
    <item>
      <title>https://media.defense.gov/2020/Aug/13/2002476465/-1/-1/0/CSA_DROVORUB_RUSSIAN_GRU_MALWARE_AUG_2020.PDF</title>
      <link>https://media.defense.gov/2020/Aug/13/2002476465/-1/-1/0/CSA_DROVORUB_RUSSIAN_GRU_MALWARE_AUG_2020.PDF</link>
      <description />
      <author> ()</author>
      <guid>https://media.defense.gov/2020/Aug/13/2002476465/-1/-1/0/CSA_DROVORUB_RUSSIAN_GRU_MALWARE_AUG_2020.PDF</guid>
      <pubDate>Fri, 21 Aug 2020 10:03:39 GMT</pubDate>
    </item>
    <item>
      <title>Building a Second Brain: The Illustrated Notes</title>
      <link>https://maggieappleton.com/basb/</link>
      <description>Maggie Appleton is an art director, anthropologist, and metaphor-making illustrator. This is her digital garden for growing visual explanations about technology, culture, and programming</description>
      <author> ()</author>
      <guid>https://maggieappleton.com/basb/</guid>
      <pubDate>Fri, 21 Aug 2020 06:15:04 GMT</pubDate>
    </item>
    <item>
      <title>Building a Second Brain</title>
      <link>https://www.buildingasecondbrain.com/</link>
      <description>An online bootcamp on leveraging digital tools to enhance your creativity, productivity, and learning, by Tiago Forte</description>
      <author> ()</author>
      <guid>https://www.buildingasecondbrain.com/</guid>
      <pubDate>Fri, 21 Aug 2020 06:07:23 GMT</pubDate>
    </item>
    <item>
      <title>Lightroom App Update Wipes Users' Photos and Presets, Adobe Says they are 'Not Recoverable'</title>
      <link>https://petapixel.com/2020/08/20/lightroom-app-update-wipes-users-photos-and-presets-adobe-says-they-are-not-recoverable/</link>
      <description>This morning, multiple readers wrote in to alert us to a major Adobe gaff. It seems the latest update to the Lightroom app for iPhone and iPad</description>
      <author> ()</author>
      <guid>https://petapixel.com/2020/08/20/lightroom-app-update-wipes-users-photos-and-presets-adobe-says-they-are-not-recoverable/</guid>
      <pubDate>Fri, 21 Aug 2020 06:03:54 GMT</pubDate>
    </item>
    <item>
      <title>Development quotes of the week [LWN.net]</title>
      <link>https://lwn.net/Articles/829123/</link>
      <description>Posted Aug 19, 2020 22:57 UTC (Wed) by flussence (subscriber, #85566)
         In reply to: Development quotes of the week by mathstuf
        Parent article: Development quotes of the week</description>
      <author> ()</author>
      <guid>https://lwn.net/Articles/829123/</guid>
      <pubDate>Fri, 21 Aug 2020 06:03:44 GMT</pubDate>
    </item>
    <item>
      <title>How Shopify Reduced Storefront Response Times with a Rewrite</title>
      <link>https://engineering.shopify.com/blogs/engineering/how-shopify-reduced-storefront-response-times-rewrite</link>
      <description>In January 2019, we set out to rewrite the critical software that powers all online storefronts on Shopify’s platform to offer the fastest online shopping experience possible, entirely from scratch and without downtime.
The Storefront Renderer is a server-side application that loads a Shopify merchant's storefront Liquid theme, along with the data required to serve the request (for example product data, collection data, inventory information, and images), and returns the HTML response back to your browser. Shaving milliseconds off response time leads to big results for merchants on the platform as buyers increasingly expect pages to load quickly, and failing to deliver on performance can hinder sales, not to mention other important signals like SEO.
The previous storefront implementation‘s development, started over 15 years ago when Tobi launched Snowdevil, lived within Shopify’s Ruby on Rails monolith. Over the years, we realized that the “storefront” part of Shopify is quite different from the other parts of the monolith: it has much stricter performance requirements and can accept more complexity implementation-wise to improve performance, whereas other components (such as payment processing) need to favour correctness and readability.
In addition to this difference in paradigm, storefront requests progressively became slower to compute as we saw more storefront traffic on the platform. This performance decline led to a direct impact on our merchant storefronts’ performance, where time-to-first-byte metrics from Shopify servers slowly crept up as time went on.
Here’s how the previous architecture looked:
Old Storefront Implementation 
Before, the Rails monolith handled almost all kinds of traffic: checkout, admin, APIs, and storefront.
With the new implementation, traffic routing looks like this:
New Storefront Implementation 
The Rails monolith still handles checkout, admin, and API traffic, but storefront traffic is handled by the new implementation.
Designing the new storefront implementation from the ground up allowed us to think about the guarantees we could provide: we took the opportunity of this evergreen project to set us up on strong primitives that can be extended in the future, which would have been much more difficult to retrofit in the legacy implementation. An example of these foundations is the decision to design the new implementation on top of an active-active replication setup. As a result, the new implementation always reads from dedicated read replicas, improving performance and reducing load on the primary writers.
Similarly, by rebuilding and extracting the storefront-related code in a dedicated application, we took the opportunity to think about building the best developer experience possible: great debugging tools, simple onboarding setup, welcoming documentation, and so on.
Finally, with improving performance as a priority, we work to increase resilience and capacity in high load scenarios (think flash sales: events where a large number of buyers suddenly start shopping on a specific online storefront), and invest in the future of storefront development at Shopify. The end result is a fast, resilient, single-purpose application that serves high-throughput online storefront traffic for merchants on the Shopify platform as quickly as possible.
Defining Our Success Criteria
Once we clearly outlined the problem we’re trying to solve and scoped out the project, we defined three main success criteria:


Establishing feature parity: for a given input, both implementations generate the same output.

Improving performance: the new implementation runs on active-active replication setup and minimizes server response times.

Improving resilience and capacity: in high-load scenarios, the new implementation generally sustains traffic without causing errors.

Building A Verifier Mechanism
Before building the new implementation, we needed a way to make sure that whatever we built would behave the same way as the existing implementation. So, we built a verifier mechanism that compares the output of both implementations and returns a positive or negative result depending on the outcome of the comparison.
This verification mechanism runs on storefront traffic in production, and it keeps track of verification results so we can identify differences in output that need fixing. Running the verifier mechanism on production traffic (in addition to comparing the implementations locally through a formal specification and a test suite) lets us identify the most impactful areas to work on when fixing issues, and keeps us focused on the prize: reaching feature parity as quickly as possible. It’s desirable for multiple reasons:

giving us an idea of progress and spreading the risk over a large amount of time
shortening the period of time that developers at Shopify work with two concurrent implementations at once
providing value to Shopify merchants as soon as possible.

There are two parts to the entire verifier mechanism implementation:

A verifier service (implemented in Ruby) compares the two responses we provide and returns a positive or negative result depending on the verification outcome. Similar to a `diff` tool, it lets us identify differences between the new and legacy implementations.
A custom nginx routing module (implemented in Lua on top of OpenResty) sends a sample of production traffic to the verifier service for verification. This module acts as a router depending on the result of the verifications for subsequent requests.

The following diagram shows how each part interacts with the rest of the architecture:
Legacy implementation and new implementation at the same conceptual layer
The legacy implementation (the Rails monolith) still exists, and the new implementation (including the Verifier service) is introduced at the same conceptual layer. Both implementations are placed behind a custom routing module that decides where to route traffic based on the request attributes and the verification data for this request type. Let’s look at an example.
When a buyer’s device sends an initial request for a given storefront page (for example, a product page from shop XYZ), the request is sent to Shopify’s infrastructure, at which point an nginx instance handles it. The routing module considers the request attributes to determine if other shop XYZ product page requests have previously passed verification.
First request routed to Legacy implementation
Since this is the first request of this kind in our example, the routing module sends the request to the legacy implementation to get a baseline reference that it will use for subsequent shop XYZ product page requests.
Routing module sends original request and legacy implementation’s response to the new implementation
Once the response comes back from the legacy implementation, the Lua routing module sends that response to the buyer. In the background, the Lua routing module also sends both the original request and the legacy implementation’s response to the new implementation. The new implementation computes a response to the original request and feeds both its response and the forwarded legacy implementation’s response to the verifier service. This is done asynchronously to make sure we’re not adding latency to responses we send to buyers, who don’t notice anything different.
At this point, the verifier service received the responses from both the legacy and new implementations and is ready to compare them. Of course, the legacy implementation is assumed to be correct as it’s been running in production for years now (it acts as our reference point). We keep track of differences between the two implementations’ responses so we can debug and fix them later. The verifier service looks at both responses’ status code, headers, and body, ensuring they’re equivalent. This lets us identify any differences in the responses so we make sure our new implementation behaves like the legacy one.
Time-related and randomness-related exceptions make it impossible to have exactly byte-equal responses, so we ignore certain patterns in the verifier service to relax the equivalence criteria. The verifier service uses a fixed time value during the comparison process and sets any random values to a known value so we reliably compare the outputs containing time-based and randomness-based differences.
The verifier service sends comparison result back to the Lua module
The verifier service sends the outcome of the comparison back to the Lua module, which keeps track of that comparison outcome for subsequent requests of the same kind.
Dynamically Routing Requests To the New Implementation
Once we had verified our new approach, we tested rendering a page using the new implementation instead of the legacy one. We iterated upon our verification mechanism to allow us to route traffic to the new implementation after a given number of successful verifications. Here’s how it works.
Just like when we only verified traffic, a request arrives from a client device and hits Shopify’s architecture. The request is sent to both implementations, and both outputs are forwarded to the verifier service for comparison. The comparison result is sent back to the Lua routing module, which keeps track of it for future requests.
When a subsequent storefront request arrives from a buyer and reaches the Lua routing module, it decides where to send it based on the previous verification results for requests similar to the current one (based on the request attributes
For subsequent storefront requests, the Lua routing module decides where to send it
If the request was verified multiple times in the past, and nearly all outcomes from the verifier service were “Pass”, then we consider the request safe to be served by the new implementation.
If most verifier service results are “Pass”, then it uses the new implementation
If, on the other hand, some verifications failed for this kind of request, we’ll play it safe and send the request to the legacy implementation.
If most verifier service results are “Fail”, then it uses the old implementation
Successfully Rendering In Production
With the verifier mechanism and the dynamic router in place, our first goal was to render one of the simplest storefront pages that exists on the Shopify platform: the password page that protects a storefront before the merchant makes it available to the public.
Once we reached full parity for a single shop’s password page, we tested our implementation in production (for the first time) by routing traffic for this password page to the new implementation for a couple of minutes to test it out.
Success! The new implementation worked in production. It was time to start implementing everything else.
Increasing Feature Parity
After our success with the password page, we tackled the most frequently accessed storefront pages on the platform (product pages, collection pages, etc). Diff by diff, endpoint by endpoint, we slowly increased the parity rate between the legacy and new implementations.
Having both implementations running at the same time gave us a safety net to work with so that if we introduced a regression, requests would easily be routed to the legacy implementation instead. Conversely, whenever we shipped a change to the new implementation that would fix a gap in feature parity, the verifier service starts to report verification successes, and our custom routing module in nginx automatically starts sending traffic to the new implementation after a predetermined time threshold.
Defining “Good” Performance with Apdex Scores
We collected Apdex (Application Performance Index) scores on server-side processing time for both the new and legacy implementations to compare them.
To calculate Apdex scores, we defined a parameter for a satisfactory threshold response time (this is the Apdex’s “T” parameter). Our threshold response time to define a frustrating experience would then be “above 4T” (defined by Apdex).
We defined our “T” parameter as 200ms, which lines up with Google’s PageSpeed Insights recommendation for server response times. We consider server processing time below 200ms as satisfying and a server processing time of 800ms or more as frustrating. Anything in between is tolerated.
From there, calculating the Apdex score for a given implementation consists of setting a time frame, and counting three values:

N, the total number of responses in the defined time frame
S, the number of satisfying responses (faster than 200ms) in the time frame
T, the number of tolerated responses (between 200ms and 800ms) in the time frame

Then, we calculate the Apdex score: 

$$\frac{s + t/2}{n}$$
By calculating Apdex scores for both the legacy and new implementations using the same T parameter, we had common ground to compare their performance.
Methods to Improve Server-side Storefront Performance
We want all Shopify storefronts to be fast, and this new implementation aims to speed up what a performance-conscious theme developer can’t by optimizing data access patterns, reducing memory allocations, and implementing efficient caching layers.
Optimizing Data Access Patterns
The new implementation uses optimized, handcrafted SQL multi-select statements maximizing the amount of data transferred in a single round trip. We carefully vet what we eager-load depending on the type of request and we optimize towards reducing instances of N+1 queries.
Reducing Memory Allocations
We reduce the number of memory allocations as much as possible so Ruby spends less time in garbage collection. We use methods that apply modifications in place (such as #map!) rather than those that allocate more memory space (like #map). This kind of performance-oriented Ruby paradigm sometimes leads to code that’s not as simple as idiomatic Ruby, but paired with proper testing and verification, this tradeoff provides big performance gains. It may not seem like much, but those memory allocations add up quickly, and considering the amount of storefront traffic Shopify handles, every optimization counts.
Implementing Efficient Caching Layers
We implemented various layers of caching throughout the application to reduce expensive calls. Frequent database queries are partitioned and cached to optimize for subsequent reads in a key-value store, and in the case of extremely frequent queries, those are cached directly in application memory to reduce I/O latency. Finally, the results of full page renders are cached too, so we can simply serve a full HTTP response directly from cache if possible.
Measuring Performance Improvement Successes
Once we could measure the performance of both implementations and reach a high enough level of verified feature parity, we started migrating merchant shops. Here are some of the improvements we’re seeing with our new implementation:

Across all shops, average server response times for requests served by the new implementation are 4x to 6x faster than the legacy implementation. This is huge!
When migrating a storefront to the new implementation, we see that the Apdex score for server-side processing time improves by +0.11 on average.
When only considering cache misses (requests that can’t be served directly from the cache and need to be computed from scratch), the new implementation increases the Apdex score for server-side processing time by a full +0.20 on average compared to the previous implementation.
We heard back from merchants mentioning a 500ms improvement in time-to-first-byte metrics when the new implementation was rolled out to their storefront.

So another success! We improved store performance in production.
Now how do we make sure this translates to our third success criteria?
Improving Resilience and Capacity
While working on the new implementation, the Verifier service identified potential parity gaps, which helped tremendously. However, a few times we shipped code to production that broke in exceedingly rare edge cases that it couldn’t catch.
As a safety mechanism, we made it so that whenever the new implementation would fail to successfully render a given request, we’d fall back to the legacy implementation. The response would be slower, but at least it was working properly. We used circuit breakers in our custom nginx routing module so that we’d open the circuit and start sending traffic to the legacy implementation if the new implementation was having trouble responding successfully. Read more on tuning circuit breakers in this blog post by my teammate Damian Polan.
Increase Capacity in High-load Scenarios
To ensure that the new implementation responds well to flash sales, we implemented and tweaked two mechanisms. The first one is an automatic scaling mechanism that adds or remove computing capacity in response to the amount of load on the current swarm of computers that serve traffic. If load increases as a result of an increase in traffic, the autoscaler will detect this increase and start provisioning more compute capacity to handle it.
Additionally, we introduced in-memory cache to reduce load on external data stores for storefronts that put a lot of pressure on the platform’s resources. This provides a buffer that reduces load on very-high traffic shops.
Failing Fast
When an external data store isn’t available, we don’t want to serve buyers an error page. If possible, we’ll try to gracefully fall back to a safe way to serve the request. It may not be as fast, or as complete as a normal, healthy response, but it’s definitely better than serving a sad error page.
We implemented circuit breakers on external datastores using Semian, a Shopify-developed Ruby gem that controls access to slow or unresponsive external services, avoiding cascading failures and making the new implementation more resilient to failure.
Similarly, if a cache store isn’t available, we’ll quickly consider the timeout as a cache miss, so instead of failing the entire request because the cache store wasn’t available, we’ll simply fetch the data from the canonical data store instead. It may take longer, but at least there’s a successful response to serve back to the buyer.
Testing Failure Scenarios and the Limits of the New Implementation
Finally, as a way to identify potential resilience issues, the new implementation uses Toxiproxy to generate test cases where various resources are made available or not, on demand, to generate problematic scenarios.
As we put these resilience and capacity mechanisms in place, we regularly ran load tests using internal tooling to see how the new implementation behaves in the face of a large amount of traffic. As time went on, we increased the new implementation’s resilience and capacity significantly, removing errors and exceptions almost completely even in high-load scenarios. With BFCM 2020 coming soon (which we consider as an organic, large-scale load test), we’re excited to see how the new implementation behaves.
Where We’re at Currently
We’re currently in the process of rolling out the new implementation to all online storefronts on the platform. This process happens automatically, without the need for any intervention from Shopify merchants. While we do this, we’re adding more features to the new implementation to bring it to full parity with the legacy implementation. The new implementation is currently at 90%+ feature parity with the legacy one, and we’re increasing that figure every day with the goal of reaching 100% parity to retire the legacy implementation.
As we roll out the new implementation to storefronts we are continuing to see and measure performance improvements as well. On average, server response times for the new implementation are 4x faster than the legacy implementation. Rhone Apparel, a Shopify Plus merchant, started using the new implementation in April 2020 and saw dramatic improvements in server-side performance over the previous month.
We learned a lot during the process of rewriting this critical piece of software. The strong foundations of this new implementation make it possible to deploy it around the world, closer to buyers everywhere, to reduce network latency involved in cross-continental networking, and we continue to explore ways to make it even faster while providing the best developer experience possible to set us up for the future.

We're always on the lookout for talent and we’d love to hear from you. Visit our Engineering career page to find out about our open positions.</description>
      <author> (Maxime Vaillancourt)</author>
      <guid>https://engineering.shopify.com/blogs/engineering/how-shopify-reduced-storefront-response-times-rewrite</guid>
      <pubDate>Fri, 21 Aug 2020 06:03:41 GMT</pubDate>
    </item>
  </channel>
</rss>