[
  {
    "Title": "Let's Learn .NET | .NET Live TV",
    "Url": "https://dotnet.microsoft.com/en-us/live/lets-learn-dotnet",
    "Timestamp": "2023-06-29T18:02:31",
    "Domain": "dotnet.microsoft.com",
    "Description": "This monthly beginner series will walk through the fundamentals of using C# and .NET to build real world applications. Come learn something new and leave with something that we all built, together, live with experts.",
    "Confidence": 0.9752842
  },
  {
    "Title": "Microsoft 365 Developer Proxy v0.9 with over-consenting guidance - Microsoft 365 Developer Blog",
    "Url": "https://devblogs.microsoft.com/microsoft365dev/microsoft-365-developer-proxy-v0-9-with-over-consenting-guidance/?ocid=M365_202306_Organic&Channel=Twitter&Product=Graph&Intent=Announcement&Audience=Developer",
    "Timestamp": "2023-06-29T17:06:46",
    "Domain": "devblogs.microsoft.com",
    "Description": "Microsoft 365 Developer Proxy introduces the preview ability to detect over-consented apps that use Microsoft Graph.",
    "Confidence": 0.99708617
  },
  {
    "Title": "Clean Architecture vs Vertical Slice Architecture",
    "Url": "https://youtube.com/watch?v=_yJJRn2_SFg",
    "Timestamp": "2023-06-29T15:04:07",
    "Domain": "youtube.com",
    "Description": "Vertical Slice Architecture vs Clean Architecture: Which one is the best for your project?üíé Be a Patreon to get the source code: https://patreon.com/gsferre...",
    "Confidence": 0.994043
  },
  {
    "Title": "Rx.NET v6.0: Enhancing Compatibility, Trimming Support, and Many More ",
    "Url": "https://www.infoq.com/news/2023/06/rx-dotnet-6/",
    "Timestamp": "2023-06-29T15:04:05",
    "Domain": "www.infoq.com",
    "Description": "Last month, the team behind Rx.NET announced the release of the 6.0 version. The latest version of the library brings several improvements and aligns itself with the current .NET ecosystem. While the update doesn't introduce significant new functionality, it focuses on enhancing compatibility, supporting the latest versions of .NET, and addressing common pain points for developers.",
    "Confidence": 0.99660486
  },
  {
    "Title": "What Is Infrastructure as Code?",
    "Url": "https://youtube.com/watch?v=a_mf8H7eQVc",
    "Timestamp": "2023-06-29T14:04:48",
    "Domain": "youtube.com",
    "Description": "As a .NET developer, I host most of my applications on Microsoft Azure. I have a few simple web apps, and I also run a SaaS product on Azure.I don't know muc...",
    "Confidence": 0.99683434
  },
  {
    "Title": "Mastering .NET MAUI SwipeView for Enhanced App Experience",
    "Url": "https://youtube.com/watch?v=BHBYHC_9URc",
    "Timestamp": "2023-06-29T14:04:48",
    "Domain": "youtube.com",
    "Description": "Let's look at all the features of adding swipe actions to your application with .NET MAUI's built in SwipeView. Swipe up, down, left, right on any control th...",
    "Confidence": 0.97973347
  },
  {
    "Title": "How to wait for multiple C++ coroutines to complete before propagating failure, peeling away at a tuple - The Old New Thing",
    "Url": "https://devblogs.microsoft.com/oldnewthing/20230629-00/?p=108380",
    "Timestamp": "2023-06-29T14:04:45",
    "Domain": "devblogs.microsoft.com",
    "Description": "Iterating over a tuple recursively.",
    "Confidence": 0.99671674
  },
  {
    "Title": "The New ‚ÄúInterceptors‚Äù Feature of C# 12 Is WILD!",
    "Url": "https://youtube.com/watch?v=91xir2oUQPg",
    "Timestamp": "2023-06-29T13:03:50",
    "Domain": "youtube.com",
    "Description": "Use code SUMMER23 until the 20th of July for a 15% discount on any bundle at https://dometrain.com/bundlesBecome a Patreon and get source code access: https:...",
    "Confidence": 0.96144474
  },
  {
    "Title": "runtime/docs/coding-guidelines/vectorization-guidelines.md at main ¬∑ dotnet/runtime",
    "Url": "https://github.com/dotnet/runtime/blob/main/docs/coding-guidelines/vectorization-guidelines.md",
    "Timestamp": "2023-06-29T13:03:49",
    "Domain": "github.com",
    "Description": ".NET is a cross-platform runtime for cloud, mobile, desktop, and IoT apps. - runtime/docs/coding-guidelines/vectorization-guidelines.md at main ¬∑ dotnet/runtime",
    "Confidence": 0.99332756
  },
  {
    "Title": "how (not) to write a pipeline",
    "Url": "https://cohost.org/tef/post/1764930-how-not-to-write-a",
    "Timestamp": "2023-06-29T12:03:09",
    "Domain": "cohost.org",
    "Description": "let me boldly assert that there are two types of programmer (at least as far as this post is concerned):\n\n 1. a programmer who builds something out of message queues and calls it a pipeline\n 2. a programmer who has had to maintain and operate a type-1 made pipeline\n\nalthough both types of programmer are kept awake by thoughts of code at night, only one of them is on the pager rota. every programmer gets to fuck around, but only a handful are blessed/cursed with finding out.\n\nthis essay is for programmers of the second variety. i'm not sure what anyone else will get, but hopefully the people who have already suffered will receive validation, and maybe a few lucky people will pick up some useful framing and vocabulary to fight the good fight later.\n\nit's also for people who won't whine about the lack of capitalization in a rough blog post\n\n----------------------------------------\n\n\nPRELUDE: CHARACTER SELECTION\n\nyou are:\n\n * ‚òê A long time industry expert, with twelve acronyms on your business card.\n * ‚òê Someone with a kanban, can-do attitude. Party planning your way to success!\n * ‚òë A well rounded burnout who got hired through word of mouth.\n\nyou are\n\n * ‚òê in a small engineering team, building out features for a website\n * ‚òë employee number four and the ceo keeps writing code on weekends\n * ‚òê in a large enterprise company with an hour and a half long daily standup\n\nyou are\n\n * ‚òê in charge of building out backend systems\n * ‚òê all working in the same repo\n * ‚òë accidentally in ops, after fixing one too many builds\n\n\nTHE FIRE IS LIT: A PIPELINE IS COMING\n\nit's 3pm, it's friday, and your coworker drops a link in the company chat. it's a 2000 line change request, and they're desperate for a +1. despite the length, the code is relatively straight forwards. a lot of it is just yaml.\n\nthere's a thumbnail generator that's starting to take too long. originally it just cropped and resized things down, but for some ungodly reason, there's video support and transcoding now. requests to the website are timing out because this process is taking too long to complete.\n\nyour coworker, bored as hell, desperate to get on with real work, volunteers as tribute to fix the bug. now the code calls \"StartThumbNailer(user, file)\", a message gets put in a queue, and another process elsewhere calls \"user, file := queue.ThumbNextNail()\". problem solved.\n\nalas, it isn't icarus' fate to know his future.\n\n\nSTEP 1: CLEANING UP AFTER DROPPED MESSAGES\n\nyou open a dm, it's best to avoid an audience. people get touchy about their code.\n\n> \"This is great work, it's good to prototype these things out\"\n\nRemember: Don't be a dick about it. Don't squeal and wail, not matter how much you want to. People really don't like being told \"You can't do it that way. You do not understand why.\" It's a bad look all round, even if it's true.\n\nEstablish common ground, reframe problem, work towards common goals. Then you can be a dick about it, later. Remember: It's only a little bit less of a dick to be Socratic about it, and ask questions you already know the answer to, so try and be nice where you can.\n\n> \"I don't see a lot of error handling.\"\n\nThere's never any error handling. The message broker is always running, the queue always exists, and the workers never make a mistake, either. That's how prototypes look, sure, but that's how pipelines will look, years later.\n\nThe only thing that changes as pipelines age is the number of graphs on the ops dashboard.\n\n> \"It will be good to work out precisely which things we can leave out of a first implementation. We don't want to lose future feature dev time to operations.\"\n\nYou're not trying to \"shut it down\", you're working out the minimum level of work needed to ship it. You're justifying why with a business case.\n\n> \"What happens when message delivery fails? Maybe there's a network blip, maybe someone tripped over the cable at the data centre?\"\n\nIt's important not to blame the broker, and focus more on \"networks are bad and haunted.\" People will just tell you the broker saves messages to disk, so they're even harder to lose, ignoring the actual problem at hand.\n\n> \"If the send fails, we can just log it instead of doing nothing, and I guess we can restart those thumbnail jobs by hand.\"\n\nAgain, it's time to move on. A log message is fine enough for a first prototype, so don't get hung up on it. A lack of error handling isn't the important point. The important point is \"how much manual work is it going to be to fix things after they go wrong?\"\n\n> \"If something else went wrong, Is there a way to tell which users are missing thumbnails? Or would we have to add logging elsewhere?\"\n\nThe answer's usually something like \"a timestamp in the database\" or something, and another klaxon starts ringing. Resist the urge to explain why timestamps are a bad choice for now, you can revisit it later.\n\nThe important bit is that \"there's some state, in a database\", and for now it only has two states \"needs doing, and has been done\". It'll end up with seven or eight states later on, and that's when you'll have \"the timestamp talk\"\n\n> \"I think the important question is: Can write some .NeedsThumbnail() or .HasThumbnail() function, and then resend those messages? We can worry about the implementation details at the end.\"\n\nThat's right. \"At the end\". Now your coworker should realise it's time for a long haul discussion about the system. Don't miss your chance to recap things.\n\n * you recognise that there's limits to error handling in a prototype\n * you're worried about the manual work required to fix errors\n * with a bit more of a plan, things can move forward\n * working out manual steps required for recovery & seeing if there's low hanging fruit\n\nyou open a shared document. it's called \"background work: operations guide\", and drop a link in the change request.\n\n>  1. lost message\n> \n>  * problem: the service might fail to send a message for a variety of reasons\n>  * solution: we can discover this through logs and alarms\n>  * solution: we can store some state in the database, so it's easy to tell the \"needs thumbnails\" from \"has thumbnails\"\n>  * resolution: we can write scripts to restart lost jobs, or do it manually\n\nwith some aplomb, you write up a series of headings underneath.\n\n>  2. duplicate messages\n>  3. failed thumbnailer\n>  4. head of line\n>  5. statistics / monitoring / debugging\n\nyour coworker is not impressed, but hasn't lost hope yet. maybe they'll ship it by the end of the week. meanwhile, there's a bit of a shit-eating-grin on your face.\n\nerror handling sometimes means running the same thing twice. duplicate handling means avoiding just that. the statistics part is yet another \"tricking them into using the database\" section, broken down into smaller bite sized chunks.\n\nit is time to make your coworker eat their vegetables.\n\n\nSTEP 2: HANDLING DUPLICATES\n\nthe original code didn't really have any deduplication. the worker assumes it's the only one running for that user's thumbnails.\n\nduplication is a always a problem because the recovery steps for \"lost messages\" involve resending potentially lost messages. for example:\n\n * workers stop running overnight\n * message queue builds up\n * workers restart in morning\n * user notices thumbnail is missing, gets manually added to queue by hand\n * now there's two messages in the queue.\n\nit isn't the worst thing in the world if two processes get run at once, but no-one's really sure if it will cause problems, writing to the same files at the same time.\n\nagain, the point of raising this isn't \"this has to be fixed\" but \"we need to understand how it can fail, and how much time will we waste fixing it.\"\n\nsometimes the answer is \"make the process idempotent\", but usually the answer is \"locks\", shortly followed by \"leases\". you'll need to timeout locks eventually, if a worker crashes midway through thumbnailing.\n\n\"well, fuck it, we'll use redis. put a worker_id, timestamp in a hash, and if that timestamp is old, or missing, i can write my own one in.\"\n\nit's not perfect by any means, but it will reduce the operations headache. you update the file and move on.\n\nsometimes the queue has a magical transactional mode, where you can hold onto a message until you've finished processing it, and after a timeout it'll be available for other workers.\n\nit's almost the same thing you're doing with redis, but there's still a little more work to do:\n\n\nSTEP 3: HANDLING FAILED THUMBNAILER.\n\n> \"if a worker takes a message, asks for a lease, and then crashes, how do we retry work?\n> Do we scan the logs by hand again? What if it crashes before being able to log anything?\"\n\nThe usual answer to \"How do we fix it\" is \"Something puts the message back in the queue.\" Your coworker points out that we can fix it in the same way as before. Putting some timestamps in the database. Writing an automated script that restarts old jobs.\n\nYou nod once more, it's still not the right time to argue about timestamps.\n\n> \"Let's call it a message pump. Since it pumps messages into the queue. Also, we should probably keep track of the last error message, and the number of attempts when we do it.\"\n\nIt's ok, it's only adding one JSONB column. One we'll make use of later. Heh heh heh.\n\n> \"There's still one problem left, but I'm not sure it applies.\"\n\n\nSTEP 4: HANDLING HEAD OF LINE BLOCKING (OPTIONAL)\n\nthankfully your coworker was sensible, and suggested using the same automated script as before. if they'd chosen the fancy transactional queue, there'd be a little surprise for them in store: head of line blocking\n\neveryone who has worked with queues usually has a story like this, give or take some details:\n\n 1. for error handling, we used a transactional queue: if a process failed, it returned to the queue.\n 2. one job kept killing all the workers during a period of high load. the worker would crash, and the bad job went back to the top of the list. two people had a screaming match over zoom\n 3. instead of limiting retries, or a time-to-live on the job message, retries are put in a new \"error queue\", with their own workers\n 4. the error queue ends up full of duplicate messages, and all progress on retries is blocked.\n\nyou write \"head of line blocking: not in scope\" and move on. It's at this point you pray for a lightbulb above your coworkers head. Handling lost messages, handling broken thumbnailer runs, ensuring two jobs don't overlap, these are all interlinked. It's far too easy to write error handling that causes more errors.\n\nwith the error handling wrapped up, it's time to move on to the last section. unfortunately for your coworker, this is where the magic happens.\n\nIt's finally time to talk about timestamps.\n\n\nSTEP 6: DEBUGGING / INTROSPECTION\n\nnow you can start asking questions like \"How do we tell if a job has been enqueued or not? how do we tell if a job is being worked on?\" before moving onto \"Actually, how many states can a process be in?\"\n\nwith the queue, it's not possible to find out what things are running, if anything has crashed, and instead all you have is a graph that has three settings:\n\n * Queue's empty. Fine. Or maybe it's broken and no work is happening.\n * Burst of work, but line is going down. Actually fine.\n * Line is going up. Something is not working, and whatever it is, the problem is only getting worse.\n\nMeanwhile, the message broker queue thing as it stands only tracks two things:\n\n * If it's in the queue, this job will be assigned to a worker next.\n * If it's not in the queue, this job will not be assigned to a worker.\n\nIn other words:\n\n * We can't really tell if things are working reliably, outside of a few cases\n * The only thing we know for sure is \"this work is about to be done\"\n\nYour coworker points out that the timestamp thing from earlier would help, and it does. Now you can track two more things:\n\n * When did I last send a message\n * When did a job last complete.\n\nNotice how neither of those two states really tell you anything about what's going on for a particular thumbnail job. You can kinda infer \"this should be run\" if the last send message is older than the job last completing. You can kinda infer \"this ran, but i don't know if it succeeded or not\" if the last send message is earlier than the job completeing.\n\nThat's not a lot to infer. The underlying problem here is that a process can be in way more than two or three states, especially now error handling has come into the mix, and a handful of timestamps won't fix it.\n\nTo be clear: This is the time to yell about timestamps.\n\nYell about having one field called state is way easier than started_at last_active_at completed_at last_error_at, and a nasty series of comparisons. A field with three booleans and a truth table isn't any better, either.\n\nAfter sketching things out with your coworker, you decide that a job can be in several different states:\n\n * initialised: an id or record exists but there's no data inside\n * created: everything needed to start the job is available.\n * enqueued: in the process of being assigned to a worker\n * active: a worker is doing the job\n * failed: a worker encountered a known error, and can be restarted\n * panic: a worker encountered an unknown error\n * timeout: a worker failed to complete the job\n * skipped: no work actually needed\n\n> \"We'll probably combine some of them together, but it's good practice to split things up as much as possible.\"\n\n\nSTEP 7: BUILD A REVISED PLAN\n\nNow you've committed to tracking state in the database, it's time to clean up the proposal.\n\n * we'll have a table of thumbnail jobs in the database\n * each one has a state field, a free text field, and a jsonb column for error handling and other details\n\n> \"We could have a table of thumbnail changes in the database, that gets a new record every time the state changes. It might be more work now, but it's probably easier to have one DB migration than two.\"\n\n * workers read from a queue to find new work, and use a redis lock to exclude others\n * there's a message pump that reads from the database and writes to the queue\n * we don't need to persist any messages in the queue\n\nIt all feels a little overkill, but it really does make a big difference. Unlike before, there's handling in place for all sorts of errors. It's easy to recover from a crashed queue, you just empty it and restart the workers. Plus one quite lovely feature: the message pump can check the queue length, and alert if things stop going down. There's no need to configure an alerting system.\n\nIt's not a lot of code to write. The redis lock code (in lua) is somewhere on stack overflow. The database migration is a pain in the ass to deploy, but it's not difficult to write. Your coworker even adds in the second table, and starts collecting statistical data in the jsonb field to show off.\n\n\nINTERMISSION: YOU HAVE NOT BUILT A PIPELINE, YET\n\nit's a good point to sigh and take a break. you've successfully got a coworker to build a reliable, robust system. one that has automated ways to handle failures, one that doesn't require human intervention on the regular, and one that doesn't remind you of all the awful systems you've suffered so far.\n\nit's a good moment to take a step back and ask \"how come it worked out this time\"\n\n * your coworker actually believes you when you share your experience\n * you aren't forcing people to reinvent your exact solution\n * not every issue is fixed, despite being identified\n * it wasn't about someone being right, or someone being wrong, it was about lowering operational costs\n\nsure enough, sometimes it doesn't work out\n\n * your coworker doesn't care about the operational cost\n * no-one's getting a bonus for taking time to ship things carefully\n * the right thing will only matter at scale, and by that time, who knows what we'll be needing\n\nsometimes it's a little bit like solving a race condition. no-one believes it can be fixed, and when people ask for help, they just want to move the problem elsewhere. turns out \"have you tried explicitly ordering the operations on the shared mutable state\" is not a popular answer, despite being correct. people hate eating their vegetables.\n\neven so, you do win the argument eventually.\n\nthe queue keeps exploding, duplicate messages keep breaking everything. the error handling caused a denial of service. things tend to steer towards \"tracking the state of a job\".\n\nthe broker grows from \"a new central point of failure that always needs more disks\" into \"a lightweight service discovery and work assignment service\", and instead of \"just fire and regret a message\" you have \"the queue buffers the results of a more expensive database query.\"\n\nin fact, we could get rid of the queue entirely, and just use a load balancer\n\n * workers connect to a load balancer instead of a broker\n * scheduler sends http request for each item of work until told to slow down\n * jobs complete in the background and update the database\n\nwe could even get rid of the load balancer, too:\n\n * workers connect to the scheduler, and ask for the next job to perform\n * scheduler hands out jobs one by one as workers scale up or finish tasks\n * like before, scheduler amortises the expensive database query\n * but now? you don't need a lock server\n\nin some ways, you've just moved the queue and locking data structures inside the scheduler, they haven't really gone away. it does, however, let us do a variety of nice things:\n\n * like before, the scheduler can be killed and restarted, as all state is kept in the database\n * scheduler can even spin up more workers as and when required by the load\n * scheduler can offer api for starting jobs, listing jobs, getting status, or watching for changes\n * workers can even report back to the scheduler instead of to the database directly, which lets scheduler check worker is trying to update an active job.\n\nthe best part? the system doesn't really look much like a pipeline.\n\nnow the message pump, the lock, the queue, the worker registration, and the worker assignment, and the recovery processes are all happening in the same place, it feels quite different from slapping messages into a queue and hoping for the best.\n\nit might feel like more work than wrapping shit together in redis, but in some ways there's less complexity going around. as far as the worker is concerned, there's no lock manager, there's no queue, there's no database, just a scheduler api for getting a job and another for progress updates.\n\nit's almost important enough to recap\n\n * keep all the process state in a database table\n * use a text field for state, there's a lot of them\n * use another table if you want to track changes\n * scheduler amortises expensive database queries\n * scheduler keeps track of which worker is active on what\n * workers poll scheduler to be assigned work\n * workers update scheduler, not database, with progress updates / heartbeat messages\n * scheduler orders work to be done by most overdue\n\n[that last one is how you handle restarting errored jobs or missing jobs]\n\nintermission almost over, and we're nearly halfway to the (non) goal.\n\n\nROUND 2: OH NO, MORE PIPELINE!\n\neven if you don't go full tilt and implement the all-in-one scheduler, it might feel like the battle is won. with just a message pump, you're handling all sorts of errors automatically, and it didn't take two sprints to write.\n\nthere's just one problem: someone has suggested splitting up the thumbnailer into seperate processes. that same someone suggests tying the parts back together with a message broker. the pipeline is back, and the same problems are back too.\n\nnot just head of line blocking, but the whole \"have you tried reading the logs\" school of state management.\n\nit's at this point that you start to ask \"why does everyone keep doing it this way?\" and it doesn't take too long to realise that the answer is unix. when people think about batch processing, they think about being at the command line, and chaining up steps together in a unix pipeline\n\nand much like a pipeline, you end up writing something different to make things robust.\n\nat some point, the unix pipeline fails, and you're faced with re-running the entire thing again, or repeating that time honoured unix tradition of breaking up the pipeline a series of Makefile steps, using temporary files for each program's input and output.\n\npipelines aren't really designed for reliability, and in some ways, they're not really designed for task level parallelism either: it's a lot easier to run a 1000 calls to process(item) than it is to run one worker pool for each step in process and wire them up together with queues.\n\nanyway, back to the problem at hand: someone has had the bright idea of connecting things up with a message broker. this time, it's a new coworker, and the argument's a bit different. sure enough, there's the same old story about service discover, or \"free error handling for a problem created by using a broker\" stuff you heard the last time, but now there's \"can scale up and down each worker queue to adjust for load\" too\n\ni've already elaborated at length about why \"don't join things together with queues\" elsewhere, and this post is already quite lengthy in the \"don't use a queue to store background work\" department, so let's cut to the meat of it.\n\n> \"There's no real end-to-end management of the task state, unless you have a database. \"\n\nThe state tracking needs to be back, or messages will fall into the void. The message pump needs to be back, or work won't get restarted after failure. We can add new pipeline-like steps to our improved system, without having to implement the all-in-one scheduler.\n\n> \"We can add new logic to the message pump, and new states to the database table.\"\n\nFine. Keep your queues and your worker pool, but you tell the database when you're done with your step, and the message pump will send off a new task. It's still a little janky, each worker has to know the name of the worker after it to glue everything together, but it'll work fine enough.\n\nThe important part is to not be woken up at night because the queue's exploded. Using a message pump keeps that queue length bounded.\n\nThat's the real problem with queues: There's never any flow control, or a way for a queue to tell clients to slow down. There's always persistence, so you can't drop messages on the floor. There's never bounds on the size of a queue, either. A queue is a machine for turning rpc calls into full disks.\n\nLook, to keep a distributed system running, you need to build a system that aims towards an equilibrium state, slowing things down when other parts can't keep up. A message broker does the exact opposite, allowing parts to get wildly out of sync until you run out of disk space to keep up appearances.\n\nOnce you have backpressure or load shedding atop of a queue, you can't just fire a message away and hope for the best. You need to implement flow control, or error handling. You have to stop pretending the queue is a magic wand.\n\nIt's fine to glue things together with queues. You've just got to avoid persistence, and demand backpressure or load shedding, and you won't end up in the same mess over and over and over again. That's the important bit. That and \"if you run things, you need to keep track of their states\"\n\nAnyway, back to the coworker.\n\n> \"That's not the only route we can go. Your way is to have six worker pools, one for each part of the thumbnail task, shared across every task. Could we have one worker pool, for the whole thumbnail task, and just run the different steps inside the same worker?\"\n\nIt's not much of a change from before. Now the worker updates the database, then runs the next step, then updates the database, and runs the next step, until it runs out of steps. Like before, it's way, way easier to run task() 1,000 times, than it is to run six different pools and queues between them, but not every pipeline can benefit from task-level-parallelism.\n\n> \"... but if we have to do stuff like aggregation, we might have to do something different\"\n\nlet's stop thinking about the janky-ass setup we have so far. remember the all in one scheduler earlier? for task level parallelism, it's pretty straight forwards, we just run all the thumbnail components in one worker, and use the same setup from before:\n\n * we have one big worker pool\n * each worker asks for a task, and which state it's in\n * the worker runs that one part of the code, and reports the output\n * the scheduler decides if that worker runs the next step\n * in other words: the scheduler can decide how to parition the work at runtime\n\nthat's a kinda nice thing to have, but it doesn't clear up running things with task-level parallelism. in this case, the thumbnailer can run one step in parallel for each of the output files it generates.\n\nyour coworker, now fully baptised in the church of state tracking, decides to step in. they're saying stuff like \"it's not a background job system, it's a series of persistent state machines executed in parallel across a shared worker pool\", so you know they've got this.\n\n> \"We just run another task, right? There's one table for thumbnail tasks, right, one per top level thumbnail job. Let's add a second table for subtasks, and a given task can have lots of\n> active subtasks running.\"\n\nIn the all in one scheduler, it looks something like this\n\n * The worker tells the scheduler to start a number of subtasks\n * As the worker asks the scheduler to create a subtask, the scheduler can choose to assign it immediately\n * The original worker polls the scheduler to find out when that subtask completes\n * The original worker moves onto other work.\n * If there's an error, the worker restarts the subtask\n\nApplying it to the redis-and-message-pump prototype, we get:\n\n * There's a redis server providing a lock and a queue\n * The database has a table for the thumbnail task and another table for subtasks\n * There's a message pump, which scans both tables and tops up the message queue with jobs\n * Workers pull out a task or a subtask from the queue, and run it\n * The top level tasks end up just starting other subtasks and waiting for most of the time.\n\nCongratulations: You are the proud author of a not-pipeline. Sure enough, there's task level parallelism, and there's even inter-task level parallelism too. There's duplicate handling, end-to-end error handling with state tracking, and it's easy to ask questions like \"What process is running?\" and \"What error did this thing return with.\" Throw on a web interface, and you can probably move a lot of the support burden to another team.\n\nIt might still smell like a pipeline, but there's those all important differences.\n\n * The queue isn't persistent. You can restart the broker at any time, or drop all messages to go back to a known state.\n * There's backpressure. The message pump can hold off on writing messages if the queue gets too big.\n * There's end-to-end error handling, it doesn't matter if an individual part fails.\n * There's even process supervision. The top level task watches over the smaller ones. Errors in subprocesses can be handled and managed, too.\n * There's task level parallelism. One broken process in one thumbnail doesn't affect other thumbnail tasks.\n * There's inter-task level parallelism. One broken substep doesn't impeded other substeps from running to completetion.\n * The system is always in recovery. Instead of assuming things work, it constantly looks out for overdue tasks, trying to push things back into equilibrium,\n * It's even pretty easy to adapt. Adding new states doesn't require migrations, and the JSONB column gets used to smuggle variables into subtasks. Nice.\n\nMost importantly? This system is the winner of the \"least likely to wake you up at night\" award, handed out by a select set of judges. Not bad for \"a lock and and a queue in redis to amortise an expensive postgres query\"\n\nNot that anyone else notices. The problem with building robust systems is that it's a thankless task that everyone eventually takes for granted. Give it a few months, the new hires will be exclaiming \"Couldn't we just use a message broker. It's so much easier than this mess of queue and redis and database.\"\n\nI blame unix, personally.\n\n\nFINALE: THE PRODUCT\n\nyour coworker has been nerd sniped. they went off and finished the all-in-one scheduler for fun. it turned out to be a little less code than the redis duct tape sandwich in production. they've made some changes\n\nthere's a process table and a 'procedure' table, some of the other names have changed too. they renamed the scheduler to \"operator\". it's a kubernetes term for a daemon that watches a database and runs set actions, very similarly to how an operator works. in some ways, your coworker has written a toolkit for writing a scheduler in.\n\nthey've also started going on about \"microsoft orleans\" and \"entity component systems\" and \"the blackboard pattern.\" you even heard \"tuplespace\" once. they're all \"here's a database that tracks state, persists objects, and here's a series of workers that collaborative update this database to achieve tasks in a distributed or parallel or concurrent style\" looking things, and your coworker really, really wants to keep talking about turning the rather fancy state machines they can build.\n\nwell, at least it's not a pipeline. you hate pipelines, remember?\n\n\nPOSTSCRIPT\n\nyou might wonder and ask me \"is this software something you want to write\", and the answer is \"i have already written this software ten times over, in slightly different forms, all in different jobs\"\n\nin one job, we had a web api for all the little tasks associated with a background process, and we'd even coded a few buttons in. i suggested to coworker that it might be easier to just return a list of actions each thingy could do, over hardcoding each and every one. we even started doing things like returning human facing values in api. a \"state_en\" along with a \"state\" with things like \"Process is running for N hours\" inside.\n\nin another job, the big database of state got copied around from place to place. we ended up using version numbers instead of timestamps. yep, that's right, there's still more timestamp content. the problem with timestamps is that you can't tell if you've missed a version, there's no easy way to handle clock skew, and you don't really know how many times a thing has changed, either. a version number handles all these things, but you'll still need a timestamp to know when a version changed, and you won't care so much about clock skew, then.\n\ni even got to write my own rpc toolkit one of the times. as much as i lament having to rebuild the same internal product in each and every job, i'm not sure i'd have learned so much about distributed systems without it. that, and i'd probably be out of a job if people could actually build batch processing systems as easily as they build websites.\n\nthankfully, this post will change nothing",
    "Confidence": 0.942045
  },
  {
    "Title": "Test Data Generation With AutoFixture in .NET - Code Maze",
    "Url": "https://code-maze.com/csharp-test-data-generation-with-autofixture/",
    "Timestamp": "2023-06-29T11:04:52",
    "Domain": "code-maze.com",
    "Description": "In this article, we will explore how to automate test data generation and enhance productivity with a single library called AutoFixture.",
    "Confidence": 0.9974616
  },
  {
    "Title": "Valve is not willing to publish games with AI generated content anymore",
    "Url": "https://old.reddit.com/r/aigamedev/comments/142j3yt/valve_is_not_willing_to_publish_games_with_ai/",
    "Timestamp": "2023-06-29T09:05:41",
    "Domain": "old.reddit.com",
    "Description": "Hey all, I tried to release a game about a month ago, with a few assets that were fairly obviously AI generated. My plan was to just submit a...",
    "Confidence": 0.8706505
  },
  {
    "Title": "Blazor Basics: Creating a Blazor Component",
    "Url": "https://www.telerik.com/blogs/blazor-basics-creating-blazor-component",
    "Timestamp": "2023-06-29T06:02:53",
    "Domain": "www.telerik.com",
    "Description": "Getting started in Blazor, among the first things to learn are how to create a component, use a template and pass parameters from parent to child components.",
    "Confidence": 0.99623424
  },
  {
    "Title": "7 Things about C#: Console I/O",
    "Url": "https://joemayo.medium.com/7-things-about-c-console-i-o-52fb8cc66cec",
    "Timestamp": "2023-06-29T06:02:49",
    "Domain": "joemayo.medium.com",
    "Description": "The console is the command line, where you type commands to run code and get a response. In general terms, input and output (I/O) describe‚Ä¶",
    "Confidence": 0.99430794
  },
  {
    "Title": "Introducing the .NET MAUI Toolbox for Visual Studio",
    "Url": "https://www.syncfusion.com/blogs/post/dotnet-maui-visual-studio-toolbox.aspx",
    "Timestamp": "2023-06-29T06:02:47",
    "Domain": "www.syncfusion.com",
    "Description": "This blog explains how to install Syncfusion .NET MAUI controls and effectively use them in Visual Studio with the new toolbox support.",
    "Confidence": 0.9976283
  },
  {
    "Title": "Is it too late to fix the problem of AI clutter on the web?",
    "Url": "https://christianheilmann.com/2023/06/28/is-it-too-late-to-fix-the-problem-of-ai-clutter-on-the-web/",
    "Timestamp": "2023-06-29T06:02:45",
    "Domain": "christianheilmann.com",
    "Description": "",
    "Confidence": 0.9644697
  },
  {
    "Title": "LINQ: Select.Where or Where.Select?",
    "Url": "https://steven-giesel.com/blogPost/57ed9867-4afd-4d02-9f35-e0941bc6f715",
    "Timestamp": "2023-06-29T06:02:45",
    "Domain": "steven-giesel.com",
    "Description": "LINQ is a very powerful tool for querying data. As the majority of functions are built on top of IEnumerable<T> and it, in most cases returns IEnumerable<T> as well, it is very easy to chain multiple functions together. That leaves you with a question: which one should I use, Select.Where or Where.Select?\n",
    "Confidence": 0.9948882
  },
  {
    "Title": "Improve the security of your GraphQL API‚Äôs - Part 4‚ÄìPersisted queries",
    "Url": "https://bartwullems.blogspot.com/2023/06/improve-security-of-your-graphql-apis_28.html",
    "Timestamp": "2023-06-29T06:02:45",
    "Domain": "bartwullems.blogspot.com",
    "Description": "As a GraphQL API gives you a lot of extra power and possibilities, it also introduces some new attack vectors. Nothing prevents the user of ...",
    "Confidence": 0.9983791
  },
  {
    "Title": "Curiosity unbounded",
    "Url": "https://www.poppastring.com/blog/curiosity-unbounded",
    "Timestamp": "2023-06-29T05:02:11",
    "Domain": "www.poppastring.com",
    "Description": "An excerpt from the speech given by Sally Kornbluth, MIT‚Äôs 18th ...",
    "Confidence": 0.95648724
  },
  {
    "Title": ".NET Rocks! Going Full Time on Open Source with Shaun Walker",
    "Url": "https://www.dotnetrocks.com/details/1852",
    "Timestamp": "2023-06-29T05:02:11",
    "Domain": "www.dotnetrocks.com",
    "Description": "Can you quit your job and work full-time on your open-source project? Carl and Richard talk to Shaun Walker about his recent move to focus on Oqtane, the open-source application framework and CMS he has been developing for the past few years. Shaun talks about recognizing when an open-source project has matured to the point that it is being held back by not also providing a commercial license. For some folks, a commercial license is not an option - they need it to be able to use the software within the company. Then comes the tricky part: Setting up a business, and balancing the needs of the open-source community with the commercial customers. It isn't easy, but it can be done!",
    "Confidence": 0.9564795
  },
  {
    "Title": "Stack Overflow Dev Survey: VS Code, Visual Studio Still Top IDEs 5 Years Running -- Visual Studio Magazine",
    "Url": "https://visualstudiomagazine.com/articles/2023/06/28/so-2023.aspx",
    "Timestamp": "2023-06-29T01:03:43",
    "Domain": "visualstudiomagazine.com",
    "Description": "Some things never seem to change in the annual SO surveys, like JavaScript being named the top programming language while Microsoft rules in IDEs.",
    "Confidence": 0.94619435
  },
  {
    "Title": "Episode 465 - Functions on Azure Container Apps",
    "Url": "https://azpodcast.azurewebsites.net/post/Episode-465-Functions-on-Azure-Container-Apps",
    "Timestamp": "2023-06-29T01:03:40",
    "Domain": "azpodcast.azurewebsites.net",
    "Description": "The Azure Podcast",
    "Confidence": 0.9935598
  },
  {
    "Title": "Ask the experts: Meet our Engineering team!",
    "Url": "https://youtube.com/watch?v=SOl6LmHM1w8",
    "Timestamp": "2023-06-28T22:05:08",
    "Domain": "youtube.com",
    "Description": "Blog:  https://aka.ms/dotnet/blogTwitter: https://aka.ms/dotnet/twitterTikTok:  https://aka.ms/dotnet/tiktokMastodon:  https://aka.ms/dotnet/mastodonLinkedIn...",
    "Confidence": 0.9993225
  },
  {
    "Title": "How to test GitHub Actions Locally!!!",
    "Url": "https://youtube.com/watch?v=YORvmxQBPeM",
    "Timestamp": "2023-06-28T22:05:08",
    "Domain": "youtube.com",
    "Description": "Are you a developer today that loves to use GitHub Actions but you are constantly interrupted as you wait for them to run in the GitHub portal, taking you ou...",
    "Confidence": 0.8960708
  },
  {
    "Title": "Xamarin Forms Migration to Uno Platform: Data Binding Techniques",
    "Url": "https://platform.uno/blog/xamarin-forms-migration-to-uno-platform-data-binding-techniques/",
    "Timestamp": "2023-06-28T21:02:06",
    "Domain": "platform.uno",
    "Description": "Explore the intricacies of data binding techniques during the migration from Xamarin Forms to Uno Platform. Discover the power of the Model-View-View Model (MVVM) paradigm, learn about dependency properties and attached properties, delve into binding markup and converters, understand formatting strings, utilize commands for actions, leverage compiled bindings for performance, and unlock the potential of x:Bind markup for powerful and efficient data binding",
    "Confidence": 0.970884
  },
  {
    "Title": "On .NET Live - Building full stack applications using gRPC-Web in ASP.NET Core",
    "Url": "https://youtube.com/watch?v=Wa3PbqMx1AM",
    "Timestamp": "2023-06-28T21:02:01",
    "Domain": "youtube.com",
    "Description": "gRPC is a modern, high-performance framework that streamlines messaging between clients and back-end services. In this week's episode, community MVP Swamy Vi...",
    "Confidence": 0.9782197
  },
  {
    "Title": "Password Purgatory - Making Life Hell for Spammers",
    "Url": "https://passwordpurgatory.com/get-hell?kvKey=cab7360f-e059-425b-b151-2a1875f4d909",
    "Timestamp": "2023-06-28T21:01:56",
    "Domain": "passwordpurgatory.com",
    "Description": "Password must contain at least one season of the year: Chloe_spring123",
    "Confidence": 0.96105134
  },
  {
    "Title": "The Smartest Boys On The Internet",
    "Url": "https://www.eschatonblog.com/2023/06/the-smartest-boys-on-internet.html",
    "Timestamp": "2023-06-28T19:02:17",
    "Domain": "www.eschatonblog.com",
    "Description": "The \"lab leak\" theory  was promoted by the usual centrist dipshits because they believed Wokeness had taken control of the entire public hea...",
    "Confidence": 0.6600677
  },
  {
    "Title": "Let's Build a Web Application in Ruby without Rails",
    "Url": "https://www.akshaykhot.com/building-web-application-without-rails/",
    "Timestamp": "2023-06-28T19:02:10",
    "Domain": "www.akshaykhot.com",
    "Description": "Rails is great for building web apps. But it can be quite overwhelming if you don't know how web applications work. In this series of articles, we'll build a simple but complete app in plain Ruby without Rails, to get¬†a deeper understanding and appreciation of everything Rails does for us.",
    "Confidence": 0.99825644
  },
  {
    "Title": "Observations | Trekhleb",
    "Url": "https://trekhleb.dev/blog/2023/observations/",
    "Timestamp": "2023-06-28T19:02:10",
    "Domain": "trekhleb.dev",
    "Description": "My subjective observations, assumptions, questions, and interpretations about the world around us. Don't take it seriously.",
    "Confidence": 0.7132878
  },
  {
    "Title": "Making Games ¬∑ Evan Todd",
    "Url": "https://etodd.io/2023/06/27/making-games/",
    "Timestamp": "2023-06-28T19:02:08",
    "Domain": "etodd.io",
    "Description": "",
    "Confidence": 0.8948207
  },
  {
    "Title": "Don't Emotionally Bootstrap Your Startup ‚Äî Daniel Stillman ",
    "Url": "https://www.danielstillman.com/blog/dont-emotionally-bootstrap-your-startup",
    "Timestamp": "2023-06-28T19:02:07",
    "Domain": "www.danielstillman.com",
    "Description": "‚ÄúSure, my co-founder and I have mild PTSD...but we‚Äôre just knuckling through‚Äù  ‚ÄúYou‚Äôre just knuckling through?‚Äù I replied.  ‚ÄúYes‚Äù  (I paused)  ‚ÄúIf I was a friend of  yours  and  I  told you that  I  had PTSD and that  I  was just knuckling through it, what would you say to me?   ‚Ä¶  A few weeks ago I",
    "Confidence": 0.8842463
  },
  {
    "Title": "How not to build your MVP or The 1-year story of Feedster",
    "Url": "https://andreybazhin.com/how-to-build-your-mvp",
    "Timestamp": "2023-06-28T19:02:07",
    "Domain": "andreybazhin.com",
    "Description": "This is the story of my, almost one-year-long ongoing project called Feedster, how it emerged, pivoted, and where I am so far.\nThe story is a good example of how things easily can be overengineered, and how far descoping can go.\nSolving the own probl...",
    "Confidence": 0.96958864
  },
  {
    "Title": "Why a plant-based diet is a good idea | Koen van Gilst",
    "Url": "https://koenvangilst.nl/blog/plantbased-diet",
    "Timestamp": "2023-06-28T19:02:07",
    "Domain": "koenvangilst.nl",
    "Description": "My arguments in favor of eating less meat.",
    "Confidence": 0.7952865
  },
  {
    "Title": "I build game about Software Development Culture",
    "Url": "https://mitrapunk.com/tech-believes/",
    "Timestamp": "2023-06-28T19:02:06",
    "Domain": "mitrapunk.com",
    "Description": "Explore software development culture through an immersive game, delving into unique 'cults' such as Agile adepts, Remoters, Process cultists.",
    "Confidence": 0.97586536
  },
  {
    "Title": "Running a Marathon with Coach GPT",
    "Url": "https://stuartmitchell.dev/blog/coachgpt/",
    "Timestamp": "2023-06-28T19:02:06",
    "Domain": "stuartmitchell.dev",
    "Description": "How I used chatGPT to train and complete the surf coast trail marathon",
    "Confidence": 0.9236643
  },
  {
    "Title": "On Stress",
    "Url": "https://selectfromwhereand.com/posts/on_stress/",
    "Timestamp": "2023-06-28T19:02:06",
    "Domain": "selectfromwhereand.com",
    "Description": "Stress I‚Äôve been meaning to jot down my thoughts on this for a while, but I keep running into things that tweak my mental model about stress.\nRecently, I watched some old home videos. Twenty years ago, my parents moved us into the home we still live in today. Around this time, my dad filmed a video of my brother and I walking the quarter mile from our house to a canal that runs through metropolitan Phoenix.",
    "Confidence": 0.78120667
  },
  {
    "Title": "I built a perfect note taking system | The Sloth Blog",
    "Url": "https://thesloth.me/posts/6/",
    "Timestamp": "2023-06-28T19:02:06",
    "Domain": "thesloth.me",
    "Description": "Shopping lists, class notes, technical documentation, time and place of important appointment - all of these things are difficult to keep in our heads, therefore we tend to write things down. It doesn‚Äôt matter who you are and which field are you working in, you probably have some kind of note taking system in place. It could be a physical notebook, a pile of post-it notes, the default ‚Äônotes‚Äô app in your phone or perhaps more sophisticated piece of software with advanced note management features.",
    "Confidence": 0.99226326
  },
  {
    "Title": "Active knowledge",
    "Url": "https://surfingcomplexity.blog/2023/06/26/active-knowledge/",
    "Timestamp": "2023-06-28T19:02:06",
    "Domain": "surfingcomplexity.blog",
    "Description": "Existential Comics is an extremely nerdy webcomic about philosophers, written and drawn by Corey Mohler, a software engineer(!). My favorite Existential Comics strip is titled Is a Hotdog a Sandwic‚Ä¶",
    "Confidence": 0.69855237
  },
  {
    "Title": "How to Write a Flexbox Layout Engine",
    "Url": "https://tchayen.com/how-to-write-a-flexbox-layout-engine",
    "Timestamp": "2023-06-28T19:02:06",
    "Domain": "tchayen.com",
    "Description": "You won't guess how little code it takes to write a full-blown layout engine.",
    "Confidence": 0.9916901
  },
  {
    "Title": "How to do templates properly",
    "Url": "https://me.svin.in/how-to-do-templates-properly/",
    "Timestamp": "2023-06-28T19:02:06",
    "Domain": "me.svin.in",
    "Description": "There are numerous templating engines out there. There is:\n Jinja2 - which is standard these days Python‚Äôs Django‚Äôs templates - which are much like jinja2, but not quite Go‚Äôs text/template which claims to be the template engine (hence, the name) Mustache, which is also popular And numerous others  I‚Äôve even recently stumbled upon Calibre‚Äôs (which is an open-source e-book management tool) own custom (!!!) templating engine. The fact that I have to learn another templating engine so that my e-books can be placed into folders is insane.",
    "Confidence": 0.99152696
  },
  {
    "Title": "Extending Context is Hard",
    "Url": "https://kaiokendev.github.io/context",
    "Timestamp": "2023-06-28T19:02:05",
    "Domain": "kaiokendev.github.io",
    "Description": "pages",
    "Confidence": 0.9834917
  },
  {
    "Title": "Noticing when an app is only hosted in us-east-1",
    "Url": "https://blog.jonlu.ca/posts/us-east-1-latency",
    "Timestamp": "2023-06-28T19:02:05",
    "Domain": "blog.jonlu.ca",
    "Description": "Every time I leave New York and land back in Europe or in Asia, I can immediately tell which apps have a global presence and which apps only deploy to a single US region. Everything just immediately feels a little slower. The pull to refresh feels a bit sluggish, the preview images take a little longer to load, and even native apps just feel less responsive.",
    "Confidence": 0.71032137
  },
  {
    "Title": "The Optics",
    "Url": "https://kinduff.com/2023/06/27/the-optics/",
    "Timestamp": "2023-06-28T19:02:05",
    "Domain": "kinduff.com",
    "Description": "The significance of questioning widely-held beliefs and how this can lead to new insights.",
    "Confidence": 0.71984136
  }
]