<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Reading /proc/pid/cmdline can hang forever - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Reading /proc/pid/cmdline can hang forever - linksfor.dev(s)"/>
    <meta property="og:description" content="Back in August, I wrote that&#xA;fork() can fail&#xA;and it made a pretty big splash.  Continuing with that general theme, &#xA;I&#x27;ll tell you about something else that can fail that you probably won&#x27;t &#xA;expect.  It has a failure mode that you&#x27;re probably not equipped to &#xA;handle."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://rachelbythebay.com/w/2014/10/27/ps/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
	<div class="devring" style="background: #222">
		<div class="grid">
			<div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
				<span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
				<a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
				<a href="https://devring.club/random" class="devring-random">Random</a>
				<a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
			</div>
		</div>
	</div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Reading /proc/pid/cmdline can hang forever</title>
<div class="readable">
        <h1>Reading /proc/pid/cmdline can hang forever</h1>
            <div>Reading time: 5-6 minutes</div>
        <div>Posted here: 27 Feb 2019</div>
        <p><a href="https://rachelbythebay.com/w/2014/10/27/ps/">https://rachelbythebay.com/w/2014/10/27/ps/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>

<p>
Back in August, I wrote that
<a href="https://rachelbythebay.com/w/2014/08/19/fork/">fork() can fail</a>
and it made a pretty big splash.  Continuing with that general theme, 
I'll tell you about something else that can fail that you probably won't 
expect.  It has a failure mode that you're probably not equipped to 
handle.
</p><p>
Here's the short version: ps, pgrep, top, and all of those things can 
hang.  I'm talking state D, uninterruptible wait, just like when you 
"cat /something/on/a/nfs/mount" with the server down.  Not even ^C will 
get you out of this one.  It can't be killed.
</p><p>
Do your system maintenance scripts and one-off tools expect things like 
ps and pgrep to hang?  What about pkill?  How about stuff that randomly 
grovels around in /proc looking for bits of data?  I bet they don't.
</p><p>
Now that I've told you what happens, let's work backwards into why.
</p><p>
Linux systems have this wonderful pseudo filesystem called /proc.  You 
can get all sorts of neat data about what's running.  /proc/pid/cmdline 
will tell you more or less what the argv looks like for a given process.  
/proc/pid/exe is probably a link to the actual executable that's running 
(even if it's been deleted).  You get the idea.
</p><p>
Recent Linux systems also have these things called cgroups.  You might 
call them containers.  You can use them to enforce limits on certain 
resources that are smaller than the whole machine provides.  A program 
might be limited to "only" 2 GB of memory instead of the whole 4 GB 
machine, for instance.  You might put caps on how much CPU time it gets, 
which cores it runs on, or how much disk bandwidth it can consume.
</p><p>
The most common use of cgroups I've seen so far is the "memcg" for 
memory limits.  Someone will come along and create a container, set a 
limit on it, then plop some processes into it.  If they grow too big, 
the kernel's OOM killer will fire inside the container, something will 
die, and life goes on.
</p><p>
Assuming you don't run afoul of any kernel bugs in the oomkiller itself, 
you're fine.  No, the problems start when you disable the kernel's OOM 
killer and try to act on your own.
</p><p>
Some process managers have decided they would rather be the ones who 
keep tabs on memory size and do the killing themselves.  To do this, 
they run a task in a container, set a limit, and disable the kernel's 
oomkiller behavior in that container.  Then they wait for notifications 
of it getting too big and kill it themselves.
</p><p>
This is all well and good, but have you ever seen what happens when the 
process manager fails?  Life gets ... interesting.
</p><p>
Now you have a container that's at its limit, and the kernel is saying
"yup, you've gone and done it now", but it's not enforcing those limits 
since you told it to.  All it will do now is stop accesses to that 
memory space until you do something about it.
</p><p>
What this means in practice is that calls which reference memory inside 
the container will hang forever.  Remember /proc/pid/cmdline and 
/proc/pid/exe?  Yeah, bad news.  Those are encumbered by this and 
attempting to read them will get you stuck.  Kiss all of those psutils 
goodbye.  You get to troubleshoot this the hard way.  Certain things 
under /proc/pid will work, but others will not.  You'll get used to 
doing "cat foo &amp;" just to avoid losing yet another login shell.
</p><p>
The most direct method for dealing with this is to scan through your 
memory cgroups (probably under /sys/fs/cgroups/memory, but your mileage 
may vary) and see which of them are reporting being in an OOM condition 
(look for "under_oom 1") and yet have the OOM killer disabled.  To 
verify this is your problem, read the "tasks" pseudo-file in there, get 
a PID of something in the container, then try to access 
/proc/that_pid/cmdline.  If it hangs, that's at least part of your 
problem.
</p><p>
Now you know about the bad cgroup, what can you do?  Well, you can raise 
the limit, and it'll get going again, at least until it grows again and 
hits the new limit.  You can also switch the kernel's enforcer back on 
and let it lay waste to whatever it wants to kill.  I guess you could 
also reboot the machine, but that's just goofy.  It's up to you.
</p><p>
Obviously, you will want to work backwards and find the problems in your 
stack that lead both to the uncontrolled memory growth and the lack of 
handling by your process manager.  Otherwise, you'll be right back here 
again soon.
</p><p>
So really, after this is all said and done and the fire is out, you have 
gained a new little nugget of data.  When a machine starts acting 
strangely, the load average is climbing without bound, commands like "ps
aux" are getting stuck at the same point every time, and you're using 
memory cgroups, you might just be in this situation.
</p><p>
Now you know how to spot it, and what to do about it.
</p><p>
Go make things better.
</p>
</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
		<div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>