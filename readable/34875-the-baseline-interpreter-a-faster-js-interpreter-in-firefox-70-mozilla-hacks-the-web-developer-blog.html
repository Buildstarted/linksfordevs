<!DOCTYPE html>
<html lang="en">
<head>
    <title>
The Baseline Interpreter: a faster JS interpreter in Firefox 70 &#x2013; Mozilla Hacks - the Web developer blog -
linksfor.dev(s)
    </title>
	<link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta charset="utf-8">
    <meta name="Description" content="A curated source of links that devs might find interesting. Updated around the clock." />
    <meta name="google" value="notranslate">
    <style type="text/css">
        html {
            font-family: sans-serif;
            line-height: 1.15;
            -webkit-text-size-adjust: 100%;
            -webkit-tap-highlight-color: transparent;
            height: 100%;
        }

        *, ::after, ::before {
            box-sizing: border-box;
        }

        body {
            margin: 0;
            font-family: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";
            font-size: 1rem;
            font-weight: 400;
            line-height: 1.5;
            color: #60656a;
            text-align: left;
            background-color: #323b44;
        }

        h1 {
            font-size: 6rem;
            font-weight: 300;
            line-height: 1.2;
            margin-top: 0;
            margin-bottom: 0.5rem;
            margin-bottom: 0.5rem
        }

        a {
            color: #007bff;
            color: #ccc;
            text-decoration: none;
            background-color: transparent;
            word-break: break-all;
        }

        .unseen a {
            font-weight: bold;
        }

        h3 {
            margin-top: 0;
            padding-top: 0;
            font-weight: normal;
        }

        .grid {
            -ms-flex-direction: column;
            flex-direction: column;
            width: 1024px;
            margin: 0 auto;
            flex: 1 0 auto;
        }

        .row {
            -ms-flex-direction: row;
            flex-direction: row;
            width: 100%;
            -ms-flex-wrap: wrap;
            flex-wrap: wrap;
            display: -ms-flexbox;
            display: flex;
        }

        .col {
            margin: 0 10px 0 10px;
            box-sizing: border-box;
            vertical-align: top;
        }

        .col-3-of-4, .col-6-of-8, .col-9-of-12 {
            width: calc(75% - 20px);
        }

        .col-1-of-4, .col-2-of-8, .col-3-of-12 {
            width: calc(25% - 20px);
        }

        @media (max-width:1023px) {
            /* big landscape tablets, laptops, and desktops */
            body {
                overflow-x: hidden;
            }

            main {
                width: 99%;
            }

            h1 {
                font-size: 50px;
            }
        }

        .text-right {
            text-align: right;
        }

        footer {
            left: 0;
            width: 100%;
            margin-top: 2em;
            padding: 50px 0;
            text-align: center;
            -moz-box-sizing: border-box;
            -webkit-box-sizing: border-box;
            box-sizing: border-box;
        }

        .readable {
            color: #949ba2;
        }

        svg:not(:root).svg-inline--fa {
            color: #60656a;
            overflow: visible;
        }

        .svg-inline--fa.fa-w-12 {
            width: 0.75em;
        }

        svg:not(:root) {
            overflow: hidden;
        }

        .svg-inline--fa {
            display: inline-block;
            font-size: inherit;
            height: 1em;
            overflow: visible;
            vertical-align: -0.125em;
        }

        img {
            max-width: 100%;
        }

        .text-center {
            text-align: center;
        }

        .readable h1 {
            font-size: 2em;
        }
    </style>
</head>
<body>
    <div class="grid">
        
<div class="readable">
    <h1>The Baseline Interpreter: a faster JS interpreter in Firefox 70 &#x2013; Mozilla Hacks - the Web developer blog</h1>
    <article class="post"> <p>Modern web applications load and execute a lot more JavaScript code than they did just a few years ago. While <a href="https://hacks.mozilla.org/2017/02/a-crash-course-in-just-in-time-jit-compilers/">JIT (just-in-time) compilers</a> have been very successful in making JavaScript performant, we needed a better solution to deal with these new workloads.</p>
<p>To address this, we&#x2019;ve added a new, generated JavaScript bytecode interpreter to the JavaScript engine in Firefox 70. The interpreter is available now in the Firefox Nightly channel, and will go to general release in October. Instead of writing or generating a new interpreter from scratch, we found a way to do this by sharing most code with our existing Baseline JIT.</p>
<p>The new Baseline Interpreter has resulted in performance improvements, memory usage reductions and code simplifications. Here&#x2019;s how we got there:</p>
<h2>Execution tiers</h2>
<p>In modern JavaScript engines, each function is initially executed in a <a href="https://en.wikipedia.org/wiki/Bytecode">bytecode interpreter</a>. Functions that are called a lot (or perform many loop iterations) are compiled to native machine code. (This is called <a href="https://hacks.mozilla.org/2017/02/a-crash-course-in-just-in-time-jit-compilers/">JIT compilation</a>.)</p>
<p>Firefox has an interpreter written in C++ and multiple JIT tiers:</p>
<ul>
<li>The <strong>Baseline JIT</strong>. Each bytecode instruction is compiled directly to a small piece of machine code. It uses <a href="https://en.wikipedia.org/wiki/Inline_caching">Inline Caches (ICs)</a> both as performance optimization and to collect type information for Ion.</li>
<li><strong>IonMonkey</strong> (or just Ion), the optimizing JIT. It uses advanced compiler optimizations to generate fast code for hot functions (at the expense of slower compile times).</li>
</ul>
<p>Ion JIT code for a function can be &#x2018;deoptimized&#x2019; and thrown away for various reasons, for example when the function is called with a new argument type. This is called a <em>bailout</em>. When a bailout happens, execution continues in the Baseline code until the next Ion compilation.</p>
<p>Until Firefox 70, the execution pipeline for a very hot function looked like this:</p>
<p><a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/08/Execution-tiers.svg"><img class="alignnone size-medium wp-image-33762" src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/08/Execution-tiers.svg" alt="Timeline showing C++ Interpreter, Baseline Compilation, Baseline JIT Code, Prepare for Ion, Ion JIT Code with an arrow (called bailout) from Ion JIT Code back to Baseline JIT Code" width="250"></a></p>
<h2>Problems</h2>
<p>Although this works pretty well, we ran into the following problems with the first part of the pipeline (C++ Interpreter and Baseline JIT):</p>
<ol>
<li>Baseline JIT compilation is fast, but modern web applications like Google Docs or Gmail execute so much JavaScript code that we could spend quite some time in the Baseline compiler, compiling thousands of functions.</li>
<li>Because the C++ interpreter is so slow and doesn&#x2019;t collect type information, delaying Baseline compilation or moving it off-thread would have been a performance risk.</li>
<li>As you can see in the diagram above, optimized Ion JIT code was only able to bail out to the Baseline JIT. To make this work, Baseline JIT code required extra metadata (the machine code offset corresponding to each bytecode instruction).</li>
<li>The Baseline JIT had some complicated code for bailouts, debugger support, and exception handling. This was especially true where these features intersect!</li>
</ol>
<h2>Solution: generate a faster interpreter</h2>
<p>We needed type information from the Baseline JIT to enable the more optimized tiers, and we wanted to use JIT compilation for runtime speed. However, the modern web has such large codebases that even the relatively fast Baseline JIT Compiler spent a lot of time compiling. To address this, Firefox 70 adds a new tier called the Baseline Interpreter to the pipeline:</p>
<p><img class="alignnone size-medium wp-image-33763" src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/08/Execution-tiers-new.svg" alt="Same timeline of execution tiers as before but now has the &apos;Baseline Interpreter&apos; between C++ interpreter and Baseline compilation. The bailout arrow points to Baseline Interpreter instead of Baseline JIT Code." width="250"></p>
<p>The Baseline Interpreter sits between the C++ interpreter and the Baseline JIT and has elements from both. It executes all bytecode instructions with a fixed interpreter loop (like the C++ interpreter). In addition, it uses Inline Caches to improve performance and collect type information (like the Baseline JIT).</p>
<p>Generating an interpreter isn&#x2019;t a new idea. However, we found a nice new way to do it by reusing most of the Baseline JIT Compiler code. The Baseline JIT is a template JIT, meaning each bytecode instruction is compiled to a mostly fixed sequence of machine instructions. We generate those sequences into an interpreter loop instead.</p>
<h2>Sharing Inline Caches and profiling data</h2>
<p>As mentioned above, the Baseline JIT uses Inline Caches (ICs) both to make it fast and to help Ion compilation. To get type information, the Ion JIT compiler can inspect the Baseline ICs.</p>
<p>Because we wanted the Baseline Interpreter to use exactly the same Inline Caches and type information as the Baseline JIT, we added a new data structure called <a href="https://searchfox.org/mozilla-central/rev/325c1a707819602feff736f129cb36055ba6d94f/js/src/jit/JitScript.h#54-113">JitScript</a>. JitScript contains all type information and IC data structures used by both the Baseline Interpreter and JIT.</p>
<p>The diagram below shows what this looks like in memory. Each arrow is a pointer in C++. Initially, the function just has a JSScript with the bytecode that can be interpreted by the C++ interpreter. After a few calls/iterations we create the JitScript, attach it to the JSScript and can now run the script in the Baseline Interpreter.</p>
<p>As the code gets warmer we may also create the BaselineScript (Baseline JIT code) and then the IonScript (Ion JIT code).<br>
<a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/08/JIT-script-data-structures.svg"><img class="alignnone size-medium wp-image-33764" src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/08/JIT-script-data-structures.svg" alt="JSScript (bytecode) points to JitScript (IC and profiling data). JitScript points to BaselineScript (Baseline JIT Code) and IonScript (Ion JIT code)." width="250"></a></p>
<p>Note that the Baseline JIT data for a function is now just the machine code. We&#x2019;ve moved all the inline caches and profiling data into JitScript.</p>
<h2>Sharing the frame layout</h2>
<p>The Baseline Interpreter uses the same frame layout as the Baseline JIT, but we&#x2019;ve added some <a href="https://searchfox.org/mozilla-central/rev/325c1a707819602feff736f129cb36055ba6d94f/js/src/jit/BaselineFrame.h#55-58">interpreter-specific fields</a> to the frame. For example, the bytecode PC (program counter), a pointer to the bytecode instruction we are currently executing, is not updated explicitly in Baseline JIT code. It can be determined from the return address if needed, but the Baseline Interpreter has to store it in the frame.</p>
<p>Sharing the frame layout like this has a lot of advantages. We&#x2019;ve made almost no changes to C++ and IC code to support Baseline Interpreter frames&#x2014;they&#x2019;re just like Baseline JIT frames. Furthermore, When the script is warm enough for Baseline JIT compilation, switching from Baseline Interpreter code to Baseline JIT code is a matter of <a href="https://searchfox.org/mozilla-central/rev/8ea946dcf51f0d6400362cc1d49c8d4808eeacf1/js/src/jit/BaselineCodeGen.cpp#1385-1392">jumping from</a> the interpreter code <a href="https://searchfox.org/mozilla-central/rev/8ea946dcf51f0d6400362cc1d49c8d4808eeacf1/js/src/jit/BaselineCodeGen.cpp#1262-1275">into JIT code</a>.</p>
<h2>Sharing code generation</h2>
<p>Because the Baseline Interpreter and JIT are so similar, a lot of the code generation code can be shared too. To do this, we added a templated <a href="https://searchfox.org/mozilla-central/rev/8ea946dcf51f0d6400362cc1d49c8d4808eeacf1/js/src/jit/BaselineCodeGen.h#264-269"><code>BaselineCodeGen</code> base class</a> with two derived classes:</p> <p>The base class has a Handler C++ template argument that can be used to specialize behavior for either the Baseline Interpreter or JIT. A lot of Baseline JIT code can be shared this way. For example, the implementation of the <code>JSOP_GETPROP</code> bytecode instruction (for a property access like <code>obj.foo</code> in JavaScript code) <a href="https://searchfox.org/mozilla-central/rev/8ea946dcf51f0d6400362cc1d49c8d4808eeacf1/js/src/jit/BaselineCodeGen.cpp#3446-3459">is shared code</a>. It calls the <code>emitNextIC</code> helper method that&#x2019;s <a href="https://searchfox.org/mozilla-central/rev/8ea946dcf51f0d6400362cc1d49c8d4808eeacf1/js/src/jit/BaselineCodeGen.cpp#531-588">specialized</a> for either Interpreter or JIT mode.</p>
<h2>Generating the Interpreter</h2>
<p>With all these pieces in place, we were able to implement the <code>BaselineInterpreterGenerator</code> class to generate the Baseline Interpreter! It generates a threaded interpreter loop: The code for each bytecode instruction is <a href="https://searchfox.org/mozilla-central/rev/8ea946dcf51f0d6400362cc1d49c8d4808eeacf1/js/src/jit/BaselineCodeGen.cpp#6920-6922">followed by</a> an indirect jump to the next bytecode instruction.</p>
<p>For example, on x64 we currently generate the following machine code to interpret <a href="https://searchfox.org/mozilla-central/rev/8ea946dcf51f0d6400362cc1d49c8d4808eeacf1/js/src/jit/BaselineCodeGen.cpp#2402-2406"><code>JSOP_ZERO</code></a> (bytecode instruction to push a zero value on the stack):</p>
<pre><code class="js">// Push Int32Value(0).
movabsq $-0x7800000000000, %r11
pushq  %r11
// Increment bytecode pc register.
addq   $0x1, %r14
// Patchable NOP for debugger support.
nopl   (%rax,%rax)
// Load the next opcode.
movzbl (%r14), %ecx
// Jump to interpreter code for the next instruction.
leaq   0x432e(%rip), %rbx
jmpq   *(%rbx,%rcx,8)
</code></pre>
<p>When we enabled the Baseline Interpreter in Firefox Nightly (version 70) back in July, we increased the Baseline JIT warm-up threshold from 10 to 100. The warm-up count is determined by counting the number of calls to the function + the number of loop iterations so far. The Baseline Interpreter has a threshold of 10, same as the old Baseline JIT threshold. This means that the Baseline JIT has a lot less code to compile.</p>
<h2>Results</h2>
<h3>Performance and memory usage</h3>
<p>After this landed in Firefox Nightly our performance testing infrastructure detected several improvements:</p>
<ul>
<li>Various 2-8% <a href="https://treeherder.mozilla.org/perf.html#/alerts?id=21879">page load improvements</a>. A lot happens during page load in addition to JS execution (parsing, style, layout, graphics). Improvements like this are quite significant.</li>
<li>Many devtools performance tests <a href="https://treeherder.mozilla.org/perf.html#/alerts?id=21880">improved by 2-10%</a>.</li>
<li>Some small memory usage wins.</li>
</ul>
<p>Note that we&#x2019;ve landed more performance improvements since this first landed.</p>
<p>To measure how the Baseline Interpreter&#x2019;s performance compares to the C++ Interpreter and the Baseline JIT, I ran Speedometer and Google Docs on Windows 10 64-bit on Mozilla&#x2019;s Try server and enabled the tiers one by one. (The following numbers reflect the best of 7 runs.):<br>
<a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/08/Google-Docs-page-load.svg"><img class="alignnone size-medium wp-image-33765" src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/08/Google-Docs-page-load.svg" alt="C++ Interpreter 901 ms, + Baseline Interpreter 676 ms, + Baseline JIT 633 ms" width="250"></a><br>
On Google Docs we see that the Baseline Interpreter is much faster than just the C++ Interpreter. Enabling the Baseline JIT too makes the page load only a little bit faster.</p>
<p>On the Speedometer benchmark we get noticeably better results when we enable the Baseline JIT tier. The Baseline Interpreter does again much better than just the C++ Interpreter:<br>
<a href="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/08/Speedometer.svg"><img class="alignnone size-medium wp-image-33766" src="https://2r4s9p1yi1fa2jd7j43zph8r-wpengine.netdna-ssl.com/files/2019/08/Speedometer.svg" alt="C++ Interpreter 31 points, + Baseline Interpreter 52 points, + Baseline JIT 69 points" width="250"></a><br>
We think these numbers are great: the Baseline Interpreter is much faster than the C++ Interpreter and its start-up time (JitScript allocation) is much faster than Baseline JIT compilation (at least 10 times faster).</p>
<h3>Simplifications</h3>
<p>After this all landed and stuck, we were able to simplify the Baseline JIT and Ion code by taking advantage of the Baseline Interpreter.</p>
<p>For example, deoptimization bailouts from Ion now resume in the Baseline Interpreter instead of in the Baseline JIT. The interpreter can re-enter Baseline JIT code at the next loop iteration in the JS code. Resuming in the interpreter is much easier than resuming in the middle of Baseline JIT code. We now have to record less metadata for Baseline JIT code, so Baseline JIT compilation got faster too. Similarly, we were able to <a href="https://hg.mozilla.org/mozilla-central/rev/49a2da59aa3e#l3.535">remove a lot of complicated code</a> for debugger support and exception handling.</p>
<h2>What&#x2019;s next?</h2>
<p>With the Baseline Interpreter in place, it should now be possible to move Baseline JIT compilation off-thread. We will be working on that in the coming months, and we anticipate more performance improvements in this area.</p>
<h2>Acknowledgements</h2>
<p>Although I did most of the Baseline Interpreter work, many others contributed to this project. In particular Ted Campbell and Kannan Vijayan reviewed most of the code changes and had great design feedback.</p>
<p>Also thanks to Steven DeTar, Chris Fallin, Havi Hoffman, Yulia Startsev, and Luke Wagner for their feedback on this blog post.</p> <section class="about"> </section> </article>
</div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2019 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
    </footer>
    
</body>
</html>