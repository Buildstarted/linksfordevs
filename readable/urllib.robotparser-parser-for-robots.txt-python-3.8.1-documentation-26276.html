<!DOCTYPE html>
<html lang="en">
<head>
    <title>linksfor.dev(s)</title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    
    <meta property="article:author" content="Buildstarted"/>
    <meta property="og:site_name" content="linksfor.dev(s)" />
    <meta property="og:title" content="linksfor.dev(s)" />
    <meta property="og:type" content="website" />
    <meta property="og:description" content="A curated list of sources of development information including c#, c++, and other dev related links." />
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">ðŸŽ‰</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - urllib.robotparser &#x2014; Parser for robots.txt &#x2014; Python 3.8.2rc1 documentation</title>
<div class="readable">
        <h1>urllib.robotparser &#x2014; Parser for robots.txt &#x2014; Python 3.8.2rc1 documentation</h1>
        <p>
Reading time: 3 minutes        </p>
        <p><a href="https://docs.python.org/3/library/urllib.robotparser.html">https://docs.python.org/3/library/urllib.robotparser.html</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
      <div>
        <div>
          <div role="main">
            
  <div id="module-urllib.robotparser">

<p><strong>Source code:</strong> <a href="https://github.com/python/cpython/tree/3.8/Lib/urllib/robotparser.py">Lib/urllib/robotparser.py</a></p>
<hr id="index-0">
<p>This module provides a single class, <a href="#urllib.robotparser.RobotFileParser" title="urllib.robotparser.RobotFileParser"><code><span>RobotFileParser</span></code></a>, which answers
questions about whether or not a particular user agent can fetch a URL on the
Web site that published the <code><span>robots.txt</span></code> file.  For more details on the
structure of <code><span>robots.txt</span></code> files, see <a href="http://www.robotstxt.org/orig.html">http://www.robotstxt.org/orig.html</a>.</p>
<dl>
<dt id="urllib.robotparser.RobotFileParser">
<em>class </em><code>urllib.robotparser.</code><code>RobotFileParser</code><span>(</span><em>url=''</em><span>)</span><a href="#urllib.robotparser.RobotFileParser" title="Permalink to this definition">Â¶</a></dt>
<dd><p>This class provides methods to read, parse and answer questions about the
<code><span>robots.txt</span></code> file at <em>url</em>.</p>
<dl>
<dt id="urllib.robotparser.RobotFileParser.set_url">
<code>set_url</code><span>(</span><em>url</em><span>)</span><a href="#urllib.robotparser.RobotFileParser.set_url" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets the URL referring to a <code><span>robots.txt</span></code> file.</p>
</dd></dl>

<dl>
<dt id="urllib.robotparser.RobotFileParser.read">
<code>read</code><span>(</span><span>)</span><a href="#urllib.robotparser.RobotFileParser.read" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Reads the <code><span>robots.txt</span></code> URL and feeds it to the parser.</p>
</dd></dl>

<dl>
<dt id="urllib.robotparser.RobotFileParser.parse">
<code>parse</code><span>(</span><em>lines</em><span>)</span><a href="#urllib.robotparser.RobotFileParser.parse" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Parses the lines argument.</p>
</dd></dl>

<dl>
<dt id="urllib.robotparser.RobotFileParser.can_fetch">
<code>can_fetch</code><span>(</span><em>useragent</em>, <em>url</em><span>)</span><a href="#urllib.robotparser.RobotFileParser.can_fetch" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns <code><span>True</span></code> if the <em>useragent</em> is allowed to fetch the <em>url</em>
according to the rules contained in the parsed <code><span>robots.txt</span></code>
file.</p>
</dd></dl>

<dl>
<dt id="urllib.robotparser.RobotFileParser.mtime">
<code>mtime</code><span>(</span><span>)</span><a href="#urllib.robotparser.RobotFileParser.mtime" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns the time the <code><span>robots.txt</span></code> file was last fetched.  This is
useful for long-running web spiders that need to check for new
<code><span>robots.txt</span></code> files periodically.</p>
</dd></dl>

<dl>
<dt id="urllib.robotparser.RobotFileParser.modified">
<code>modified</code><span>(</span><span>)</span><a href="#urllib.robotparser.RobotFileParser.modified" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Sets the time the <code><span>robots.txt</span></code> file was last fetched to the current
time.</p>
</dd></dl>

<dl>
<dt id="urllib.robotparser.RobotFileParser.crawl_delay">
<code>crawl_delay</code><span>(</span><em>useragent</em><span>)</span><a href="#urllib.robotparser.RobotFileParser.crawl_delay" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns the value of the <code><span>Crawl-delay</span></code> parameter from <code><span>robots.txt</span></code>
for the <em>useragent</em> in question.  If there is no such parameter or it
doesnâ€™t apply to the <em>useragent</em> specified or the <code><span>robots.txt</span></code> entry
for this parameter has invalid syntax, return <code><span>None</span></code>.</p>
<p><span>New in version 3.6.</span></p>
</dd></dl>

<dl>
<dt id="urllib.robotparser.RobotFileParser.request_rate">
<code>request_rate</code><span>(</span><em>useragent</em><span>)</span><a href="#urllib.robotparser.RobotFileParser.request_rate" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns the contents of the <code><span>Request-rate</span></code> parameter from
<code><span>robots.txt</span></code> as a <a href="https://docs.python.org/3/glossary.html#term-named-tuple"><span>named tuple</span></a> <code><span>RequestRate(requests,</span> <span>seconds)</span></code>.
If there is no such parameter or it doesnâ€™t apply to the <em>useragent</em>
specified or the <code><span>robots.txt</span></code> entry for this parameter has invalid
syntax, return <code><span>None</span></code>.</p>
<p><span>New in version 3.6.</span></p>
</dd></dl>

<dl>
<dt id="urllib.robotparser.RobotFileParser.site_maps">
<code>site_maps</code><span>(</span><span>)</span><a href="#urllib.robotparser.RobotFileParser.site_maps" title="Permalink to this definition">Â¶</a></dt>
<dd><p>Returns the contents of the <code><span>Sitemap</span></code> parameter from
<code><span>robots.txt</span></code> in the form of a <a href="https://docs.python.org/3/library/stdtypes.html#list" title="list"><code><span>list()</span></code></a>. If there is no such
parameter or the <code><span>robots.txt</span></code> entry for this parameter has
invalid syntax, return <code><span>None</span></code>.</p>
<p><span>New in version 3.8.</span></p>
</dd></dl>

</dd></dl>

<p>The following example demonstrates basic use of the <a href="#urllib.robotparser.RobotFileParser" title="urllib.robotparser.RobotFileParser"><code><span>RobotFileParser</span></code></a>
class:</p>
<div><div><p><span title="Hide the prompts and output">&gt;&gt;&gt;</span></p><pre><span></span><span>&gt;&gt;&gt; </span><span>import</span> <span>urllib.robotparser</span>
<span>&gt;&gt;&gt; </span><span>rp</span> <span>=</span> <span>urllib</span><span>.</span><span>robotparser</span><span>.</span><span>RobotFileParser</span><span>()</span>
<span>&gt;&gt;&gt; </span><span>rp</span><span>.</span><span>set_url</span><span>(</span><span>"http://www.musi-cal.com/robots.txt"</span><span>)</span>
<span>&gt;&gt;&gt; </span><span>rp</span><span>.</span><span>read</span><span>()</span>
<span>&gt;&gt;&gt; </span><span>rrate</span> <span>=</span> <span>rp</span><span>.</span><span>request_rate</span><span>(</span><span>"*"</span><span>)</span>
<span>&gt;&gt;&gt; </span><span>rrate</span><span>.</span><span>requests</span>
<span>3</span>
<span>&gt;&gt;&gt; </span><span>rrate</span><span>.</span><span>seconds</span>
<span>20</span>
<span>&gt;&gt;&gt; </span><span>rp</span><span>.</span><span>crawl_delay</span><span>(</span><span>"*"</span><span>)</span>
<span>6</span>
<span>&gt;&gt;&gt; </span><span>rp</span><span>.</span><span>can_fetch</span><span>(</span><span>"*"</span><span>,</span> <span>"http://www.musi-cal.com/cgi-bin/search?city=San+Francisco"</span><span>)</span>
<span>False</span>
<span>&gt;&gt;&gt; </span><span>rp</span><span>.</span><span>can_fetch</span><span>(</span><span>"*"</span><span>,</span> <span>"http://www.musi-cal.com/"</span><span>)</span>
<span>True</span>
</pre></div>
</div>
</div>


          </div>
        </div>
      </div>
      
      
    </div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>