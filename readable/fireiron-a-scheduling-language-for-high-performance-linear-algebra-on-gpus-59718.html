<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Fireiron: A Scheduling Language for High-Performance Linear Algebra on GPUs - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Fireiron: A Scheduling Language for High-Performance Linear Algebra on GPUs - linksfor.dev(s)"/>
    <meta property="article:author" content="Authors:Bastian Hagedorn, Archibald Samuel Elliott, Henrik Barthels, Rastislav Bodik, Vinod Grover"/>
    <meta property="og:description" content="Achieving high-performance GPU kernels requires optimizing algorithm&#xA;implementations to the targeted GPU architecture. It is of utmost importance to&#xA;fully use the compute and memory hierarchy, as well as available specialised&#xA;hardware. Currently, vendor libraries like cuBLAS and cuDNN provide the best&#xA;performing implementations of GPU algorithms. However the task of the library&#xA;programmer is incredibly challenging: for each provided algorithm,&#xA;high-performance implementations have to be developed for all commonly used&#xA;architectures, input sizes, and different storage formats. These&#xA;implementations are generally provided as optimized assembly code because&#xA;performance-critical architectural features are only exposed at this level.&#xA;This prevents reuse between different implementations of even the same&#xA;algorithm, as simple differences can have major effects on low-level&#xA;implementation details. In this paper we introduce Fireiron, a DSL and compiler&#xA;which allows the specification of high-performance GPU implementations as&#xA;compositions of simple and reusable building blocks. We show how to use&#xA;Fireiron to optimize matrix multiplication implementations, achieving&#xA;performance matching hand-coded CUDA kernels, even when using specialised&#xA;hardware such as NIVIDA Tensor Cores, and outperforming state-of-the-art&#xA;implementations provided by cuBLAS by more than 2x."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://arxiv.org/abs/2003.06324"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Fireiron: A Scheduling Language for High-Performance Linear Algebra on GPUs</title>
<div class="readable">
        <h1>Fireiron: A Scheduling Language for High-Performance Linear Algebra on GPUs</h1>
            <div>by Authors:Bastian Hagedorn, Archibald Samuel Elliott, Henrik Barthels, Rastislav Bodik, Vinod Grover</div>
            <div>Reading time: 2 minutes</div>
        <div>Posted here: 16 Mar 2020</div>
        <p><a href="https://arxiv.org/abs/2003.06324">https://arxiv.org/abs/2003.06324</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">

    
    
    <p>
  
  
  
    
  
  
    
    
  

  (Submitted on 13 Mar 2020)</p>
    <blockquote><span>Abstract:</span>  Achieving high-performance GPU kernels requires optimizing algorithm
implementations to the targeted GPU architecture. It is of utmost importance to
fully use the compute and memory hierarchy, as well as available specialised
hardware. Currently, vendor libraries like cuBLAS and cuDNN provide the best
performing implementations of GPU algorithms. However the task of the library
programmer is incredibly challenging: for each provided algorithm,
high-performance implementations have to be developed for all commonly used
architectures, input sizes, and different storage formats. These
implementations are generally provided as optimized assembly code because
performance-critical architectural features are only exposed at this level.
This prevents reuse between different implementations of even the same
algorithm, as simple differences can have major effects on low-level
implementation details. In this paper we introduce Fireiron, a DSL and compiler
which allows the specification of high-performance GPU implementations as
compositions of simple and reusable building blocks. We show how to use
Fireiron to optimize matrix multiplication implementations, achieving
performance matching hand-coded CUDA kernels, even when using specialised
hardware such as NIVIDA Tensor Cores, and outperforming state-of-the-art
implementations provided by cuBLAS by more than 2x.
</blockquote>
    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Vinod Grover [<a href="https://arxiv.org/show-email/e9bf03fb/2003.06324">view email</a>]
      <br><strong>[v1]</strong>
Fri, 13 Mar 2020 14:40:30 UTC (3,267 KB)<br></p></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
		<div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>