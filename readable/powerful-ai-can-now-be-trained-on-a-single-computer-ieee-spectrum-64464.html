<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Powerful AI Can Now Be Trained on a Single Computer - IEEE Spectrum - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Powerful AI Can Now Be Trained on a Single Computer - IEEE Spectrum - linksfor.dev(s)"/>
    <meta property="article:author" content="By Edd Gent"/>
    <meta property="og:description" content="The enormous computing resources required to train state-of-the-art artificial intelligence systems&#xA0;means well-heeled tech firms are leaving academic teams in the dust. But a new approach could help balance the scales, allowing scientists to tackle cutting-edge AI problems on a single computer."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/powerful-ai-can-now-be-trained-on-a-single-computer"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Powerful AI Can Now Be Trained on a Single Computer - IEEE Spectrum</title>
<div class="readable">
        <h1>Powerful AI Can Now Be Trained on a Single Computer - IEEE Spectrum</h1>
            <div>by By Edd Gent</div>
            <div>Reading time: 6-7 minutes</div>
        <div>Posted here: 18 Jul 2020</div>
        <p><a href="https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/powerful-ai-can-now-be-trained-on-a-single-computer">https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/powerful-ai-can-now-be-trained-on-a-single-computer</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div appgoogleadmobdetail="" apphtmlscrolltoelement="" appjwvideoplayer="" appscriptloader="" id="blog-inner"><p>The enormous computing resources required to train state-of-the-art artificial intelligence systems&nbsp;means well-heeled tech firms are leaving academic teams in the dust. But a new approach could help balance the scales, allowing scientists to tackle cutting-edge AI problems on a single computer.</p> 
<p>A&nbsp;2018 report&nbsp;from <a href="https://openai.com/">OpenAI</a> found the processing power used to train the most powerful AI is increasing at&nbsp;an incredibly fast pace,&nbsp;<a href="https://openai.com/blog/ai-and-compute/">doubling every 3.4 <em>months</em></a>. One of the most data-hungry approaches is deep reinforcement learning, where AI learns through trial and error by iterating through millions of simulations. Impressive recent advances on&nbsp;<a href="https://spectrum.ieee.org/tech-talk/artificial-intelligence/machine-learning/deepminds-ai-shows-itself-to-be-a-worldbeating-world-builder" target="_blank">videogames like Starcraft</a>&nbsp;and Dota2 have relied on servers packed with hundreds of CPUs and GPUs.</p> 
<p>Specialized hardware such as the&nbsp;<a href="https://spectrum.ieee.org/semiconductors/processors/cerebrass-giant-chip-will-smash-deep-learnings-speed-barrier" target="_blank">Cerebras System’s Wafer Scale Engine</a>&nbsp;promises to replace these racks of processors&nbsp;with a single large chip perfectly optimized for training AI. But with a price tag running into the millions, it’s not much solace for under-funded researchers.</p> 
<p>Now a team from the <a href="https://www.usc.edu/">University of Southern California</a> and <a href="https://www.intel.com/content/www/us/en/research/overview.html">Intel Labs</a> have created a way to train deep reinforcement learning (RL) algorithms on hardware commonly available in academic labs. In a&nbsp;<a href="https://arxiv.org/abs/2006.11751" target="_blank">paper</a>&nbsp;presented at the 2020 <a href="https://icml.cc/">International Conference on Machine Learning</a> (ICML)&nbsp;this week, they describe how they were able to use a single high-end workstation to train AI with state-of-the-art performance on the first-person shooter videogame <a href="https://en.wikipedia.org/wiki/Doom_(franchise)">Doom</a>. They also tackle a suite of 30 diverse 3D challenges created by <a href="https://deepmind.com/">DeepMind</a> using a fraction of the normal computing power.</p> 
<p>“Inventing ways to do deep RL on commodity hardware is a fantastic research goal,” says&nbsp;<a href="https://www.cs.utexas.edu/~pstone/" target="_blank">Peter Stone</a>, a professor at the University of Texas at Austin who specializes in deep RL. As well as leaving smaller research groups behind, the computing resources normally required to carry out this kind of research have a significant carbon footprint, he adds. “Any progress towards democratizing RL and reducing the energy needs for doing research is a step in the right direction,” he says.</p> 
<p>The inspiration for the project was a classic case of necessity being the mother of invention, says lead author&nbsp;<a href="https://robotics.usc.edu/resl/people/100/" target="_blank">Aleksei Petrenko</a>, a graduate student at USC. As a summer internship at Intel came to an end, Petrenko lost access to the company’s supercomputing cluster putting unfinished deep RL projects in jeopardy. So he and colleagues decided to find a way to continue the work on simpler systems.</p> 
 
<p>“From my experience, a lot of researchers don’t have access to cutting-edge, fancy hardware,” says Petrenko. “We realized that just by rethinking in terms of maximizing the hardware utilization you can actually approach the performance you will usually squeeze out of a big cluster even on a single workstation.”</p> 
<p>The leading approach to deep RL places an AI agent in a simulated environment that provides rewards for achieving certain goals, which the agent uses as feedback to work out the best strategy. This involves three main computational jobs: simulating the environment and the agent; deciding what to do next next based on learned rules called a policy; and using the results of those actions to update the policy.</p> 
<p>Training is always limited by the slowest process, says Petrenko, but these three jobs are often intertwined in standard deep RL approaches, making it hard to optimize them individually. The researchers’ new approach, dubbed <a href="https://sites.google.com/view/sample-factory">Sample Factory</a>, splits them up so resources can be dedicated to get them all running at peak speeds.</p> 
<p>Piping data between processes is another major bottleneck as these can often be spread across multiple machines, Petrenko explains. His group took advantage of working on a single machine by simply cramming all the data to shared memory where all processes can access it instantaneously.</p> 
<p>This resulted in significant speed-ups compared to leading deep RL approaches. Using a single machine equipped with a 36-core CPU and one GPU, the researchers were able to process roughly 140,000 frames per second while training on Atari videogames and Doom, or double the next best approach. On the 3D training environment&nbsp;<a href="https://deepmind.com/blog/article/open-sourcing-deepmind-lab" target="_blank">DeepMind Lab</a>,&nbsp;they clocked 40,000 frames per second—about 15 percent better than second place.</p> 
<p>To check how frame rate translated into training time the team pitted Sample Factory against<a href="https://ai.googleblog.com/2020/03/massively-scaling-reinforcement.html" target="_blank">&nbsp;an algorithm Google Brain open-sourced in March</a>&nbsp;that is designed to dramatically increase deep RL efficiency. Sample Factory trained on two simple tasks in Doom in a quarter of the time it took the other algorithm. The team also tested their approach on a collection of 30 challenges in DeepMind Lab using a more powerful 36-core 4-GPU machine. The resulting AI significantly outperformed the original AI that DeepMind used to tackle the challenge, which was trained on a large computing cluster.</p> 
<p><a href="https://edbeeching.github.io/" target="_blank">Edward Beeching</a>, a graduate student working on deep RL at the Institut National des Sciences Appliquées de Lyon, in France, says the approach might struggle with memory intensive challenges like the photo-realistic 3D simulator&nbsp;<a href="https://aihabitat.org/" target="_blank">Habitat</a>&nbsp;released by Facebook last year.</p> 
<p>But he adds that these kinds of efficient training approaches are vitally important for smaller research teams. “A four-fold increase compared to the state of the art implementation is huge,” he says. “This means in the same time you can run four times as many experiments.”</p> 
<p>While the computers used in the paper are still high-end workstations designed for AI research, Petrenko says he and his collaborators have also been using Sample Factory on much simpler devices. He’s even been able to run some advanced&nbsp;<span>deep RL experiments</span> on his mid-range gaming laptop, he says. “This is unheard of.”</p></div></div></div>
    </div>
    <footer>
        <div>created by <a href="https://buildstarted.com">buildstarted</a> &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>