<!DOCTYPE html>
<html lang="en">
<head>
    <title>
firefox&#x27;s low-latency webassembly compiler -- wingolog - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="firefox&#x27;s low-latency webassembly compiler -- wingolog - linksfor.dev(s)"/>
    <meta property="og:description" content="Good day!"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="http://wingolog.org/archives/2020/03/25/firefoxs-low-latency-webassembly-compiler"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - firefox&#x27;s low-latency webassembly compiler -- wingolog</title>
<div class="readable">
        <h1>firefox&#x27;s low-latency webassembly compiler -- wingolog</h1>
            <div>Reading time: 13-17 minutes</div>
        <div>Posted here: 27 Mar 2020</div>
        <p><a href="http://wingolog.org/archives/2020/03/25/firefoxs-low-latency-webassembly-compiler">http://wingolog.org/archives/2020/03/25/firefoxs-low-latency-webassembly-compiler</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div><div><p>Good day!</p><p>Today I'd like to write a bit about the WebAssembly baseline compiler in Firefox.</p><p><b>background: throughput and latency</b></p><p>WebAssembly, as you know, is a virtual machine that is present in web browsers like Firefox.  An important initial goal for WebAssembly was to be a good target for compiling programs written in C or C++.  You can visit a web page that includes a program written in C++ and compiled to WebAssembly, and that WebAssembly module will be downloaded onto your computer and run by the web browser.</p><p>A good virtual machine for C and C++ has to be fast.  The <i>throughput</i> of a program compiled to WebAssembly (the amount of work it can get done per unit time) should be approximately the same as its throughput when compiled to "native" code (x86-64, ARMv7, etc.).  WebAssembly meets this goal by defining an instruction set that consists of similar operations to those directly supported by CPUs; WebAssembly implementations use optimizing compilers to translate this portable instruction set into native code.</p><p>There is another dimension of fast, though: not just work per unit time, but also time until first work is produced.  If you want to go play <a href="http://wasm.continuation-labs.com/d3demo/">Doom 3 on the web</a>, you care about frames per second but also time to first frame.  Therefore, WebAssembly was designed not just for high throughput but also for low latency.  This focus on low-latency compilation expresses itself in two ways: binary size and binary layout.</p><p>On the size front, WebAssembly is optimized to encode small files, reducing download time.  One way in which this happens is to use a <a href="https://webassembly.github.io/spec/core/binary/values.html#integers">variable-length encoding</a> anywhere an instruction needs to specify an integer.  In the usual case where, for example, there are fewer than 128 local variables, this means that a <a href="https://webassembly.github.io/spec/core/syntax/instructions.html#syntax-instr-variable"><tt>local.get</tt> instruction</a> can refer to a local variable using just one byte.  Another strategy is that WebAssembly programs target a stack machine, reducing the need for the instruction stream to explicitly load operands or store results.  Note that size optimization only goes so far: it's assumed that the bytes of the encoded module will be compressed by gzip or some other algorithm, so sub-byte entropy coding is out of scope.</p><p>On the layout side, the WebAssembly binary encoding is sorted by design:  definitions come before uses.  For example, there is a <a href="https://webassembly.github.io/spec/core/binary/modules.html#binary-typesec">section of type definitions</a> that occurs early in a WebAssembly module.  Any use of a declared type can only come after the definition.  In the case of functions which are of course mutually recursive, function type declarations come before the actual definitions.  In theory this allows web browsers to take a one-pass, streaming approach to compilation, starting to compile as functions arrive and before download is complete.</p><p><b>implementation strategies</b></p><p>The goals of high throughput and low latency conflict with each other.  To get best throughput, a compiler needs to spend time on code motion, register allocation, and instruction selection; to get low latency, that's exactly what a compiler should not do.  Web browsers therefore take a two-pronged approach: they have a compiler optimized for throughput, and a compiler optimized for latency.  As a WebAssembly file is being downloaded, it is first compiled by the quick-and-dirty low-latency compiler, with the goal of producing machine code as soon as possible.  After that "baseline" compiler has run, the "optimizing" compiler works in the background to produce high-throughput code.  The optimizing compiler can take more time because it runs on a separate thread.  When the optimizing compiler is done, it replaces the baseline code.  (<a href="https://searchfox.org/mozilla-central/source/js/src/wasm/WasmCompile.cpp#270-418">The actual heuristics about whether to do baseline + optimizing ("tiering") or just to go straight to the optimizing compiler are a bit hairy</a>, but this is a summary.)</p><p>This article is about the WebAssembly baseline compiler in Firefox.  It's a surprising bit of code and I learned a few things from it.</p><p><b>design questions</b></p><p>Knowing what you know about the goals and design of WebAssembly, how would you implement a low-latency compiler?</p><p>It's a question worth thinking about so I will give you a bit of space in which to do so.</p><p>.</p><p>.</p><p>.</p><p>After spending a lot of time in Firefox's WebAssembly baseline compiler, I have extracted the following principles:</p><ol>
<li><p>The function is the unit of compilation</p></li>
<li><p>One pass, and one pass only</p></li>
<li><p>Lean into the stack machine</p></li>
<li><p>No noodling!</p></li>
</ol><p>In the remainder of this article we'll look into these individual points.  Note, although I have done a good bit of hacking on this compiler, its design and original implementation comes mainly from Mozilla hacker Lars Hansen, who also currently maintains it.  All errors of exegesis are mine, of course!</p><p><b>the function is the unit of compilation</b></p><p>As we mentioned, in the binary encoding of a WebAssembly module, all definitions needed by any function come before all function definitions.  This naturally leads to a partition between two phases of bytestream parsing: an initial serial phase that collects the set of global type definitions, annotations as to which functions are imported and exported, and so on, and a subsequent phase that compiles individual functions in an essentially independent manner.</p><p>The advantage of this approach is that compiling functions is a natural task unit of parallelism.  If the user has a machine with 8 virtual cores, the web browser can keep one or two cores for the browser itself and farm out WebAssembly compilation tasks to the rest.  The result is that the compiled code is available sooner.</p><p>Taking functions to be the unit of compilation also allows for an easy "tier-up" mechanism: after the baseline compiler is done, the optimizing compiler can take more time to produce better code, and when it is done, it can swap out the results on a per-function level.  All function calls from the baseline compiler go through a jump table indirection, to allow for tier-up.  In SpiderMonkey there is no mechanism currently to tier down; if you need to debug WebAssembly code, you need to refresh the page, causing the wasm code to be compiled in debugging mode.  For the record, SpiderMonkey can only tier up at function calls (it doesn't do OSR).</p><p>This simple approach does have some down-sides, in that it leaves intraprocedural optimizations on the table (inlining, contification, custom calling conventions, speculative optimizations).  This is mitigated in two ways, the most obvious being that LLVM or whatever produced the WebAssembly has ideally already done whatever inlining might be fruitful.  The second is that WebAssembly is designed for predictable performance.  In JavaScript, an implementation needs to do run-time type feedback and speculative optimizations to get good performance, but the result is that it can be hard to understand why a program is fast or slow.  The designers and implementers of WebAssembly in browsers all had first-hand experience with JavaScript virtual machines, and actively wanted to avoid unpredictable performance in WebAssembly.  Therefore there is currently a kind of d√©tente among the various browser vendors, that everyone has agreed that they won't do speculative inlining -- yet, anyway.  Who knows what will happen in the future, though.</p><p>Digressing, the summary here is that the baseline compiler receives an individual function body as input, and generates code just for that function.</p><p><b>one pass, and one pass only</b></p><p>The WebAssembly baseline compiler makes one pass through the bytecode of a function.  Nowhere in all of this are we going to build an abstract syntax tree or a graph of basic blocks.  Let's follow through how that works.</p><p>Firstly, <a href="https://searchfox.org/mozilla-central/source/js/src/wasm/WasmBaselineCompile.cpp#12827"><tt>emitFunction</tt></a> simply emits a prologue, then the body, then an epilogue.  <tt>emitBody</tt> is basically a <a href="https://searchfox.org/mozilla-central/source/js/src/wasm/WasmBaselineCompile.cpp#11813">big loop</a> that consumes opcodes from the instruction stream, dispatching to opcode-specific code emitters (e.g. <a href="https://searchfox.org/mozilla-central/source/js/src/wasm/WasmBaselineCompile.cpp#7440"><tt>emitAddI32</tt></a>).</p><p>The opcode-specific code emitters are also responsible for validating their arguments; for example, <tt>emitAddI32</tt> is wrapped in an <a href="https://searchfox.org/mozilla-central/source/js/src/wasm/WasmBaselineCompile.cpp#11821">assertion that there are two <tt>i32</tt> values on the stack</a>.  This validation logic is shared by a templatized <a href="https://searchfox.org/mozilla-central/source/js/src/wasm/WasmOpIter.h#549">codestream iterator</a> so that it can be re-used by the optimizing compiler, as well as by the publicly-exposed <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/WebAssembly/validate"><tt>WebAssembly.validate</tt></a> function.</p><p>A corollary of this approach is that machine code is emitted in bytestream order; if the WebAssembly instruction stream has an <tt>i32.add</tt> followed by a <tt>i32.sub</tt>, then the machine code will have an <tt>addl</tt> followed by a <tt>subl</tt>.</p><p>WebAssembly has a syntactically limited form of non-local control flow; it's not <tt>goto</tt>.  Instead, instructions are contained in a tree of nested <i>control blocks</i>, and control can only exit nonlocally to a containing control block.  There are three kinds of control blocks:  jumping to a <tt>block</tt> or an <tt>if</tt> will continue at the end of the block, whereas jumping to a <tt>loop</tt> will continue at its beginning.  In either case, as the compiler keeps a stack of nested control blocks, it has the set of valid jump targets and can use the usual assembler logic to patch forward jump addresses when the compiler gets to the block exit.</p><p><b>lean into the stack machine</b></p><p>This is the interesting bit!  So, WebAssembly instructions target a stack machine.  That is to say, there's an abstract stack onto which evaluating <tt>i32.const 32</tt> pushes a value, and if followed by <tt>i32.const 10</tt> there would then be <tt>i32(32) | i32(10)</tt> on the stack (where new elements are added on the right).  A subsequent <tt>i32.add</tt> would pop the two values off, and push on the result, leaving the stack as <tt>i32(42)</tt>.  There is also a fixed set of local variables, declared at the beginning of the function.</p><p>The easiest thing that a compiler can do, then, when faced with a stack machine, is to emit code for a stack machine: as values are pushed on the abstract stack, emit code that pushes them on the machine stack.</p><p>The downside of this approach is that you emit a fair amount of code to do read and write values from the stack.  Machine instructions generally take arguments from registers and write results to registers; going to memory is a bit superfluous.  We're willing to accept suboptimal code generation for this quick-and-dirty compiler, but isn't there something smarter we can do for ephemeral intermediate values?</p><p>Turns out -- yes!  The baseline compiler keeps an abstract <a href="https://searchfox.org/mozilla-central/source/js/src/wasm/WasmBaselineCompile.cpp#2097"><i>value stack</i></a> as it compiles.  For example, compiling <tt>i32.const 32</tt> pushes nothing on the machine stack: it just adds a <tt>ConstI32</tt> node to the value stack.  When an instruction needs an operand that turns out to be a <tt>ConstI32</tt>, it can either encode the operand as an immediate argument or <a href="https://searchfox.org/mozilla-central/source/js/src/wasm/WasmBaselineCompile.cpp#3730">load it into a register</a>.</p><p>Say we are evaluating the <tt>i32.add</tt> discussed above.  After the add, where does the result go?  For the baseline compiler, the answer is always "in a register" via pushing a new <tt>RegisterI32</tt> entry on the value stack.  The baseline compiler includes a <a href="https://searchfox.org/mozilla-central/source/js/src/wasm/WasmBaselineCompile.cpp#742">stupid register allocator</a> that <a href="https://searchfox.org/mozilla-central/source/js/src/wasm/WasmBaselineCompile.cpp#3456">spills the value stack to the machine stack if no register is available</a>, updating value stack entries from e.g. <tt>RegisterI32</tt> to <tt>MemI32</tt>.  Note, a <tt>ConstI32</tt> never needs to be spilled:  its value can always be reloaded as an immediate.</p><p>The end result is that the baseline compiler avoids lots of stack store and load code generation, which speeds up the compiler, and happens to make faster code as well.</p><p>Note that there is one limitation, currently: control-flow joins can have multiple predecessors and can pass a value (in the current WebAssembly specification), so the allocation of that value needs to be agreed-upon by all predecessors.  As in this code:</p><pre>(func $f (param $arg i32) (result i32)
  (block $b (result i32)
    (i32.const 0)
    (local.get $arg)
    (i32.eqz)
    (br_if $b) ;; return 0 from $b if $arg is zero
    (drop)
    (i32.const 1))) ;; otherwise return 1
;; result of block implicitly returned
</pre><p>When the <tt>br_if</tt> branches to the block end, where should it put the result value?  The baseline compiler effectively punts on this question and just puts it in a well-known register (e.g., <tt>$rax</tt> on x86-64).  Results for block exits are the only place where WebAssembly has "phi" variables, and the baseline compiler allocates all integer phi variables to the same register.  A hack, but there we are.</p><p><b>no noodling!</b></p><p>When I started to hack on the baseline compiler, I did a lot of code reading, and eventually came on code like this:</p><pre>void BaseCompiler::emitAddI32() {
  int32_t c;
  if (popConstI32(&amp;c)) {
    RegI32 r = popI32();
    masm.add32(Imm32(c), r);
    pushI32(r);
  } else {
    RegI32 r, rs;
    pop2xI32(&amp;r, &amp;rs);
    masm.add32(rs, r);
    freeI32(rs);
    pushI32(r);
  }
}
</pre><p>I said to myself, this is silly, why are we only emitting the add-immediate code if the constant is on top of the stack?  What if instead the constant was the deeper of the two operands, why do we then load the constant into a register?  I asked on the chat channel if it would be OK if I improved codegen here and got a response I was not expecting: no noodling!</p><p>The reason is, performance of baseline-compiled code essentially doesn't matter.  Obviously let's not pessimize things but the reason there's a baseline compiler is to emit code quickly.  If we start to add more code to the baseline compiler, the compiler itself will slow down.</p><p>For that reason, changes are only accepted to the baseline compiler if they are necessary for some reason, <i>or</i> if they improve latency as measured using some real-world benchmark (time-to-first-frame on Doom 3, for example).</p><p>This to me was a real eye-opener: a compiler optimized not for the quality of the code that it generates, but rather for how fast it can produce the code.  I had seen this in action before but this example really brought it home to me.</p><p>The focus on compiler throughput rather than compiled-code throughput makes it pretty gnarly to hack on the baseline compiler -- care has to be taken when adding new features not to significantly regress the old.  It is much more like hacking on a production JavaScript parser than your traditional SSA-based compiler.</p><p><b>that's a wrap!</b></p><p>So that's the WebAssembly baseline compiler in SpiderMonkey / Firefox.  Until the next time, happy hacking!</p></div></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>