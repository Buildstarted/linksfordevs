<!DOCTYPE html>
<html lang="en">
<head>
    <title>
English to SQL: progess updates - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.min.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="English to SQL: progess updates - linksfor.dev(s)"/>
    <meta property="og:description" content="English to SQL translation is getting better!  Can you guess which of&#xA;these queries to find the actor appearing in the most movies (in a fictional dataset)&#xA;was written by a human, and which by machine?"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://paulfitz.github.io/2020/08/01/translate-english-to-sql-progress-updates.html"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1 style="margin: unset">
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - English to SQL: progess updates</title>
<div class="readable">
        <h1>English to SQL: progess updates</h1>
            <div>Reading time: 6-8 minutes</div>
        <div>Posted here: 01 Aug 2020</div>
        <p><a href="https://paulfitz.github.io/2020/08/01/translate-english-to-sql-progress-updates.html">https://paulfitz.github.io/2020/08/01/translate-english-to-sql-progress-updates.html</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
<p>English to SQL translation is getting better!  Can you guess which of
these queries to find the actor appearing in the most movies (in a fictional dataset)
was written by a human, and which by machine?</p>

<p><img src="https://paulfitz.github.io/images/db/most_films.png" alt="a human query, or is it"></p>

<p><img src="https://paulfitz.github.io/images/db/machine.png" alt="a machine query, or is it"></p>

<p>Well ok yes you probably can, but the point is they are both pretty good!</p>

<p>In early 2019, when I
was looking for published models for text to SQL translation, I had the most joy with one
called <a href="https://github.com/naver/sqlova/">SQLova</a> (<a href="https://news.ycombinator.com/item?id=20101381">Hacker News discussion from that time</a>).
SQLova was trained on the <a href="https://github.com/salesforce/WikiSQL">WikiSQL</a> dataset, a collection of natural
language questions and SQL queries for tables drawn from Wikipedia.
Part of what made SQLova work well was using BERT to transform its input.
<a href="https://jalammar.github.io/illustrated-bert/">BERT</a> is a model released in 2018 for generic NLP tasks, trained on
BooksCorpus and English Wikipedia, that led to a wave of
state-of-the-art improvements in all sorts of language problems as
people bolted it on to their models.  That wave continues to this day,
and BERT‚Äôs descendants get better and better.</p>

<p>SQLova was limited to queries on a single table, 
which is not the most interesting use to make of relational databases.
In 2018 the <a href="https://yale-lily.github.io/spider">Spider dataset</a> had been released, with questions and queries
involving multiple tables, so I was looking forward to models showing up
trained on that.  <a href="https://github.com/microsoft/IRNet">IRNet</a> come out with a pretrained model in late 2019, and I started
playing with it.  It was great to see joins and more complex clauses
coming into play.  But a downside of work benchmarked on the Spider dataset
was that the benchmark didn‚Äôt include what is called ‚Äúvalue‚Äù prediction
(such as figuring out parameters in a query), and research code developed with
Spider in mind often skipped that.  This makes sense from a research perspective,
but generates incomplete queries.</p>

<p>I noticed a network called <a href="https://github.com/brunnurs/valuenet">ValueNet</a> released recently.
Building on IRNet, it adds on some machinery for guessing values, and generally makes more of an
effort to produce fully executable queries.  I appreciate that.  Let‚Äôs try it out!</p>

<p>As a concrete example, let‚Äôs use the Sakila database,
as introduced on the <a href="https://www.jooq.org/sakila">jook website</a>.
This is a (fictional) database about movie rentals from physical stores back
when that was a thing.  It has 16 tables, with a rich relational
structure:</p>

<p><img src="https://paulfitz.github.io/images/db/sakila.png" alt="a database schema"></p>

<p>On the <a href="https://www.jooq.org/sakila">jook website</a>, they give an
example of a (human-written) query that ‚Äúfinds the actor with most films‚Äù:</p>

<p><img src="https://paulfitz.github.io/images/db/most_films.png" alt="human query for acting-est actor"></p>

<p>Let‚Äôs see what ValueNet can do:</p>

<p><img src="https://paulfitz.github.io/images/db/made_most_movies_id.png" alt="machine query for acting-est actor"></p>

<p>(I wrote movies rather than films because I‚Äôve lived in the United
States too long, but it works either way).
The SQL looks plausible!  It picked the right tables, relations,
and aggregations. But the answer is just an ID.  Let‚Äôs be
more explicit that we want a name:</p>

<p><img src="https://paulfitz.github.io/images/db/made_most_movies_first_name.png" alt="give me a name"></p>

<p>Gina!  Looks like the result matches what the human got.  ValueNet gave
us a name, but in a begrudging way, just the first name.  Let‚Äôs get
more specific again and ask for a full name:</p>

<p><img src="https://paulfitz.github.io/images/db/made_most_movies_full_name.png" alt="a full name"></p>

<p>Neat, it gave us all the name parts in the table.  It didn‚Äôt know
how to construct a full name but <a href="https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/">who does really</a>.
To match the human query, let‚Äôs also ask how many films this Gina
person acted in:</p>

<p><img src="https://paulfitz.github.io/images/db/made_most_movies_full_name_and_count.png" alt="how many movies"></p>

<p>That was a pleasant experience.  There was no cherry-picking here, I downloaded
the database and tried it on ValueNet and this is what I got.  It‚Äôd be nice if
the network could better guess what full set of information is useful to give, but it was
definitely helpful.  Also, compared to single-table operation in Sqlova, I am
excited to see the network picking good tables to look at from the soup available,
and relating them appropriately.</p>

<p>The <a href="https://www.jooq.org/sakila">jook website</a> goes on to give another
example (human-written) query to ‚Äúcalculate the cumulative revenue of all stores‚Äù:</p>

<p><img src="https://paulfitz.github.io/images/db/cumulative_revenue_real.png" alt="human query for revenue"></p>

<p>That‚Äôs a mouthful.  Let‚Äôs see what ValueNet does:</p>

<p><img src="https://paulfitz.github.io/images/db/cumulative_revenue.png" alt="machine query for revenue"></p>

<p>That‚Äôs not bad!  It figured out the relevant tables and columns.
I couldn‚Äôt nudge ValueNet to break this down by day though.
Understandable, since there is nothing structured around days
in the database.  I‚Äôd expect the next generation of models
to be able to get that kind of thing though, given that
GPT-3 could no doubt write a detailed essay about it.</p>

<p>As a consolation prize, I asked for a break-down by movie, which I got
without fuss:</p>

<p><img src="https://paulfitz.github.io/images/db/revenue_per_movie.png" alt="revenue per movie"></p>

<p>Neat!  And the great thing is, you don‚Äôt need to take my word about
any of this, this is not some <a href="https://twitter.com/FaraazNishtar/status/1285934622891667457">massive network behind an invite-only
API</a> like some networks I could mention üòâ.  Just go to
<a href="https://github.com/brunnurs/valuenet">https://github.com/brunnurs/valuenet</a>
and follow their instructions.</p>

<p>My experience with research code in this area is that it is often
difficult to run on data outside of the dataset it is benchmarked on,
since the pipeline for pre-processing that data can be hard to nail
down.  I‚Äôve made a docker image specifically for running ValueNet on
fresh data, and without a GPU (since you don‚Äôt need it for inference
really).  Also, to make the whole thing self-contained, I ripped out a
use of Google‚Äôs Named Entity Recognition API and replaced it with
something from spacy.  If you have docker, and it is configured so it
can use lots of RAM (3GB or so?), then you can do:</p>

<figure><pre><code data-lang="bash"><span>$ </span>wget https://paulfitz.github.io/files/sakila.db
<span>$ </span>docker run <span>--name</span> valuenet <span>-d</span> <span>-p</span> 5050:5050 paulfitz/valuenet
<span># wait a while</span>
<span>$ </span>curl <span>-F</span> <span>"sqlite=@sakila.db"</span> <span>-F</span> <span>"q=what is the title of the longest film"</span> http://localhost:5050
<span># {"result":{"answer":[["CHICAGO NORTH"]],"sql":"SELECT T1.title FROM film AS T1    ORDER BY T1.length DESC LIMIT 1"},"split":"case_1db37f79-bbfe-4d70-a367-13e785f5e180"}</span>
<span>$ </span>curl <span>-F</span> <span>"sqlite=@sakila.db"</span> <span>-F</span> <span>"q=what is the full name of the actress whose last name is 'WITHERSPOON'"</span> http://localhost:5050
<span># {"result":{"answer":[["ANGELA","WITHERSPOON"]],"sql":"SELECT T1.first_name, T1.last_name FROM actor AS T1 WHERE T1.last_name = 'WITHERSPOON'"},"split":"case_2cbddbed-2704-4037-8a4a-82e9a8a0f3a2"}</span></code></pre></figure>

<p>There‚Äôs more information at <a href="https://github.com/paulfitz/mlsql#valuenet">https://github.com/paulfitz/mlsql</a>.</p>

<p>How we query databases is ripe for a transformation.  Companies have
been developing and releasing natural language interfaces for decades.
But outside of niche uses they‚Äôve so far been more trouble than they
are worth - brittle, inflexible, lacking common sense.
But the field of natural language processing has evolved a lot, to the
point where we now have access to representations that are far more
robust, flexible, and - if not exactly having common sense - encode a
lot of knowledge about relationships between currencies, names,
chronology, phone numbers, movies, discounts, street names, airports,
email addresses, menus, pokemon, and so on.
I‚Äôm looking forward to database query engines that know know more of that!</p>

</div></div></div>
    </div>
    <footer>
        <div>created by <a href="https://buildstarted.com">buildstarted</a> &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>