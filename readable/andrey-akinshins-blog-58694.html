<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Andrey Akinshin&#x27;s blog - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Andrey Akinshin&#x27;s blog - linksfor.dev(s)"/>
    <meta property="article:author" content="Andrey Akinshin"/>
    <meta property="og:description" content="Andrey Akinshin&#x27;s blog"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://aakinshin.net/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">ðŸŽ‰</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Andrey Akinshin&#x27;s blog</title>
<div class="readable">
        <h1>Andrey Akinshin&#x27;s blog</h1>
        <p>
by Andrey Akinshin <br/>Reading time: 10-13 minutes        </p>
        <p><a href="https://aakinshin.net/">https://aakinshin.net/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
    <div>
        <h2 id="distribution-comparison-via-the-shift-and-ratio-functions"><a aria-label="Anchor" data-anchorjs-icon="Â§" href="#distribution-comparison-via-the-shift-and-ratio-functions"></a><a href="https://aakinshin.net/posts/shift-and-ratio-functions/">Distribution comparison via the shift and ratio functions</a></h2>
        <p><span>
          <b>Date:</b> October 11, 2019.
          <b>Tags:</b>
                <a href="https://aakinshin.net/tags/statistics"><span>Statistics</span></a>
        </span></p><p>When we compare two distributions, it's not always enough to detect a statistically significant difference between them.
In many cases, we also want to evaluate the magnitude of this difference.
Let's look at the following image:</p>
<div>
<a href="https://aakinshin.net/img/posts/shift-and-ratio-functions/compare1-light.png" target="_blank">
<picture>
<source theme="dark" srcset="/img/posts/shift-and-ratio-functions/compare1-dark.png" media="none">
<source theme="light" srcset="/img/posts/shift-and-ratio-functions/compare1-light.png" media="all">
<img width="800" src="https://aakinshin.net/img/posts/shift-and-ratio-functions/compare1-light.png">
</picture>
</a>
</div>
<p>On the left side, we can see a timeline plot with 2000 points
(at the middle of this plot, the distribution was significantly changed).
On the right side, you can see density plots for the left and the right side of
the timeline plot (before and after the change).
It's a pretty simple case, the difference between distributions be expressed via the
difference between mean values.</p>
<p>Now let's look at a more tricky case:</p>
<div>
<a href="https://aakinshin.net/img/posts/shift-and-ratio-functions/compare2-light.png" target="_blank">
<picture>
<source theme="dark" srcset="/img/posts/shift-and-ratio-functions/compare2-dark.png" media="none">
<source theme="light" srcset="/img/posts/shift-and-ratio-functions/compare2-light.png" media="all">
<img width="800" src="https://aakinshin.net/img/posts/shift-and-ratio-functions/compare2-light.png">
</picture>
</a>
</div>
<p>Here we have a bimodal distribution; after the change, the left mode "moved right."
Now it's much harder to evaluate the difference between distributions
because the mean and the median values almost not changed:
the right mode has the biggest impact on these metrics than the left more.</p>
<p>And here is a much more tricky case:</p>
<div>
<a href="https://aakinshin.net/img/posts/shift-and-ratio-functions/compare3-light.png" target="_blank">
<picture>
<source theme="dark" srcset="/img/posts/shift-and-ratio-functions/compare3-dark.png" media="none">
<source theme="light" srcset="/img/posts/shift-and-ratio-functions/compare3-light.png" media="all">
<img width="800" src="https://aakinshin.net/img/posts/shift-and-ratio-functions/compare3-light.png">
</picture>
</a>
</div>
<p>Here we also have a bimodal distribution; after the change, both modes moved:
the left mode "moved right" and the right mode "moved left."
How should we describe the difference between these distributions now?</p>

        <p><a href="https://aakinshin.net/posts/shift-and-ratio-functions/">Read more</a></p><hr>
    </div>
    <div>
        <h2 id="normality-is-a-myth"><a aria-label="Anchor" data-anchorjs-icon="Â§" href="#normality-is-a-myth"></a><a href="https://aakinshin.net/posts/normality/">Normality is a myth</a></h2>
        <p><span>
          <b>Date:</b> October 09, 2019.
          <b>Tags:</b>
                <a href="https://aakinshin.net/tags/statistics"><span>Statistics</span></a>
                <a href="https://aakinshin.net/tags/normality"><span>Normality</span></a>
                <a href="https://aakinshin.net/tags/central-limit-theorem"><span>Central Limit Theorem</span></a>
                <a href="https://aakinshin.net/tags/performance"><span>Performance</span></a>
                <a href="https://aakinshin.net/tags/r"><span>R</span></a>
        </span></p><p>In many statistical papers, you can find the following phrase: "assuming that we have a normal distribution."
Probably, you saw plots of the normal distribution density function in some statistics textbooks,
it looks like this:</p>
<div>
<a href="https://aakinshin.net/img/posts/normality/normal-light.png" target="_blank">
<picture>
<source theme="dark" srcset="/img/posts/normality/normal-dark.png" media="none">
<source theme="light" srcset="/img/posts/normality/normal-light.png" media="all">
<img width="800" src="https://aakinshin.net/img/posts/normality/normal-light.png">
</picture>
</a>
</div>
<p>The normal distribution is a pretty user-friendly mental model when we are trying to interpret the statistical metrics
like mean and standard deviation.
However, it may also be an insidious and misleading model when your distribution is not normal.
There is a great sentence in the <a href="https://doi.org/10.1093/biomet/34.3-4.209">"Testing for normality"</a> paper by R.C. Geary, 1947 (the quote was found <a href="https://garstats.wordpress.com/2019/06/17/myth/">here</a>):</p>
<blockquote>
<p>Normality is a myth; there never was, and never will be, a normal distribution.</p>
</blockquote>
<p>I 100% agree with this statement.
At least, if you are working with performance distributions
(that are based on the multiple iterations of your benchmarks that measure the performance metrics of your applications),
you should forget about normality.
That's how a typical performance distribution looks like
(I built the below picture based on a real benchmark that measures the load time of assemblies
when we open the <a href="https://github.com/OrchardCMS/Orchard">Orchard</a> solution in <a href="https://www.jetbrains.com/rider/">Rider</a> on Linux):</p>
<div>
<a href="https://aakinshin.net/img/posts/normality/performance-light.png" target="_blank">
<picture>
<source theme="dark" srcset="/img/posts/normality/performance-dark.png" media="none">
<source theme="light" srcset="/img/posts/normality/performance-light.png" media="all">
<img width="800" src="https://aakinshin.net/img/posts/normality/performance-light.png">
</picture>
</a>
</div>

        <p><a href="https://aakinshin.net/posts/normality/">Read more</a></p><hr>
    </div>
    <div>
        <h2 id="implementation-of-efficient-algorithm-for-changepoint-detection"><a aria-label="Anchor" data-anchorjs-icon="Â§" href="#implementation-of-efficient-algorithm-for-changepoint-detection"></a><a href="https://aakinshin.net/posts/edpelt/">Implementation of efficient algorithm for changepoint detection: ED-PELT</a></h2>
        <p><span>
          <b>Date:</b> October 07, 2019.
          <b>Tags:</b>
                <a href="https://aakinshin.net/tags/dotnet"><span>.NET</span></a>
                <a href="https://aakinshin.net/tags/csharp"><span>C#</span></a>
                <a href="https://aakinshin.net/tags/ed-pelt"><span>ED-PELT</span></a>
                <a href="https://aakinshin.net/tags/statistics"><span>Statistics</span></a>
                <a href="https://aakinshin.net/tags/changepoints"><span>ChangePoints</span></a>
        </span></p><p><a href="https://en.wikipedia.org/wiki/Change_detection">Changepoint detection</a> is an important task that has a lot of applications.
For example, I use it to detect changes in the <a href="https://www.jetbrains.com/rider/">Rider</a> performance test suite.
It's very important to detect not only performance degradations, but any kinds of performance changes
(e.g., the variance may increase, or a unimodal distribution may be split to several modes).
You can see examples of such changes on the following picture (we change the color when a changepoint is detected):</p>
<div>
<a href="https://aakinshin.net/img/posts/edpelt/edpelt-light.png" target="_blank">
<picture>
<source theme="dark" srcset="/img/posts/edpelt/edpelt-dark.png" media="none">
<source theme="light" srcset="/img/posts/edpelt/edpelt-light.png" media="all">
<img width="600" src="https://aakinshin.net/img/posts/edpelt/edpelt-light.png">
</picture>
</a>
</div>
<p>Unfortunately, it's pretty hard to write a reliable and fast algorithm for changepoint detection.
Recently, I found a cool paper (<a href="https://link.springer.com/article/10.1007/s11222-016-9687-5">Haynes, K., Fearnhead, P. &amp; Eckley, I.A. "A computationally efficient nonparametric approach for changepoint detection," Stat Comput (2017) 27: 1293</a>) that describes the ED-PELT algorithm.
It has <code>O(N*log(N))</code> complexity and pretty good detection accuracy.
The reference implementation can be used via the <a href="https://cran.r-project.org/web/packages/changepoint.np/index.html">changepoint.np</a> R package.
However, I can't use <a href="https://www.r-project.org/">R</a> on our build server, so I decided to write my own C# implementation.</p>

        <p><a href="https://aakinshin.net/posts/edpelt/">Read more</a></p><hr>
    </div>
    <div>
        <h2 id="a-story-about-slow-nuget-package-browsing"><a aria-label="Anchor" data-anchorjs-icon="Â§" href="#a-story-about-slow-nuget-package-browsing"></a><a href="https://aakinshin.net/posts/nuget-package-browsing/">A story about slow NuGet package browsing</a></h2>
        <p><span>
          <b>Date:</b> May 08, 2018.
          <b>Tags:</b>
                <a href="https://aakinshin.net/tags/nuget"><span>NuGet</span></a>
                <a href="https://aakinshin.net/tags/rider"><span>Rider</span></a>
        </span></p><p>In <a href="https://www.jetbrains.com/rider/">Rider</a>, we have integration tests which interact with <a href="https://api.nuget.org/">api.nuget.org</a>.
Also, we have an internal service which monitors the performance of these tests.
Two days ago, I noticed that some of these tests sometimes are running for too long.
For example, <code>nuget_NuGetTest_shouldUpgradeVersionForDotNetCore</code> usually takes around <code>10 sec</code>.
However, in some cases, it takes around <code>110 sec</code>, <code>210 sec</code>, or <code>310 sec</code>:</p>
<p><a href="https://aakinshin.net/img/posts/nuget-package-browsing/perf-chart.png" target="_blank"><img width="600" src="https://aakinshin.net/img/posts/nuget-package-browsing/perf-chart.png"></a></p>
<p>It looks very suspicious and increases the whole test suite duration.
Also, our dashboard with performance degradations contains only such tests
and some real degradations (which are introduced by the changes in our codebase) can go unnoticed.
So, my colleagues and I decided to investigate it.</p>

        <p><a href="https://aakinshin.net/posts/nuget-package-browsing/">Read more</a></p><hr>
    </div>
    <div>
        <h2 id="cross-runtime-net-disassembly-with-benchmarkdotnet"><a aria-label="Anchor" data-anchorjs-icon="Â§" href="#cross-runtime-net-disassembly-with-benchmarkdotnet"></a><a href="https://aakinshin.net/posts/dotnet-crossruntime-disasm/">Cross-runtime .NET disassembly with BenchmarkDotNet</a></h2>
        <p><span>
          <b>Date:</b> April 10, 2018.
          <b>Tags:</b>
                <a href="https://aakinshin.net/tags/dotnet"><span>.NET</span></a>
                <a href="https://aakinshin.net/tags/csharp"><span>C#</span></a>
                <a href="https://aakinshin.net/tags/benchmarkdotnet"><span>BenchmarkDotNet</span></a>
                <a href="https://aakinshin.net/tags/benchmarking"><span>benchmarking</span></a>
                <a href="https://aakinshin.net/tags/disassembly"><span>disassembly</span></a>
        </span></p><p><a href="https://github.com/dotnet/BenchmarkDotNet">BenchmarkDotNet</a> is a cool tool for benchmarking.
It has a lot of useful features that help you with performance investigations.
However, you can use these features even if you are not actually going to benchmark something.
One of these features is <code>DisassemblyDiagnoser</code>.
It shows you a disassembly listing of your code for all required runtimes.
In this post, I will show you how to get disassembly listing for .NET Framework, .NET Core, and Mono with one click!
You can do it with a very small code snippet like this:</p>
<pre><code>[<span>DryCoreJob, DryMonoJob, DryClrJob(Platform.X86)</span>]
[<span>DisassemblyDiagnoser</span>]
<span>public</span> <span>class</span> <span>IntroDisasm</span>
{
    [<span>Benchmark</span>]
    <span><span>public</span> <span>double</span> <span>Sum</span>(<span></span>)</span>
    {
        <span>double</span> res = <span>0</span>;
        <span>for</span> (<span>int</span> i = <span>0</span>; i &lt; <span>64</span>; i++)
            res += i;
        <span>return</span> res;
    }
}
</code></pre>

        <p><a href="https://aakinshin.net/posts/dotnet-crossruntime-disasm/">Read more</a></p><hr>
    </div>
    <div>
        <h2 id="benchmarkdotnet-v0-10-14"><a aria-label="Anchor" data-anchorjs-icon="Â§" href="#benchmarkdotnet-v0-10-14"></a><a href="https://aakinshin.net/posts/bdn-v0_10_14/">BenchmarkDotNet v0.10.14</a></h2>
        <p><span>
          <b>Date:</b> April 09, 2018.
          <b>Tags:</b>
                <a href="https://aakinshin.net/tags/dotnet"><span>.NET</span></a>
                <a href="https://aakinshin.net/tags/csharp"><span>C#</span></a>
                <a href="https://aakinshin.net/tags/benchmarkdotnet"><span>BenchmarkDotNet</span></a>
                <a href="https://aakinshin.net/tags/benchmarking"><span>benchmarking</span></a>
        </span></p><p>BenchmarkDotNet v0.10.14 has been released! This release includes:</p>
<ul>
<li><strong>Per-method parameterization</strong> (<a href="http://benchmarkdotnet.org/Advanced/Arguments.htm">Read more</a>)</li>
<li><strong>Console histograms and multimodal disribution detection</strong> (<a href="https://aakinshin.net/blog/post/dotnet-crossruntime-disasm/">Read more</a>)</li>
<li><strong>Many improvements for Mono disassembly support on Windows</strong> (A blog post is coming soon)</li>
<li><strong>Many bugfixes</strong></li>
</ul>
<p>In the <a href="https://github.com/dotnet/BenchmarkDotNet/issues?q=milestone:v0.10.14">v0.10.14</a> scope,
8 issues were resolved and 11 pull requests where merged.
This release includes 47 commits by 8 contributors.</p>

        <p><a href="https://aakinshin.net/posts/bdn-v0_10_14/">Read more</a></p><hr>
    </div>
    <div>
        <h2 id="benchmarkdotnet-v0-10-13"><a aria-label="Anchor" data-anchorjs-icon="Â§" href="#benchmarkdotnet-v0-10-13"></a><a href="https://aakinshin.net/posts/bdn-v0_10_13/">BenchmarkDotNet v0.10.13</a></h2>
        <p><span>
          <b>Date:</b> March 02, 2018.
          <b>Tags:</b>
                <a href="https://aakinshin.net/tags/dotnet"><span>.NET</span></a>
                <a href="https://aakinshin.net/tags/csharp"><span>C#</span></a>
                <a href="https://aakinshin.net/tags/benchmarkdotnet"><span>BenchmarkDotNet</span></a>
                <a href="https://aakinshin.net/tags/benchmarking"><span>benchmarking</span></a>
        </span></p><p>BenchmarkDotNet v0.10.13 has been released! This release includes:</p>
<ul>
<li><strong>Mono Support for DisassemblyDiagnoser:</strong>
Now you can easily get an assembly listing not only on .NET Framework/.NET Core, but also on Mono.
It works on Linux, macOS, and Windows (Windows requires installed cygwin with <code>obj</code> and <code>as</code>).
(See <a href="https://github.com/dotnet/BenchmarkDotNet/issues/541">#541</a>)</li>
<li><strong>Support ANY CoreFX and CoreCLR builds:</strong>
BenchmarkDotNet allows the users to run their benchmarks against ANY CoreCLR and CoreFX builds.
You can compare your local build vs MyGet feed or Debug vs Release or one version vs another.
(See <a href="https://github.com/dotnet/BenchmarkDotNet/issues/651">#651</a>)</li>
<li><strong>C# 7.2 support</strong>
(See <a href="https://github.com/dotnet/BenchmarkDotNet/issues/643">#643</a>)</li>
<li><strong>.NET 4.7.1 support</strong>
(See <a href="https://github.com/dotnet/BenchmarkDotNet/commit/28aa946a9a277b6c2b1166af0397134b02bedf2d">28aa94</a>)</li>
<li><strong>Support Visual Basic project files (.vbroj) targeting .NET Core</strong>
(See <a href="https://github.com/dotnet/BenchmarkDotNet/issues/626">#626</a>)</li>
<li><strong>DisassemblyDiagnoser now supports generic types</strong>
(See <a href="https://github.com/dotnet/BenchmarkDotNet/issues/640">#640</a>)</li>
<li><strong>Now it's possible to benchmark both Mono and .NET Core from the same app</strong>
(See <a href="https://github.com/dotnet/BenchmarkDotNet/issues/653">#653</a>)</li>
<li><strong>Many bug fixes</strong>
(See details below)</li>
</ul>

        <p><a href="https://aakinshin.net/posts/bdn-v0_10_13/">Read more</a></p><hr>
    </div>
    <div>
        <h2 id="analyzing-distribution-of-mono-gc-collections"><a aria-label="Anchor" data-anchorjs-icon="Â§" href="#analyzing-distribution-of-mono-gc-collections"></a><a href="https://aakinshin.net/posts/mono-gc-collects/">Analyzing distribution of Mono GC collections</a></h2>
        <p><span>
          <b>Date:</b> February 20, 2018.
          <b>Tags:</b>
                <a href="https://aakinshin.net/tags/dotnet"><span>.NET</span></a>
                <a href="https://aakinshin.net/tags/csharp"><span>C#</span></a>
                <a href="https://aakinshin.net/tags/r"><span>R</span></a>
                <a href="https://aakinshin.net/tags/rider"><span>Rider</span></a>
                <a href="https://aakinshin.net/tags/mono"><span>Mono</span></a>
                <a href="https://aakinshin.net/tags/gc"><span>GC</span></a>
        </span></p><p>Sometimes I want to understand the GC performance impact on an application quickly.
I know that there are many powerful diagnostic tools and approaches,
but I'm a fan of the "right tool for the job" idea.
In simple cases, I prefer simple noninvasive approaches which provide a quick way
to get an overview of the current situation
(if everything is terrible, I always can switch to an advanced approach).
Today I want to share with you my favorite way to quickly get statistics
of GC pauses in Mono and generate nice plots like this:</p>
<p><a href="https://aakinshin.net/img/posts/mono-gc-collects/plot-64.png" target="_blank"><img width="600" src="https://aakinshin.net/img/posts/mono-gc-collects/plot-64.png"></a></p>

        <p><a href="https://aakinshin.net/posts/mono-gc-collects/">Read more</a></p><hr>
    </div>
    <div>
        <h2 id="benchmarkdotnet-v0-10-12"><a aria-label="Anchor" data-anchorjs-icon="Â§" href="#benchmarkdotnet-v0-10-12"></a><a href="https://aakinshin.net/posts/bdn-v0_10_12/">BenchmarkDotNet v0.10.12</a></h2>
        <p><span>
          <b>Date:</b> January 15, 2018.
          <b>Tags:</b>
                <a href="https://aakinshin.net/tags/dotnet"><span>.NET</span></a>
                <a href="https://aakinshin.net/tags/csharp"><span>C#</span></a>
                <a href="https://aakinshin.net/tags/benchmarkdotnet"><span>BenchmarkDotNet</span></a>
                <a href="https://aakinshin.net/tags/benchmarking"><span>benchmarking</span></a>
        </span></p><p>BenchmarkDotNet v0.10.12 has been released! This release includes:</p>
<ul>
<li><strong>Improved DisassemblyDiagnoser:</strong>
BenchmarkDotNet contains an embedded disassembler so that it can print assembly code for all benchmarks;
it's not easy, but the disassembler evolves in every release.</li>
<li><strong>Improved MemoryDiagnoser:</strong>
it has a better precision level, and it takes less time to evaluate memory allocations in a benchmark.</li>
<li><strong>New TailCallDiagnoser:</strong>
now you get notifications when JIT applies the tail call optimizations to your methods.</li>
<li><strong>Better environment info:</strong>
when your share performance results, it's very important to share information about your environment.
The library generates the environment summary for you by default.
Now it contains information about the amount of physical CPU, physical cores, and logic cores.
If you run a benchmark on a virtual machine, you will get the name of the hypervisor
(e.g., Hyper-V, VMware, or VirtualBox).</li>
<li><strong>Better summary table:</strong>
one of the greatest features of BenchmarkDotNet is the summary table.
It shows all important information about results in a compact and understandable form.
Now it has better customization options: you can display relative performance of different environments
(e.g., compare .NET Framework and .NET Core) and group benchmarks by categories.</li>
<li><strong>New GC settings:</strong> now we support <code>NoAffinitize</code>, <code>HeapAffinitizeMask</code>, <code>HeapCount</code>.</li>
<li>Other minor improvements and bug fixes</li>
</ul>

        <p><a href="https://aakinshin.net/posts/bdn-v0_10_12/">Read more</a></p><hr>
    </div>
    <div>
        <h2 id="benchmarkdotnet-v0-10-10"><a aria-label="Anchor" data-anchorjs-icon="Â§" href="#benchmarkdotnet-v0-10-10"></a><a href="https://aakinshin.net/posts/bdn-v0_10_10/">BenchmarkDotNet v0.10.10</a></h2>
        <p><span>
          <b>Date:</b> November 03, 2017.
          <b>Tags:</b>
                <a href="https://aakinshin.net/tags/dotnet"><span>.NET</span></a>
                <a href="https://aakinshin.net/tags/csharp"><span>C#</span></a>
                <a href="https://aakinshin.net/tags/benchmarkdotnet"><span>BenchmarkDotNet</span></a>
                <a href="https://aakinshin.net/tags/benchmarking"><span>benchmarking</span></a>
        </span></p><p>BenchmarkDotNet v0.10.10 has been released!
This release includes many new features like Disassembly Diagnoser, ParamsSources, .NET Core x86 support, Environment variables, and more!</p>

        <p><a href="https://aakinshin.net/posts/bdn-v0_10_10/">Read more</a></p><hr>
    </div>
</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>