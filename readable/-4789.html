<!DOCTYPE html>
<html lang="en">
<head>
    <title>linksfor.dev(s)</title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">ðŸŽ‰</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Automatic Recognition of Facial Displays of Unfelt Emotions</title>
<div class="readable">
        <h1>Automatic Recognition of Facial Displays of Unfelt Emotions</h1>
        <p>
by (Submitted on 13 Jul 2017 (v1), last revised 9 Jan 2018 (this version, v2)) <br/>Reading time: 2 minutes        </p>
        <p><a href="https://arxiv.org/abs/1707.04061">https://arxiv.org/abs/1707.04061</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">

    
    
    
    <blockquote><span>Abstract:</span>  Humans modify their facial expressions in order to communicate their internal
states and sometimes to mislead observers regarding their true emotional
states. Evidence in experimental psychology shows that discriminative facial
responses are short and subtle. This suggests that such behavior would be
easier to distinguish when captured in high resolution at an increased frame
rate. We are proposing SASE-FE, the first dataset of facial expressions that
are either congruent or incongruent with underlying emotion states. We show
that overall the problem of recognizing whether facial movements are
expressions of authentic emotions or not can be successfully addressed by
learning spatio-temporal representations of the data. For this purpose, we
propose a method that aggregates features along fiducial trajectories in a
deeply learnt space. Performance of the proposed model shows that on average it
is easier to distinguish among genuine facial expressions of emotion than among
unfelt facial expressions of emotion and that certain emotion pairs such as
contempt and disgust are more difficult to distinguish than the rest.
Furthermore, the proposed methodology improves state of the art results on CK+
and OULU-CASIA datasets for video emotion recognition, and achieves competitive
results when classifying facial action units on BP4D datase.
</blockquote>
    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Ciprian Corneanu [<a href="https://arxiv.org/show-email/366a45b4/1707.04061">view email</a>]
      <br>
  <strong><a href="https://arxiv.org/abs/1707.04061v1">[v1]</a></strong>
  Thu, 13 Jul 2017 10:57:31 UTC (7,207 KB)<br><strong>[v2]</strong>
Tue, 9 Jan 2018 11:44:01 UTC (5,996 KB)<br></p></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>