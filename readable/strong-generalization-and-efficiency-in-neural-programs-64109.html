<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Strong Generalization and Efficiency in Neural Programs - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Strong Generalization and Efficiency in Neural Programs - linksfor.dev(s)"/>
    <meta property="article:author" content="[Submitted on 7 Jul 2020 (v1), last revised 8 Jul 2020 (this version, v2)]"/>
    <meta property="og:description" content="We study the problem of learning efficient algorithms that strongly&#xA;generalize in the framework of neural program induction. By carefully designing&#xA;the input / output interfaces of the neural model and through imitation, we are&#xA;able to learn models that produce correct results for arbitrary input sizes,&#xA;achieving strong generalization. Moreover, by using reinforcement learning, we&#xA;optimize for program efficiency metrics, and discover new algorithms that&#xA;surpass the teacher used in imitation. With this, our approach can learn to&#xA;outperform custom-written solutions for a variety of problems, as we tested it&#xA;on sorting, searching in ordered lists and the NP-complete 0/1 knapsack&#xA;problem, which sets a notable milestone in the field of Neural Program&#xA;Induction. As highlights, our learned model can perform sorting perfectly on&#xA;any input data size we tested on, with $O(n log n)$ complexity, whilst&#xA;outperforming hand-coded algorithms, including quick sort, in number of&#xA;operations even for list sizes far beyond those seen during training."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://arxiv.org/abs/2007.03629"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Strong Generalization and Efficiency in Neural Programs</title>
<div class="readable">
        <h1>Strong Generalization and Efficiency in Neural Programs</h1>
            <div>by [Submitted on 7 Jul 2020 (v1), last revised 8 Jul 2020 (this version, v2)]</div>
            <div>Reading time: 2 minutes</div>
        <div>Posted here: 10 Jul 2020</div>
        <p><a href="https://arxiv.org/abs/2007.03629">https://arxiv.org/abs/2007.03629</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    
      
    
  
    <p><a href="https://arxiv.org/pdf/2007.03629">Download PDF</a></p><blockquote>
      <span>Abstract:</span>  We study the problem of learning efficient algorithms that strongly
generalize in the framework of neural program induction. By carefully designing
the input / output interfaces of the neural model and through imitation, we are
able to learn models that produce correct results for arbitrary input sizes,
achieving strong generalization. Moreover, by using reinforcement learning, we
optimize for program efficiency metrics, and discover new algorithms that
surpass the teacher used in imitation. With this, our approach can learn to
outperform custom-written solutions for a variety of problems, as we tested it
on sorting, searching in ordered lists and the NP-complete 0/1 knapsack
problem, which sets a notable milestone in the field of Neural Program
Induction. As highlights, our learned model can perform sorting perfectly on
any input data size we tested on, with <span id="MathJax-Element-1-Frame" tabindex="0"><nobr><span id="MathJax-Span-1"><span><span><span id="MathJax-Span-2"><span id="MathJax-Span-3">O</span><span id="MathJax-Span-4">(</span><span id="MathJax-Span-5">n</span><span id="MathJax-Span-6">l</span><span id="MathJax-Span-7">o</span><span id="MathJax-Span-8">g<span></span></span><span id="MathJax-Span-9">n</span><span id="MathJax-Span-10">)</span></span><span></span></span></span><span></span></span></nobr></span> complexity, whilst
outperforming hand-coded algorithms, including quick sort, in number of
operations even for list sizes far beyond those seen during training.

    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Yujia Li [<a href="https://arxiv.org/show-email/4d62f020/2007.03629">view email</a>]
      <br>
  <strong><a href="https://arxiv.org/abs/2007.03629v1">[v1]</a></strong>
  Tue, 7 Jul 2020 17:03:02 UTC (541 KB)<br><strong>[v2]</strong>
Wed, 8 Jul 2020 09:19:58 UTC (541 KB)<br></p></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>