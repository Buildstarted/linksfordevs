<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Compute Shader - OpenGL Wiki -
linksfor.dev(s)
    </title>
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta charset="utf-8">
    <meta name="Description" content="A curated source of links that devs might find interesting. Updated around the clock." />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        
<div class="readable">
    <div id="readOverlay" class="style-ebook"><div id="readInner" class="margin-medium size-medium"><h1>Compute Shader - OpenGL Wiki</h1><div><div class="mw-parser-output"><table class="infobox" cellspacing="5"><caption class="">Compute Shader</caption><tbody><tr><td></td><td></td><td></td></tr><tr class="" valign="top"><th scope="row" colspan="2">Core in version</th><td class="">
4.6</td></tr><tr class="" valign="top"><th scope="row" colspan="2">Core since version</th><td class="">
4.3</td></tr><tr class="" valign="top"><th scope="row">Core ARB extension</th><td class="" colspan="2"><a rel="nofollow" class="external text" href="http://www.opengl.org/registry/specs/ARB/compute_shader.txt">ARB_compute_shader</a></td></tr></tbody></table><p>A <b>Compute Shader</b> is a <a href="/opengl/wiki/Shader_Stage" class="mw-redirect" title="Shader Stage">Shader Stage</a> that is used entirely for computing arbitrary information. While it can do rendering, it is generally used for tasks not <i>directly</i> related to drawing triangles and pixels.
</p><h2><span class="mw-headline" id="Execution_model">Execution model</span></h2><p>Compute shaders operate differently from other shader stages. All of the other shader stages have a well-defined set of input values, some built-in and some user-defined. The frequency at which a shader stage executes is specified by the nature of that stage; vertex shaders execute once per input vertex, for example (though some executions can be skipped via caching). Fragment shader execution is defined by the fragments generated from the rasterization process.
</p><p>Compute shaders work very differently. The "space" that a compute shader operates on is largely abstract; it is up to each compute shader to decide what the space means. The number of compute shader executions is defined by the function used to execute the compute operation. Most important of all, compute shaders have no user-defined inputs and no outputs at all. The built-in inputs only define where in the "space" of execution a particular compute shader invocation is.
</p><p>Therefore, if a compute shader wants to take some values as input, it is up to the shader itself to fetch that data, via <a href="/opengl/wiki/GLSL_Sampler" class="mw-redirect" title="GLSL Sampler">texture access</a>, <a href="/opengl/wiki/Image_Load_Store" title="Image Load Store">arbitrary image load</a>, <a href="/opengl/wiki/Shader_Storage_Buffer_Object" title="Shader Storage Buffer Object">shader storage blocks</a>, or other forms of interface. Similarly, if a compute shader is to actually compute anything, it must explicitly write to an image or shader storage block.
</p><h3><span class="mw-headline" id="Compute_space">Compute space</span></h3><p>The space that compute shaders operate within is abstract. There is the concept of a <i>work group</i>; this is the smallest amount of compute operations that the user can execute. Or to put it another way, the user can execute some number of work groups.
</p><p>The number of work groups that a compute operation is executed with is defined by the user when they invoke the compute operation. The space of these groups is three dimensional, so it has a number of "X", "Y", and "Z" groups. Any of these can be 1, so you can perform a two-dimensional or one-dimensional compute operation instead of a 3D one. This is useful for processing image data or linear arrays of a particle system or whatever.
</p><p>When the system actually computes the work groups, it can do so in any order. So if it is given a work group set of (3, 1, 2), it could execute group (0, 0, 0) first, then skip to group (1, 0, 1), then jump to (2, 0, 0), etc. So your compute shader should not rely on the order in which individual groups are processed.
</p><p>Do not think that a single work group is the same thing as a single compute shader invocation; there's a reason why it is called a "group". Within a single work group, there may be many compute shader invocations. How many is defined by the <i>compute shader itself</i>, not by the call that executes it. This is known as the <i>local size</i> of the work group.
</p><p>Every compute shader has a three-dimensional local size (again, sizes can be 1 to allow 2D or 1D local processing). This defines the number of invocations of the shader that will take place within each work group.
</p><p>Therefore, if the local size of a compute shader is (128, 1, 1), and you execute it with a work group count of (16, 8, 64), then you will get 1,048,576 separate shader invocations. Each invocation will have a set of inputs that <i>uniquely</i> identifies that specific invocation.
</p><p>This distinction is useful for doing various forms of image compression or decompression; the local size would be the size of a block of image data (8x8, for example), while the group count will be the image size divided by the block size. Each block is processed as a single work group.
</p><p>The individual invocations within a work group will be executed "in parallel". The main purpose of the distinction between work group count and local size is that the different compute shader invocations <i>within</i> a work group can communicate through a set of <span class="tpl-code">shared</span> variables and special functions. Invocations in different work groups (within the same compute shader dispatch) cannot effectively communicate. Not without potentially deadlocking the system.
</p><h2><span class="mw-headline" id="Dispatch">Dispatch</span></h2><p>Compute shaders are not part of the regular <a href="/opengl/wiki/Rendering_Pipeline_Overview" title="Rendering Pipeline Overview">rendering pipeline</a>. So when executing a <a href="/opengl/wiki/Drawing_Command" class="mw-redirect" title="Drawing Command">Drawing Command</a>, the compute shader linked into the current program or pipeline is not involved.
</p><p>There are two functions to initiate compute operations. They will use whichever compute shader is currently active (via <span class="tpl-code"><a href="/opengl/wiki/GLAPI/glBindProgramPipeline" title="GLAPI/glBindProgramPipeline">glBindProgramPipeline</a></span> or <span class="tpl-code"><a href="/opengl/wiki/GLAPI/glUseProgram" title="GLAPI/glUseProgram">glUseProgram</a></span>, following the usual rules for determining the active program for a stage). Though they are not <a href="/opengl/wiki/Drawing_Command" class="mw-redirect" title="Drawing Command">Drawing Commands</a>, they are <a href="/opengl/wiki/Rendering_Command" class="mw-redirect" title="Rendering Command">Rendering Commands</a>, so they can be <a href="/opengl/wiki/Conditional_Rendering" class="mw-redirect" title="Conditional Rendering">conditionally executed</a>.
</p><pre> void <span class="tpl-code"><a href="/opengl/wiki/GLAPI/glDispatchCompute" title="GLAPI/glDispatchCompute">glDispatchCompute</a></span>(GLuint <span class="tpl-param">num_groups_x​</span>, GLuint <span class="tpl-param">num_groups_y​</span>, GLuint <span class="tpl-param">num_groups_z​</span>);
</pre><p>The <span class="tpl-param">num_groups_*​</span> parameters define the work group count, in three dimensions. These numbers cannot be zero. There are <a href="#Limitations">limitations</a> on the number of work groups that can be dispatched.
</p><p>It is possible to execute dispatch operations where the work group counts come from information stored in a <a href="/opengl/wiki/Buffer_Object" title="Buffer Object">Buffer Object</a>. This is similar to <a href="/opengl/wiki/Indirect_Drawing" class="mw-redirect" title="Indirect Drawing">indirect drawing for vertex data</a>:
</p><pre> void <span class="tpl-code"><a href="/opengl/wiki/GLAPI/glDispatchComputeIndirect" title="GLAPI/glDispatchComputeIndirect">glDispatchComputeIndirect</a></span>(GLintptr <span class="tpl-param">indirect​</span>);
</pre><p>The <span class="tpl-param">indirect​</span> parameter is the byte-offset to the buffer currently bound to the <span class="tpl-enum">GL_DISPATCH_INDIRECT_BUFFER​</span> target. Note that the same <a href="#Limitations">limitations on the work group counts</a> still apply; however, indirect dispatch bypasses OpenGL's usual error checking. As such, attempting to dispatch with out-of-bounds work group sizes can cause a crash or even a GPU hard-lock, so be careful when generating this data.
</p><h2><span class="mw-headline" id="Inputs">Inputs</span></h2><p>Compute shaders cannot have any user-defined input variables. If you wish to provide input to a CS, you must use the implementation-defined inputs coupled with resources like <a href="/opengl/wiki/Ssbo" class="mw-redirect" title="Ssbo">storage buffers</a> or <a href="/opengl/wiki/Texture" title="Texture">Textures</a>. You can use the shader's invocation and work group indices to decide which data to fetch and process.
</p><p><b>Compute Shader</b>s have the following built-in input variables.
</p><div class="mw-highlight mw-content-ltr" dir="ltr"><pre><span></span><span class="k">in</span><span class="n">uvec3</span><span class="n">gl_NumWorkGroups</span><span class="p">;</span><span class="k">in</span><span class="n">uvec3</span><span class="n">gl_WorkGroupID</span><span class="p">;</span><span class="k">in</span><span class="n">uvec3</span><span class="n">gl_LocalInvocationID</span><span class="p">;</span><span class="k">in</span><span class="n">uvec3</span><span class="n">gl_GlobalInvocationID</span><span class="p">;</span><span class="k">in</span><span class="n">uint</span><span class="n">gl_LocalInvocationIndex</span><span class="p">;</span></pre></div><dl><dt><span class="tpl-code">gl_NumWorkGroups</span></dt><dd>This variable contains the number of work groups passed to the dispatch function.</dd><dt><span class="tpl-code">gl_WorkGroupID</span></dt><dd>This is the current work group for this shader invocation. Each of the XYZ components will be on the half-open range [0, gl_NumWorkGroups.XYZ).</dd><dt><span class="tpl-code">gl_LocalInvocationID</span></dt><dd>This is the current invocation of the shader <i>within</i> the work group. Each of the XYZ components will be on the half-open range [0, <span class="tpl-code">gl_WorkGroupSize.XYZ</span>).</dd><dt><span class="tpl-code">gl_GlobalInvocationID</span></dt><dd>This value uniquely identifies this particular invocation of the compute shader among <i>all</i> invocations of this compute dispatch call. It's a short-hand for the math computation:</dd></dl><div class="mw-highlight mw-content-ltr" dir="ltr"><pre><span></span><span class="n">gl_WorkGroupID</span><span class="o">*</span><span class="n">gl_WorkGroupSize</span><span class="o">+</span><span class="n">gl_LocalInvocationID</span><span class="p">;</span></pre></div><dl><dt><span class="tpl-code">gl_LocalInvocationIndex</span></dt><dd>This is a 1D version of <span class="tpl-code">gl_LocalInvocationID</span>. It identifies this invocation's index <i>within</i> the work group. It is short-hand for this math computation:</dd></dl><div class="mw-highlight mw-content-ltr" dir="ltr"><pre><span></span><span class="n">gl_LocalInvocationIndex</span><span class="o">=</span><span class="n">gl_LocalInvocationID</span><span class="p">.</span><span class="n">z</span><span class="o">*</span><span class="n">gl_WorkGroupSize</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">gl_WorkGroupSize</span><span class="p">.</span><span class="n">y</span><span class="o">+</span><span class="n">gl_LocalInvocationID</span><span class="p">.</span><span class="n">y</span><span class="o">*</span><span class="n">gl_WorkGroupSize</span><span class="p">.</span><span class="n">x</span><span class="o">+</span><span class="n">gl_LocalInvocationID</span><span class="p">.</span><span class="n">x</span><span class="p">;</span></pre></div><h3><span class="mw-headline" id="Local_size">Local size</span></h3><p>The local size of a compute shader is defined within the shader, using a special layout input declaration:
</p><pre> layout(local_size_x = <span class="tpl-param">X​</span>, local_size_y = <span class="tpl-param">Y​</span>, local_size_z = <span class="tpl-param">Z​</span>) in;
</pre><p>By default, the local sizes are 1, so if you only want a 1D or 2D work group space, you can specify just the <span class="tpl-param">X​</span> or the <span class="tpl-param">X​</span> and <span class="tpl-param">Y​</span> components. They must be integral constant expressions of value greater than 0. Their values must abide by the <a href="#Limitations">limitations imposed below</a>; if they do not, a compiler or linker error occurs.
</p><p>The local size is available to the shader as a <a href="/opengl/wiki/Constant_Expression" class="mw-redirect" title="Constant Expression">compile-time constant variable</a>, so you don't need to define it yourself:
</p><div class="mw-highlight mw-content-ltr" dir="ltr"><pre><span></span><span class="k">const</span><span class="n">uvec3</span><span class="n">gl_WorkGroupSize</span><span class="p">;</span></pre></div><h2><span class="mw-headline" id="Outputs">Outputs</span></h2><p>Compute shaders do not have output variables. If you wish to have a CS generate some output, you must use a resource to do so. <a href="/opengl/wiki/Ssbo" class="mw-redirect" title="Ssbo">Shader storage buffers</a> and <a href="/opengl/wiki/Image_Load_Store" title="Image Load Store">Image Load Store</a> operations are useful ways to output data from a CS.
</p><h2><span class="mw-headline" id="Shared_variables">Shared variables</span></h2><p>Global variables in compute shaders can be declared with the <span class="tpl-code">shared</span> storage qualifier. The value of such variables are shared between all invocations within a work group. You cannot declare any <a href="/opengl/wiki/Opaque_Type" class="mw-redirect" title="Opaque Type">opaque types</a> as shared, but aggregates (arrays and structs) are fine.
</p><p>At the beginning of a work group, these values are uninitialized. Also, the variable declaration cannot have initializers, so this is illegal:
</p><div class="mw-highlight mw-content-ltr" dir="ltr"><pre><span></span><span class="n">shared</span><span class="n">uint</span><span class="n">foo</span><span class="o">=</span><span class="mo">0</span><span class="p">;</span><span class="c1">// No initializers for shared variables.</span></pre></div><p>If you want to initialize a shared variable to a particular value, then one of the invocations must explicitly set the variable to that value. And <i>only one</i> invocation must do so, due to the following.
</p><h3><span class="mw-headline" id="Shared_memory_coherency">Shared memory coherency</span></h3><p>Shared variable access uses the rules for incoherent memory access. This means that the user must perform certain synchronization in order to ensure that shared variables are visible.
</p><p>Shared variables are all implicitly declared <span class="tpl-code">coherent</span>, so you don't need to (and can't use) that qualifier. However, you still need to provide an appropriate memory barrier.
</p><p>The <a href="/opengl/wiki/Incoherent_Memory_Visibility" class="mw-redirect" title="Incoherent Memory Visibility">usual set of memory barriers</a> is available to compute shaders, but they also have access to <span class="tpl-code">memoryBarrierShared()</span>; this barrier is specifically for shared variable ordering. <span class="tpl-code">groupMemoryBarrier()</span> acts like <span class="tpl-code">memoryBarrier()</span>, ordering memory writes for all kinds of variables, but it only orders read/writes for the current work group.
</p><p>While all invocations within a work group are said to execute "in parallel", that doesn't mean that you can assume that all of them are executing in lock-step. If you need to ensure that an invocation has written to some variable so that you can read it, you need to synchronize <i>execution</i> with the invocations, not just issue a memory barrier (you still need the memory barrier though).
</p><p>To synchronize reads and writes between invocations within a work group, you must employ the <span class="tpl-code">barrier()</span> function. This forces an explicit synchronization between all invocations in the work group. Execution within the work group will not proceed until all other invocations have reach this barrier. Once past the <span class="tpl-code">barrier()</span>, all shared variables previously written across all invocations in the group will be visible.
</p><p>There are limitations on how you can call <span class="tpl-code">barrier()</span>. However, compute shaders are not as limited as <a href="/opengl/wiki/Tessellation_Control_Shader" title="Tessellation Control Shader">Tessellation Control Shaders</a> in their use of this function. <span class="tpl-code">barrier()</span> can be called from flow-control, but it can only be called from <i>uniform</i> flow control. All expressions that lead to the evaluation of a <span class="tpl-code">barrier()</span> must be <a href="/opengl/wiki/Dynamically_Uniform_Expression" class="mw-redirect" title="Dynamically Uniform Expression">dynamically uniform</a>.
</p><p>In short, if you execute the same compute shader, no matter how different the data they fetch is, every execution must hit the <i>exact</i> same set of <span class="tpl-code">barrier()</span> calls in the exact same order. Otherwise, serious errors may occur.
</p><h3><span class="mw-headline" id="Atomic_operations">Atomic operations</span></h3><p>A number of atomic operations can be performed on shared variables of integral type (and vectors/arrays/structs of them). These functions are shared with <a href="/opengl/wiki/Shader_Storage_Buffer_Object" title="Shader Storage Buffer Object">Shader Storage Buffer Object</a> atomics.
</p><p>All of the atomic functions return the <i><b>original</b></i> value. The term "<i>n</i>int" can be <span class="tpl-code">int</span> or <span class="tpl-code">uint</span>.
</p><p class="funcdef"><i>n</i>int atomicAdd(inout <i>n</i>int <span class="tpl-param">mem​</span>, <i>n</i>int <span class="tpl-param">data​</span>)</p><p>Adds <span class="tpl-param">data​</span> to <span class="tpl-param">mem​</span>.
</p><p class="funcdef"><i>n</i>int atomicMin(inout <i>n</i>int <span class="tpl-param">mem​</span>, <i>n</i>int <span class="tpl-param">data​</span>)</p><p>The <span class="tpl-param">mem​</span>'s value is no lower than <span class="tpl-param">data​</span>.
</p><p class="funcdef"><i>n</i>int atomicMax(inout <i>n</i>int <span class="tpl-param">mem​</span>, <i>n</i>int <span class="tpl-param">data​</span>)</p><p>The <span class="tpl-param">mem​</span>'s value is no greater than <span class="tpl-param">data​</span>.
</p><p class="funcdef"><i>n</i>int atomicAnd (inout <i>n</i>int <span class="tpl-param">mem​</span>, <i>n</i>int <span class="tpl-param">data​</span>)</p><p><span class="tpl-param">mem​</span> becomes the bitwise-and between <span class="tpl-param">mem​</span> and <span class="tpl-param">data​</span>.
</p><p class="funcdef"><i>n</i>int atomicOr(inout <i>n</i>int <span class="tpl-param">mem​</span>, <i>n</i>int <span class="tpl-param">data​</span>)</p><p><span class="tpl-param">mem​</span> becomes the bitwise-or between <span class="tpl-param">mem​</span> and <span class="tpl-param">data​</span>.
</p><p class="funcdef"><i>n</i>int atomicXor(inout <i>n</i>int <span class="tpl-param">mem​</span>, <i>n</i>int <span class="tpl-param">data​</span>)</p><p><span class="tpl-param">mem​</span> becomes the bitwise-xor between <span class="tpl-param">mem​</span> and <span class="tpl-param">data​</span>.
</p><p class="funcdef"><i>n</i>int atomicExchange(inout <i>n</i>int <span class="tpl-param">mem​</span>, <i>n</i>int <span class="tpl-param">data​</span>)</p><p>Sets <span class="tpl-param">mem​</span>'s value to <span class="tpl-param">data​</span>.
</p><p class="funcdef"><i>n</i>int atomicCompSwap(inout <i>n</i>int <span class="tpl-param">mem​</span>, <i>n</i>int <span class="tpl-param">compare​</span>, <i>n</i>int <span class="tpl-param">data​</span>)</p><p>If the current value of <span class="tpl-param">mem​</span> is equal to <span class="tpl-param">compare​</span>, then <span class="tpl-param">mem​</span> is set to <span class="tpl-param">data​</span>. Otherwise it is left unchanged.
</p><h2><span class="mw-headline" id="Limitations">Limitations</span></h2><p>The number of work groups that can be dispatched in a single dispatch call is defined by <span class="tpl-enum">GL_MAX_COMPUTE_WORK_GROUP_COUNT</span>. This must be queried with <span class="tpl-code"><a href="/opengl/wiki/GLAPI/glGet" title="GLAPI/glGet">glGetIntegeri_v</a></span>, with the index being on the closed range [0, 2], representing the X, Y and Z components of the maximum work group count. Attempting to call <span class="tpl-code"><a href="/opengl/wiki/GLAPI/glDispatchCompute" title="GLAPI/glDispatchCompute">glDispatchCompute</a></span> with values that exceed this range is an error. Attempting to call <span class="tpl-code"><a href="/opengl/wiki/GLAPI/glDispatchComputeIndirect" title="GLAPI/glDispatchComputeIndirect">glDispatchComputeIndirect</a></span> is much worse; it may result in program termination or other badness.
</p><p>Note that the <i>minimum</i> these values must be is 65535 in all three axes. So you've probably got a lot of room to work with.
</p><p>There are limits on the local size as well; indeed, there are two sets of limitations. There is a general limitation on the local size dimensions, queried with <span class="tpl-enum">GL_MAX_COMPUTE_WORK_GROUP_SIZE</span> in the same way as above. Note that the minimum requirements here are much smaller: 1024 for X and Y, and a mere 64 for Z.
</p><p>There is another limitation: the total number of invocations within a work group. That is, the product of the X, Y and Z components of the local size must be less than <span class="tpl-enum">GL_MAX_COMPUTE_WORK_GROUP_INVOCATIONS</span>. The minimum value here is 1024.
</p><p>There is also a limit on the total storage size for all shared variables in a compute shader. This is <span class="tpl-enum">GL_MAX_COMPUTE_SHARED_MEMORY_SIZE</span>, which is in bytes. The OpenGL-required minimum is 32KB. OpenGL does not specify the exact mapping between GL types and shared variable storage, though you could use the std140 layout rules and UBO/SSBO sizes as a general guideline.
</p></div></div></div></div>
</div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script>
        (function () {
            var COLLECT_URL = "https://dna.buildstarted.com/t";
            var SITE_ID = "linksfor.devs";
            var GLOBAL_VAR_NAME = "__DNA__";

            window[GLOBAL_VAR_NAME] = {};

            window[GLOBAL_VAR_NAME].sendPageView = function () {
                var path = location.pathname;
                var referrer = document.referrer;

                var url = COLLECT_URL + "?siteid=" + SITE_ID + "&p=" + encodeURIComponent(path) + "&r=" + encodeURIComponent(referrer);

                try { fetch(url, { method: "GET" }); } catch (e) { }
            };

            window[GLOBAL_VAR_NAME].sendPageView();
        })();
    </script>
</body>
</html>