<!DOCTYPE html>
<html lang="en">
<head>
    <title>
.NET for Apache&#xAE; Spark&#x2122; In-Memory DataFrame Support | .NET Blog - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content=".NET for Apache&#xAE; Spark&#x2122; In-Memory DataFrame Support | .NET Blog - linksfor.dev(s)"/>
    <meta property="article:author" content="Brigit MurtaughProgram Manager, .NETFollow"/>
    <meta property="og:description" content=".NET for Apache Spark is aimed at making Apache&#xAE; Spark&#x2122;, and thus the exciting world of big data analytics, accessible to .NET developers. .NET for Spark can be used for processing batches of data, real-time streams, machine learning, and ad-hoc query."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://devblogs.microsoft.com/dotnet/net-for-apache-spark-in-memory-dataframe-support/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - .NET for Apache&#xAE; Spark&#x2122; In-Memory DataFrame Support | .NET Blog</title>
<div class="readable">
        <h1>.NET for Apache&#xAE; Spark&#x2122; In-Memory DataFrame Support | .NET Blog</h1>
            <div>by Brigit MurtaughProgram Manager, .NETFollow</div>
            <div>Reading time: 11-13 minutes</div>
        <div>Posted here: 30 Mar 2020</div>
        <p><a href="https://devblogs.microsoft.com/dotnet/net-for-apache-spark-in-memory-dataframe-support/">https://devblogs.microsoft.com/dotnet/net-for-apache-spark-in-memory-dataframe-support/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="featured"><div><div><div><div><p><img src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2020/01/Profile-Pic-150x150.jpg" width="58" height="58" alt="Brigit Murtaugh"></p><p>Brigit</p></div></div></div><p>March 30th, 2020</p><p><a href="https://dot.net/spark" target="_blank">.NET for Apache Spark</a> is aimed at making <a href="https://spark.apache.org/" target="_blank">Apache® Spark™</a>, and thus the exciting world of big data analytics, accessible to .NET developers. .NET for Spark can be used for processing batches of data, real-time streams, machine learning, and ad-hoc query.</p><p>The <a href="https://docs.microsoft.com/dotnet/api/microsoft.spark.sql.dataframe?view=spark-dotnet" target="_blank">DataFrame</a> is one of the core data structures in Spark programming. A DataFrame is a distributed collection of data organized into named columns. In a Spark application, we typically start off by reading input data from a data source, storing it in a DataFrame, and then leveraging functionality like Spark SQL to transform and gain insights from our data. User-defined functions, or UDFs, are column-based functions that allow us to manipulate data stored in DataFrames.</p><p>In December 2019, the <a href="https://devblogs.microsoft.com/dotnet/an-introduction-to-dataframe/">.NET team announced</a> the preview of the <a href="https://www.nuget.org/packages/Microsoft.Data.Analysis/" target="_blank">Microsoft.Data.Analysis.DataFrame</a> type to make data exploration easy in .NET. Now in March 2020, we have <a href="https://github.com/dotnet/spark/pull/277" target="_blank">introduced convenience APIs</a> to the .NET for Spark codebase for using Microsoft.Data.Analysis.DataFrame objects with UDFs in Spark. These convenience APIs make data manipulation and analysis with UDFs much more convenient and concise in .NET for Spark.</p><p>In this blog post, we’ll explore:</p><ul><li><a href="#implement">Implementation goal and details</a></li><li><a href="#example">Coding examples and DataFrame comparisons</a></li><li><a href="#wrapup">Wrap Up</a></li></ul><h3><a id="implement"></a>Implementation goals and details</h3><h4>Context and Goals</h4><p>Let’s start off with some context about data-sharing in Spark UDFs. Apache Spark streams data to Arrow-based UDFs in the <a href="https://arrow.apache.org/" target="_blank">Apache Arrow</a> format. Apache Arrow provides a standardized, language-independent format for working with data in-memory. It’s designed for high-performance, efficient analysis through its columnar memory format, and it provides libraries and zero-copy messaging for communication across processes.</p><p><a href="https://github.com/bamurtaugh/dotnet-blog/blob/march-spark/2020/03-Mar/Spark/Arrow.png?raw=true" target="_blank" data-featherlight="image"> <img src="https://github.com/bamurtaugh/dotnet-blog/blob/march-spark/2020/03-Mar/Spark/Arrow.png?raw=true" alt="Diagram of the benefits of Apache Arrow"> </a></p><h6>Diagram credit: https://arrow.apache.org/.</h6><p>Because Spark streams data to UDFs in the Arrow format, you need to understand the Arrow format when working with UDFs, such as how to read Arrow columns, write to Arrow columns, and unwrap a RecordBatch, which is a 2D data type in Arrow consisting of a set of rows of equal-length columns.</p><p>The main goal of the work described in this blog post is to improve scalar and vector UDFs in .NET for Spark through a set of convenience APIs. You can now use Microsoft.Data.Analysis.DataFrame objects in your .NET for Spark apps, which take care of working with Arrow-formatted data for you behind-the-scenes of your UDFs.</p><h4>Details</h4><p>There are a few kinds of Spark UDFs: pickling, scalar, and vector. Our convenience APIs specifically apply to scalar and vector UDFs.</p><p><a href="https://docs.python.org/3/library/pickle.html" target="_blank">Python pickling UDFs</a> are an older version of Spark UDFs. They leverage the Python pickling format of serialization, rather than Arrow, to convert data between the JVM and .NET for Spark processes. Once a column is specified for processing, a pickling UDF will take each of its rows, apply the given functionality, and then add a new column, resulting in quite a bit of overhead.</p><p>By contrast, scalar and vector UDFs leverage Arrow serialization, enabling them to reap the benefits of an in-memory columnar format and making data transfers more efficient. Once data is serialized to the Arrow format, it can be used directly in the Spark processes and doesn’t need to be serialized or deserialized anymore, which is a major improvement over the Python pickling format. Arrow can create DataFrames using zero-copy methods across chunks of data (multiple rows and columns all at once) rather than row-by-row.</p><p>Our new .NET for Apache Spark convenience APIs specifically apply to scalar and vector UDFs since they use Arrow.</p><p>Prior to these convenience APIs, you needed to enumerate an Arrow RecordBatch to work with columns in an Arrow-based UDF. RecordBatches are Arrow-based objects, not standard Spark objects, and can thus disrupt the flow or familiarity of code in your program.</p><p>Our new APIs automatically wrap data in a Microsoft.Data.Analysis.DataFrame instead of a RecordBatch. The wrapping doesn’t involve copying data, thus ensuring performance remains high as our ease of coding also improves.</p><p>You can use both traditional Spark SQL and Microsoft.Data.Analysis.DataFrames in your programs. The traditional Spark DataFrame distributes data across your Spark cluster. It’s used for the entire dataset in your Spark driver program. Once you create a UDF, the data in the traditional DataFrame will be streamed to the UDF on the worker machines in the Arrow format. Once inside the UDF, you’ll now work with the Microsoft.Data.Analysis.DataFrame (rather than RecordBatches)- it will be in-memory on a single machine. The concept of the Microsoft.Data.Analysis.DataFrame is similar to the <a href="https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html" target="_blank">Python Pandas DataFrame</a>.</p><h3><a id="example"></a>Example</h3><h4>Simple Examples</h4><p>Let’s start with a basic example. Suppose we have a vector UDF that adds 2 columns and returns the result. Traditionally, the UDF would take in 2 ArrowArrays (for example, DoubleArray) and return a new ArrowArray. You would unfortunately need to create the new array, and then loop over each row in the data. In addition to the loop, you’d also need to deal with Builder objects in the Arrow library to create the new array, resulting in more allocations than necessary.</p><p>If we instead used the Microsoft.Data.Analysis.DataFrame, we can write something along the lines of: <code>dataframe.ColumnA + dataframe.ColumnB</code>. Isn’t that convenient!</p><p>As another example, we often create UDFs that return a set of columns. With the traditional Spark DataFrames, these columns must be returned as an Arrow RecordBatch. But with our new convenience APIs, we can just return a DataFrame, and everything else is handled internally!</p><h4>Detailed Examples</h4><p><strong><em>Vector Udfs</em></strong></p><p>Let’s take a look at a more detailed, concrete example. <a href="https://github.com/dotnet/spark/blob/master/examples/Microsoft.Spark.CSharp.Examples/Sql/Batch/VectorUdfs.cs" target="_blank">VectorUdfs.cs</a> is a program using the traditional Spark DataFrame. It reads in a Json file with people’s names and ages as input and stores the data in a DataFrame. The program leverages Spark to group records by the same age, and then applies a custom UDF over each age group.</p><p>Let’s say you have 2 people with the same age:</p><pre><span>21</span><span> </span><span>|</span><span> </span><span>John</span><span>
</span><span>21</span><span> </span><span>|</span><span> </span><span>Sally</span></pre><p>The UDF will count the number of characters in all the names that have the same age. So, in this case, you’d get 1 row back: <code>21 | 9</code>, where 9 is the result of “John”.Length + “Sally”.Length.</p><p><a href="https://github.com/dotnet/spark/blob/master/examples/Microsoft.Spark.CSharp.Examples/Sql/Batch/VectorDataFrameUdfs.cs" target="_blank">VectorDataFrameUdfs.cs</a> is an updated program that accomplishes the same task with both a traditional DataFrame and the Microsoft.Data.Analysis.DataFrame.</p><p>Both programs use a Grouped Map Vector UDF and apply it very similarly. In VectorUdfs.cs, the code is as follows:</p><pre><span>df</span><span>.</span><span>GroupBy</span><span>(</span><span>"age"</span><span>)</span><span>
    </span><span>.</span><span>Apply</span><span>(</span><span>
    </span><span>new</span><span> </span><span>StructType</span><span>(</span><span>new</span><span>[]</span><span>
    </span><span>{</span><span>
        </span><span>new</span><span> </span><span>StructField</span><span>(</span><span>"age"</span><span>,</span><span> </span><span>new</span><span> </span><span>IntegerType</span><span>()),</span><span>
        </span><span>new</span><span> </span><span>StructField</span><span>(</span><span>"nameCharCount"</span><span>,</span><span> </span><span>new</span><span> </span><span>IntegerType</span><span>())</span><span>
    </span><span>}),</span><span>
r </span><span>=&gt;</span><span> </span><span>CountCharacters</span><span>(</span><span>r</span><span>))</span></pre><p><code>CountCharacters</code> is implemented differently in each program. In VectorUdfs.cs, the definition is:</p><pre><span>private</span><span> </span><span>static</span><span> </span><span>RecordBatch</span><span> </span><span>CountCharacters</span><span>(</span><span>RecordBatch</span><span> records</span><span>)</span><span>
</span><span>{</span><span>
    </span><span>StringArray</span><span> nameColumn </span><span>=</span><span> records</span><span>.</span><span>Column</span><span>(</span><span>"name"</span><span>)</span><span> </span><span>as</span><span> </span><span>StringArray</span><span>;</span><span>

    </span><span>int</span><span> characterCount </span><span>=</span><span> </span><span>0</span><span>;</span><span>

    </span><span>for</span><span> </span><span>(</span><span>int</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> nameColumn</span><span>.</span><span>Length</span><span>;</span><span> </span><span>++</span><span>i</span><span>)</span><span>
    </span><span>{</span><span>
        </span><span>string</span><span> current </span><span>=</span><span> nameColumn</span><span>.</span><span>GetString</span><span>(</span><span>i</span><span>);</span><span>
        characterCount </span><span>+=</span><span> current</span><span>.</span><span>Length</span><span>;</span><span>
    </span><span>}</span><span>

    </span><span>int</span><span> ageFieldIndex </span><span>=</span><span> records</span><span>.</span><span>Schema</span><span>.</span><span>GetFieldIndex</span><span>(</span><span>"age"</span><span>);</span><span>
    </span><span>Field</span><span> ageField </span><span>=</span><span> records</span><span>.</span><span>Schema</span><span>.</span><span>GetFieldByIndex</span><span>(</span><span>ageFieldIndex</span><span>);</span><span>

    </span><span>// Return 1 record, if we were given any. 0, otherwise.</span><span>
    </span><span>int</span><span> returnLength </span><span>=</span><span> records</span><span>.</span><span>Length</span><span> </span><span>&gt;</span><span> </span><span>0</span><span> </span><span>?</span><span> </span><span>1</span><span> </span><span>:</span><span> </span><span>0</span><span>;</span><span>

    </span><span>return</span><span> </span><span>new</span><span> </span><span>RecordBatch</span><span>(</span><span>
        </span><span>new</span><span> </span><span>Schema</span><span>.</span><span>Builder</span><span>()</span><span>
            </span><span>.</span><span>Field</span><span>(</span><span>ageField</span><span>)</span><span>
            </span><span>.</span><span>Field</span><span>(</span><span>f </span><span>=&gt;</span><span> f</span><span>.</span><span>Name</span><span>(</span><span>"name_CharCount"</span><span>).</span><span>DataType</span><span>(</span><span>Int32Type</span><span>.</span><span>Default</span><span>))</span><span>
            </span><span>.</span><span>Build</span><span>(),</span><span>
        </span><span>new</span><span> </span><span>IArrowArray</span><span>[]</span><span>
        </span><span>{</span><span>
            records</span><span>.</span><span>Column</span><span>(</span><span>ageFieldIndex</span><span>),</span><span>
            </span><span>new</span><span> </span><span>Int32Array</span><span>.</span><span>Builder</span><span>().</span><span>Append</span><span>(</span><span>characterCount</span><span>).</span><span>Build</span><span>()</span><span>
        </span><span>},</span><span>
        returnLength</span><span>);</span><span>
</span><span>}</span></pre><p>In VectorDataFrameUdfs.cs, the method is:</p><pre><span>private</span><span> </span><span>static</span><span> </span><span>FxDataFrame</span><span> </span><span>CountCharacters</span><span>(</span><span>FxDataFrame</span><span> dataFrame</span><span>)</span><span>
</span><span>{</span><span>
    </span><span>int</span><span> characterCount </span><span>=</span><span> </span><span>0</span><span>;</span><span>

    </span><span>var</span><span> characterCountColumn </span><span>=</span><span> </span><span>new</span><span> </span><span>PrimitiveDataFrameColumn</span><span>&lt;int&gt;</span><span>(</span><span>"nameCharCount"</span><span>);</span><span>
    </span><span>var</span><span> ageColumn </span><span>=</span><span> </span><span>new</span><span> </span><span>PrimitiveDataFrameColumn</span><span>&lt;/</span><span>int</span><span>&gt;&lt;</span><span>int</span><span>&gt;(</span><span>"age"</span><span>);</span><span>
    </span><span>ArrowStringDataFrameColumn</span><span> nameColumn </span><span>=</span><span> dataFrame</span><span>[</span><span>"name"</span><span>]</span><span> </span><span>as</span><span> </span><span>ArrowStringDataFrameColumn</span><span>;</span><span>
    </span><span>for</span><span> </span><span>(</span><span>long</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> dataFrame</span><span>.</span><span>Rows</span><span>.</span><span>Count</span><span>;</span><span> </span><span>++</span><span>i</span><span>)</span><span>
    </span><span>{</span><span>
        characterCount </span><span>+=</span><span> nameColumn</span><span>[</span><span>i</span><span>].</span><span>Length</span><span>;</span><span>
    </span><span>}</span><span>

    </span><span>if</span><span> </span><span>(</span><span>dataFrame</span><span>.</span><span>Rows</span><span>.</span><span>Count</span><span> </span><span>&gt;</span><span> </span><span>0</span><span>)</span><span>
    </span><span>{</span><span>
        characterCountColumn</span><span>.</span><span>Append</span><span>(</span><span>characterCount</span><span>);</span><span>
        ageColumn</span><span>.</span><span>Append</span><span>((</span><span>int</span><span>?)</span><span>dataFrame</span><span>[</span><span>"age"</span><span>][</span><span>0</span><span>]);</span><span>
    </span><span>}</span><span>

    </span><span>return</span><span> </span><span>new</span><span> </span><span>FxDataFrame</span><span>(</span><span>ageColumn</span><span>,</span><span> characterCountColumn</span><span>);</span><span>
</span><span>}</span><span>
</span><span>&lt;/</span><span>int</span><span>&gt;</span></pre><p>Note that the <code>FxDataFrame</code> type represents the Microsoft.Data.Analysis.DataFrame, while <code>DataFrame</code> represents the traditional Spark DataFrame. This is signified in the latter sample at the top of the program:</p><pre><span>using</span><span> </span><span>DataFrame</span><span> </span><span>=</span><span> </span><span>Microsoft</span><span>.</span><span>Spark</span><span>.</span><span>Sql</span><span>.</span><span>DataFrame</span><span>;</span><span>
</span><span>using</span><span> </span><span>FxDataFrame</span><span> </span><span>=</span><span> </span><span>Microsoft</span><span>.</span><span>Data</span><span>.</span><span>Analysis</span><span>.</span><span>DataFrame</span><span>;</span></pre><p>As you can see, the latter <code>CountCharacters</code> implementation deals completely with DataFrames rather than RecordBatches. It is also almost half the length of the first implementation!</p><p>In this single comparison, we can see where these new APIs add a great deal of convenience to our .NET for Spark apps. VectorUdfs.cs requires us to convert to and from the RecordBatch type, requiring many extra lines of code. By contrast, the new VectorDataFrameUdfs.cs sample can dive immediately into our data processing.</p><p><strong><em>TPC-H Vector Functions</em></strong></p><p>.NET for Apache Spark is designed for high performance and performs well on the <a href="http://www.tpc.org/tpch/" target="_blank">TPC-H benchmark</a>. The TPC-H benchmark consists of a suite of business-oriented ad hoc queries and concurrent data modifications. The queries and the data populating the database have been chosen to have broad industry-wide relevance.</p><p><a href="https://github.com/dotnet/spark/blob/master/benchmark/csharp/Tpch/VectorFunctions.cs#L12" target="_blank">VectorFunctions.cs</a> and <a href="https://github.com/dotnet/spark/blob/master/benchmark/csharp/Tpch/VectorDataFrameFunctions.cs#L12" target="_blank">VectorDataFrameFunctions.cs</a> both perform the same <code>ComputeTotal</code> TPC-H function where prices are calculated based on taxes and discounts. However, only the latter program leverages Microsoft.Data.Analysis.DataFrame.</p><p><code>ComputeTotal</code> in VectorFunctions.cs:</p><pre><span>internal</span><span> </span><span>static</span><span> </span><span>DoubleArray</span><span> </span><span>ComputeTotal</span><span>(</span><span>DoubleArray</span><span> price</span><span>,</span><span> </span><span>DoubleArray</span><span> discount</span><span>,</span><span> </span><span>DoubleArray</span><span> tax</span><span>)</span><span>
</span><span>{</span><span>
    </span><span>if</span><span> </span><span>((</span><span>price</span><span>.</span><span>Length</span><span> </span><span>!=</span><span> discount</span><span>.</span><span>Length</span><span>)</span><span> </span><span>||</span><span> </span><span>(</span><span>price</span><span>.</span><span>Length</span><span> </span><span>!=</span><span> tax</span><span>.</span><span>Length</span><span>))</span><span>
    </span><span>{</span><span>
        </span><span>throw</span><span> </span><span>new</span><span> </span><span>ArgumentException</span><span>(</span><span>"Arrays need to be the same length"</span><span>);</span><span>
    </span><span>}</span><span>

    </span><span>int</span><span> length </span><span>=</span><span> price</span><span>.</span><span>Length</span><span>;</span><span>
    </span><span>var</span><span> builder </span><span>=</span><span> </span><span>new</span><span> </span><span>DoubleArray</span><span>.</span><span>Builder</span><span>().</span><span>Reserve</span><span>(</span><span>length</span><span>);</span><span>
    </span><span>ReadOnlySpan</span><span>&lt;double&gt;</span><span> prices </span><span>=</span><span> price</span><span>.</span><span>Values</span><span>;</span><span>
    </span><span>ReadOnlySpan</span><span>&lt;/</span><span>double</span><span>&gt;&lt;</span><span>double</span><span>&gt;</span><span> discounts </span><span>=</span><span> discount</span><span>.</span><span>Values</span><span>;</span><span>
    </span><span>ReadOnlySpan</span><span>&lt;/</span><span>double</span><span>&gt;&lt;</span><span>double</span><span>&gt;</span><span> taxes </span><span>=</span><span> tax</span><span>.</span><span>Values</span><span>;</span><span>
    </span><span>for</span><span> </span><span>(</span><span>int</span><span> i </span><span>=</span><span> </span><span>0</span><span>;</span><span> i </span><span>&lt;</span><span> length</span><span>;</span><span> </span><span>++</span><span>i</span><span>)</span><span>
    </span><span>{</span><span>
        builder</span><span>.</span><span>Append</span><span>(</span><span>prices</span><span>[</span><span>i</span><span>]</span><span> </span><span>*</span><span> </span><span>(</span><span>1</span><span> </span><span>-</span><span> discounts</span><span>[</span><span>i</span><span>])</span><span> </span><span>*</span><span> </span><span>(</span><span>1</span><span> </span><span>+</span><span> taxes</span><span>[</span><span>i</span><span>]));</span><span>
    </span><span>}</span><span>

    </span><span>return</span><span> builder</span><span>.</span><span>Build</span><span>();</span><span>
</span><span>}</span><span>
</span><span>&lt;/</span><span>double</span><span>&gt;</span></pre><p>Whereas the logic in <code>ComputeTotal</code> in VectorDataFrameFunctions.cs (not including the initial array length check) is just 1 line!</p><pre><span>return</span><span> price </span><span>*</span><span> </span><span>(</span><span>1</span><span> </span><span>-</span><span> discount</span><span>)</span><span> </span><span>*</span><span> </span><span>(</span><span>1</span><span> </span><span>+</span><span> tax</span><span>);</span></pre><p>Now we can harness the tremendous benefits of Apache Arrow without extra code overhead or confusion – awesome!</p><h3><a id="wrapup"></a>Wrap Up</h3><p>Thank you to Prashanth Govindarajan, Eric Erhardt, Terry Kim, and the other members of the .NET and .NET for Apache Spark teams for their contributions to this outstanding work.</p><p>We’d love to help you get started with .NET for Apache Spark and hear your feedback. You can <a href="https://dot.net/spark" target="_blank">Request a Demo</a> from our landing page and check out the <a href="https://github.com/dotnet/spark" target="_blank">.NET for Spark GitHub repo</a> to get involved with our effort to make .NET a great tech stack for building big data applications.</p></div></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs" /></noscript>
</body>
</html>