<!DOCTYPE html>
<html lang="en">
<head>
    <title>
google/robotstxt - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="google/robotstxt - linksfor.dev(s)"/>
    <meta property="article:author" content="epere4"/>
    <meta property="og:description" content="The repository contains Google&#x27;s robots.txt parser and matcher as a C&#x2B;&#x2B; library (compliant to C&#x2B;&#x2B;11). - google/robotstxt"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://github.com/google/robotstxt"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
	<div class="devring" style="background: #222">
		<div class="grid">
			<div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
				<span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
				<a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
				<a href="https://devring.club/random" class="devring-random">Random</a>
				<a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
			</div>
		</div>
	</div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - google/robotstxt</title>
<div class="readable">
        <h1>google/robotstxt</h1>
            <div>by epere4</div>
            <div>Reading time: 4-5 minutes</div>
        <div>Posted here: 01 Jul 2019</div>
        <p><a href="https://github.com/google/robotstxt">https://github.com/google/robotstxt</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="readme">
    
        

      <div>
        <article itemprop="text">
<p>The repository contains Google's robots.txt parser and matcher as a C++ library
(compliant to C++11).</p>
<h2>About the library</h2>
<p>The Robots Exclusion Protocol (REP) is a standard that enables website owners to
control which URLs may be accessed by automated clients (i.e. crawlers) through
a simple text file with a specific syntax. It's one of the basic building blocks
of the internet as we know it and what allows search engines to operate.</p>
<p>Because the REP was only a de-facto standard for the past 25 years, different
implementers implement parsing of robots.txt slightly differently, leading to
confusion. This project aims to fix that by releasing the parser that Google
uses.</p>
<p>The library is slightly modified (i.e. some internal headers and equivalent
symbols) production code used by Googlebot, Google's crawler, to determine which
URLs it may access based on rules provided by webmasters in robots.txt files.
The library is released open-source to help developers build tools that better
reflect Google's robots.txt parsing and matching.</p>
<p>For webmasters, we included a small binary in the project that allows testing a
single URL and user-agent against a robots.txt.</p>
<h2>Building the library</h2>
<h3>Quickstart</h3>
<p>We included with the library a small binary to test a local robots.txt against a
user-agent and URL. Running the included binary requires:</p>
<ul>
<li>A compatible platform (e.g. Windows, macOS, Linux, etc.). Most platforms are
fully supported.</li>
<li>A compatible C++ compiler supporting at least C++11. Most major compilers
are supported.</li>
<li><a href="https://git-scm.com/" rel="nofollow">Git</a> for interacting with the source code repository.
To install Git, consult the
<a href="https://help.github.com/articles/set-up-git/">Set Up Git</a> guide on
<a href="https://github.com/">GitHub</a>.</li>
<li>Although you are free to use your own build system, most of the
documentation within this guide will assume you are using
<a href="https://bazel.build/" rel="nofollow">Bazel</a>. To download and install Bazel (and any of its
dependencies), consult the
<a href="https://docs.bazel.build/versions/master/install.html" rel="nofollow">Bazel Installation Guide</a></li>
</ul>
<h4>Building with Bazel</h4>
<p><a href="https://bazel.build/" rel="nofollow">Bazel</a> is the official build system for the library,
which is supported on most major platforms (Linux, Windows, MacOS, for example)
and compilers.</p>
<p>To build and run the binary:</p>
<div><pre>$ git clone https://github.com/google/robotstxt.git robotstxt
Cloning into <span><span>'</span>robotstxt<span>'</span></span>...
...
$ <span>cd</span> robotstxt/
bazel-robots$ bazel <span>test</span> :robots_test
...
/:robots_test                                                      PASSED <span>in</span> 0.1s

Executed 1 out of 1 test: 1 <span>test</span> passes.
...
bazel-robots$ bazel build :robots_main
...
Target //:robots_main up-to-date:
  bazel-bin/robots_main
...
bazel-robots$ bazel run robots_main -- <span>~</span>/local/path/to/robots.txt YourBot https://example.com/url
  user-agent <span><span>'</span>YourBot<span>'</span></span> with url <span><span>'</span>https://example.com/url<span>'</span></span> allowed: YES</pre></div>
<h4>Building with CMake</h4>
<p><a href="https://cmake.org/" rel="nofollow">CMake</a> is the community-supported build system for the
library.</p>
<p>To build the library using CMake, just follow the steps below:</p>
<div><pre>$ git clone https://github.com/google/robotstxt.git robotstxt
Cloning into <span><span>'</span>robotstxt<span>'</span></span>...
...
$ <span>cd</span> robotstxt/
...
$ mkdir c-build <span>&amp;&amp;</span> <span>cd</span> c-build
...
$ cmake .. -DROBOTS_BUILD_TESTS=ON
...
$ make
...
$ make <span>test</span>
Running tests...
Test project robotstxt/c-build
    Start 1: robots-test
1/1 Test <span><span>#</span>1: robots-test ......................   Passed    0.02 sec</span>

100% tests passed, 0 tests failed out of 1

Total Test <span>time</span> (real) =   0.02 sec
...
$ robots <span>~</span>/local/path/to/robots.txt YourBot https://example.com/url
  user-agent <span><span>'</span>YourBot<span>'</span></span> with url <span><span>'</span>https://example.com/url<span>'</span></span> allowed: YES</pre></div>
<h2>Notes</h2>
<p>Parsing of robots.txt files themselves is done exactly as in the production
version of Googlebot, including how percent codes and unicode characters in
patterns are handled. The user must ensure however that the URI passed to the
AllowedByRobots and OneAgentAllowedByRobots functions, or to the URI parameter
of the robots tool, follows the format specified by RFC3986, since this library
will not perform full normalization of those URI parameters. Only if the URI is
in this format, the matching will be done according to the REP specification.</p>
<h2>License</h2>
<p>The robots.txt parser and matcher C++ library is licensed under the terms of the
Apache license. See LICENSE for more information.</p>
<h2>Links</h2>
<p>To learn more about this project:</p>
<ul>
<li>check out the
<a href="https://tools.ietf.org/html/draft-koster-rep" rel="nofollow">internet draft</a>,</li>
<li>how
<a href="https://developers.google.com/search/reference/robots_txt" rel="nofollow">Google's handling robots.txt</a>,</li>
<li>or for a high level overview, the
<a href="https://en.wikipedia.org/wiki/Robots_exclusion_standard" rel="nofollow">robots.txt page on Wikipedia</a>.</li>
</ul>
</article>
      </div>
  </div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
		<div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>