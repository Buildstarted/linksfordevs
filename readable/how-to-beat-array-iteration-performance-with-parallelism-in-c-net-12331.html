<!DOCTYPE html>
<html lang="en">
<head>
    <title>
How to Beat Array Iteration Performance with Parallelism in C# .NET - Michael&#x27;s Coding Spot - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="How to Beat Array Iteration Performance with Parallelism in C# .NET - Michael&#x27;s Coding Spot - linksfor.dev(s)"/>
    <meta property="og:description" content="Let&#x27;s consider a simple programming challenge: Summing all items of a large array. Now it stands to reason that this can be easily optimized by using parallelism..."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://michaelscodingspot.com/array-iteration-vs-parallelism-in-c-net/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - How to Beat Array Iteration Performance with Parallelism in C# .NET - Michael&#x27;s Coding Spot</title>
<div class="readable">
        <h1>How to Beat Array Iteration Performance with Parallelism in C# .NET - Michael&#x27;s Coding Spot</h1>
            <div>Reading time: 14-18 minutes</div>
        <div>Posted here: 02 Apr 2019</div>
        <p><a href="https://michaelscodingspot.com/array-iteration-vs-parallelism-in-c-net/">https://michaelscodingspot.com/array-iteration-vs-parallelism-in-c-net/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><article id="post-3624">
														
							
														
							
														
							<div>
															<div data-content-ads-inserted="true">
									
<p>Let’s consider a simple programming challenge: <strong>Summing all elements in a large array</strong>.</p>



<p>Now it stands to reason that this can be easily optimized by using parallelism. Especially for huge arrays with thousands or millions of elements. It also stands to reason that the processing time with parallelism should take as much as regular time divided by the number of CPU cores.</p>



<p>As it turns out, this feat is not that easy to achieve. I’ll show you several ways to do this in parallel,  how they improve or degrade performance and all the little details that affect performance one way or the other.</p>



<h6>For all Benchmarks, I use the excellent <a href="https://github.com/dotnet/BenchmarkDotNet">BenchmarkDotNet</a> library. It takes care to run several iterations of each benchmark, do warm-up iterations and so on. My PC is Intel Core i7-7700HQ CPU 2.80GHz (Kaby Lake), 1 CPU, 8 logical and 4 physical cores. The host is .NET Framework 4.7.2 (CLR 4.0.30319.42000), with a 32bit process.</h6>



<h2>Establishing a Baseline</h2>



<p>First, let’s see the straightforward solution:
</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5e49ac3b59d57286275875" data-settings=" touchscreen no-popup minimize scroll-mouseover wrap">
		
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="hide">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p></div>
				</td>
						<td><div><p><span>private</span><span> </span><span>int</span><span> </span><span>ITEMS</span><span> </span><span>{</span><span> </span><span>get</span><span>;</span><span> </span><span>set</span><span>;</span><span> </span><span>}</span><span> </span><span>=</span><span> </span><span>100000</span><span>;</span></p><p><span>private</span><span> </span><span>int</span><span>[</span><span>]</span><span> </span><span>arr</span><span> </span><span>=</span><span> </span><span>null</span><span>;</span></p><p><span>public</span><span> </span><span>ParallelForeach2</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>arr</span><span> </span><span>=</span><span> </span><span>new</span><span> </span><span>int</span><span>[</span><span>ITEMS</span><span>]</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>var</span><span> </span><span>rnd</span><span> </span><span>=</span><span> </span><span>new</span><span> </span><span>Random</span><span>(</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>ITEMS</span><span>;</span><span> </span><span>i</span><span>++</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>arr</span><span>[</span><span>i</span><span>]</span><span> </span><span>=</span><span> </span><span>rnd</span><span>.</span><span>Next</span><span>(</span><span>1000</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>partSize</span><span> </span><span>=</span><span> </span><span>ITEMS</span><span> </span><span>/</span><span> </span><span>parts</span><span>;</span></p><p><span>}</span></p><p><span>[</span><span>Benchmark</span><span>]</span></p><p><span>public</span><span> </span><span>long</span><span> </span><span>RegularIterationLocalArr</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>long</span><span> </span><span>total</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span>&nbsp;&nbsp;</span><span>ITEMS</span><span>;</span><span> </span><span>i</span><span>++</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>total</span><span> </span><span>+=</span><span> </span><span>arr</span><span>[</span><span>i</span><span>]</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>total</span><span>;</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0012 seconds] -->




<p>The straightforward solution is as simple as it gets, right? Just iterate over the array and sum all the items.</p>



<p>Now, let’s try to beat it with some parallelism.</p>



<h2>First attempt at a Parallel Solution</h2>



<p>The basic beating-it strategy is as follows:</p>



<ul><li>Create X threads (as much as I have CPU Cores)</li><li>Each thread will run over a range in the array and add up the values</li><li>Adding to the same variable won’t work from multiple threads, we will need a locking mechanism or get wrong results.</li></ul>



<p>Should be simple enough I guess. Here’s the code:
</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5e49ac3b59d5e794748855" data-settings=" touchscreen no-popup minimize scroll-mouseover wrap" data-slot-rendered-dynamic="true">
		
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="hide">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p></div>
				</td>
						<td><div><p><span>private</span><span> </span><span>object</span><span> </span><span>_lock</span><span> </span><span>=</span><span> </span><span>new</span><span> </span><span>object</span><span>(</span><span>)</span><span>;</span></p><p><span>[</span><span>Benchmark</span><span>]</span></p><p><span>public</span><span> </span><span>long</span><span> </span><span>ThreadPoolWithLock</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>long</span><span> </span><span>total</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>int</span><span> </span><span>threads</span><span> </span><span>=</span><span> </span><span>8</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>var</span><span> </span><span>partSize</span><span> </span><span>=</span><span> </span><span>ITEMS</span><span> </span><span>/</span><span> </span><span>threads</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>Task</span><span>[</span><span>]</span><span> </span><span>tasks</span><span> </span><span>=</span><span> </span><span>new</span><span> </span><span>Task</span><span>[</span><span>threads</span><span>]</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>iThread</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>iThread</span><span> </span><span>&lt;</span><span>&nbsp;&nbsp;</span><span>threads</span><span>;</span><span> </span><span>iThread</span><span>++</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>var</span><span> </span><span>localThread</span><span> </span><span>=</span><span> </span><span>iThread</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>tasks</span><span>[</span><span>localThread</span><span>]</span><span> </span><span>=</span><span> </span><span>Task</span><span>.</span><span>Run</span><span>(</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>j</span><span> </span><span>=</span><span> </span><span>localThread *</span><span> </span><span>partSize</span><span>;</span><span> </span><span>j</span><span> </span><span>&lt;</span><span> </span><span>(</span><span>localThread</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>*</span><span> </span><span>partSize</span><span>;</span><span> </span><span>j</span><span>++</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>lock</span><span> </span><span>(</span><span>_lock</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>total</span><span> </span><span>+=</span><span> </span><span>arr</span><span>[</span><span>j</span><span>]</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>Task</span><span>.</span><span>WaitAll</span><span>(</span><span>tasks</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>total</span><span>;</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
        <div id="content_btf_wrapper" data-wrapper="content_btf">
          
        <div>
        
        <p><a href="https://www.mediavine.com/" target="_blank" rel="noopener">
            <img height="10" width="82" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKQAAAAUCAMAAAA0oWYGAAAANlBMVEUAAACkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKT0RuBeAAAAEXRSTlMAECAwQFBgcHuEj5+vv8/f7w0rGDcAAANcSURBVEjHzZbLlsMoDEQLMMYBPaj//9lZCDt2Oj1nZtesHCKbS0klwLFnACh9SwDQWkaM1Cj4I2OSDUAjtQAw8gUAyD6V9e9AcgA7SW6AktQEJPeMKQCaqqpKBoDDVNX2c1JVVW0k1PUsvRUAQLOIA4BNVVUK0FRUKwBsomIdaajoyEhdRaUAQFfRkZC6yjm0wUmyBSQTlAH9YgLMAQySJHcAyUiS/ZokSc6Mdv3wUXC+1AOyne/3a/IgSUH2kCa+ewBISnKW9c8agkmSc0G+ApIFOoFEeUN2ANtcUbHeN8i1nb7iznVJWa8bAAhJ1kCZZYXMbQV7RnpCxq9SSZKWZGHIBIQbLh5NpyZvSJ8+fVpaW/TYA7cH5NrZLME2CwLOErKR9BOSCiRZkEaSM8YIJblvS5SAHGjcPXyzIM9FbpBHziWXkhe9lLL7Eu0GeYreVlgD6krNByRf4YkTctZccsklLyUXJBekAJOyfSxS/Am5X+5rj4KY2w0yGTktdMoeBd+X3tnu6SZZcFdylru7b0qOpSTKtgI6yemkoMbDBemiotpPyHFV236DrCR186AakWZb5fOpJA39nm4TUbEd35Uctx7VSfqYtHSQIj+MY+kOOT4hB8kODaV3kiz59PJDSZ8kj3aH5Anzm5IPyNmMswp5/F/I7CQbDpKewrS1Lis/lRyNqzB+Qv4nJbkP0ia93iF9iIgej3RrNJcLcilTYhqD5OgkJX0qqauz3NM9RMT2S8n6r0pyjyYj2X43zgBQZzTOC1JJej/GOtgqSc7w+IeSM+X5hJz5q3F+VzI+cKS7cY6Ucsr5akE575M3/76Ajc+ufzZpz/hRk+Xsw+8WlFJKKYfTyJYXZP8FMuLqA3KamZnbFoaYFgTz1sxfd0i2q5jjfvVQ0q9GfKXbYwFdbx1L0bR9h2zhn8jIx7HI/ddjMVlk+3WMdWotaSu+KYnI14dxOKOk2deyCfMTUmITe1wJvlwwWG+QM46AdcF4G+p0VBh1poCc9wtGwepRzDjLM8Z1WkRgjtK+QzYz84piZg1J3XyPyTXcCup6VjnWVc3NfMfuZlavGavAy8183Y+yuLkWpOHmmgFkdXPJSOLvFWRZs68LSAkD/pkr+XuUPg8AqDozgPya/W8B/gPQAm/tWHkI8wAAAABJRU5ErkJggg==">
          </a>
        </p>
      </div></div>
    
<!-- [Format Time: 0.0007 seconds] -->




<p>Note that you have to use a <code>localThread</code> variable to “save” the value of <code>iThread</code> at that point in time. Otherwise, it would be a captured variable that changes as the <code>for</code> loop advances.</p>



<p>Let’s use <a href="https://github.com/dotnet/BenchmarkDotNet">BenchmarkDotNet</a> to compare the performance of the first parallel solution to the regular-iteration baseline (for 100,000 Items):</p>



<table><thead><tr><th>Method</th><th>Mean</th><th>Error</th><th>StdDev</th></tr></thead><tbody><tr><td>RegularIteration</td><td>161.6 us</td><td>1.992 us</td><td>1.765 us</td></tr><tr><td>ThreadPoolWithLock</td><td>8,147.0 us</td><td>148.396 us</td><td>138.810 us</td></tr></tbody></table>



<h6>The measuring unit ‘us’ stands for microseconds. 1000 us = 1 millisecond</h6>



<p>Well, that didn’t do so well. Seems like either the overhead of creating threads or more likely the locking overhead is really hurting performance.</p>



<p>Maybe this can be improved with some optimizations.</p>



<h2>Optimizing with Interlocked</h2>



<p>The first possible optimization we can do is change the locked with the <code>Interlocked</code> helper class. Consider the expression <code>total += something</code>. It both <strong>reads</strong> from total, adds items, and then <strong>writes</strong> back to total. These are 2 operations on the <code>total</code> variable. So with multiple threads, a different thread might do an operation on <code>total</code> <strong>during</strong> the read and write, corrupting the data. <code>Interlocked.Add(ref total, something)</code> guarantees that this will be a single <strong>atomic</strong> operation (in-depth explanation <a href="http://www.albahari.com/threading/part4.aspx#_Interlocked">here</a>).</p>



<p>Here’s the implementation:
</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5e49ac3b59d60113980743" data-settings=" touchscreen no-popup minimize scroll-mouseover wrap">
		
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="hide">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p></div>
				</td>
						<td><div><p><span>[</span><span>Benchmark</span><span>]</span></p><p><span>public</span><span> </span><span>long</span><span> </span><span>ThreadPoolStrategy</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>long</span><span> </span><span>total</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>int</span><span> </span><span>threads</span><span> </span><span>=</span><span> </span><span>8</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>var</span><span> </span><span>partSize</span><span> </span><span>=</span><span> </span><span>ITEMS</span><span> </span><span>/</span><span> </span><span>threads</span><span>;</span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>Task</span><span>[</span><span>]</span><span> </span><span>tasks</span><span> </span><span>=</span><span> </span><span>new</span><span> </span><span>Task</span><span>[</span><span>threads</span><span>]</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>iThread</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>iThread</span><span> </span><span>&lt;</span><span> </span><span>threads</span><span>;</span><span> </span><span>iThread</span><span>++</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>var</span><span> </span><span>localThread</span><span> </span><span>=</span><span> </span><span>iThread</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>tasks</span><span>[</span><span>localThread</span><span>]</span><span> </span><span>=</span><span> </span><span>Task</span><span>.</span><span>Run</span><span>(</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>j</span><span> </span><span>=</span><span> </span><span>localThread *</span><span> </span><span>partSize</span><span>;</span><span> </span><span>j</span><span> </span><span>&lt;</span><span> </span><span>(</span><span>localThread</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>*</span><span> </span><span>partSize</span><span>;</span><span> </span><span>j</span><span>++</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>Interlocked</span><span>.</span><span>Add</span><span>(</span><span>ref </span><span>total</span><span>,</span><span> </span><span>arr</span><span>[</span><span>j</span><span>]</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>Task</span><span>.</span><span>WaitAll</span><span>(</span><span>tasks</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>total</span><span>;</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0006 seconds] -->




<p>Comparing it to the previous implementation with <code>lock</code> gives the following results (for 100,000 Items):</p>



<table><thead><tr><th>Method</th><th>Mean</th><th>Error</th><th>StdDev</th><th>Median</th></tr></thead><tbody><tr><td>RegularIteration</td><td>159.3 us</td><td>3.136 us</td><td>4.694 us</td><td>160.9 us</td></tr><tr><td>ThreadPoolWithLock</td><td>8,271.0 us</td><td>157.944 us</td><td>188.021 us</td><td>8,310.9 us</td></tr><tr><td>ThreadPoolInterlocked</td><td>26,994.1 us</td><td>2,702.796 us</td><td>7,489.435 us</td><td>29,745.2 us</td></tr></tbody></table>



<p>Wow, it actually got much worse when using <code>Interlocked</code>. It seems that the further I try to optimize the worst the performance gets. I should probably stop while I can.</p>



<p>Actually, the reason why this happens is quite sneaky. If you followed closely, you might have noticed that I’m running in a <strong>32-bit process</strong> but using a <strong>long</strong> variable for the total sum. Since long is a 64-bit size variable, and the process is 32-bit, the <code>Interlocked</code> operation is very expensive. Let’s run the same benchmark in a 64-bit process:</p>



<table><thead><tr><th>Method (64-bit)</th><th>Mean</th><th>Error</th><th>StdDev</th></tr></thead><tbody><tr><td>RegularIteration</td><td>67.34 us</td><td>1.297 us</td><td>1.442 us</td></tr><tr><td>ThreadPoolWithLock</td><td>7,895.20 us</td><td>156.038 us</td><td>179.694 us</td></tr><tr><td>ThreadPoolInterlocked</td><td>3,107.76 us</td><td>20.343 us</td><td>19.029 us</td></tr></tbody></table>



<p data-slot-rendered-dynamic="true">In a 64-bit process, the <code>Interlocked</code> solution is more than twice as fast as the <code>lock</code> solution. And the regular-iteration performance time is now also reduced. It seems that when working with <code>long</code> variables the performance is much better with 64-bit processes. All the next benchmarks from now on will be with a 64-bit process.</p>
        <div id="content_2_btf_wrapper" data-wrapper="content_2_btf">
          
        <div>
        
        <p><a href="https://www.mediavine.com/" target="_blank" rel="noopener">
            <img height="10" width="82" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKQAAAAUCAMAAAA0oWYGAAAANlBMVEUAAACkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKT0RuBeAAAAEXRSTlMAECAwQFBgcHuEj5+vv8/f7w0rGDcAAANcSURBVEjHzZbLlsMoDEQLMMYBPaj//9lZCDt2Oj1nZtesHCKbS0klwLFnACh9SwDQWkaM1Cj4I2OSDUAjtQAw8gUAyD6V9e9AcgA7SW6AktQEJPeMKQCaqqpKBoDDVNX2c1JVVW0k1PUsvRUAQLOIA4BNVVUK0FRUKwBsomIdaajoyEhdRaUAQFfRkZC6yjm0wUmyBSQTlAH9YgLMAQySJHcAyUiS/ZokSc6Mdv3wUXC+1AOyne/3a/IgSUH2kCa+ewBISnKW9c8agkmSc0G+ApIFOoFEeUN2ANtcUbHeN8i1nb7iznVJWa8bAAhJ1kCZZYXMbQV7RnpCxq9SSZKWZGHIBIQbLh5NpyZvSJ8+fVpaW/TYA7cH5NrZLME2CwLOErKR9BOSCiRZkEaSM8YIJblvS5SAHGjcPXyzIM9FbpBHziWXkhe9lLL7Eu0GeYreVlgD6krNByRf4YkTctZccsklLyUXJBekAJOyfSxS/Am5X+5rj4KY2w0yGTktdMoeBd+X3tnu6SZZcFdylru7b0qOpSTKtgI6yemkoMbDBemiotpPyHFV236DrCR186AakWZb5fOpJA39nm4TUbEd35Uctx7VSfqYtHSQIj+MY+kOOT4hB8kODaV3kiz59PJDSZ8kj3aH5Anzm5IPyNmMswp5/F/I7CQbDpKewrS1Lis/lRyNqzB+Qv4nJbkP0ia93iF9iIgej3RrNJcLcilTYhqD5OgkJX0qqauz3NM9RMT2S8n6r0pyjyYj2X43zgBQZzTOC1JJej/GOtgqSc7w+IeSM+X5hJz5q3F+VzI+cKS7cY6Ucsr5akE575M3/76Ajc+ufzZpz/hRk+Xsw+8WlFJKKYfTyJYXZP8FMuLqA3KamZnbFoaYFgTz1sxfd0i2q5jjfvVQ0q9GfKXbYwFdbx1L0bR9h2zhn8jIx7HI/ddjMVlk+3WMdWotaSu+KYnI14dxOKOk2deyCfMTUmITe1wJvlwwWG+QM46AdcF4G+p0VBh1poCc9wtGwepRzDjLM8Z1WkRgjtK+QzYz84piZg1J3XyPyTXcCup6VjnWVc3NfMfuZlavGavAy8183Y+yuLkWpOHmmgFkdXPJSOLvFWRZs68LSAkD/pkr+XuUPg8AqDozgPya/W8B/gPQAm/tWHkI8wAAAABJRU5ErkJggg==">
          </a>
        </p>
      </div></div>
    



<p>So using <code>Interlocked</code> helped a bit, but the result is still far worse than using regular iterative approach.</p>



<h6>If you wonder at this point about the <code>volatile</code> keyword, it actually doesn’t help. The issue is that we both <strong>read</strong> and <strong>write</strong> from different threads. <code>volatile</code> might work just for read or just for write operations. So by using <code>volatile</code> without an additional lock will give the wrong result. You can read more in Joseph Albahari’s <a href="http://www.albahari.com/threading/part4.aspx">explaination</a>.</h6>



<h2>Optimizing with Parallel.For</h2>



<p>Before going any further, let’s try the fancy <code>Parallel.For</code> feature that was added as part of <strong>Task Parallel Library (TPL)</strong> in .NET 4.0. This is an optimized way to be able to run <code>for</code> loops on multiple threads. The code is:
</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5e49ac3b59d63553808516" data-settings=" touchscreen no-popup minimize scroll-mouseover wrap">
		
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="hide">
					
				</td>
						<td><div><p><span>[</span><span>Benchmark</span><span>]</span></p><p><span>public</span><span> </span><span>long</span><span> </span><span>ParallelFor</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>long</span><span> </span><span>total</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>int</span><span> </span><span>parts</span><span> </span><span>=</span><span> </span><span>8</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>int</span><span> </span><span>partSize</span><span> </span><span>=</span><span> </span><span>ITEMS</span><span> </span><span>/</span><span> </span><span>parts</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>var</span><span> </span><span>parallel</span><span> </span><span>=</span><span> </span><span>Parallel</span><span>.</span><span>For</span><span>(</span><span>0</span><span>,</span><span> </span><span>parts</span><span>,</span><span> </span><span>new</span><span> </span><span>ParallelOptions</span><span>(</span><span>)</span><span>,</span><span> </span><span>(</span><span>iter</span><span>)</span><span> </span><span>=</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>j</span><span> </span><span>=</span><span> </span><span>iter *</span><span> </span><span>partSize</span><span>;</span><span> </span><span>j</span><span> </span><span>&lt;</span><span> </span><span>(</span><span>iter</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>*</span><span> </span><span>partSize</span><span>;</span><span> </span><span>j</span><span>++</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>Interlocked</span><span>.</span><span>Add</span><span>(</span><span>ref </span><span>total</span><span>,</span><span> </span><span>arr</span><span>[</span><span>j</span><span>]</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>total</span><span>;</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0005 seconds] -->




<p>Comparing it with the baseline and the previous interlocked implementation:</p>



<table><thead><tr><th>Method</th><th>Mean</th><th>Error</th><th>StdDev</th></tr></thead><tbody><tr><td>RegularIteration</td><td>69.43 us</td><td>1.373 us</td><td>1.969 us</td></tr><tr><td>ThreadPoolInterlocked</td><td>3,117.44 us</td><td>13.520 us</td><td>12.646 us</td></tr><tr><td>ParallelFor</td><td>3,028.13 us</td><td>55.719 us</td><td>52.119 us</td></tr></tbody></table>



<h6>Note that <code>Parallel.For</code> <a href="https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.parallel.for?view=netframework-4.7.2">doesn’t promise</a> to run all the iterations in parallel. For example, if you were to set the number of <strong>parts</strong> to 100 and the PC only has 8 cores it’s impossible. It does optimize to run in parallel as much as possible. You can actually set the maximum number of “parallelism” with an additional configuration like this: <code>Parallel.For(from, to, new ParallelOptions()  {MaxDegreeOfParallelism = 4}, ...</code></h6>



<p>Alright, so while the syntax is much nicer with <code>Parallel.For</code>, it seems to be just slightly more efficient than manually queuing thread-pool threads. And still far less efficient than just iterating over the array and summing up items.</p>



<h2>Eliminating Suspects</h2>



<p>The biggest suspect to hurt performance is the <code>Interlocked.Add</code> operation. Let’s just comment it out and see what changes. Instead of <code>Interlocked.Add(ref total, arr[j])</code> I replaced it with one line that reads from the array <code>x = arr[j]</code>. Here are the results:</p>



<table><thead><tr><th>Method</th><th>Mean</th><th>Error</th><th>StdDev</th></tr></thead><tbody><tr><td>RegularIteration</td><td>57.76 us</td><td>0.8526 us</td><td>0.7976 us</td></tr><tr><td>ThreadPoolInterlocked</td><td>34.21 us</td><td>0.3934 us</td><td>0.3487 us</td></tr><tr><td>ParallelFor</td><td>33.74 us</td><td>0.6407 us</td><td>0.7379 us</td></tr></tbody></table>



<p data-slot-rendered-dynamic="true">Alright, now we’re getting somewhere here. Without the <code>Interlocked</code> line of code, the parallel code runs almost 2 times faster with <code>Parallel.For</code> and the thread-pool strategy.</p>
        <div id="content_3_btf_wrapper" data-wrapper="content_3_btf">
          
        <div>
        
        <p><a href="https://www.mediavine.com/" target="_blank" rel="noopener">
            <img height="10" width="82" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKQAAAAUCAMAAAA0oWYGAAAANlBMVEUAAACkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKT0RuBeAAAAEXRSTlMAECAwQFBgcHuEj5+vv8/f7w0rGDcAAANcSURBVEjHzZbLlsMoDEQLMMYBPaj//9lZCDt2Oj1nZtesHCKbS0klwLFnACh9SwDQWkaM1Cj4I2OSDUAjtQAw8gUAyD6V9e9AcgA7SW6AktQEJPeMKQCaqqpKBoDDVNX2c1JVVW0k1PUsvRUAQLOIA4BNVVUK0FRUKwBsomIdaajoyEhdRaUAQFfRkZC6yjm0wUmyBSQTlAH9YgLMAQySJHcAyUiS/ZokSc6Mdv3wUXC+1AOyne/3a/IgSUH2kCa+ewBISnKW9c8agkmSc0G+ApIFOoFEeUN2ANtcUbHeN8i1nb7iznVJWa8bAAhJ1kCZZYXMbQV7RnpCxq9SSZKWZGHIBIQbLh5NpyZvSJ8+fVpaW/TYA7cH5NrZLME2CwLOErKR9BOSCiRZkEaSM8YIJblvS5SAHGjcPXyzIM9FbpBHziWXkhe9lLL7Eu0GeYreVlgD6krNByRf4YkTctZccsklLyUXJBekAJOyfSxS/Am5X+5rj4KY2w0yGTktdMoeBd+X3tnu6SZZcFdylru7b0qOpSTKtgI6yemkoMbDBemiotpPyHFV236DrCR186AakWZb5fOpJA39nm4TUbEd35Uctx7VSfqYtHSQIj+MY+kOOT4hB8kODaV3kiz59PJDSZ8kj3aH5Anzm5IPyNmMswp5/F/I7CQbDpKewrS1Lis/lRyNqzB+Qv4nJbkP0ia93iF9iIgej3RrNJcLcilTYhqD5OgkJX0qqauz3NM9RMT2S8n6r0pyjyYj2X43zgBQZzTOC1JJej/GOtgqSc7w+IeSM+X5hJz5q3F+VzI+cKS7cY6Ucsr5akE575M3/76Ajc+ufzZpz/hRk+Xsw+8WlFJKKYfTyJYXZP8FMuLqA3KamZnbFoaYFgTz1sxfd0i2q5jjfvVQ0q9GfKXbYwFdbx1L0bR9h2zhn8jIx7HI/ddjMVlk+3WMdWotaSu+KYnI14dxOKOk2deyCfMTUmITe1wJvlwwWG+QM46AdcF4G+p0VBh1poCc9wtGwepRzDjLM8Z1WkRgjtK+QzYz84piZg1J3XyPyTXcCup6VjnWVc3NfMfuZlavGavAy8183Y+yuLkWpOHmmgFkdXPJSOLvFWRZs68LSAkD/pkr+XuUPg8AqDozgPya/W8B/gPQAm/tWHkI8wAAAABJRU5ErkJggg==">
          </a>
        </p>
      </div></div>
    



<p>Let’s do some brainstorming. How can we sum the elements of an array without adding an <code>Interlocked</code> expression?</p>



<p>In the specific case of summing array elements, it can be easily done with per-thread locals. We’ll have a <strong>thread-sum</strong> for each thread and just add them up in the end. <code>Parallel.For</code> even has a helpful functionality for that. There’s an overload with a parameter called <strong>localFinally</strong>.</p>



<h2>Parallel.For with local thread totals</h2>



<p>The idea is that each iteration will return a value. An additional delegate <code>Action<tvalue></tvalue></code> will execute at the end of each iteration, with the value as a parameter. In our case, there are 8 iterations, 1 for each thread. Each iteration will return a <strong>localTotal</strong> which represents the sum total of elements in that part of the array. And the <strong>localFinally</strong> will sum those up. Here’s the code:
</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5e49ac3b59d65782126811" data-settings=" touchscreen no-popup minimize scroll-mouseover wrap">
		
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="hide">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p></div>
				</td>
						<td><div><p><span>[</span><span>Benchmark</span><span>]</span></p><p><span>public</span><span> </span><span>int</span><span> </span><span>ParallelForWithLocalFinally</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>int</span><span> </span><span>total</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>int</span><span> </span><span>parts</span><span> </span><span>=</span><span> </span><span>8</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>int</span><span> </span><span>partSize</span><span> </span><span>=</span><span> </span><span>ITEMS</span><span> </span><span>/</span><span> </span><span>parts</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>var</span><span> </span><span>parallel</span><span> </span><span>=</span><span> </span><span>Parallel</span><span>.</span><span>For</span><span>(</span><span>0</span><span>,</span><span> </span><span>parts</span><span>,</span><span> </span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>localInit</span><span>:</span><span>(</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>0L</span><span>,</span><span> </span><span>// Initializes the "localTotal"</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>body</span><span>:</span><span>(</span><span>iter</span><span>,</span><span> </span><span>state</span><span>,</span><span> </span><span>localTotal</span><span>)</span><span> </span><span>=</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>j</span><span> </span><span>=</span><span> </span><span>iter *</span><span> </span><span>partSize</span><span>;</span><span> </span><span>j</span><span> </span><span>&lt;</span><span> </span><span>(</span><span>iter</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>*</span><span> </span><span>partSize</span><span>;</span><span> </span><span>j</span><span>++</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>localTotal</span><span> </span><span>+=</span><span> </span><span>arr</span><span>[</span><span>j</span><span>]</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>localTotal</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>localFinally</span><span>:</span><span>(</span><span>localTotal</span><span>)</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>{</span><span> </span><span>total</span><span> </span><span>+=</span><span> </span><span>localTotal</span><span>;</span><span> </span><span>}</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>total</span><span>;</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0006 seconds] -->




<p>Now when running this against the simple regular-iteration sum:</p>



<table><thead><tr><th>Method</th><th>Mean</th><th>Error</th><th>StdDev</th></tr></thead><tbody><tr><td>RegularIteration</td><td>66.12 us</td><td>0.8337 us</td><td>0.7391 us</td></tr><tr><td>ParallelFor</td><td>3,058.63 us</td><td>58.6600 us</td><td>65.2005 us</td></tr><tr><td>ParallelForWithLocalFinally</td><td>36.23 us</td><td>0.6024 us</td><td>0.5635 us</td></tr></tbody></table>



<p><strong>Great success!</strong> We were able to minimize processing time by about 50%. Not as much as the number of cores, but still, mission successful.</p>



<h2>Going Deeper</h2>



<p>There are still some questions unanswered. Why is the parallelism 2 times faster and not 8, like the number of my cores? What happens with bigger and smaller arrays? Does CPU memory cache play any role in this?</p>



<p>Maybe some more benchmarks will help us understand. Let’s try with a different amounts of items:</p>



<table><thead><tr><th>Method</th><th>ITEMS</th><th>Mean</th><th>Error</th><th>StdDev</th></tr></thead><tbody><tr><td>RegularIteration</td><td>5000</td><td>3.312 us</td><td>0.0642 us</td><td>0.0789 us</td></tr><tr><td>ParallelForWithLocalFinally</td><td>5000</td><td>9.630 us</td><td>0.2453 us</td><td>0.7234 us</td></tr><tr><td>RegularIteration</td><td>10000</td><td>8.157 us</td><td>0.1588 us</td><td>0.2121 us</td></tr><tr><td>ParallelForWithLocalFinally</td><td>10000</td><td>12.705 us</td><td>0.2319 us</td><td>0.2055 us</td></tr><tr><td>RegularIteration</td><td>30000</td><td>19.76 us</td><td>0.2826 us</td><td>0.2505 us</td></tr><tr><td>ParallelForWithLocalFinally</td><td>30000</td><td>16.90 us</td><td>0.2695 us</td><td>0.2521 us</td></tr><tr><td>RegularIteration</td><td>100000</td><td>65.61 us</td><td>0.9373 us</td><td>0.8768 us</td></tr><tr><td>ParallelForWithLocalFinally</td><td>100000</td><td>35.58 us</td><td>0.6241 us</td><td>0.5838 us</td></tr><tr><td>RegularIteration</td><td>250000</td><td>163.55 us</td><td>1.910 us</td><td>1.693 us</td></tr><tr><td>ParallelForWithLocalFinally</td><td>250000</td><td>75.91 us</td><td>1.679 us</td><td>1.866 us</td></tr></tbody></table>



<p data-slot-rendered-dynamic="true">So in our scenario, at about <strong>20,000</strong> elements, the regular-iteration strategy is as effective as the parallel strategy. As the number of elements grow, the parallel strategy becomes more effective. At 250,000 elements, the parallel strategy is about 2.2 times faster than regular iteration strategy.</p>
        <div id="content_4_btf_wrapper" data-wrapper="content_4_btf">
          
        <div>
        
        <p><a href="https://www.mediavine.com/" target="_blank" rel="noopener">
            <img height="10" width="82" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKQAAAAUCAMAAAA0oWYGAAAANlBMVEUAAACkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKT0RuBeAAAAEXRSTlMAECAwQFBgcHuEj5+vv8/f7w0rGDcAAANcSURBVEjHzZbLlsMoDEQLMMYBPaj//9lZCDt2Oj1nZtesHCKbS0klwLFnACh9SwDQWkaM1Cj4I2OSDUAjtQAw8gUAyD6V9e9AcgA7SW6AktQEJPeMKQCaqqpKBoDDVNX2c1JVVW0k1PUsvRUAQLOIA4BNVVUK0FRUKwBsomIdaajoyEhdRaUAQFfRkZC6yjm0wUmyBSQTlAH9YgLMAQySJHcAyUiS/ZokSc6Mdv3wUXC+1AOyne/3a/IgSUH2kCa+ewBISnKW9c8agkmSc0G+ApIFOoFEeUN2ANtcUbHeN8i1nb7iznVJWa8bAAhJ1kCZZYXMbQV7RnpCxq9SSZKWZGHIBIQbLh5NpyZvSJ8+fVpaW/TYA7cH5NrZLME2CwLOErKR9BOSCiRZkEaSM8YIJblvS5SAHGjcPXyzIM9FbpBHziWXkhe9lLL7Eu0GeYreVlgD6krNByRf4YkTctZccsklLyUXJBekAJOyfSxS/Am5X+5rj4KY2w0yGTktdMoeBd+X3tnu6SZZcFdylru7b0qOpSTKtgI6yemkoMbDBemiotpPyHFV236DrCR186AakWZb5fOpJA39nm4TUbEd35Uctx7VSfqYtHSQIj+MY+kOOT4hB8kODaV3kiz59PJDSZ8kj3aH5Anzm5IPyNmMswp5/F/I7CQbDpKewrS1Lis/lRyNqzB+Qv4nJbkP0ia93iF9iIgej3RrNJcLcilTYhqD5OgkJX0qqauz3NM9RMT2S8n6r0pyjyYj2X43zgBQZzTOC1JJej/GOtgqSc7w+IeSM+X5hJz5q3F+VzI+cKS7cY6Ucsr5akE575M3/76Ajc+ufzZpz/hRk+Xsw+8WlFJKKYfTyJYXZP8FMuLqA3KamZnbFoaYFgTz1sxfd0i2q5jjfvVQ0q9GfKXbYwFdbx1L0bR9h2zhn8jIx7HI/ddjMVlk+3WMdWotaSu+KYnI14dxOKOk2deyCfMTUmITe1wJvlwwWG+QM46AdcF4G+p0VBh1poCc9wtGwepRzDjLM8Z1WkRgjtK+QzYz84piZg1J3XyPyTXcCup6VjnWVc3NfMfuZlavGavAy8183Y+yuLkWpOHmmgFkdXPJSOLvFWRZs68LSAkD/pkr+XuUPg8AqDozgPya/W8B/gPQAm/tWHkI8wAAAABJRU5ErkJggg==">
          </a>
        </p>
      </div></div>
    



<p>Before drawing any conclusions, let’s do another experiment. This time, instead of summing the elements as they are, we’ll change to <strong>string</strong> and then parse them back to <strong>int</strong>. This operation is much heavier and should take more time.
</p>



<!-- Crayon Syntax Highlighter v_2.7.2_beta -->

		<div id="crayon-5e49ac3b59d67612399776" data-settings=" touchscreen no-popup minimize scroll-mouseover wrap">
		
			
			<div>
				<table>
					<tbody><tr>
				<td data-settings="hide">
					
				</td>
						<td><div><p><span>public</span><span> </span><span>double</span><span> </span><span>RegularIteration</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>double</span><span> </span><span>total</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>ITEMS</span><span>;</span><span> </span><span>i</span><span>++</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>total</span><span> </span><span>+=</span><span> </span><span>int</span><span>.</span><span>Parse</span><span>(</span><span>arr</span><span>[</span><span>i</span><span>]</span><span>.</span><span>ToString</span><span>(</span><span>)</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>total</span><span>;</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
		</div>
<!-- [Format Time: 0.0002 seconds] -->




<p>The results this time are:</p>



<table><thead><tr><th>Method</th><th>ITEMS</th><th>Mean</th><th>Error</th><th>StdDev</th><th>Median</th></tr></thead><tbody><tr><td>RegularIteration</td><td>1000</td><td>153.9 us</td><td>3.021 us</td><td>3.928 us</td><td>153.0 us</td></tr><tr><td>ParallelForWithLocalFinally</td><td>1000</td><td>104.5 us</td><td>3.240 us</td><td>9.554 us</td><td>107.6 us</td></tr><tr><td>RegularIteration</td><td>5000</td><td>781.1 us</td><td>15.340 us</td><td>25.203 us</td><td>780.6 us</td></tr><tr><td>ParallelForWithLocalFinally</td><td>5000</td><td>412.2 us</td><td>12.422 us</td><td>36.625 us</td><td>410.3 us</td></tr><tr><td>RegularIteration</td><td>10000</td><td>1,551.9 us</td><td>29.551 us</td><td>34.031 us</td><td>1,548.4 us</td></tr><tr><td>ParallelForWithLocalFinally</td><td>10000</td><td>763.4 us</td><td>21.766 us</td><td>64.179 us</td><td>769.7 us</td></tr><tr><td>RegularIteration</td><td>100000</td><td>17,349.3 us</td><td>748.256 us</td><td>2,206.251 us</td><td>16,212.8 us</td></tr><tr><td>ParallelForWithLocalFinally</td><td>100000</td><td>6,238.6 us</td><td>123.227 us</td><td>280.650 us</td><td>6,261.2 us</td></tr></tbody></table>



<p>As you can see, in this case, the parallel solution is as much as 3 times faster than the regular-iteration solution for 100,000 elements. And it starts being more effective for smaller arrays, with as much as 1000 elements.</p>



<h2>Conclusions and Summary</h2>



<p>I admit that instead of taking the direct route from the challenge to the <g id="10" data-gr-id="10">solution</g>, we kind of took the long, scenic route. But I wanted you to see some of the performance issues along the way. Here are some of my conclusions from this journey:</p>



<ol><li>Optimization with Parallelism can definitely improve performance, but it can easily hurt it as well. It depends on a lot of factors and each case should be measured and checked.</li><li>When the various threads need to rely on each other with some kind of locking mechanism, the performance can degrade significantly.</li><li>As the last benchmark proved, each use-case is different. For example, in the regular benchmark, parallelism became effective on more than 20,000 array elements. However, in the more complex scenario where we parsed integers to string and back, parallelism was effective even for 1000 elements.</li><li><code>Interlocked</code> works well according to process bitness. In other words, don’t <g id="20" data-gr-id="20">use </g><code>Interlocked</code><g id="20" data-gr-id="20"> </g><g id="21" data-gr-id="21"><g id="20" data-gr-id="20">for</g> </g><code>long</code><g id="21" data-gr-id="21"> variables</g> in 32-bit processes.</li><li></li></ol>



<p data-slot-rendered-dynamic="true">Another thing to consider is <a href="https://en.wikipedia.org/wiki/CPU_cache">CPU Cache</a>. It’s hard to measure how exactly it affects the performance, but it’s important to understand that caching happens under the hood without our control or knowledge and it’s more effective without parallelism. The fastest L1 cache is not shared between CPU cores. The mid-level L2 cache is usually shared between 2 CPU cores and only the slowest L3 cache is shared between all the cores. Note that even the “slow” L3 cache is much faster than RAM.</p>
        <div id="content_5_btf_wrapper" data-wrapper="content_5_btf">
          
        <div>
        
        <p><a href="https://www.mediavine.com/" target="_blank" rel="noopener">
            <img height="10" width="82" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAKQAAAAUCAMAAAA0oWYGAAAANlBMVEUAAACkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKSkpKT0RuBeAAAAEXRSTlMAECAwQFBgcHuEj5+vv8/f7w0rGDcAAANcSURBVEjHzZbLlsMoDEQLMMYBPaj//9lZCDt2Oj1nZtesHCKbS0klwLFnACh9SwDQWkaM1Cj4I2OSDUAjtQAw8gUAyD6V9e9AcgA7SW6AktQEJPeMKQCaqqpKBoDDVNX2c1JVVW0k1PUsvRUAQLOIA4BNVVUK0FRUKwBsomIdaajoyEhdRaUAQFfRkZC6yjm0wUmyBSQTlAH9YgLMAQySJHcAyUiS/ZokSc6Mdv3wUXC+1AOyne/3a/IgSUH2kCa+ewBISnKW9c8agkmSc0G+ApIFOoFEeUN2ANtcUbHeN8i1nb7iznVJWa8bAAhJ1kCZZYXMbQV7RnpCxq9SSZKWZGHIBIQbLh5NpyZvSJ8+fVpaW/TYA7cH5NrZLME2CwLOErKR9BOSCiRZkEaSM8YIJblvS5SAHGjcPXyzIM9FbpBHziWXkhe9lLL7Eu0GeYreVlgD6krNByRf4YkTctZccsklLyUXJBekAJOyfSxS/Am5X+5rj4KY2w0yGTktdMoeBd+X3tnu6SZZcFdylru7b0qOpSTKtgI6yemkoMbDBemiotpPyHFV236DrCR186AakWZb5fOpJA39nm4TUbEd35Uctx7VSfqYtHSQIj+MY+kOOT4hB8kODaV3kiz59PJDSZ8kj3aH5Anzm5IPyNmMswp5/F/I7CQbDpKewrS1Lis/lRyNqzB+Qv4nJbkP0ia93iF9iIgej3RrNJcLcilTYhqD5OgkJX0qqauz3NM9RMT2S8n6r0pyjyYj2X43zgBQZzTOC1JJej/GOtgqSc7w+IeSM+X5hJz5q3F+VzI+cKS7cY6Ucsr5akE575M3/76Ajc+ufzZpz/hRk+Xsw+8WlFJKKYfTyJYXZP8FMuLqA3KamZnbFoaYFgTz1sxfd0i2q5jjfvVQ0q9GfKXbYwFdbx1L0bR9h2zhn8jIx7HI/ddjMVlk+3WMdWotaSu+KYnI14dxOKOk2deyCfMTUmITe1wJvlwwWG+QM46AdcF4G+p0VBh1poCc9wtGwepRzDjLM8Z1WkRgjtK+QzYz84piZg1J3XyPyTXcCup6VjnWVc3NfMfuZlavGavAy8183Y+yuLkWpOHmmgFkdXPJSOLvFWRZs68LSAkD/pkr+XuUPg8AqDozgPya/W8B/gPQAm/tWHkI8wAAAABJRU5ErkJggg==">
          </a>
        </p>
      </div></div>
    



<p>So the article is at an end and I still didn’t figure out why the optimization wasn’t more successful. I did learn a few things and I hope you did too. Feel free to share any insight in the comments section.</p>

   <div>
<p><span>Enjoy the blog? I would love you to subscribe!</span>
<img src="https://i0.wp.com/michaelscodingspot.com/wp-content/uploads/2019/04/pdf-icon.png?w=1080&amp;ssl=1" width="28" height="32">
<span>Performance Optimizations in C#: 10 Best Practices (exclusive article)</span>
</p>
<div>
<div id="myflex123">
<p><img src="https://i2.wp.com/michaelscodingspot.com/wp-content/uploads/2017/06/black-small-optimized-flipped.gif?w=1080&amp;ssl=1" data-recalc-dims="1"></p><!--mailchimp here-->

</div>
</div>
</div>
   																	</div>
														</div>
														

																				</article></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>