<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Enable Git LFS and merge the corefx-testdata repo with corefx &#xB7; Issue #30973 &#xB7; dotnet/runtime &#xB7; GitHub -
linksfor.dev(s)
    </title>
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta charset="utf-8">
    <meta name="Description" content="A curated source of links that devs might find interesting. Updated around the clock." />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        
<div class="readable">
    <div id="readOverlay" class="style-ebook"><div id="readInner" class="margin-medium size-medium"><h1>Enable Git LFS and merge the corefx-testdata repo with corefx · Issue #30973 · dotnet/runtime · GitHub</h1><div><div id="" class="d-block comment-body markdown-body  js-comment-body"><blockquote><p>I don't have numbers of how often we fresh clone our repository but I wouldn't be surprised if that happens about 50 times per day which results in 5.8GB bandwidth per day and 174GB per month. That means we would need to buy 35 data plans which cost 174 dollars per month.</p></blockquote><p>Looking at just the PR queue for CoreFX we clone several hundred times a day. Consider just the following few dates:</p><ul><li>Monday: 660 clones</li><li>Tuesday: 440 clones</li></ul><p>The actual number of builds created via PRs is ~40-50 but each build has 10+ jobs which execute a checkout operation.</p><p>The actual number is likely much higher here because this is counting CoreFX PR only. To truly get the number for the consolidated repository we need to consider PR + CI + Official builds for core-setup, coreclr and corefx + likely grab some data from GitHub about how many other clone operations we see per day.</p><p>I'd wager that CI / PR is our biggest cost here though. Those clones are pretty much guaranteed to be fresh, or at least need to be planned for as fresh. Individual developers likely don't do a fresh clone every time hence not as impactful here. But I'd still like to find a way to get data on that.</p><p><strong>edit</strong> removed some ambiguity around job vs. build</p></div></div></div></div>
</div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script>
        (function () {
            var COLLECT_URL = "https://dna.buildstarted.com/t";
            var SITE_ID = "linksfor.devs";
            var GLOBAL_VAR_NAME = "__DNA__";

            window[GLOBAL_VAR_NAME] = {};

            window[GLOBAL_VAR_NAME].sendPageView = function () {
                var path = location.pathname;
                var referrer = document.referrer;

                var url = COLLECT_URL + "?siteid=" + SITE_ID + "&p=" + encodeURIComponent(path) + "&r=" + encodeURIComponent(referrer);

                try { fetch(url, { method: "GET" }); } catch (e) { }
            };

            window[GLOBAL_VAR_NAME].sendPageView();
        })();
    </script>
</body>
</html>