<!DOCTYPE html>
<html lang="en">
<head>
    <title>
A Federal Blue Checkmark, and Not Learning Lessons - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="A Federal Blue Checkmark, and Not Learning Lessons - linksfor.dev(s)"/>
    <meta property="article:author" content="https://www.facebook.com/anildash"/>
    <meta property="og:description" content="People are wrong on the Internet every day; generally I don&#x2019;t try to fuss about that too much. But when Sam Lessin, a former VP of Product Management at Facebook, publishes a wildly wrong recommendation about online identity in a credible media outlet, it&#x2019;s worth correcting because others"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://anildash.com/2020/07/21/a-federal-blue-checkmark-wont-solve-online-speech-obviously/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - A Federal Blue Checkmark, and Not Learning Lessons</title>
<div class="readable">
        <h1>A Federal Blue Checkmark, and Not Learning Lessons</h1>
            <div>by https://www.facebook.com/anildash</div>
            <div>Reading time: 10-13 minutes</div>
        <div>Posted here: 24 Jul 2020</div>
        <p><a href="https://anildash.com/2020/07/21/a-federal-blue-checkmark-wont-solve-online-speech-obviously/">https://anildash.com/2020/07/21/a-federal-blue-checkmark-wont-solve-online-speech-obviously/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="site-main" role="main">
    <div>

        <article>

            

            <figure>
            </figure>

            <section>
                <p>People are wrong on the Internet every day; generally I don’t try to fuss about that too much. But when Sam Lessin, a former VP of Product Management at Facebook, publishes a <a href="https://www.theinformation.com/articles/the-simple-and-practical-steps-the-federal-government-should-take-to-fix-online-speech">wildly wrong recommendation</a> about online identity in a credible media outlet, it’s worth correcting because others may take these ideas as credible and cause actual harm. I was frankly surprised by how absolutely broken this suggestion was because I've read other things from Sam that show him to be a smart person who understands a lot about product and out industry.</p><p>I was hoping this piece today is in the “Modest Proposals” category on The Information’s site because it’s some sort of Swiftian satire, but it appears that this article is meant sincerely. That's dismaying, because even as far back as when I wrote <a href="https://medium.com/humane-tech/the-immortal-myths-about-online-abuse-a156e3370aee">The Immortal Myths About Online Abuse</a>, the insights of experienced experts from vulnerable communities had already explained the problems with these kinds of approaches many years prior. I hadn't imagined that people considered experts in this area were still so far behind what is common knowledge for vulnerable people on these platforms.</p><p>But, since this has popped up again, let's explain the problems.</p><blockquote>I believe the federal government should mandate that all social networks &nbsp;of any size adopt a national version of the coveted blue “validated” &nbsp;check mark confirming an authentic identity that is popular among minor celebrities on services like Twitter and Facebook. That would make clear who has validated their status as a real citizen and who has not.</blockquote><p>Phew! There are so, so many problems here. Let's see if we can find <strong>10 fatal flaws in just this one paragraph</strong>:</p><ol><li>We currently have a fascist government that is regularly inflicting violence on people for exercising their free speech rights. This would centralize and simplify their access to tracking vulnerable people's speech.</li><li>This system would <em>by design</em> limit promoted speech to citizens, explicitly disempowering non-citizens, and making even more incentives for the current administation to make citizenship contingent, harkening back to the past efforts that retroactively stripped citizenship from people in America.</li><li>By applying this burden to networks of any size, massively-funded companies would see a trivial increase in the regulatory costs of maintaining their networks, but small independent networks would see a huge relative increase in their cost of compliance, putting a burden on the most at-risk communities online.</li><li>What is "authentic" identity? Is that a government name? What about people whose true identities aren't described by their government names? What is the plan for important public speech that should <em>necessarily</em> not be tied to a individual person's legal identity, like whistleblowers or those reporting abuse?</li><li>Given the repeated, effective, well-funded, deeply damaging efforts at spreading systematic misinformation on all the major social networks, who would trust the current administration to hire, fund, support and secure talent capable of creating and maintaining a verified identity network that would withstand constant, nonstop attempts to undermine its validity and reliability?</li><li>What incentive does the current administration have to make a system that would increase the spread of accurate information? They have consistently worked to <em>undermine</em> all such existing systems, so why would we put the seat of trust in the hands of those who seek to destroy the concept of a shared public truth?</li><li>How would such a proposal be funded? Passport control is currently under the Department of State. Which State programs would be defunded to support the creation of a Federal Blue Check Registry? Who would be accountable for auditing and oversight of such a registry? Who would pay for vulnerable people to be able to get access to a passport registry online?</li><li>Have you ever seen any past issues arise when a single centralized government registry database was created by a violent, white supremacist fascist government? </li><li>How would you address the fact that verified accounts on every major social network already regularly spread deliberate misinformation, intentional hate speech, and purposeful targeted harassment of vulnerable people? Society treats blue checkmarks as validating the <em>content</em> being shared, not the identity of the person sharing them.</li><li>Can a government verification be rescinded? Who decides if it is? Do networks have to abide by it? Would the government be the only source of validation that a network could show? </li></ol><p>By the time I got to the article mentioning the idea of "a national archive of speech from trusted Americans", I figured this <em>had</em> to be satire. But I fear it's not. So let's go over the facts again.</p><h2 id="people-using-their-real-names-does-not-solve-abuse-or-misinformation-">People using their "real" names does not solve abuse or misinformation.</h2><p>There are people who are really white supremacists who want to cause others harm. There are people who will knowingly tell dangerous lies under their government names. Here, I already wrote it, let me just <a href="https://medium.com/humane-tech/the-immortal-myths-about-online-abuse-a156e3370aee">quote myself</a>:</p><blockquote>One of the most common reflexive solutions to abuse is to call for the use of “real names”. This is usually from people with little experience in managing large-scale online communities. Those who do run such systems can attest that an enormous amount of abuse is caused by people who are acting under their legal names; this is possible because many abusive behaviors can be extremely destructive without actually being illegal. (See #7.) For dedicated trolls, it’s also usually not very hard to create a name that seems “real”, which they can use for their attacks. For vulnerable people, using one’s legal name can make them targets for stalkers or others they are trying to avoid, or can force people to retain an identity that is no longer theirs. Worse, even if a user <em>does</em> want to use their legal name on a service, it can be <a href="https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/" rel="noopener nofollow">almost impossible</a> to capture someone’s real name in most common social apps. While persistent identities (pseudonyms) can be a useful tool for making a more accountable community when appropriate, legal names do very little to reduce abuse in large scale communities.</blockquote><p>Just as importantly: <strong>The platforms using these verified accounts would have to want to stop abuse.</strong> And for the most part, they <em>don't.</em></p><p>Take Facebook, where Sam used to work. When they found out that their WhatsApp platform was being used to spread misinformation that was used to incite a genocide against the Rohingya in Myanmar, they could have shut down the platform there, just as Twitter did for some accounts when they found out their service was hacked recently. But Facebook chose not to do that. When extremist American leaders call for military attacks on innocent people in our country, as Tom Cotton did recently, the inclination of major media platforms was to <em>amplify</em> him and give him more reach for his call for violence; we should expect that Facebook would do the same.</p><h2 id="the-systemic-problems-exposed-here">The systemic problems exposed here</h2><p>Worse than even the proposal laid out here is the larger systemic problems revealed by the mere existence of this proposal. Imagine the reaction if a proposal were made to solve security issues in software by "creating a federal code security review program, maybe run by the Department of Interior?" Having such a breathtaking lack of fluency in the <em>decades</em> of research into online identity would be striking for anyone proposing such a grandiose solution; seeing it from someone who was in a position of significant authority at the largest social networking platform that's ever existed is terrifying.</p><p>Worse, seeing a bald trust in the benevolence of a government and administration that has <em>already </em>abused surveillance technology to cause real harm to the most vulnerable is astonishing, <em>especially</em> in a moment where we're literally seeing the largest civil rights demonstrations in the history of our country.</p><p>Then there's the casual handwaving around deeply complex and important systems that reveals a privilege that verges on "let them eat cake" levels. An offhand mention of a <em>government ID page</em> for every person who was registered in this system?! And this as a precondition for "legitimacy" on networks? We already <em>have</em> a blue check system on Twitter, and for years, many have outlined the <a href="https://medium.com/humane-tech/network-inequality-3309fb1aac59">Network Inequality</a> that results in skewed amplification and distortion of messages. Twitter alone likely sends out 100 million emails a week offering free promotion to Trump's racist and sexist messages —&nbsp;now a government infrastructure controlled by him would get to skew which other people could be similarly amplified.</p><p>We know the <a href="https://medium.com/humane-tech/the-online-abuse-playbook-575648c9f798">dynamics of how abuse happens online</a>. We know the patterns of how <a href="https://datasociety.net/research/media-manipulation/">social networks are manipulated</a> to amplify misinformation. It's telling that this piece <em>doesn't even identify the harm it's trying to solve.</em> What does "fix online speech" mean? In the introduction, it's described as "the same safeguards of accountability and reputation" as in the offline world. Who has the safeguard of reputation? Is it those who can get a platform to propose ideas without being fluent in the domain they're speaking to? How could such a dangerous and flawed proposal be presented as "broadly unobjectionable" unless there's a truly extreme bubble of cultural isolation amongst the most powerful in Silicon Valley?</p><p>I believe strongly in regulation-based solutions to keeping social networks and tech giants accountable. I believe deeply in the power of well-functioning government to serve the needs of its citizens. But I also believe deeply in protecting our civil rights and freedoms, and recognize the grave danger of thoughtlessly "solving" vaguely-defined social problems by overburdening fragile systems like the Passport office, already struggling to serve vulnerable immigrants and travelers, with the challenge of addressing an issue that's being shirked by the wealthiest companies that have ever existed.</p><p>A stated goal of this effort is to "create an incentive for voices who want to be trusted online to prove their identity as American citizens". It's telling that one of the first, and most effective, public profiles of Mark Zuckerberg that dared to be deeply critical of Facebook's shortcomings was this <a href="https://www.newyorker.com/magazine/2010/09/20/the-face-of-facebook">2010 New Yorker piece</a>. It is trusted. It is credible. It was written by Jose Antonio Vargas, a deeply talented journalist who is, among many other things, not a citizen and undocumented, and thus ineligible for having a passport and greatly at risk under this administration.</p><p>The core of the criticisms leveled in that piece, written 10 years ago just before Sam joined Facebook to run the Identity Product Group, was about the risks that Facebook's extremist view of identity could pose to the most vulnerable.</p>
            </section>


            


        </article>

    </div>
</div></div></div>
    </div>
    <footer>
        <div>created by <a href="https://buildstarted.com">buildstarted</a> &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>