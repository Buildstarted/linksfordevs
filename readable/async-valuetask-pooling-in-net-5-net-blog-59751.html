<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Async ValueTask Pooling in .NET 5 | .NET Blog - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Async ValueTask Pooling in .NET 5 | .NET Blog - linksfor.dev(s)"/>
    <meta property="article:author" content="Stephen ToubFollow"/>
    <meta property="og:description" content="The async/await feature in C# has revolutionized how developers targeting .NET write asynchronous code. Sprinkle some async and await around, change some return types to be tasks, and badda bing badda boom, you&#x2019;ve got an asynchronous implementation. In theory.&#xA;In practice,"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://devblogs.microsoft.com/dotnet/async-valuetask-pooling-in-net-5/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Async ValueTask Pooling in .NET 5 | .NET Blog</title>
<div class="readable">
        <h1>Async ValueTask Pooling in .NET 5 | .NET Blog</h1>
            <div>by Stephen ToubFollow</div>
            <div>Reading time: 14-18 minutes</div>
        <div>Posted here: 17 Mar 2020</div>
        <p><a href="https://devblogs.microsoft.com/dotnet/async-valuetask-pooling-in-net-5/">https://devblogs.microsoft.com/dotnet/async-valuetask-pooling-in-net-5/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="featured"><div><div><div><div><p><img src="https://secure.gravatar.com/avatar/49e67eaea0533a547f3489aa03707bbb?s=58&amp;d=mm&amp;r=g" width="58" height="58" alt="Avatar"></p></div></div></div><p>March 16th, 2020</p><p>The async/await feature in C# has revolutionized how developers targeting .NET write asynchronous code. Sprinkle some <code>async</code> and <code>await</code> around, change some return types to be tasks, and badda bing badda boom, you’ve got an asynchronous implementation. In theory.</p><p>In practice, obviously I’ve exaggerated the ease with which a codebase can be made fully asynchronous, and as with many a software development task, the devil is often in the details. One such “devil” that performance-minded .NET developers are likely familiar with are the state machines objects the enable async methods to perform their magic.</p><h3>State Machines and Allocations</h3><p>When you write an async method in C#, the compiler rewrites that method into a state machine, where the bulk of your code in your async method is moved into a <code>MoveNext</code> method on a compiler-generated type (a struct in Release builds), and with that <code>MoveNext</code> method littered with jumps and labels that enable the method to suspend and resume at <code>await</code> points. An <code>await</code>‘d incomplete tasks has a continuation (a callback) hooked up to it that, upon the task’s eventual completion, calls back to the <code>MoveNext</code> method and jumps to the location where the function was suspended. In order for local variables to maintain their state across these method exits and re-entrances, relevant “locals” are rewritten by the compiler to be fields on the state machine type. And in order for that state machine as a struct to persist across those same suspensions, it needs to be moved to the heap.</p><p>The C# compiler and the .NET runtime try hard to avoid putting that state machine on the heap. Many async method invocations actually complete synchronously, and the compiler and runtime are tuned to that use case. As noted, in Release builds the state machine generated by the compiler is a struct, and when an async method is invoked, the state machine starts its life on the stack. If the async method completes without ever suspending, the state machine will happily complete having never caused an allocation. However, if the async method ever needs to suspend, the state machine needs to somehow be promoted to the heap.</p><p>In .NET Framework, the moment a <code>Task</code>– or <code>ValueTask</code>-returning async method (both generic and non-generic) suspends for the first time, several allocations occur: 1. The state machine struct is copied to the heap via standard runtime boxing; every state machine implements the <code>IAsyncStateMachine</code> interface, and the runtime literally casts the struct to this interface, resulting in an allocation. 2. The runtime captures the current <code>ExecutionContext</code>, and then allocates an object (it calls this a “runner”) that it uses to store both the boxed state machine and the <code>ExecutionContext</code> (note, too, that in the .NET Framework, capturing <code>ExecutionContext</code> when it’s not the default also results in one or more allocations). 3. The runtime allocates an <code>Action</code> delegate that points to a method on that runner object, because the awaiter pattern requires an <code>Action</code> that can be passed to the awaiter’s <code>{Unsafe}OnCompleted</code> method; when invoked, the <code>Action</code> will use the captured <code>ExecutionContext</code> to invoke the <code>MoveNext</code> method on the state machine. 4. The runtime allocates a <code>Task</code> object that will be completed when the async method completes and that’s returned from the async method to its synchronous caller (if the async method is typed to return a <code>ValueTask</code>, the <code>ValueTask</code> struct is just wrapped around the <code>Task</code> object).</p><p>That’s at least four allocations when an async method suspends for the first time. On top of that, every subsequent time the async method suspends, if we find ourselves with a non-default <code>ExecutionContext</code> (e.g. it’s carrying state for an <code>AsyncLocal&lt;T&gt;</code>), the runtime re-allocates that runner object and then re-allocates the <code>Action</code> that points to it (because delegates are immutable), for at least two additional allocations each time the async method suspends after the first time. Here’s a simple repro of that in Visual Studio, with the right window showing allocations as profiled by the .NET Object Allocation Tracking tool:</p><p><a href="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2020/03/NetFramework_1-1.png" data-featherlight="image"> <img src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2020/03/NetFramework_1-1.png" alt="Async Allocations in .NET Framework"> </a></p><p>This has been improved significantly for .NET Core, in particular as of .NET Core 2.1. When an async method suspends, a <code>Task</code> is allocated. But it’s not of the base <code>Task</code> or <code>Task&lt;TResult&gt;</code> type. Instead, it’s of an internal <code>AsyncStateMachineBox&lt;TStateMachine&gt;</code> type that derives from <code>Task</code>. The state machine struct is stored in a strongly-typed field on this derived type, eliminating the need for a separate boxing allocation. This type also has a field for the captured <code>ExecutionContext</code> (which is immutable in .NET Core, which means capturing one never allocates), which means we don’t need a separate runner object. And the runtime now has special code paths that support passing this <code>AsyncStateMachineBox&lt;TStateMachine&gt;</code> type directly through to all awaiters the runtime knows about, which means that as long as an async method only ever awaits <code>Task</code>, <code>Task&lt;TResult&gt;</code>, <code>ValueTask</code>, or <code>ValueTask&lt;TResult&gt;</code> (either directly or via their <code>ConfigureAwait</code> counterparts), it needn’t allocate an <code>Action</code> delegate at all. Then, since we have direct access to the <code>ExecutionContext</code> field, subsequent suspensions don’t require allocating a new runner (runners are gone entirely), which also means even if we did need to allocate an <code>Action</code>, we don’t need to re-allocate it. That means, whereas in .NET Framework we have at least four allocations for the first suspension and often at least two allocations for each subsequent suspension, in .NET Core we have one allocation for the first suspension (worst case two, if custom awaiters are used), and that’s it. Other changes, such as a rewrite to the <code>ThreadPool</code>‘s queueing infrastructure, also significantly decreased allocations.</p><p><a href="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2020/03/NetCore31_2-1.png" data-featherlight="image"> <img src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2020/03/NetCore31_2-1.png" alt="Async Allocations in .NET Core 3.1"> </a></p><p>That change has had a very measurable impact on performance (and, as it happens, on more than just performance; it’s also very beneficial for debugging), and we can all rejoice in seeing unnecessary allocations removed. However, as noted, one allocation still remains when an async method completes asynchronously. But… what if we could get rid of that last one, too? What if we could make it so that invoking an async method had (amortized) zero-allocation overhead, regardless of whether it completed synchronously or asynchronously?</p><h3>ValueTask</h3><p><code>ValueTask&lt;TResult&gt;</code> was introduced in the .NET Core 1.0 timeframe to help developers avoid allocations when async methods complete synchronously. It was a relatively simple struct representing a discriminated union between a <code>TResult</code> and a <code>Task&lt;TResult&gt;</code>. When used as the result type of an async method, if an invocation of the async method returns synchronously, regardless of the value of the <code>TResult</code> result, the method incurs zero allocations of overhead: the state machine doesn’t need to be moved to the heap, and no <code>Task&lt;TResult&gt;</code> need be allocated for the result; the result value is simply stored into the <code>TResult</code> field of the returned <code>ValueTask&lt;TResult&gt;</code>. However, if the async method completes asynchronously, the runtime falls back to behaving just as it would with <code>Task&lt;TResult&gt;</code>: it produces the single <code>AsyncStateMachineBox&lt;TStateMachine&gt;</code> task, which is then wrapped in the returned <code>ValueTask&lt;TResult&gt;</code> struct.</p><p>In .NET Core 2.1, we introduced the <code>IValueTaskSource&lt;TResult&gt;</code> interface, along with non-generic counterparts <code>ValueTask</code> and <code>IValueTaskSource</code>. We also made <code>ValueTask&lt;TResult&gt;</code> capable of storing not just a <code>TResult</code> and a <code>Task&lt;TResult&gt;</code>, but also an <code>IValueTaskSource&lt;TResult&gt;</code> (same for the non-generic <code>ValueTask</code>, which could store a <code>Task</code> or an <code>IValueTaskSource</code>). This advanced interface allows an enterprising developer to write their own backing store for the value task, and they can do so in a way that allows them to reuse that backing store object for multiple non-concurrent operations (much more information on this is available in <a href="https://devblogs.microsoft.com/dotnet/understanding-the-whys-whats-and-whens-of-valuetask/">this blog post</a>. For example, an individual <code>Socket</code> is generally used for no more than one receive operation and one send operation at a time. <code>Socket</code> was modified to store a reusable/resettable <code>IValueTaskSource&lt;int&gt;</code> for each direction, and each consecutive read or write operation that completes asynchronously hands out a <code>ValueTask&lt;int&gt;</code> backed by the appropriate shared instance. This means that in the vast majority of cases, the <code>ValueTask&lt;int&gt;</code>-based <code>ReceiveAsync</code>/<code>SendAsync</code> methods on <code>Socket</code> end up being non-allocating, regardless of whether they complete synchronously or asynchronously. A handful of types got this treatment, but only where we knew it would be impactful because the types were often used on high-throughput code paths, we knew we could do it in a way where it would pretty much always be a win (often performance optimizations come with trade-offs), and we knew it would be worth the painstaking effort it would take to effectively implement these interfaces.</p><p>As such, a handful of implementations were added in .NET Core 2.1 in key areas, like <code>System.Net.Sockets</code>, <code>System.Threading.Channels</code>, and <code>System.IO.Pipelines</code>, but not much beyond that. We subsequently introduced the <code>ManualResetValueTaskSource&lt;TResult&gt;</code> type to make such implementations easier, and as a result more implementations of these interfaces were added in .NET Core 3.0 and also in .NET 5, though mostly as internal implementation details within various components, like <code>System.Net.Http</code>.</p><h3>.NET 5 Improvements</h3><p>In .NET 5, we’re experimenting with taking this optimization much further. With .NET 5 Preview 1, if prior to your process running you set the <code>DOTNET_SYSTEM_THREADING_POOLASYNCVALUETASKS</code> environment variable to either <code>true</code> or <code>1</code>, the runtime will use state machine box objects that implement the <code>IValueTaskSource</code> and <code>IValueTaskSource&lt;TResult&gt;</code> interfaces, and it will pool the objects it creates to back the instances returned from <code>async ValueTask</code> or <code>async ValueTask&lt;TResult&gt;</code> methods. So, if as in the earlier example you repeatedly invoke the same method and await its result, each time you’ll end up getting back a <code>ValueTask</code> that, under the covers, is wrapping the exact same object, simply reset each time to enable it to track another execution. Magic.</p><p><a href="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2020/03/Net5_3-1.png" data-featherlight="image"> <img src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2020/03/Net5_3-1.png" alt="Async Allocations in .NET 5"> </a></p><p>Why isn’t it just on by default right now? Two main reasons:</p><ol><li><p><strong>Pooling isn’t free.</strong> There are a variety of ways allocations can be eliminated by a developer looking to optimize their code. One is to simply improve the code to no longer need the allocation; from a performance perspective, this is generally very low risk. Another is to reuse an existing object already readily available, such as by adding an additional field to some existing object with a similar lifespan; this likely requires more performance analysis, but is still often a clear win. Then comes pooling. Pooling can be very beneficial when it’s really expensive to construct the thing being pooled; a good example of this is with HTTPS connection pooling, where the cost of establishing a new secure connection is generally orders of magnitude more expensive than accessing one in even the most naïve of pooling data structures. The more controversial form of pooling is when the pool is for cheaply constructed objects, with the goal of avoiding garbage collection costs. In employing such a pool, the developer is betting that they can implement a custom allocator (which is really what a pool is) that’s better than the general-purpose GC allocator. Beating the GC is not trivial. But, a developer might be able to, given knowledge they have of their specific scenario. For example, the .NET GC is very good at efficiently collecting short-lived objects, those that become collectible in generation 0, and attempting to pool such objects can easily make a program more expensive (even if doing so looks good on a microbenchmark focused on measuring allocation). But if you know that your objects are likely to survive gen0, such as if they’re used to represent potentially long-latency asynchronous operations, it’s possible a custom pool could shave off some overhead. We haven’t made this <code>async ValueTask</code> pooling the default yet because, while it looks good on microbenchmarks, we’re not sure it’s actually a meaningful improvement on real-world workloads.</p></li><li><p><strong>ValueTasks have constraints.</strong> The <code>Task</code> and <code>Task&lt;TResult&gt;</code> types were designed to be very robust. You can cache them. You can await them any number of times. They support multiple continuations. They’re thread-safe, with any number of threads able to concurrently register continuations. And in addition to being awaitable and supporting asynchronous completion notifications, they also support a blocking model, with synchronous callers able to wait for a result to be available. None of that holds for <code>ValueTask</code> and <code>ValueTask&lt;TResult&gt;</code>. Because they might be backed by resettable <code>IValueTaskSource</code> instances, you mustn’t cache them (the thing they wrap might get reused) nor await them multiple times. You mustn’t try to register multiple continuations (after the first completes the object might try to reset itself for another operation), whether concurrently or not. And you mustn’t try to block waiting for them to complete (<code>IValueTaskSource</code> implementations need not provide such semantics). As long as callers directly await the result of calling a method that returns a <code>ValueTask</code> or <code>ValueTask&lt;TResult&gt;</code>, everything should work well, but the moment someone steps off that golden path, things can go awry quickly; that could mean getting exceptions, or it could mean corruption in the process. Further, these complications generally only present themselves when the <code>ValueTask</code> or <code>ValueTask&lt;TResult&gt;</code> wraps an <code>IValueTaskSource</code> implementation; when they wrap a <code>Task</code>, things typically “just work”, as the <code>ValueTask</code> inherits <code>Task</code>‘s robustness, and when they wrap a raw result value, the constraints technically don’t apply at all. And that means that by switching <code>async ValueTask</code> methods from being backed by <code>Task</code>s as they are today to instead being backed by these pooled <code>IValueTaskSource</code> implementations, we could be exposing latent bugs in a developer’s app, either directly or via libraries they consume. An upcoming release of the <a href="https://github.com/dotnet/roslyn-analyzers" target="_blank">Roslyn Analyzers</a> will include <a href="https://github.com/dotnet/roslyn-analyzers/pull/3001" target="_blank">an analyzer</a> that should help find most misuse.</p></li></ol><h3>Call to Action</h3><p>This is where you come in. If you have an application you think would benefit from this pooling, we’d love to hear from you. Download <a href="https://dotnet.microsoft.com/download/dotnet-core/5.0" target="_blank">.NET 5 Preview 1</a>. Try turning on the feature. Does anything break, and if so, in your code, or in another library, or in .NET itself? And do you see measurable performance wins, whether measured as throughput or latency or working set or anything else of interest? Note that the change only affects <code>async ValueTask</code> and <code>async ValueTask&lt;TResult&gt;</code> methods, so if you have <code>async Task</code> or <code>async Task&lt;TResult&gt;</code> methods, you might also need to experiment with first changing those to use their <code>ValueTask</code> equivalents.</p><p><a href="https://github.com/dotnet/runtime/issues/13633" target="_blank">Issue dotnet/runtime#13633</a> is tracking our figuring out what we should do with this feature for .NET 5, and we’d love to hear from you; we’d welcome you posting any thoughts or results there.</p><p>Thanks in advance for any feedback, and happy pooling!</p></div></div></div></div>
    </div>
    <footer>
        <div>created by <a href="https://buildstarted.com">buildstarted</a> &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>