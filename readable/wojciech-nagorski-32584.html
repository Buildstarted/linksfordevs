<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Analyzing native memory allocation with BenchmarkDotNet - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Analyzing native memory allocation with BenchmarkDotNet - linksfor.dev(s)"/>
    <meta property="article:author" content="Wojciech Nag&#xF3;rski"/>
    <meta property="og:description" content="How to analyze native memory allocation with BenchmarkDotNet."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://wojciechnagorski.com/2019/08/analyzing-native-memory-allocation-with-benchmarkdotnet/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
	<div class="devring" style="background: #222">
		<div class="grid">
			<div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
				<span class="devring-title">devring.club</span>
				<a href="https://devring.club/site/1/previous" class="devring-previous">Previous</a>
				<a href="https://devring.club/random" class="devring-random">Random</a>
				<a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
			</div>
		</div>
	</div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Analyzing native memory allocation with BenchmarkDotNet</title>
<div class="readable">
        <h1>Analyzing native memory allocation with BenchmarkDotNet</h1>
            <div>by Wojciech Nag&#xF3;rski</div>
            <div>Reading time: 9-11 minutes</div>
        <div>Posted here: 08 Aug 2019</div>
        <p><a href="https://wojciechnagorski.com/2019/08/analyzing-native-memory-allocation-with-benchmarkdotnet/">https://wojciechnagorski.com/2019/08/analyzing-native-memory-allocation-with-benchmarkdotnet/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><article>

    

    
    

    

    

    

<p>The <strong><code>NativeMemoryProfiler</code></strong> is a new diagnoser for <a href="https://benchmarkdotnet.org/">BenchmarkDotNet</a> that I implemented in version 0.12.0. In this post, you will learn how to analyze native memory allocations in your code. It sounds like a difficult topic, but trust me, you can do it really easily with BenchmarkDotNet.</p>

<h2 id="the-story">The story</h2>

<p>Not so long ago, I got a task that was difficult for me. To be honest, I did not know where to start. I like this kind of tasks because they are a challenge and a good opportunity to learn something new. I had to create an application to validate native DLLs that were created by other companies. This application should call all functions, check how long it takes to execute all functions and check if functions do not allocate native memory. The last thing was the hardest for me.</p>

<p>I thought I would find a solution in some open source project. I started from BenchmarkDotNet which is my favorite .NET library for benchmarking. To my surprise, it turned out that BenchmarkDotNet did not support tracking native allocations. I even found an issue <a href="https://github.com/dotnet/BenchmarkDotNet/issues/457">dotnet/BenchmarkDotNet#457</a> that had labels: <code>help wanted</code> and <code>up-for-grabs</code>. Luckily in this issue, I found information that <a href="https://github.com/kayle">@kayle</a> added support for tracking type of native memory allocations in <a href="https://github.com/microsoft/perfview">PerfView</a>. Here is his PR <a href="https://github.com/microsoft/perfview/pull/857">microsoft/perfview#857</a>. Thanks to it, I had all information to solve my problem but also I was able to make <code>NativeMemoryProfiler</code> for BenchmarkDotNet. So I did it.</p>

<h2 id="demo">Demo</h2>

<p>Bellow is a sample benchmark which uses the <code>Marshal.AllocHGlobal</code> and <code>Marshal.FreeHGlobal</code> methods to allocate and free native memory.</p>
<div><pre><code data-lang="c#"><span>[ShortRunJob]</span>
<span>[NativeMemoryProfiler]</span> <span>// &lt;-- This attribute enables the profiler for native allocation.
</span><span></span><span>[MemoryDiagnoser]</span>
<span>public</span> <span>class</span> <span>IntroNativeMemory</span>
{
    <span>private</span> <span>const</span> <span>int</span> Size = <span>20</span>; <span>// Greater value could cause System.OutOfMemoryException for a test with memory leaks.
</span><span></span>    <span>private</span> <span>int</span> ArraySize = Size * Marshal.SizeOf(<span>typeof</span>(<span>int</span>));
<span>
</span><span>    [Benchmark]</span>
    <span>public</span> <span>unsafe</span> <span>void</span> AllocHGlobal()
    {
        IntPtr unmanagedHandle = Marshal.AllocHGlobal(ArraySize);
        Span&lt;<span>byte</span>&gt; unmanaged = <span>new</span> Span&lt;<span>byte</span>&gt;(unmanagedHandle.ToPointer(), ArraySize);
        Marshal.FreeHGlobal(unmanagedHandle);
    }
<span>
</span><span>    [Benchmark]</span>
    <span>public</span> <span>unsafe</span> <span>void</span> AllocHGlobalWithLeaks()
    {
        IntPtr unmanagedHandle = Marshal.AllocHGlobal(ArraySize);
        Span&lt;<span>byte</span>&gt; unmanaged = <span>new</span> Span&lt;<span>byte</span>&gt;(unmanagedHandle.ToPointer(), ArraySize);
    }
}
</code></pre></div>
<p>As you can see, all you have to do to enable the profiler for native allocations is to add the <code>NativeMemoryProfiler</code> attribute to your benchmark.</p>

<p>If you use <code>ManualConfig</code> you can add this profiler this way:</p>
<div><pre><code data-lang="c#"><span>private</span> <span>class</span> <span>Config</span> : ManualConfig
{
    <span>public</span> Config()
    {
        Add(<span>new</span> NativeMemoryProfiler()); <span>// &lt;-- adding profiler for native allocation
</span><span></span>        <span>//Your configuration
</span><span></span>    }
}
</code></pre></div>
<p>If you don’t want to use this profiler every time, you can also enable it from the command line using <code>-p NativeMemory</code> or <code>--profiler NativeMemory</code> parameter. This allows you to enable the <code>NativeMemoryProfiler</code> on demand.</p>
<div><pre><code data-lang="ini"><span># for .Net Framework application:</span>
<span>NativeMemorySample.exe --profiler NativeMemory</span>
<span># for .Net Core application:</span>
<span>dotnet NativeMemorySample.dll --profiler NativeMemory </span>
<span># or run benchmark from the directory where is your csproj:</span>
<span>dotnet run -c Release -f netcoreapp2.1 -- --filter *IntroNativeMemory.Alloc* --profiler NativeMemory</span></code></pre></div>
<p>After running the above example code, you will see the results:</p>

<table>
<thead>
<tr>
<th>Method</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
<th>Gen 0</th>
<th>Gen 1</th>
<th>Gen 2</th>
<th>Allocated</th>
<th>Allocated native memory</th>
<th>Native memory leak</th>
</tr>
</thead>

<tbody>
<tr>
<td>AllocHGlobal</td>
<td>78.60 ns</td>
<td>10.55 ns</td>
<td>0.578 ns</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>80 B</td>
<td>-</td>
</tr>

<tr>
<td>AllocHGlobal WithLeaks</td>
<td>101.17 ns</td>
<td>150.67 ns</td>
<td>8.259 ns</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>80 B</td>
<td>80 B</td>
</tr>
</tbody>
</table>

<p>As you can see, <code>NativeMemoryProfiler</code> adds extra columns: “Allocated native memory” and “Native memory leak”, to the summary table. In output, you can also find additional information from this diagnoser. This log contains useful information, e.g.: the location of the exported <code>*.etl</code> files or the number of allocated and not deallocated objects.</p>
<div><pre><code data-lang="perl"><span>//</span> <span>*</span> Diagnostic Output <span>-</span> NativeMemoryProfiler <span>*</span>
Exported <span>2</span> trace file(s)<span>.</span> Example:
C:<span>\</span>Work<span>\</span>NativeMemorySample<span>\</span>NativeMemorySample<span>\</span>BenchmarkDotNet<span>.</span>Artifacts<span>\</span>NativeMemorySample<span>.</span>IntroNativeMemory<span>.</span>AllocHGlobal<span>-</span><span>20190806</span><span>-</span><span>115958</span><span>.</span>etl

<span>--------------------</span>
IntroNativeMemory<span>.</span>AllocHGlobal: ShortRun(IterationCount<span>=</span><span>3</span>, LaunchCount<span>=</span><span>1</span>, WarmupCount<span>=</span><span>3</span>)
<span>--------------------</span>
Native memory allocated per single operation: <span>80</span> B

<span>--------------------</span>
IntroNativeMemory<span>.</span>AllocHGlobalWithLeaks: ShortRun(IterationCount<span>=</span><span>3</span>, LaunchCount<span>=</span><span>1</span>, WarmupCount<span>=</span><span>3</span>)
<span>--------------------</span>
Native memory allocated per single operation: <span>80</span> B
Native memory leak per single operation: <span>80</span> B
Count of <span>not</span> deallocated object: <span>1</span>

<span>//</span> <span>*</span> Diagnostic Output <span>-</span> MemoryDiagnoser <span>*</span></code></pre></div>
<h2 id="the-tracking-type-of-native-memory-allocation">The tracking type of native memory allocation</h2>

<p>Currently, BenchmarkDotNet does not print information about native memory allocation types, but <code>NativeMemoryProfiler</code> saves this information in <code>*.etl</code> files. As I mentioned earlier, thanks to <a href="https://github.com/kayle">@kayle</a> and his great PR <a href="https://github.com/microsoft/perfview/pull/857">microsoft/perfview#857</a>, you can easily get type names using PerfView.</p>

<p>If the benchmark uses your native DLL, you can check what types were used. Here is an example C++ code of a native DLL:</p>
<div><pre><code data-lang="c++"><span>typedef</span> <span>struct</span> <span>_Point</span> {
	<span>int</span> X;
	<span>int</span> Y;
}Point;

<span>__declspec</span>(dllexport) Point<span>*</span> AllocateArrayOfPoint(<span>int</span> size)
{
	Point<span>*</span> a <span>=</span> <span>new</span> Point[size];
    
	<span>// Initialize all elements.
</span><span></span>	<span>for</span> (<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> size; i<span>++</span>) {
		a[i].X <span>=</span> i;      
		a[i].Y <span>=</span> i <span>+</span> <span>1</span>;
	}
	<span>return</span> a;
}

<span>__declspec</span>(dllexport) <span>void</span> DeallocateArrayOfPoint(Point<span>*</span> ptr)
{
	<span>delete</span>[] ptr;
}
</code></pre></div>
<p>The<code>AllocateArrayOfPoint</code> method allocates an array of <code>Point</code> and <code>DeallocateArrayOfPoint</code> deletes this array.</p>

<p>In C#, you need to create a wrapper for this DLL:</p>
<div><pre><code data-lang="c#"><span>[StructLayout(LayoutKind.Sequential)]</span>
<span>public</span> <span>struct</span> <span>Point</span>
{
    <span>public</span> <span>int</span> X;
    <span>public</span> <span>int</span> Y;
}

<span>public</span> <span>class</span> <span>NativeDll</span>
{
<span>    [DllImport("NativeDll.dll")]</span>
    <span>public</span> <span>static</span> <span>extern</span> IntPtr AllocateArrayOfPoint(<span>int</span> count);
<span>
</span><span>    [DllImport("NativeDll.dll")]</span>
    <span>public</span> <span>static</span> <span>extern</span> <span>void</span> DeallocateArrayOfPoint(IntPtr ptr);
}
</code></pre></div>
<p>Your benchmark can look like this:</p>
<div><pre><code data-lang="c#"><span>[ShortRunJob]</span>
<span>[NativeMemoryProfiler]</span>
<span>public</span> <span>class</span> <span>IntroNativeMemoryFromNativeDll</span>
{
<span>    [Benchmark]</span>
    <span>public</span> <span>int</span> AllocAndFreeNativeStruct()
    {
        <span>var</span> ptr = NativeDll.AllocateArrayOfPoint(<span>200</span>);
        <span>var</span> result = <span>0</span>;
        <span>unsafe</span>
        {
            <span>var</span> bytes = <span>new</span> Span&lt;Point&gt;((Point*)ptr, <span>200</span>);
            <span>foreach</span> (<span>var</span> item <span>in</span> bytes)
            {
                result += item.X + item.Y;
            }
        }
        NativeDll.DeallocateArrayOfPoint(ptr);
        <span>return</span> result;
    }
}
</code></pre></div>
<p>You can run this benchmark from the command line using the following command:</p>
<div><pre><code data-lang="ini"><span>dotnet run -c Release -f netcoreapp2.1 -- --filter *AllocAndFreeNativeStruct*</span></code></pre></div>
<p>In output you can see the summary table:</p>

<table>
<thead>
<tr>
<th>Method</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
<th>Allocated native memory</th>
<th>Native memory leak</th>
</tr>
</thead>

<tbody>
<tr>
<td>AllocAndFreeNativeStruct</td>
<td>323.0 ns</td>
<td>66.38 ns</td>
<td>3.64 ns</td>
<td>1600 B</td>
<td>-</td>
</tr>
</tbody>
</table>

<p>This benchmark uses 1600 B of native memory because <code>Point</code> has two filed <code>int X</code> and <code>int Y</code>, <code>int</code> has 4 B and in this benchmark there was an array with 200 elements allocated. (2 * 4B * 200 = 1600 B)</p>

<p>Now it’s time to use the PerfView.</p>

<p>The first step is to open the <code>etl</code> file in PerfView and navigate to the Events window.</p>

<p>Because BenchmarkDotNet runs your benchmarked function many times in one workload and it runs many workloads, we would like to narrow down the search. For example, the above test on my computer generates the following result log which means that my benchmarked function was running 131072 times in one workload.  And we know that there were tree workloads.</p>

<p><img src="https://wojciechnagorski.com/images/NativeMemoryProfiler/WorkloadActual.gif" alt="1565168838473"></p>

<p>Firstly, you need to find the start and end times of the first WarkloadActual. When you have these times, you can find all <code>HeapTrace</code> events. In summary, you can find information about how many objects were allocated:</p>
<div><pre><code data-lang="c#">Native memory allocated per single operation: <span>1600</span> B
Count of allocated <span>object</span>: <span>1</span>
</code></pre></div>
<p>In my example, there was only one object which means that the first event <code>HeapTraceProvider/HeapTrace/Alloc</code> came from the first run of my benchmarked function, from the first workload. The following image shows how to find this information in PerfView:</p>

<p><img src="https://wojciechnagorski.com/images/NativeMemoryProfiler/PerfView-events-windows.gif#mid" alt="PerfView-events-windows"></p>

<p>Now it is time to show the information regarding types. In PerfView you should open <code>Net OS Heap Alloc Stacks</code> window from <code>Memory Group</code>. You can use the start and end times of the first Workload because only data between these times is interesting. Below you can see, how to show the information about on types of allocated objects.</p>

<p><img src="https://wojciechnagorski.com/images/NativeMemoryProfiler/PerfView-heap-windows.gif#mid" alt="PerfView-events-windows"></p>

<h2 id="how-it-works">How it works</h2>

<p>To implement <code>NativeMemoryProfiler</code> I used <code>EtwProfiler</code> that runs User, Kernel, and Heap ETW sessions. Each session writes data to its own file and in the end these files are marge to one <code>*.etl</code> file. The <code>NativeMemoryProfiler</code> uses different events from different sessions:</p>

<ul>
<li>BenchmarkDotNet Engine events, like <code>WorkloadActualStart</code> and <code>WorkloadActualStop</code> from User session,</li>
<li>HeapTrace events, like <code>HeapTraceAlloc</code>, <code>HeapTraceFree</code>, <code>HeapTraceReAlloc</code>, <code>HeapTraceDestroy</code>, from Heap session.</li>
</ul>

<p>You can find the source code in my PRs: <a href="https://github.com/dotnet/BenchmarkDotNet/pull/1131">#1131</a> and <a href="https://github.com/dotnet/BenchmarkDotNet/pull/1208">#1208</a> or directly in the BenchmarkDotNet <a href="https://github.com/dotnet/BenchmarkDotNet/blob/master/src/BenchmarkDotNet.Diagnostics.Windows/NativeMemoryProfiler.cs">code</a>.</p>

<h2 id="limitations">Limitations</h2>

<p>Because <code>NativeMemoryProfiler</code> uses <code>EtwProfiler</code>, it also has its limitations:</p>

<ul>
<li>Windows only</li>
<li>Requires running as Admin (ETW Kernel Session)</li>
<li>No <code>InProcessToolchain</code> support</li>
</ul>

<h2 id="summary">Summary</h2>

<p>In advanced projects, native code and resources are used very often. Currently, during benchmarking your code, not only you can easily check its speed, but also check how much native memory it uses, thanks to <code>NativeMemoryProfiler</code>.</p>


</article></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
		<div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>