<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Performance analysis of multithreaded applications. | Easyperf - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Performance analysis of multithreaded applications. | Easyperf - linksfor.dev(s)"/>
    <meta property="article:author" content="Denis Bakhvalov"/>
    <meta property="og:description" content="Contents:"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://easyperf.net/blog/2019/10/05/Performance-Analysis-Of-MT-apps"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">ðŸŽ‰</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Performance analysis of multithreaded applications. | Easyperf</title>
<div class="readable">
        <h1>Performance analysis of multithreaded applications. | Easyperf</h1>
            <div>by Denis Bakhvalov</div>
            <div>Reading time: 12-15 minutes</div>
        <div>Posted here: 06 Oct 2019</div>
        <p><a href="https://easyperf.net/blog/2019/10/05/Performance-Analysis-Of-MT-apps">https://easyperf.net/blog/2019/10/05/Performance-Analysis-Of-MT-apps</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
				<p><strong>Contents:</strong></p>
<ul id="markdown-toc">
  <li><a href="#benchmark-under-the-test" id="markdown-toc-benchmark-under-the-test">Benchmark under the test</a></li>
  <li><a href="#performance-scaling" id="markdown-toc-performance-scaling">Performance scaling</a></li>
  <li><a href="#cpu-utilization" id="markdown-toc-cpu-utilization">CPU utilization</a></li>
  <li><a href="#synchronization-overhead" id="markdown-toc-synchronization-overhead">Synchronization overhead</a></li>
  <li><a href="#profiling-multithreaded-apps" id="markdown-toc-profiling-multithreaded-apps">Profiling multithreaded apps</a></li>
  <li><a href="#per-thread-view" id="markdown-toc-per-thread-view">Per-thread view</a></li>
  <li><a href="#using-strace-tool" id="markdown-toc-using-strace-tool">Using strace tool</a></li>
  <li><a href="#optimizing-multithreaded-apps" id="markdown-toc-optimizing-multithreaded-apps">Optimizing multithreaded apps</a></li>
</ul>

<hr>
<p><strong>Subscribe to my <a href="https://easyperf.net/blog/2019/10/05/Performance-Analysis-Of-MT-apps#mc_embed_signup">mailing list</a> and support me on <a href="https://www.patreon.com/dendibakh">Patreon</a>.</strong></p>

<hr>

<p>Modern CPUs are getting more and more cores each year. As of 2019 you can buy fresh x86 server processor which will have more than 50 cores! And even mid-range desktop with 8 execution threads will not be surprising. Usually the question is how to find the workload to feed those hungry guys.</p>

<p>Most of the articles in my blog so far were focused on the performance of a single core, completely ignoring the entire spectrum of multithreaded applications (MT app). I decided to fill this gap and write a <strong>beginner-friendly article</strong> showing how one can quickly jump into analyzing performance of the MT app. Sure, there is a lot of details which is impossible to cover in one article. Here I just want to touch ground on performance analysis of MT apps, give you the checklist and the set of tools which you can use. But be sure, there will be more of it on my blog, just stay tuned.</p>

<p>This is a series of articles. Other parts of the series can be found here:</p>

<ol>
  <li><a href="https://easyperf.net/blog/2019/10/05/Performance-Analysis-Of-MT-apps">Performance analysis of multithreaded applications</a> (this article).</li>
  <li><a href="https://easyperf.net/blog/2019/10/12/MT-Perf-Analysis-part2">How to find expensive locks in multithreaded application</a>.</li>
  <li><a href="https://easyperf.net/blog/2019/12/17/Detecting-false-sharing-using-perf">Detecting false sharing with Data Address Profiling</a>.</li>
</ol>

<p>As usual, I provide my articles with examples, so let me start with the benchmark which we will be working on.</p>

<h3 id="benchmark-under-the-test">Benchmark under the test</h3>

<p>For better illustration I had few constraints in mind when choosing the benchmark: <sup id="fnref:1"><a href="#fn:1">1</a></sup></p>
<ol>
  <li>It should have explicit parallelism using <code>pthread/std::thread</code> (no OpenMP).</li>
  <li>It does not scale with the amount of threads added. Work is not split, equally between threads.</li>
  <li>Of course, open source and free.</li>
</ol>

<p>I took <code>h264dec</code> benchmark from the <a href="https://www.aes.tu-berlin.de/menue/research/projects/completed_projects/starbench_parallel_benchmark_suite/">Starbench parallel benchmark suite</a>. This benchmark decodes H.264 raw videos and uses pthread library for managing threads.</p>

<p>One can run this benchmark like this:</p>

<div><div><pre><code><span>$ </span>./h264dec <span>-i</span> park_joy_2160p.h264 <span>-t</span> &lt;number of threads&gt; <span>-o</span> output.file
</code></pre></div></div>

<p>In this benchmark there is one main thread (mostly idle), one thread that reads the input, configurable number of worker threads (that do decoding) and one thread that writes the output.</p>

<h3 id="performance-scaling">Performance scaling</h3>

<p>First thing in MT app that needs to be estimated is how it scales as we throw more cores/threads to it. In fact, this is the most important metric of how successful the future of the app will be. The chart below shows the scaling of <code>h264dec</code> benchmark. My CPU (Intel Core i5-8259U) has 4 cores/8 threads, so I took upper bound as 8 threads. Notice, that after using 4 threads, performance doesnâ€™t scale much.</p>

<p><img src="https://easyperf.net/img/posts/MT_apps/scaling.png" alt=""></p>

<p>This is very useful information when you try to model performance of the workload. For example, when you estimate what HW you need for the task you are trying to solve. Looking at this picture, I will better choose less cores but higher frequency of a single core. <sup id="fnref:2"><a href="#fn:2">2</a></sup></p>

<p>Sometimes we could be asked what is the minimal system configuration that can handle a certain workload. When the application scales linearly (i.e. when threads work on independent piece of data and do not require synchronization) you can provide rough estimation pretty easily. Just run the workload in a single thread and measure the number of cycles executed. Then you can select CPU with specific number of cores and frequency to meet your latency/throughput goals. Situation gets tricky however, when performance of the app doesnâ€™t scale well. Here you canâ€™t rely on IPC anymore (see later), since one thread can be busy and show high utilization, but in fact all it was doing is just spinning on a lock. There is more information on capacity planning in the book <a href="https://amzn.to/2Vd6GwS">Systems Performance</a> by Brendan Gregg.</p>

<h3 id="cpu-utilization">CPU utilization</h3>

<p>Next important metric is CPU utilization <sup id="fnref:3"><a href="#fn:3">3</a></sup>. It can tell you how much threads on average were busy doing something. Note, that it is not necessarily useful work. It can be just spinning. Below you can see the chart for <code>h264dec</code> benchmark.</p>

<p><img src="https://easyperf.net/img/posts/MT_apps/utilization.png" alt=""></p>

<p>For example, when having 5 worker threads for the workload, on average only 4 were busy. I.e. typically, one thread was always sleeping, which limits scaling. This tells that there is some synchronization going between the threads.</p>

<h3 id="synchronization-overhead">Synchronization overhead</h3>

<p>To estimate how much overhead is spent on communication between threads we can collect the total number of cycles and instructions:</p>

<div><div><pre><code><span># 1 worker thread</span>
<span>$ </span>perf <span>stat</span> ./h264dec <span>-i</span> park_joy_2160p.h264 <span>-t</span> 1 <span>-o</span> output.file <span>-v</span>
   261,963,433,544      cycles           <span>#    3.766 GHz</span>
   485,932,999,948      instructions     <span>#    1.85  insn per cycle</span>
      66.236645032 seconds <span>time </span>elapsed
      66.290561000 seconds user
       3.324930000 seconds sys

<span># 4 worker thread</span>
<span>$ </span>perf <span>stat</span> ./h264dec <span>-i</span> park_joy_2160p.h264 <span>-t</span> 4 <span>-o</span> output.file <span>-v</span>
   272,518,956,365      cycles           <span>#    3.479 GHz</span>
   523,079,251,733      instructions     <span>#    1.92  insn per cycle</span>
     23.643595782 seconds <span>time </span>elapsed
      73.979057000 seconds user
       4.402318000 seconds sys

<span># 8 worker thread</span>
<span>$ </span>perf <span>stat</span> ./h264dec <span>-i</span> park_joy_2160p.h264 <span>-t</span> 8 <span>-o</span> output.file <span>-v</span>
   453,581,394,912      cycles           <span>#    3.410 GHz</span>
   661,715,307,682      instructions     <span>#    1.46  insn per cycle</span>
      22.700304401 seconds <span>time </span>elapsed
     128.122821000 seconds user
       4.883838000 seconds sys
</code></pre></div></div>

<p>There is a couple of interesting things here. First, donâ€™t be confused by the timings for the case with 8 threads. CPU time is more than 5 times bigger than the wall time. It perfectly correlates with CPU utilization.</p>

<p>Second, look at the number of instructions retired for 8 threads case. For 8 worker threads we have 36% more executed instructions than in single-thread which is all can be considered as overhead. All this is likely caused by thread active synchronization (spinning).</p>

<h3 id="profiling-multithreaded-apps">Profiling multithreaded apps</h3>

<p>To do analysis on a source code level letâ€™s run the profiler on it: <sup id="fnref:4"><a href="#fn:4">4</a></sup></p>

<div><div><pre><code><span># 1 worker thread</span>
<span>$ </span>perf record <span>-o</span> perf1.data <span>--</span> ./h264dec <span>-i</span> park_joy_2160p.h264 <span>-t</span> 1 <span>-o</span> output.file <span>-v</span>
<span>[</span> perf record: Captured and wrote 10.790 MB perf1.data <span>(</span>282808 samples<span>)</span> <span>]</span>
<span># 4 worker thread</span>
<span>$ </span>perf record <span>-o</span> perf4.data <span>--</span> ./h264dec <span>-i</span> park_joy_2160p.h264 <span>-t</span> 4 <span>-o</span> output.file <span>-v</span>
<span>[</span> perf record: Captured and wrote 12.592 MB perf4.data <span>(</span>330029 samples<span>)</span> <span>]</span>
<span># 8 worker thread</span>
<span>$ </span>perf record <span>-o</span> perf8.data <span>--</span> ./h264dec <span>-i</span> park_joy_2160p.h264 <span>-t</span> 8 <span>-o</span> output.file <span>-v</span>
<span>[</span> perf record: Captured and wrote 21.239 MB perf8.data <span>(</span>556685 samples<span>)</span> <span>]</span>
</code></pre></div></div>

<p>The number of samples correlates with the user time we saw earlier. I.e. the more workers we have the more <a href="https://easyperf.net/blog/2018/06/01/PMU-counters-and-profiling-basics">interrupts</a> profiler needs to do. If we look into the profiles, they will mostly look similar except one function <code>ed_rec_thread</code>:</p>

<div><div><pre><code><span># 1 worker thread</span>
<span>$ </span>perf report <span>-n</span> <span>-i</span> perf1.data <span>--stdio</span>
<span># Overhead       Samples  Command  Shared Object     Symbol                               </span>
<span># ........  ............  .......  ................  .....................................</span>
     0.18%           524  h264dec  h264dec           <span>[</span>.] ed_rec_thread

<span># 4 worker thread</span>
<span>$ </span>perf report <span>-n</span> <span>-i</span> perf4.data <span>--stdio</span>
<span># Overhead       Samples  Command  Shared Object     Symbol                               </span>
<span># ........  ............  .......  ................  .....................................</span>
     3.62%         11417  h264dec  h264dec           <span>[</span>.] ed_rec_thread

<span># 8 worker thread</span>
<span>$ </span>perf report <span>-n</span> <span>-i</span> perf8.data <span>--stdio</span>
<span># Overhead       Samples  Command  Shared Object     Symbol                               </span>
<span># ........  ............  .......  ................  .....................................</span>
    17.53%         95619  h264dec  h264dec           <span>[</span>.] ed_rec_thread
</code></pre></div></div>

<p>Notice how <code>ed_rec_thread</code> function takes much more samples with increasing the number of threads. This is likely the bottleneck that prevents us from scaling further with adding more threads.</p>

<p>Also, this is one of the methods how we can find synchronization bottlenecks in the MT app. By simply comparing profiles for the different number of workers.</p>

<p>And in fact, there is this code in <code>decode_slice_mb</code> function that is inlined into <code>ed_rec_thread</code>:</p>
<div><div><pre><code>  <span>while</span> <span>(</span><span>rle</span><span>-&gt;</span><span>mb_cnt</span> <span>&gt;=</span> <span>rle</span><span>-&gt;</span><span>prev_line</span><span>-&gt;</span><span>mb_cnt</span> <span>-</span><span>1</span><span>);</span>
</code></pre></div></div>

<p>where <code>mb_cnt</code> is defined as volatile. So, it is in fact active spinning happens here.</p>

<h3 id="per-thread-view">Per-thread view</h3>

<p>Linux perf is powerful enough to collect profiles for every thread that is spawn from the main thread of the process. If you want to look inside the execution of a single thread perf let you do this with <code>-s</code> option:</p>

<div><div><pre><code><span>$ </span>perf record <span>-s</span> ./h264dec <span>-i</span> park_joy_2160p.h264 <span>-t</span> 8 <span>-o</span> output.file <span>-v</span>
</code></pre></div></div>

<p>Then you can list all the thread IDs along with the number of samples collected for each of them:</p>

<div><div><pre><code>$ perf report -n -T
...
#  PID   TID   cycles:ppp
  6602  6607  52758679502
  6602  6603    487183790
  6602  6613  49670283608
  6602  6608  51173619921
  6602  6604    165362635
  6602  6609  38662454026
  6602  6610  31375722931
  6602  6606  48270267494
  6602  6611  53793234480
  6602  6612  25640899076
  6602  6605  14481176486
</code></pre></div></div>

<p>Now, if you want to only analyze the samples that were collected for particular software thread, you can do it with <code>--tid</code> option:</p>

<div><div><pre><code><span>$ </span>perf report <span>-T</span> <span>--tid</span> 6607 <span>-n</span>
     8.28%         25657  h264dec  h264dec           <span>[</span>.] decode_cabac_residual_nondc
     7.12%         35880  h264dec  h264dec           <span>[</span>.] put_h264_qpel8_hv_lowpass
     6.19%         31430  h264dec  h264dec           <span>[</span>.] put_h264_qpel8_v_lowpass
     5.87%         28874  h264dec  h264dec           <span>[</span>.] h264_v_loop_filter_luma_c
     2.82%         10105  h264dec  h264dec           <span>[</span>.] ff_h264_decode_mb_cabac
     1.19%          4525  h264dec  h264dec           <span>[</span>.] get_cabac_noinline
</code></pre></div></div>

<p>If you are a lucky owner of <a href="https://software.intel.com/en-us/vtune">Intel Vtune Amplifier</a>, you can use itâ€™s nice GUI to do the filtering and zooming into particular thread and point in time.</p>

<p>When you nailed down the thread that is causing you troubles and you donâ€™t care much about the other threads, you can profile only one thread by attaching to it with perf:</p>



<h3 id="using-strace-tool">Using strace tool</h3>

<p>Another thing which I use regularly is <code>strace</code> tool:</p>

<div><div><pre><code><span>$ </span>strace <span>-tt</span> <span>-ff</span> <span>-T</span> <span>-o</span> strace-dump <span>--</span> ./h264dec <span>-i</span> park_joy_2160p.h264 <span>-t</span> 8 <span>-o</span> output.file
</code></pre></div></div>

<p>This will generate syscall dumps per running thread with precise time stamps and duration for each syscall. We can further process individual dump file to extract lots of interesting information from it. For example:</p>

<div><div><pre><code><span># Total time spent by parser thread waiting for mutex to unlock</span>
<span>$ </span><span>grep </span>futex strace-dump.3740 <span>&gt;</span> futex.dump
<span>$ </span><span>sed</span> <span>-i</span> <span>'s/.*&lt;//g'</span> futex.dump
<span>$ </span><span>sed</span> <span>-i</span> <span>'s/&gt;//g'</span> futex.dump
<span>$ </span><span>paste</span> <span>-s</span> <span>-d</span>+ futex.dump | bc
16.407458
</code></pre></div></div>

<div><div><pre><code><span># Total time spent by parser thread on reading input from the file</span>
<span>$ </span><span>grep read </span>strace-dump.3740 <span>&gt;</span> read.dump
<span>$ </span><span>sed</span> <span>-i</span> <span>'s/.*&lt;//g'</span> read.dump 
<span>$ </span><span>sed</span> <span>-i</span> <span>'s/&gt;//g'</span> read.dump 
<span>$ </span><span>paste</span> <span>-s</span> <span>-d</span>+ read.dump | bc
2.179850
</code></pre></div></div>

<p>Considering total running time of the thread is 21 seconds, almost 80% of the time this thread was blocked. Since this thread provides input for the worker threads, thatâ€™s likely another thing that limits performance scaling of the benchmark.</p>

<h3 id="optimizing-multithreaded-apps">Optimizing multithreaded apps</h3>

<p>When dealing with single-threaded application, optimizing one portion of the program usually yields positive results on performance<sup id="fnref:5"><a href="#fn:5">5</a></sup>. However, itâ€™s not necessary the case for multithreaded applications. And in fact, it can be very hard to predict. Thatâ€™s where <a href="https://plasma-umass.org/coz/">coz</a> profiler might help. I wasnâ€™t able to extract any useful information from using it, but it was the first time I tried it, so maybe I was doing something wrong.</p>

<p>If your application scales well or threads work on independent piece of input, then you may see a proportional increase in performance as a result of your optimizations. In this case itâ€™s easier to do performance analysis of the application running on a single thread. There is a good chance that optimizations that are valid for single thread will scale well. <sup id="fnref:6"><a href="#fn:6">6</a></sup></p>

<p><a href="https://easyperf.net/blog/2019/02/09/Top-Down-performance-analysis-methodology">Top-Down Methodology</a>, our best friend in finding michroarchitectural issues, will become even better in new Intel CPU generations. See the <a href="https://dyninst.github.io/scalable_tools_workshop/petascale2018/assets/slides/TMA%20addressing%20challenges%20in%20Icelake%20-%20Ahmad%20Yasin.pdf">presentation</a> by Ahmad Yasin for more details.</p>

<p>However, there are performance problems that are specific to multithreading. In future articles I will touch the topics of lock contention, false sharing and more. Stay tuned!</p>

<hr>


			</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>