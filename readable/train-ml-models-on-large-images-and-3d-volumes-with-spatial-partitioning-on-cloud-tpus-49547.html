<!DOCTYPE html>
<html lang="en">
<head>
    <title>linksfor.dev(s)</title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    
    <meta property="article:author" content="Buildstarted"/>
    <meta property="og:site_name" content="linksfor.dev(s)" />
    <meta property="og:title" content="linksfor.dev(s)" />
    <meta property="og:type" content="website" />
    <meta property="og:description" content="A curated list of sources of development information including c#, c++, and other dev related links." />
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">ðŸŽ‰</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Train ML models on large images and 3D volumes with spatial partitioning on Cloud TPUs | Google Cloud Blog</title>
<div class="readable">
        <h1>Train ML models on large images and 3D volumes with spatial partitioning on Cloud TPUs | Google Cloud Blog</h1>
        <p>
by Youlong Cheng  Software Engineer, Google Brain <br/>Reading time: 5-6 minutes        </p>
        <p><a href="https://cloud.google.com/blog/products/ai-machine-learning/train-ml-models-on-large-images-and-3d-volumes-with-spatial-partitioning-on-cloud-tpus/">https://cloud.google.com/blog/products/ai-machine-learning/train-ml-models-on-large-images-and-3d-volumes-with-spatial-partitioning-on-cloud-tpus/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div><article-page><main id="jump-content"><article><article-header-block><section></section></article-header-block><!----><!----><article-aspect-image-block><figure><p><span>Cloud_TPU.png</span></p></figure></article-aspect-image-block><div><div><div><!----><div><article-author-block><div><!----><div><p> HyoukJoong Lee </p><p> Software Engineer, Google Brain </p></div><div><p> Tamas Berghammer </p><p> Software Engineer, DeepMind </p></div><p><span> September 12, 2019 </span></p></div></article-author-block></div></div></div><article-cta _nghost-c13=""><!----><div _ngcontent-c13=""><div _ngcontent-c13=""><h4 _ngcontent-c13=""><!----><!----><span _ngcontent-c13="">Try GCP</span><!----><!----><!----><!----><!----></h4><p _ngcontent-c13=""><!----><!----><span _ngcontent-c13="">Get $300 free credit to spend over 12 months.</span><!----><!----><!----><!----><!----></p><a _ngcontent-c13="" clicktracker="" rel="external" track-type="freeTrial" track-name="gcpCta" track-metadata-eventdetail="body" href="https://cloud.google.com/free/"><!----><!----><span _ngcontent-c13="">Free Trial</span><!----><!----><!----><!----><!----></a></div></div></article-cta></div><article-share-block></article-share-block><article-sticky-share-block></article-sticky-share-block><section><div><div><!----><article-content-stream-block><!----><div><!----><!----><div><div><div><!----><!----><paragraph-block _nghost-c16=""><div _ngcontent-c16=""><p><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional neural networks</a> (CNNs) are the foundation of recent advances in image classification, object detection, image segmentation, and many other computer vision applications. However, practitioners often encounter a problem when they try to train and run state-of-the-art computer vision models on larger input images: their CNN no longer fits on a single accelerator chip!</p><p>To overcome this limitation, Cloud TPUs now provide a new <a href="https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/tpu/spatial_partitioning_api.md">spatial partitioning capability</a> that makes it possible to split up a single model across several TPU chips to process much larger input data sizes. This technique is general enough to handle large 2D images as well as 3D volumes, which makes it valuable for applications ranging from object detection for autonomous navigation to analysis of 3D medical scans. For example, Mayo Clinic has used spatial partitioning on Cloud TPU Pods to segment CT scans at their full 256x256x256 pixel resolution instead of being forced to downsample, which can cause accuracy loss and other issues.</p><p>At Google, we have been using <a href="https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/tpu/spatial_partitioning_api.md">spatial partitioning</a> for many different applications, including medical image segmentation, video content analysis, and object detection for autonomous driving.&nbsp;</p><p><b>Cloud TPU spatial partitioning</b> allows you to seamlessly scale your model by leveraging 2, 4, 8, or even 16 cores for training ML models that would otherwise not fit into the memory on a single TPU core. When using more than one core for your model, our <a href="https://www.tensorflow.org/xla">XLA compiler</a> will automatically handle the necessary communications among all cores. This means there are no code changes required! All you need to do is configure how the inputs to the model should be partitioned.</p><p>Below is an example of how one big image can be split up into four smaller images that are then processed separately on individual TPU cores.</p></div></paragraph-block><!----><!----><!----></div></div></div><!----><!----><!----><!----><!----><!----></div><div><!----><!----><div><div><div><!----><!----><paragraph-block _nghost-c16=""><div _ngcontent-c16=""><h2>TPU spatial partitioning API</h2><p>The TPU spatial partitioning API is supported in TPUEstimator; to use it, you specify in TPUConfig how to partition each input tensor.&nbsp;</p><p>The following is a TPUConfig example of four-way spatial partitioning for an image classification model. This configuration will split the features tensor into four parts along the height dimension (assuming the tensor has shape [batch, height, width, channel]).</p></div></paragraph-block><!----><!----><!----></div></div></div><!----><!----><!----><!----><!----><!----></div><div><!----><!----><div><div><div><!----><!----><!----><article-code-block _nghost-c17=""><!----><pre _ngcontent-c17="">  <!----><code _ngcontent-c17="">tpu_config=tpu_config.TPUConfig(</code><code _ngcontent-c17="">    iterations_per_loop=100,</code><code _ngcontent-c17="">    num_cores_per_replica=4,</code><code _ngcontent-c17="">    per_host_input_for_training=tpu_config.InputPipelineConfig.PER_HOST_V2,</code><code _ngcontent-c17="">    input_partition_dims=[[1, 4, 1, 1], None]])</code>
</pre></article-code-block></div></div></div><!----><!----><!----><!----><!----><!----></div><div><!----><!----><div><div><div><!----><!----><paragraph-block _nghost-c16=""><div _ngcontent-c16=""><h2>Reference models</h2><p><b>2D object detection<br></b><a href="https://github.com/tensorflow/tpu/tree/master/models/official/detection">RetinaNet</a> is an object detection model that localizes objects in images with a bounding box and also classifies the identified objects. The largest image size that fits on a single Cloud TPU core (with per-device batch 8) is 1280x1280. With spatial partitioning, we can train 4x larger images across the eight TPU cores of a single Cloud TPU device.&nbsp;</p><p>The table below shows that spatial partitioning can also be used across a multi-host Cloud TPU Pod slice to accommodate an even larger image size (2560x2560). By automatically distributing all of the necessary processing across 64 TPU cores, the overall step time remains low even when working with a much larger image:</p></div></paragraph-block><!----><!----><!----></div></div></div><!----><!----><!----><!----><!----><!----></div><div><!----><!----><div><div><div><!----><!----><paragraph-block _nghost-c16=""><div _ngcontent-c16=""><p><b>3D image segmentation<br></b><a href="https://github.com/tensorflow/tpu/tree/master/models/official/unet3d">3D UNet</a> is a popular dense 3D segmentation model which has been widely used in the medical imaging domain. The original resolution for CT images can be as large as 256x256x256, which is too large to fit into a single Cloud TPU core. In the past, medical researchers would typically need to downsample the input volume to 128x128x128, potentially giving up accuracy in the process. With Cloud TPU spatial partitioning, no compromise is necessary: 16-way spatial partitioning makes it possible to process CT image scans at the the full input resolution of 256x256x256.</p><p>The table below shows that spatial partitioning across 128 TPU cores makes it possible to process a full-resolution 256x256x256 CT scan sample even faster than a 128x128x128 sample can be processed on a smaller number of cores.</p></div></paragraph-block><!----><!----><!----></div></div></div><!----><!----><!----><!----><!----><!----></div><div><!----><!----><div><div><div><!----><!----><paragraph-block _nghost-c16=""><div _ngcontent-c16=""><h2>Getting started with spatial partitioning</h2><p>To learn how to configure spatial partitioning properly for your applications, consult this <a href="https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/tpu/spatial_partitioning_api.md">guide</a>. You can also try out our reference models (<a href="https://github.com/tensorflow/tpu/tree/master/models/official/detection">RetinaNet</a>, <a href="https://github.com/tensorflow/tpu/tree/master/models/official/unet3d">3D UNet</a>) to train 2D object detection and 3D image segmentation models with spatial partitioning enabled.</p><p><b>Acknowledgements<br></b>Many thanks to our collaborators Panagiotis Korfiatis, Ph.D., and Daniel Blezek, Ph.D., from Mayo Clinic for providing the initial 3D UNet model and training data.</p><p>Thanks also to those who contributed to this post and who helped implement spatial partitioning on Cloud TPUs, including Zak Stone, Wes Wahlin, Xiaodan Song, Greg Mikels, Yeqing Li, Le Hou, Chiachen Chou, and Allen Wang.</p></div></paragraph-block><!----><!----><!----></div></div></div><!----><!----><!----><!----><!----><!----></div></article-content-stream-block><!----><article-tag-list-block><!----></article-tag-list-block></div><related-articles-block _nghost-c14=""></related-articles-block><related-articles-drawer-block _nghost-c15=""></related-articles-drawer-block></div></section></article></main></article-page></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>