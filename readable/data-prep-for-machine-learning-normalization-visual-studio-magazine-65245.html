<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Data Prep for Machine Learning: Normalization -- Visual Studio Magazine - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.min.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Data Prep for Machine Learning: Normalization -- Visual Studio Magazine - linksfor.dev(s)"/>
    <meta property="article:author" content="By James McCaffrey08/04/2020"/>
    <meta property="og:description" content="Dr. James McCaffrey of Microsoft Research uses a full code sample and screenshots to show how to programmatically normalize numeric data for use in a machine learning system such as a deep neural network classifier or clustering algorithm. "/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://visualstudiomagazine.com/articles/2020/08/04/ml-data-prep-normalization.aspx"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1 style="margin: unset">
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Data Prep for Machine Learning: Normalization -- Visual Studio Magazine</title>
<div class="readable">
        <h1>Data Prep for Machine Learning: Normalization -- Visual Studio Magazine</h1>
            <div>by By James McCaffrey08/04/2020</div>
            <div>Reading time: 13-17 minutes</div>
        <div>Posted here: 05 Aug 2020</div>
        <p><a href="https://visualstudiomagazine.com/articles/2020/08/04/ml-data-prep-normalization.aspx">https://visualstudiomagazine.com/articles/2020/08/04/ml-data-prep-normalization.aspx</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="level0">
    <div id="article"> 
        
        <p id="ph_pcontent2_0_KickerText"><a href="https://visualstudiomagazine.com/Articles/List/Neural-Network-Lab.aspx">The Data Science Lab</a></p>
        
        <h3 id="ph_pcontent2_0_MainHeading">Data Prep for Machine Learning: Normalization</h3>
        <p id="ph_pcontent2_0_Deck">Dr. James McCaffrey of Microsoft Research uses a full code sample and screenshots to show how to programmatically normalize numeric data for use in a machine learning system such as a deep neural network classifier or clustering algorithm. </p>
        
        <ul>
                    
                <li>
                    <a id="ph_pcontent2_0_ListViewAssociatedFiles_AssociatedURL_0" href="https://visualstudiomagazine.com/~/media/ECG/visualstudiomagazine/Code%20Download/2020/08/data_normalize.zip">Get Code Download</a>                               
                    
                </li>
            
                </ul>

        <p><img alt="" src="https://visualstudiomagazine.com/articles/2020/08/04/~/media/ECG/visualstudiomagazine/Images/introimages/0613vsm_evogel1.ashx"> </p>



<p>
  This article explains how to programmatically normalize numeric data for use in a machine learning (ML) system such as a deep neural network classifier or clustering algorithm. Suppose you are trying to predict election voting behavior from a file of people data. Your data would likely include things like each person's age in years and annual income in dollars. To use the data to train a neural network, you'd want to scale the data so that all numeric values are roughly in the same range, so that the large income values don't overwhelm the smaller age values.

</p>
  


<p>
  In situations where the source data file is small, about 500 lines or less, you can usually normalize numeric data manually using a text editor or spreadsheet. But in almost all realistic scenarios with large datasets you must normalize your data programmatically.

</p>
  


<p>
  Preparing data for use in a machine learning (ML) system is time consuming, tedious, and error prone. A reasonable rule of thumb is that data preparation requires at least 80  percent  of the total time needed to create an ML system. There are three main phases of data preparation: cleaning; normalizing and encoding; and splitting. Each of the three phases has several steps.

</p>
  


<p>
  A good way to understand data normalization and see where this article is headed is to take a look at the screenshot of a demo program in <b>Figure 1</b>. The demo uses a small text file named people_clean.txt where each line represents one person. There are five fields/columns: sex, age, region, income, and political leaning. The "clean" in the file name indicates that the data has been standardized by removing missing values, and editing bad data so that all lines have the same format, but numeric values have not yet been normalized.

</p>
  


<p>
  The ultimate goal of a hypothetical ML system is to use the demo data to create a neural network model that predicts political leaning from sex, age, region, and income. The demo analyzes the age and income predictor fields, then normalizes those two fields using a technique called min-max normalization. The results are saved as a new file named people_normalized.

</p>

    

<br>  
 


<div><figure> <a href="https://visualstudiomagazine.com/articles/2020/08/04/~/media/ECG/visualstudiomagazine/Images/2020/08/dataprep_normalization1.asxh" target="_blank">
<img alt="Figure 1: Programmatically Normalizing Numeric Data" src="https://visualstudiomagazine.com/articles/2020/08/04/~/media/ECG/visualstudiomagazine/Images/2020/08/dataprep_normalization1_s.asxh"> </a>
<figcaption> <b>[Click on image for larger view.]</b> <em>Figure 1:</em> Programmatically Normalizing Numeric Data
 </figcaption>
</figure></div>





<p>
  The demo is a Python language program but programmatic data normalization can be implemented using any language. The first five lines of the demo source data are:

</p>
  


<pre>M   32   eastern   59200.00   moderate
F   43   central   38400.00   moderate
M   35   central   30800.00   liberal
M   26   western   53800.00   conservative
M   28   central   68700.00   liberal
. . .</pre>




<p>
  The demo begins by displaying the source data file. Next the demo scans through the age column and income column and computes four statistics that are needed for normalization: the smallest and largest value in each column, and the mean and standard deviation of the values in each column. These statistics are stored into an array of Dictionary objects, with one Dictionary for each numeric column.

</p>
  


<p>
  There are several different types of data normalization. The three most common types are min-max normalization, z-score normalization, and constant factor normalization. The demo program uses min-max normalization but the program can be easily modified to use z-score or constant factor normalization. After applying min-max normalization, all age and income values are between 0.0 and 1.0.

</p>
  


<p>
  This article assumes you have intermediate or better skill with a C-family programming language. The demo program is coded using Python but you shouldn't have too much trouble refactoring the demo code to another language if you wish. The complete source code for the demo program is presented in this article. The source code is also available in the accompanying file download.

</p>
  


<p><span><b>The Data Preparation Pipeline</b></span><br>
Although data preparation is different for every problem scenario, in general the data preparation pipeline for most ML systems usually follows something similar to the steps shown in <b>Figure 2</b>.</p>


 


<div><figure> <a href="https://visualstudiomagazine.com/articles/2020/08/04/~/media/ECG/visualstudiomagazine/Images/2020/08/dataprep_normalization2.asxh" target="_blank">
<img alt="Figure 1: Data Preparation Pipeline Typical Tasks" src="https://visualstudiomagazine.com/articles/2020/08/04/~/media/ECG/visualstudiomagazine/Images/2020/08/dataprep_normalization2_s.asxh"> </a>
<figcaption> <b>[Click on image for larger view.]</b> <em>Figure 2:</em> Data Preparation Pipeline Typical Tasks
 </figcaption>
</figure></div>





<p>
  Data preparation for ML is deceptive because the process is conceptually easy. However, there are many steps, and each step is much trickier than you might expect if you're new to ML. This article explains the seventh step in <b>Figure 2</b>. Other Data Science Lab articles explain the other steps. The articles can be found <a href="https://visualstudiomagazine.com/Articles/List/Neural-Network-Lab.aspx" target="_blank">here</a>.

</p>
  


<p>
  The tasks in <b>Figure 2</b> are usually not followed in a strictly sequential order. You often have to backtrack and jump around to different tasks. But it's a good idea to follow the steps shown in order as much as possible. For example, it's better to normalize data before encoding because encoding generates many additional numeric columns which makes it a bit more complicated to normalize the original numeric data.

</p>
  


<p><span><b>Understanding Normalization Techniques</b></span><br>
The min-max, z-score, and constant factor normalization techniques are best explained by examples. Suppose you have just three numeric values: 28, 46, 34. Expressed as a math equation, min-max normalization is x' = (x - min) / (max - min), where x is a raw value, x' is the normalized value, min is the smallest value in the column, and max is the largest value. For the three example values, min = 28 and max = 46. Therefore, the min-max normalized values are:</p>




<pre>28: (28 - 28) / (46 - 28) = 0 / 18 = 0.00
46: (46 - 28) / (46 - 28) = 18 / 18 = 1.00
34: (34 - 28) / (46 - 28) = 6 / 18 = 0.33</pre>




<p>
  The min-max technique results in values between 0.0 and 1.0 where the smallest value is normalized to 0.0 and the largest value is normalized to 1.0.

</p>
  


<p>
  Expressed as a math equation, z-score normalization is x' = (x - u) / sd, where x is a raw value, x' is the normalized value, u is the mean of the values, and sd is the standard deviation of the values. For the three example values, u = (28 + 46 + 34) / 3 = 108 / 3 = 36.0. The standard deviation of a set of values is the square root of the sum of the squared difference of each value and the mean, divided by the number of values, and so is:

</p>
  


<pre>sd = sqrt( [(28 - 36.0)^2 + (46 - 36.0)^2 + (34 - 36.0)^2] / 3 )
     = sqrt( [(-8.0)^2 + (10.0)^2 + (-2.0)^2] / 3 )
     = sqrt( [64.0 + 100.0 + 4.0] / 3 )
     = sqrt( 168.0 / 3 )
     = sqrt(56.0)
     = 7.48</pre>




<p>
  Therefore, the z-score normalized values are:

</p>
  


<pre>28: (28 - 36.0) / 7.48 = -1.07
46: (46 - 36.0) / 7.48 = +1.34
34: (34 - 36.0) / 7.48 = -0.27</pre>




<p>
  A z-score normalized value that is positive corresponds to an x value that is greater than the mean value, and a z-score that is negative corresponds to an x value that is less than the mean.

</p>
  


<p>
  The simplest normalization technique is constant factor normalization. Expressed as a math equation constant factor normalization is x' = x / k, where x is a raw value, x' is the normalized value, and k is a numeric constant. If k = 100, the constant factor normalized values are:

</p>
  


<pre>28: 28 / 100 = 0.28
46: 46 / 100 = 0.46
34: 34 / 100 = 0.34</pre>




<p>
  So, which normalization technique should you use? There is very little research on the effects of different types of normalization, but what little research there is suggests that all three techniques work about equally well. Other factors, such as the training optimization algorithm and learning rate, usually have greater influence than type of normalization technique used.

</p>
  


<p>
  In most situations I prefer using constant factor normalization. It's easy, normalized values maintain sign, and the normalized values are easy to interpret. There are some rather vague theoretical advantages for min-max and z-score normalization, but there are no solid research results to support these claims.

</p>
  


<p><span><b>The Demo Program</b></span><br>
The structure of the demo program, with a few minor edits to save space, is shown in <b>Listing 1</b>. I indent my Python programs using two spaces, rather than the more common four spaces or a tab character, as a matter of personal preference. The program has five worker functions plus a main() function to control program flow. The purpose of worker functions line_count(), show_file(), make_col_stats(), make_stats_arr(), and normalize_mm_file() should be clear from their names.</p>





<p><b>Listing 1: Data Normalization Demo Program</b></p>




<pre># data_normalize.py
# Python 3.7.6  NumPy 1.18.1

import numpy as np

def show_file(fn, start, end, indices=False,
 strip_nl=False): . . .

def line_count(fn): . . . 

def make_col_stats(data, col, delim): . . .

def make_stats_arr(fn, col_types,
  delim): . . . 

def normalize_mm_file(src, dest, col_types,
  stats_arr, delim): . . .

def main():
  print("
Begin data normalization ")

  src = ".\people_clean.txt"
  dest = ".\people_normalized.txt"

  print("
Source file: ")
  show_file(src, 1, 9999, indices=True,
    strip_nl=True)  

  print("
Column types: ")
  col_types = ["c", "n", "c", "n", "dc"] 
  print(col_types)

  print("
Computing stats for n-type columns")
  stats_arr = make_stats_arr(src,
    col_types, "	")

  print("
Applying min-max normalization")
  normalize_mm_file(src, dest,
    col_types, stats_arr, "	")
  print("Done")

  print("
Result file: ")
  show_file(dest, 1, 9999, indices=True,
    strip_nl=True)

  print("
End 
")

if __name__ == "__main__":
  main()</pre>





<p>
  Program execution begins with:

</p>
  


<pre>def main():
  print("
Begin data normalization ")
  src = ".\people_clean.txt"
  dest = ".\people_normalized.txt"
  print("
Source file: ")
  show_file(src, 1, 9999, indices=True,
    strip_nl=True) 
 . . .</pre>




<p>
  The first step when working with any machine learning data file is to do a preliminary investigation. The source data is named people_clean.txt and has only 12 lines to keep the main ideas of data normalization as clear as possible. The number of lines in the file could have been determined by a call to the line_count() function. The entire data file is examined by a call to show_file() with arguments start=1 and end=9999. In most cases with large data files, you'll examine just specified lines of your data file rather than the entire file.

</p>
  


<p>
  The indices=True argument instructs show_file() to display 1-based line numbers. With some data preparation tasks it's more natural to use 1-based indexing, but with other tasks it's more natural to use 0-based indexing. Either approach is OK but you've got to be careful of off-by-one errors. The strip_nl=True argument instructs function show_file() to remove trailing newlines from the data lines before printing them to the console shell so that there aren't blank lines between data lines in the display.

</p>
  


<p>
  The demo continues with:

</p>
  


<pre>  print("
Column types: ")
  col_types = ["c", "n", "c", "n", "dc"] 
  print(col_types)
  print("
Computing stats for all n columns")
  stats_arr = make_stats_arr(src,
    col_types, "	")
. . .</pre>




<p>
  The demo identifies the kind of each column because different kinds of columns must be normalized and encoded in different ways. There is no standard way to identify columns so you can use whatever scheme is suited to your problem scenario. The demo uses "c" for the two categorical predictor data columns sex and region, "n" for the two numeric predictor columns age and income, and "dc" for the dependent categorical variable column political leaning.

</p>
  


<p>
  The demo uses program-defined function make_stats_arr() to compute a stats_arr object. The result stats_arr object is a NumPy array of references to Dictionary objects, one object per data column. If a column is not numeric, the corresponding array cell is set to None (roughly equivalent to null in other languages). The numeric columns have a corresponding cell that is a reference to a Dictionary where the keys are "min", "max", "mean", and "sd", and the values are the smallest value, largest value, average value, and standard deviation of the column. For example, stats_arr[0] is None because column [0] is the sex variable, which is categorical. And stats_arr[1]["min"] is the smallest value in column [1], the age column, which is 26.

</p>
  


<p>
  The demo program concludes with:

</p>
  


<pre>. . .
  print("
Applying min-max normalization")
  normalize_mm_file(src, dest, col_types,
    stats_arr, "	")
  print("Done")

  print("
Result file: ")
  show_file(dest, 1, 9999, indices=True,
    strip_nl=True)
  print("
End 
")
if __name__ == "__main__":
  main()</pre>




<p>
  The source file is min-max normalized using a call to the normalize_mm_file() function and the results are saved to a destination file, and then displayed. As you'll see shortly, you can easily modify normalize_mm_file() so that it will use z-score or constant factor normalization.

</p>
  


<p><span><b>Examining the Data</b></span><br>
When working with data for an ML system you always need to determine how many lines there are in the data, how many columns/fields there are on each line, and what type of delimiter is used. The demo defines a function line_count() as:</p>




<pre>def line_count(fn):
  ct = 0
  fin = open(fn, "r")
  for line in fin:
    ct += 1
  fin.close()
  return ct</pre>




<p>
  The file is opened for reading and then traversed using a Python for-in idiom. Each line of the file, including the terminating newline character, is stored into variable named "line" but that variable isn't used.  There are many alternative approaches. 

</p>
  


<p>
  The definition of function show_file() is presented in <b>Listing 2</b>. As is the case with all data preparation functions, there are many possible implementations.

</p>
<br>
        
        
        
        
        
        
        
        <!-- pager start -->
        

        <!-- pager end -->
        
        
            
        
                
            

        
    </div>
</div></div></div>
    </div>
    <footer>
        <div>created by <a href="https://buildstarted.com">buildstarted</a> &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>