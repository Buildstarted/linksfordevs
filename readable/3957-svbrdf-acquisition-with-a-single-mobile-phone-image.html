<!DOCTYPE html>
<html lang="en">
<head>
    <title>
SVBRDF Acquisition with a Single Mobile Phone Image -
linksfor.dev(s)
    </title>
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta charset="utf-8">
    <meta name="Description" content="A curated source of links that devs might find interesting. Updated around the clock." />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        
<div class="readable">
    <div id="readOverlay" class="style-ebook"><div id="readInner" class="margin-medium size-medium"><h1>SVBRDF Acquisition with a Single Mobile Phone Image</h1><div><div class="ac ae af ag ah dp aj ak"><p id="80df" class="hu hv ds ba hw b hx hy hz ia ib ic id ie if ig ih dk">Wide variety of images around us are the outcome of interactions between lighting, shapes and materials. In recent years, the advent of convolutional neural networks (CNNs) has led to significant advances in recovering shape using just a single image. One of the problems which didnâ€™t get much attention is <strong class="hw ii">material estimation</strong> which has not seen as much progress, which might be attributed to multiple causes. First, material properties can be more complex. Even discounting more complex global illumination effects, materials are represented by a <strong class="hw ii">spatially-varying bidirectional reflectance distribution function (SVBRDF)</strong>, which is an unknown high-dimensional function that depends on incident lighting directions. Secondly, pixel observations in a single image contain entangled information from factors such as shape and lighting, besides material, which makes estimation ill-posed.</p><p id="5c7f" class="hu hv ds ba hw b hx hy hz ia ib ic id ie if ig ih dk">The researchers from <a href="https://research.adobe.com/" class="fc cf ij ik il im" target="_blank" rel="noopener nofollow">Adobe</a> developed a state-of-the-art technique to recover SVBRDF from a single image of a near-planer surface, acquired using the camera of the mobile phone. This is contrast to conventional BRDF captures setups that usually require significant equipment and expenses. Convolutional Neural Networks is specifically designed to account for the physical form of NDRFs and the interaction of light with materials.</p><h1 id="e544" class="in io ds ba az ip du iq dw ir is it iu iv iw ix iy"><strong class="bm">How It Works</strong></h1><p id="9d74" class="hu hv ds ba hw b hx iz hz ja ib jb id jc if jd ih dk">A state of the art novel architecture that encodes the input image into a latent representation, which is decoded into components corresponding to surface normal, diffuse texture and specular roughness. The experiments demonstrate advantages over several baselines and prior works in quantitative comparisons, while also achieving superior qualitative results. The generalization ability of this network trained on the synthetic BRDF dataset is demonstrated by strong performance on real images, acquired in the wild, in both indoor and outdoor environments, using multiple different phone cameras. Given the estimated BRDF parameters, authors also demonstrate applications such as material editing and relighting of novel shapes. To summarise, authors propose the following contributions:</p><ul class=""><li id="8db0" class="hu hv ds ba hw b hx hy hz ia ib ic id ie if ig ih je jf jg">A novel lightweight SVBRDF acquisition method that produces state-of-the-art reconstruction quality.</li><li id="dc7d" class="hu hv ds ba hw b hx jh hz ji ib jj id jk if jl ih je jf jg">A CNN architecture that exploits domain knowledge for joint SVBRDF reconstruction and material classification.</li><li id="f55e" class="hu hv ds ba hw b hx jh hz ji ib jj id jk if jl ih je jf jg">Novel DCRF-based post-processing that accounts for the microfacet BRDF model to refine network outputs.</li><li id="b615" class="hu hv ds ba hw b hx jh hz ji ib jj id jk if jl ih je jf jg">An SVBRDF dataset that is large-scale and specifically attuned to estimation of spatially-varying materials.</li></ul><figure class="gr gs gt gu gv gh db dc paragraph-image"><figcaption class="be ew ho hp hq dd db dc hr hs az ev"><em class="ht">Figure 2: Distribution of materials in our Training and test sets</em></figcaption></figure><p id="ba4b" class="hu hv ds ba hw b hx hy hz ia ib ic id ie if ig ih dk"><strong class="hw ii"><em class="jo">Setup</em></strong><em class="jo">: </em>Our goal is to reconstruct the spatially-varying BRDF of a near planar surface from a single image captured by a mobile phone with the flash turned on for illumination. Authors assume that the z-axis of the camera is approximately perpendicular to the planar surface (they explicitly evaluate against this assumption in our experiments). For most mobile devices, the position of the flash light is usually very close to the position of the camera, which provides us a univariate sampling of a isotropic BRDF. Our surface appearance is represented by a microfacet parametric BRDF model. Let <em class="jo">di, ni, ri</em> be the diffuse color, normal and roughness, respectively, at pixel <em class="jo">i</em>. The BRDF model is defined as:</p><figure class="gr gs gt gu gv gh db dc paragraph-image"><p id="424b" class="hu hv ds ba hw b hx hy hz ia ib ic id ie if ig ih dk">Where <em class="jo">vi </em>and <em class="jo">li </em>are the view and light directions and <em class="jo">hi</em> is the half angle vector. Given an observed image <em class="jo">I (di, ni, ri, </em><strong class="hw ii"><em class="jo">L</em></strong><em class="jo">)</em>, captured under unknown illumination L, scientists wish to recover the parameters <em class="jo">di, ni</em> and <em class="jo">ri</em> for each pixel <em class="jo">i </em>in the image.</p><p id="4df8" class="hu hv ds ba hw b hx hy hz ia ib ic id ie if ig ih dk"><strong class="hw ii"><em class="jo">Dataset: </em></strong>The dataset has been used is Adobe Stock 3D Material <a href="https://stock.adobe.com/3d-assets" class="fc cf ij ik il im" target="_blank" rel="noopener nofollow">dataset</a> which contain 688 materials with high resolution (4096 x 4096) spatially-varying BRDFs. Scientists use 588 materials for training and 100 materials for testing. For data augmentation, authors randomly crop 12, 8, 4, 2, 1 image patches of size 512, 1024, 2048, 3072, 4096. The distribution is shown in figure 2.</p><h1 id="0ee5" class="in io ds ba az ip du iq dw ir is it iu iv iw ix iy"><strong class="bm"><em class="ht">Network Design</em></strong></h1></figure></div></div></div></div>
</div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script>
        (function () {
            var COLLECT_URL = "https://dna.buildstarted.com/t";
            var SITE_ID = "linksfor.devs";
            var GLOBAL_VAR_NAME = "__DNA__";

            window[GLOBAL_VAR_NAME] = {};

            window[GLOBAL_VAR_NAME].sendPageView = function () {
                var path = location.pathname;
                var referrer = document.referrer;

                var url = COLLECT_URL + "?siteid=" + SITE_ID + "&p=" + encodeURIComponent(path) + "&r=" + encodeURIComponent(referrer);

                try { fetch(url, { method: "GET" }); } catch (e) { }
            };

            window[GLOBAL_VAR_NAME].sendPageView();
        })();
    </script>
</body>
</html>