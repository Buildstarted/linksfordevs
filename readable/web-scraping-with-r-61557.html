<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Web Scraping with R - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Web Scraping with R - linksfor.dev(s)"/>
    <meta property="article:author" content="Pierre de Wulf"/>
    <meta property="og:description" content="Learn web scraping with R with this step-by-step tutorial. We will see the different ways to scrape the web in R through lots of example."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://www.scrapingbee.com/blog/web-scraping-r/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Web Scraping with R</title>
<div class="readable">
        <h1>Web Scraping with R</h1>
            <div>by Pierre de Wulf</div>
            <div>Reading time: 21-26 minutes</div>
        <div>Posted here: 11 May 2020</div>
        <p><a href="https://www.scrapingbee.com/blog/web-scraping-r/">https://www.scrapingbee.com/blog/web-scraping-r/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
          <!-- raw HTML omitted -->
<!-- raw HTML omitted -->
























<div>
  
  <p><img data-sizes="auto" data-srcset="
    
      https://d33wubrfki0l68.cloudfront.net/9824a1c57acd2bda2b10dea471e7596659f4915c/f0519/blog/web-scraping-r/blog_header_r_hucc481e568c14cb156741a7079f0e75b3_28126_500x0_resize_q75_box.jpg 500w
    
    
      , https://d33wubrfki0l68.cloudfront.net/0531850c455ea056353fd796bf044fc6d6df2111/d015a/blog/web-scraping-r/blog_header_r_hucc481e568c14cb156741a7079f0e75b3_28126_800x0_resize_q75_box.jpg 800w
    
    
      , https://d33wubrfki0l68.cloudfront.net/496c49842468aed1ef47384a31c9f822db9a8513/03097/blog/web-scraping-r/blog_header_r_hucc481e568c14cb156741a7079f0e75b3_28126_1200x0_resize_q75_box.jpg 1200w
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/e3124b1ed1c53f1e89ccca00661fcceda2638ad3/a9f98/blog/web-scraping-r/blog_header_r.jpg" width="1200" height="628" alt="Web Scraping with R" sizes="825px" srcset="
    
      https://d33wubrfki0l68.cloudfront.net/9824a1c57acd2bda2b10dea471e7596659f4915c/f0519/blog/web-scraping-r/blog_header_r_hucc481e568c14cb156741a7079f0e75b3_28126_500x0_resize_q75_box.jpg 500w
    
    
      , https://d33wubrfki0l68.cloudfront.net/0531850c455ea056353fd796bf044fc6d6df2111/d015a/blog/web-scraping-r/blog_header_r_hucc481e568c14cb156741a7079f0e75b3_28126_800x0_resize_q75_box.jpg 800w
    
    
      , https://d33wubrfki0l68.cloudfront.net/496c49842468aed1ef47384a31c9f822db9a8513/03097/blog/web-scraping-r/blog_header_r_hucc481e568c14cb156741a7079f0e75b3_28126_1200x0_resize_q75_box.jpg 1200w
    
    " src="https://d33wubrfki0l68.cloudfront.net/e3124b1ed1c53f1e89ccca00661fcceda2638ad3/a9f98/blog/web-scraping-r/blog_header_r.jpg">
  
</p></div>
<h2 id="table-of-content">Table of Content:</h2>
<ol>
<li><a href="#web-scraping-with-r--introduction">Web Scraping with R - Introduction</a></li>
<li><a href="#common-web-scraping-scenarios-with-r">Common web scraping scenarios with R</a></li>
<li><a href="#web-scraping-using-rvest">Web scraping using Rvest</a></li>
<li><a href="#1-access-web-data-using-r-over-ftp">Access data over FTP</a></li>
<li><a href="#2-scraping-information-from-wikipedia-using-r">Scraping wikipedia</a></li>
<li><a href="#2-scraping-information-from-wikipedia-using-r">Handling HTML forms while scraping with R</a></li>
<li><a href="#web-scraping-using-rcrawler">Web Scraping using Rcrawler</a></li>
</ol>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<p>Want to scrape the web with R? You’re at the right place!</p>
<p>We will teach you from ground up on how to scrape the web with R, and will take you through fundamentals of web scraping (with examples from R).</p>
<p>Throughout this article, we won’t just take you through prominent R libraries like rvest and Rcrawler, but will also walk you through how to scrape information with barebones code.</p>
<p>Overall, here’s what you are going to learn:</p>
<ol>
<li>R web scraping fundamentals</li>
<li>Handling different web scraping scenarios with R</li>
<li>Leveraging rvest and Rcrawler to carry out web scraping</li>
</ol>
<p>Let’s start the journey!</p>
<h2 id="web-scraping-with-r--introduction">Web scraping with R - Introduction</h2>
<p>The first step towards scraping the web with R requires you to understand HTML and web scraping fundamentals. You’ll learn how to get browsers to display the source code, then you will develop the logic of markup languages which sets you on the path to scrape that information. And, above all - you’ll master the vocabulary you need to scrape data with R.</p>
<p>We would be looking at the following basics that’ll help you scrape R:</p>
<ol>
<li>HTML Basics</li>
<li>Browser presentation</li>
<li>And Parsing HTML data in R</li>
</ol>
<p>So, let’s get into it.</p>
<h3 id="html-basics">HTML Basics</h3>
<p>HTML is behind everything on the web. Our goal here is to briefly understand how Syntax rules, browser presentation, tags and attributes help us learn how to parse HTML and scrape the web for the information we need.</p>
<h3 id="browser-presentation">Browser Presentation</h3>
<p>Before we scrape anything using R we need to know the underlying structure of a webpage. And the first thing you notice, is what you see when you open a webpage, isn’t the HTML document. It’s rather how an underlying HTML code is represented. You can basically open any HTML document using a text editor like notepad.</p>
<p>HTML tells a browser how to show a webpage, what goes into a headline, what goes into a text, etc. The underlying marked up structure is what we need to understand to actually scrape it.</p>
<p>For example, here’s what Scrapingbee.com looks like when you see it in a browser.</p>
























<div>
  
  <p><img data-sizes="auto" data-srcset="
    
      https://d33wubrfki0l68.cloudfront.net/30a3ea5030631ad6950f744b49f2882391e8518e/c1630/blog/web-scraping-r/scrapingbee_home_page_hud88f4499dff480abd994a4c5f28c09e3_254332_500x0_resize_box_2.png 500w
    
    
      , https://d33wubrfki0l68.cloudfront.net/dad93488b1e3145e111a9ce388b1b101c048cf21/1b048/blog/web-scraping-r/scrapingbee_home_page_hud88f4499dff480abd994a4c5f28c09e3_254332_800x0_resize_box_2.png 800w
    
    
      , https://d33wubrfki0l68.cloudfront.net/75e4e577a101db1cccc48bd8a2d2c864830012a1/37273/blog/web-scraping-r/scrapingbee_home_page_hud88f4499dff480abd994a4c5f28c09e3_254332_1200x0_resize_box_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/5b5ad8a6341b2cac3ad5d00b67b812e32545cceb/3c8a6/blog/web-scraping-r/scrapingbee_home_page_hud88f4499dff480abd994a4c5f28c09e3_254332_1500x0_resize_box_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/51b71f34937d1601b2159a71324d96e68d7c2ec1/85856/blog/web-scraping-r/scrapingbee_home_page.png" width="1669" height="1014" alt="Scrapingbee Home page" srcset="
    
      https://d33wubrfki0l68.cloudfront.net/30a3ea5030631ad6950f744b49f2882391e8518e/c1630/blog/web-scraping-r/scrapingbee_home_page_hud88f4499dff480abd994a4c5f28c09e3_254332_500x0_resize_box_2.png 500w
    
    
      , https://d33wubrfki0l68.cloudfront.net/dad93488b1e3145e111a9ce388b1b101c048cf21/1b048/blog/web-scraping-r/scrapingbee_home_page_hud88f4499dff480abd994a4c5f28c09e3_254332_800x0_resize_box_2.png 800w
    
    
      , https://d33wubrfki0l68.cloudfront.net/75e4e577a101db1cccc48bd8a2d2c864830012a1/37273/blog/web-scraping-r/scrapingbee_home_page_hud88f4499dff480abd994a4c5f28c09e3_254332_1200x0_resize_box_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/5b5ad8a6341b2cac3ad5d00b67b812e32545cceb/3c8a6/blog/web-scraping-r/scrapingbee_home_page_hud88f4499dff480abd994a4c5f28c09e3_254332_1500x0_resize_box_2.png 1500w 
    " src="https://d33wubrfki0l68.cloudfront.net/51b71f34937d1601b2159a71324d96e68d7c2ec1/85856/blog/web-scraping-r/scrapingbee_home_page.png">
  
</p></div>
<p>And, here’s what the underlying HTML looks like for it</p>
























<div>
  
  <p><img data-sizes="auto" data-srcset="
    
      https://d33wubrfki0l68.cloudfront.net/b62f6c9bbd6f21f7eda5a001806fd36dc3290c46/2416c/blog/web-scraping-r/scrapingbee_dom_hud54df7e346912d4dab3e8e21a1d2d603_378395_500x0_resize_box_2.png 500w
    
    
      , https://d33wubrfki0l68.cloudfront.net/cf4a29e879eba52085b24d7631a495dbd8f690c6/5d128/blog/web-scraping-r/scrapingbee_dom_hud54df7e346912d4dab3e8e21a1d2d603_378395_800x0_resize_box_2.png 800w
    
    
      , https://d33wubrfki0l68.cloudfront.net/ccdac308bf68feff6d76677282043b1e62e4fb56/4a1f5/blog/web-scraping-r/scrapingbee_dom_hud54df7e346912d4dab3e8e21a1d2d603_378395_1200x0_resize_box_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/f11e7394fff37b5d55dc6c2b831e1945b87e6bab/0c13c/blog/web-scraping-r/scrapingbee_dom_hud54df7e346912d4dab3e8e21a1d2d603_378395_1500x0_resize_box_2.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/1cd20939230ea789991e39c77844d5b62ac9c172/27d9a/blog/web-scraping-r/scrapingbee_dom.png" width="1521" height="1017" alt="HTML inside Chrome dev tools" srcset="
    
      https://d33wubrfki0l68.cloudfront.net/b62f6c9bbd6f21f7eda5a001806fd36dc3290c46/2416c/blog/web-scraping-r/scrapingbee_dom_hud54df7e346912d4dab3e8e21a1d2d603_378395_500x0_resize_box_2.png 500w
    
    
      , https://d33wubrfki0l68.cloudfront.net/cf4a29e879eba52085b24d7631a495dbd8f690c6/5d128/blog/web-scraping-r/scrapingbee_dom_hud54df7e346912d4dab3e8e21a1d2d603_378395_800x0_resize_box_2.png 800w
    
    
      , https://d33wubrfki0l68.cloudfront.net/ccdac308bf68feff6d76677282043b1e62e4fb56/4a1f5/blog/web-scraping-r/scrapingbee_dom_hud54df7e346912d4dab3e8e21a1d2d603_378395_1200x0_resize_box_2.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/f11e7394fff37b5d55dc6c2b831e1945b87e6bab/0c13c/blog/web-scraping-r/scrapingbee_dom_hud54df7e346912d4dab3e8e21a1d2d603_378395_1500x0_resize_box_2.png 1500w 
    " src="https://d33wubrfki0l68.cloudfront.net/1cd20939230ea789991e39c77844d5b62ac9c172/27d9a/blog/web-scraping-r/scrapingbee_dom.png">
  
</p></div>
<p>Looking at this source code might seem like a lot of information to digest at once, let alone scrape it! But don’t worry. The next section exactly shows how to see this information better.</p>
<p><strong>HTML elements and tags</strong></p>
<p>If you carefully checked the raw HTML of Scrapingbee.com earlier, you would notice something like <code>&lt;title&gt;...&lt;/title&gt;, &lt;body&gt;...&lt;/body</code> etc. Those are tags that HTML uses, and each of those tags have their own unique property. For example <code>&lt;title&gt;</code> tag helps a browser render the title of a web page, similarly <code>&lt;body&gt;</code> tag defines the body of an HTML document.</p>
<p>Once you understand those tags, that raw HTML would start talking to you and you’d already start to get the feeling of how you would be scraping web using R. All you need to take away form this section is that a page is structured with the help of HTML tags, and while scraping knowing these tags can help you locate and extract the information easily.</p>
<h3 id="parsing-a-webpage-using-r">Parsing a webpage using R</h3>
<p>With what we know, let’s use R to scrape an HTML webpage and see what we get. Keep in mind, we only know about HTML page structures so far, we know what RAW HTML looks like. That’s why, with the code, we will simply scrape a webpage and get the raw HTML. It is the first step towards scraping the web as well.</p>
<p>Earlier in this post, I mentioned that we can even use a text editor to open an HTML document. And in the code below, we will parse HTML in the same way we would parse a text document and read it with R.</p>
<p>I want to scrape the HTML code of Scrapingbee.com and see how it looks. We will use readLines() to map every line of the HTML document and create a flat representation of it.</p>
<div><pre><code data-lang="r">scrape_url <span>&lt;-</span> <span>"</span><span>https://www.scrapingbee.com/"</span>

flat_html <span>&lt;-</span> <span>readLines</span>(con <span>=</span> url)
</code></pre></div><p>Now, when you see what flat_html looks like, you should see something like this in your R Console:</p>
<div><pre><code data-lang="r">[1] <span>"</span><span>&lt;!DOCTYPE html&gt;"</span>
[2] <span>"</span><span>&lt;html lang="en"&gt;"</span>
[3] <span>"</span><span>&lt;head&gt;"</span>
[4] <span>"</span><span>    &lt;meta name="generator" content="Hugo 0.60.1"/&gt;"</span>
[6] <span>"</span><span>    &lt;meta http-equiv="x-ua-compatible" content="ie=edge"/&gt;"</span>
[7] <span>"</span><span>    &lt;title&gt;ScrapingBee - Web Scraping API&lt;/title&gt;"</span>
[8] <span>"</span><span>    &lt;meta name="description""</span>
[9] <span>"</span><span>          content="ScrapingBee is a Web Scraping API that handles proxies and Headless browser for you, so you can focus on extracting the data you want, and nothing else."/&gt;"</span>
[10] <span>"</span><span>    &lt;meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/&gt;"</span>
[11] <span>"</span><span>    &lt;meta name="twitter:title" content="ScrapingBee - Web Scraping API"/&gt;"</span> 
[12] <span>"</span><span>    &lt;meta name="twitter:description""</span>
[13] <span>"</span><span>          content="ScrapingBee is a Web Scraping API that handles proxies and Headless browser for you, so you can focus on extracting the data you want, and nothing else."/&gt;"</span>
[14] <span>"</span><span>    &lt;meta name="twitter:card" content="summary_large_image"/&gt;"</span>
[15] <span>"</span><span>    &lt;meta property="og:title" content="ScrapingBee - Web Scraping API"/&gt;"</span>
[16] <span>"</span><span>    &lt;meta property="og:url" content="https://www.scrapingbee.com/" /&gt;"</span>
[17] <span>"</span><span>    &lt;meta property="og:type" content="website"/&gt;"</span> 
[18] <span>"</span><span>    &lt;meta property="og:image""</span>
[19] <span>"</span><span>          content="https://www.scrapingbee.com/images/cover_image.png"/&gt;"</span>
[20] <span>"</span><span>    &lt;meta property="og:description" content="ScrapingBee is a Web Scraping API that handles proxies and Headless browser for you, so you can focus on extracting the data you want, and nothing else."/&gt;"</span>
[21] <span>"</span><span>    &lt;meta property="og:image:width" content="1200"/&gt;"</span>
[22] <span>"</span><span>    &lt;meta property="og:image:height" content="630"/&gt;"</span>
[23] <span>"</span><span>    &lt;meta name="twitter:image""</span>
[24] <span>"</span><span>          content="https://www.scrapingbee.com/images/terminal.png"/&gt;"</span> 
[25] <span>"</span><span>    &lt;link rel="canonical" href="https://www.scrapingbee.com/"/&gt;"</span>
[26] <span>"</span><span>    &lt;meta name="p:domain_verify" content="7a00b589e716d42c938d6d16b022123f"/&gt;"</span>
</code></pre></div><p>The whole output would be a hundred pages so I’ve trimmed it for you. But, here’s something you can do to have some fun before I take you further towards scraping web with R:</p>
<ol>
<li>Scrape <a href="http://www.google.com/">www.google.com</a> and try to make sense of the information you received</li>
<li>Scrape a very simple web page like <a href="https://www.york.ac.uk/teaching/cws/wws/webpage1.html"></a><a href="https://www.york.ac.uk/teaching/cws/wws/webpage1.html">https://www.york.ac.uk/teaching/cws/wws/webpage1.html</a> and see what you get</li>
</ol>
<p>Remember, scraping is only fun if you experiment with it. So, as we move forward with the blog post, I’d love it if you try out each and every example as you go through them and bring your own twist. Share in comments if you found something interesting or feel stuck somewhere.</p>
<p>While our output above looks great, it still is something that doesn’t closely reflect an HTML document. In HTML we have a document hierarchy of tags which looks something like</p>
<div><pre><code data-lang="html"><span>&lt;!DOCTYPE html&gt;</span>
&lt;<span>head</span>&gt;
    &lt;<span>title</span>&gt;Page Title&lt;/<span>title</span>&gt;
&lt;/<span>head</span>&gt;
&lt;<span>body</span>&gt;
    &lt;<span>h1</span>&gt;My First Heading&lt;/<span>h1</span>&gt;
    &lt;<span>p</span>&gt;My first paragraph.&lt;/<span>p</span>&gt;
&lt;/<span>body</span>&gt;
&lt;/<span>html</span>&gt;

</code></pre></div><p>But clearly, our output from readLines() discarded the markup structure/hierarchies of HTML. Given that, I just wanted to give you a barebones look at scraping, this code looks like a good illustration.</p>
<p>However, in reality, our code is a lot more complicated. But fortunately, we have a lot of libraries that simplify web scraping in R for us. We will go through four of these libraries in later sections.</p>
<p>First, we need to go through different scraping situations that you’ll frequently encounter when you scrape data through R.</p>
<h2 id="common-web-scraping-scenarios-with-r">Common web scraping scenarios with R</h2>
<h3 id="1-access-web-data-using-r-over-ftp">#1 Access web data using R over FTP</h3>
<p>FTP is one of the ways to access data over the web. And with the help of CRAN FTP servers, I’ll show you how you can request data over FTP with just a few lines of code.  Overall, the whole process is:</p>
<ol>
<li>Save ftp URL</li>
<li>Save names of files from the URL into an R object</li>
<li>Save files onto your local directory</li>
</ol>
<p>Let’s get started now. The URL that we are trying to get data from is <a href="ftp://cran.r-project.org/pub/R/web/packages/BayesMixSurv/">ftp://cran.r-project.org/pub/R/web/packages/BayesMixSurv/</a>.</p>
<div><pre><code data-lang="r">ftp_url <span>&lt;-</span> <span>"</span><span>ftp://cran.r-project.org/pub/R/web/packages/BayesMixSurv/"</span>

get_files <span>&lt;-</span> <span>getURL</span>(ftp_url, dirlistonly <span>=</span> <span>TRUE</span>)
</code></pre></div><p>Let’s check the name of the files we received with get_files</p>
<div><pre><code data-lang="r"><span>&gt;</span> get_files

<span>"</span><span>BayesMixSurv.pdf
ChangeLog
DESCRIPTION
NAMESPACE
aliases.rds
index.html
rdxrefs.rds
"</span>
</code></pre></div><p>Looking at the string above can you see what the file names are?</p>
<p>The screenshot from the URL shows real file names</p>
























<div>
  
  <p><img data-sizes="auto" data-srcset="
    
      https://d33wubrfki0l68.cloudfront.net/d8b342b90b04ce7293b93a0a1d782ca3e2f35323/5948a/blog/web-scraping-r/ftp_hu8350a2fb628c45f29ed1663fc1a5c1d6_39102_500x0_resize_box_2.png 500w
    
    
      , https://d33wubrfki0l68.cloudfront.net/798a12c577e25e899abd9f218a6c07ee3f0445a3/983fa/blog/web-scraping-r/ftp_hu8350a2fb628c45f29ed1663fc1a5c1d6_39102_800x0_resize_box_2.png 800w
    
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/aecb45152d23a15c44d13c6b5b288de113bd1795/d93e5/blog/web-scraping-r/ftp.png" width="805" height="401" alt="Files and directory inside an FTP server" srcset="
    
      https://d33wubrfki0l68.cloudfront.net/d8b342b90b04ce7293b93a0a1d782ca3e2f35323/5948a/blog/web-scraping-r/ftp_hu8350a2fb628c45f29ed1663fc1a5c1d6_39102_500x0_resize_box_2.png 500w
    
    
      , https://d33wubrfki0l68.cloudfront.net/798a12c577e25e899abd9f218a6c07ee3f0445a3/983fa/blog/web-scraping-r/ftp_hu8350a2fb628c45f29ed1663fc1a5c1d6_39102_800x0_resize_box_2.png 800w
    
    
    " src="https://d33wubrfki0l68.cloudfront.net/aecb45152d23a15c44d13c6b5b288de113bd1795/d93e5/blog/web-scraping-r/ftp.png">
  
</p></div>
<p>It turns out that when you download those file names you get carriage return representations too. And it is pretty easy to solve this issue. In the code below, I used str_split() and str_extract_all() to get the HTML file names of interest.</p>
<div><pre><code data-lang="r">extracted_filenames <span>&lt;-</span> <span>str_split</span>(get_files, <span>"</span><span>
"</span>)[[1]]

extracted_html_filenames <span>&lt;-</span><span>unlist</span>(<span>str_extract_all</span>(extracted_filenames, <span>"</span><span>.+(.html)"</span>))
</code></pre></div><p>Let’s print the file names to see what we have now:</p>
<p>extracted_html_filenames</p>
<div><pre><code data-lang="r"><span>&gt;</span> extracted_html_filenames

[1] <span>"</span><span>index.html"</span>
</code></pre></div><p>Great! So, we now have a list of HTML files that we want to access. In our case, it was only one HTML file.</p>
<p>Now, all we have to do is to write a function that stores them in a folder and a function that downloads HTML docs in that folder from the web.</p>
<div><pre><code data-lang="r">FTPDownloader <span>&lt;-</span> <span>function</span>(filename, folder, handle) {

  <span>dir.create</span>(folder, showWarnings <span>=</span> <span>FALSE</span>)

  fileurl <span>&lt;-</span> <span>str_c</span>(ftp, filename)

  <span>if </span>(<span>!</span><span>file.exists</span>(<span>str_c</span>(folder, <span>"</span><span>/"</span>, filename))) {

    file_name <span>&lt;-</span> <span>try</span>(<span>getURL</span>(fileurl, curl <span>=</span> handle))

    <span>write</span>(file_name, <span>str_c</span>(folder, <span>"</span><span>/"</span>, filename))

    <span>Sys.sleep</span>(<span>1</span>)

  }

}  
</code></pre></div><p>We are almost there now! All we now have to do is to download these files to a specified folder in your local drive. Save those files in a folder called scrapignbee_html. To do so, use GetCurlHandle().</p>
<div><pre><code data-lang="r">Curlhandle <span>&lt;-</span> <span>getCurlHandle</span>(ftp.use.epsv <span>=</span> <span>FALSE</span>)
</code></pre></div><p>After that, we’ll use plyr package’s l_ply() function.</p>
<div><pre><code data-lang="r"><span>library</span>(plyr)

<span>l_ply</span>(extracted_html_filenames, FTPDownloader, folder <span>=</span> <span>"</span><span>scrapingbee_html"</span>, handle <span>=</span> Curlhandle)
</code></pre></div><p>And, we are done!</p>
<p>I can see that on my local drive I have a folder named scrapingbee_html, where I have inde.html file stored. But, if you don’t want to manually go and check the scraped content, use this command to retrieve a list of HTMLs downloaded:</p>
<div><pre><code data-lang="r"><span>list.files</span>(<span>"</span><span>./scrapingbee_html"</span>)

[1] <span>"</span><span>index.html"</span>
</code></pre></div><p>That was via FTP, but what about HTML retrieving specific data from a webpage? That’s what our next section covers.</p>
<h3 id="2-scraping-information-from-wikipedia-using-r">#2 Scraping information from Wikipedia using R</h3>
<p>In this section, I’ll show you how to retrieve information from Leonardo Da Vinci’s Wikipedia page <a href="https://en.wikipedia.org/wiki/Leonardo_da_Vinci"></a><a href="https://en.wikipedia.org/wiki/Leonardo_da_Vinci">https://en.wikipedia.org/wiki/Leonardo_da_Vinci</a>.</p>
<p>Let’s take the basic steps to parse information:</p>
<div><pre><code data-lang="r">wiki_url <span>&lt;-</span> <span>"</span><span>https://en.wikipedia.org/wiki/Leonardo_da_Vinci"</span>

wiki_read <span>&lt;-</span> <span>readLines</span>(wiki_url, encoding <span>=</span> <span>"</span><span>UTF-8"</span>)

parsed_wiki <span>&lt;-</span> <span>htmlParse</span>(wiki_read, encoding <span>=</span> <span>"</span><span>UTF-8"</span>)
</code></pre></div><p>Leonardo Da Vinci’s Wikipedia HTML has now been parsed and stored in parsed_wiki.</p>
<p>But, let’s say you wanted to see what text we were able to parse. A very simple way to do that would be:</p>
<div><pre><code data-lang="r">wiki_intro_text <span>&lt;-</span> parsed_wiki[<span>"</span><span>//p"</span>]
</code></pre></div><p>By doing that, we have essentially parsed everything that exists within the <code>&lt;p&gt;</code> node. And since it is an XML node set, we can easily use subsetting rules to access different paragraphs. For example, let’s say we pick the 4th element on a random name. Here’s what you’ll see:</p>
<div><pre><code data-lang="r">wiki_intro_text[[4]]

<span>&lt;</span>p<span>&gt;</span>Born <span>&lt;</span>a href<span>=</span><span>"</span><span>/wiki/Legitimacy_(family_law)"</span> title<span>=</span><span>"</span><span>Legitimacy (family law)"</span><span>&gt;</span>out of wedlock<span>&lt;</span><span>/</span>a<span>&gt;</span> to a notary, Piero da Vinci, and a peasant woman, Caterina, in <span>&lt;</span>a href<span>=</span><span>"</span><span>/wiki/Vinci,_Tuscany"</span> title<span>=</span><span>"</span><span>Vinci, Tuscany"</span><span>&gt;</span>Vinci<span>&lt;</span><span>/</span>a<span>&gt;</span>, in the region of <span>&lt;</span>a href<span>=</span><span>"</span><span>/wiki/Florence"</span> title<span>=</span><span>"</span><span>Florence"</span><span>&gt;</span>Florence<span>&lt;</span><span>/</span>a<span>&gt;</span>, <span>&lt;</span>a href<span>=</span><span>"</span><span>/wiki/Italy"</span> title<span>=</span><span>"</span><span>Italy"</span><span>&gt;</span>Italy<span>&lt;</span><span>/</span>a<span>&gt;</span>, Leonardo was educated in the studio of the renowned Italian painter <span>&lt;</span>a href<span>=</span><span>"</span><span>/wiki/Andrea_del_Verrocchio"</span> title<span>=</span><span>"</span><span>Andrea del Verrocchio"</span><span>&gt;</span>Andrea del Verrocchio<span>&lt;</span><span>/</span>a<span>&gt;</span>. Much of his earlier working life was spent in the service of <span>&lt;</span>a href<span>=</span><span>"</span><span>/wiki/Ludovico_il_Moro"</span> class<span>=</span><span>"</span><span>mw-redirect"</span> title<span>=</span><span>"</span><span>Ludovico il Moro"</span><span>&gt;</span>Ludovico il Moro<span>&lt;</span><span>/</span>a<span>&gt;</span> in Milan, and he later worked in Rome, Bologna and Venice. He spent his last three years in France, where he died in <span>1519</span>.
<span>&lt;</span><span>/</span>p<span>&gt;</span> 

</code></pre></div><p>Reading text is fun, but let’s do something else - let’s get all links that exist on this page. We can easily do that by using getHTMLLinks() function:</p>
<div><pre><code data-lang="r"><span>getHTMLLinks</span>(wiki_read)

[1] <span>"</span><span>/wiki/Wikipedia:Good_articles"</span>                                                       

[2] <span>"</span><span>/wiki/Wikipedia:Protection_policy#semi"</span>                                              

[3] <span>"</span><span>/wiki/Da_Vinci_(disambiguation)"</span>                                                     

[4] <span>"</span><span>/wiki/Leonardo_da_Vinci_(disambiguation)"</span>                                            

[5] <span>"</span><span>/wiki/Republic_of_Florence"</span>                                                          

[6] <span>"</span><span>/wiki/Surname"</span>                                                                       

[7] <span>"</span><span>/wiki/Given_name"</span>                                                                    

[8] <span>"</span><span>/wiki/File:Francesco_Melzi_-_Portrait_of_Leonardo.png"</span>                               

[9] <span>"</span><span>/wiki/Francesco_Melzi"</span>    

…
</code></pre></div><p>Notice what you see above is a mix of actual links and links to files.</p>
<p>You can also see the total number of links on this page by using length() function:</p>
<div><pre><code data-lang="r"><span>length</span>(<span>getHTMLLinks</span>(wiki_read))

[1] <span>1566</span>

</code></pre></div><p>I’ll throw in one more use case here which is to scrape tables off such HTML pages. And it is something that you’ll encounter quite frequently too for web scraping purposes. XML package in R offers a function named readHTMLTable() which makes our life so easy when it comes to scraping tables from HTML pages.</p>
<p>Leonardo’s Wikipedia page has no HTML though, so I will use a different page to show how we can scrape HTML from a webpage using R. Here’s the new URL:</p>
<p><a href="https://en.wikipedia.org/wiki/Help:Table"></a><a href="https://en.wikipedia.org/wiki/Help:Table">https://en.wikipedia.org/wiki/Help:Table</a></p>
<p>As usual, we will read this URL:</p>
<div><pre><code data-lang="r">wiki_url1 <span>&lt;-</span> <span>"</span><span>https://en.wikipedia.org/wiki/Help:Table"</span>

wiki_read1 <span>&lt;-</span> <span>readLines</span>(wiki_url1, encoding <span>=</span> <span>"</span><span>UTF-8"</span>)

Now, let’s see how many tables this webpage exactly has<span>:</span>

<span>length</span>((<span>readHTMLTable</span>(wiki_read1)))

[1] <span>108</span>
</code></pre></div><p>If you look at the page you’ll disagree with the number “108”. For a closer inspection I’ll use name() function to get names of all 108 tables:</p>
<div><pre><code data-lang="r"><span>names</span>(<span>readHTMLTable</span>(wiki_read1))

[1] <span>"</span><span>NULL"</span>                                                                             

[2] <span>"</span><span>NULL"</span>                                                                             

[3] <span>"</span><span>NULL"</span>                                                                             

[4] <span>"</span><span>NULL"</span>                                                                             

[5] <span>"</span><span>NULL"</span>                                                                             

[6] <span>"</span><span>The table's caption
"</span> 

…
</code></pre></div><p>Our suspicion was right, there are too many “NULL” and only a few tables. I’ll now read data from one of those tables in R:</p>
<div><pre><code data-lang="r"><span>readHTMLTable</span>(wiki_read1)<span>$</span><span>"</span><span>The table's caption
"</span>

               V1              V2              V3

<span>1</span> Column header <span>1</span> Column header <span>2</span> Column header <span>3</span>

<span>2</span>    Row header <span>1</span>          Cell <span>2</span>          Cell <span>3</span>

<span>3</span>    Row header A          Cell B          Cell C

</code></pre></div><p>Here’s how this table looks in HTML</p>
























<div>
  
  <p><img data-sizes="auto" data-srcset="
    
      https://d33wubrfki0l68.cloudfront.net/bb81e9073cac44c0e66039ce0017c29f59112ecf/aeeb6/blog/web-scraping-r/table_hu687ed8005ca2916953a91efc516c27d0_30059_500x0_resize_box_2.png 500w
    
    
      , https://d33wubrfki0l68.cloudfront.net/947cf3d1b3c76f8ec18629cb725782391b1c9ac2/fb018/blog/web-scraping-r/table_hu687ed8005ca2916953a91efc516c27d0_30059_800x0_resize_box_2.png 800w
    
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/e09941584ff3ea679a5c843396409e8f00e0488d/bc607/blog/web-scraping-r/table.png" width="872" height="309" alt="Html Table" srcset="
    
      https://d33wubrfki0l68.cloudfront.net/bb81e9073cac44c0e66039ce0017c29f59112ecf/aeeb6/blog/web-scraping-r/table_hu687ed8005ca2916953a91efc516c27d0_30059_500x0_resize_box_2.png 500w
    
    
      , https://d33wubrfki0l68.cloudfront.net/947cf3d1b3c76f8ec18629cb725782391b1c9ac2/fb018/blog/web-scraping-r/table_hu687ed8005ca2916953a91efc516c27d0_30059_800x0_resize_box_2.png 800w
    
    
    " src="https://d33wubrfki0l68.cloudfront.net/e09941584ff3ea679a5c843396409e8f00e0488d/bc607/blog/web-scraping-r/table.png">
  
</p></div>
<p>Awesome isn’t it? Imagine being able to access census, pricing, etc data over R and scraping it. Wouldn’t it be fun? That’s why I took a boring one, and kept the fun part for you. Try something much cooler than what I did. Here’s an example of table data that you can scrape <a href="https://en.wikipedia.org/wiki/United_States_Census"></a><a href="https://en.wikipedia.org/wiki/United_States_Census">https://en.wikipedia.org/wiki/United_States_Census</a></p>
<p>Let me know how it goes for you. But it usually isn’t that straightforward. We have forms and authentication that can block your R code from scraping. And that’s exactly what we are going to learn to get through here.</p>
<h3 id="3-handling-html-forms-while-scraping-with-r">#3 Handling HTML forms while scraping with R</h3>
<p>Often we come across pages that aren’t that easy to scrape. Take a look at the Meteorological Service Singapore’s page (that lack of SSL though :O). Notice the dropdowns here</p>
























<div>
  
  <p><img data-sizes="auto" data-srcset="
    
      https://d33wubrfki0l68.cloudfront.net/fa9afe3bf90eea5da9180685402c4664719b82d1/0896f/blog/web-scraping-r/weather_singapore_hu79e9c881b4f2af7a2e84506799a615ec_375308_500x0_resize_box_2.png 500w
    
    
      , https://d33wubrfki0l68.cloudfront.net/21c68a0ef365f1176e3cb96f1754330e56479f1c/7fd66/blog/web-scraping-r/weather_singapore_hu79e9c881b4f2af7a2e84506799a615ec_375308_800x0_resize_box_2.png 800w
    
    
      , https://d33wubrfki0l68.cloudfront.net/4fa3cae702cf3dfade140c9146e03225822fbe83/2b91e/blog/web-scraping-r/weather_singapore_hu79e9c881b4f2af7a2e84506799a615ec_375308_1200x0_resize_box_2.png 1200w
    
    " data-src="https://d33wubrfki0l68.cloudfront.net/e7b871bd35bc00f2b1418ea6fbbd19d9959144d9/96199/blog/web-scraping-r/weather_singapore.png" width="1307" height="867" alt="Screenshot weather.gov website" srcset="
    
      https://d33wubrfki0l68.cloudfront.net/fa9afe3bf90eea5da9180685402c4664719b82d1/0896f/blog/web-scraping-r/weather_singapore_hu79e9c881b4f2af7a2e84506799a615ec_375308_500x0_resize_box_2.png 500w
    
    
      , https://d33wubrfki0l68.cloudfront.net/21c68a0ef365f1176e3cb96f1754330e56479f1c/7fd66/blog/web-scraping-r/weather_singapore_hu79e9c881b4f2af7a2e84506799a615ec_375308_800x0_resize_box_2.png 800w
    
    
      , https://d33wubrfki0l68.cloudfront.net/4fa3cae702cf3dfade140c9146e03225822fbe83/2b91e/blog/web-scraping-r/weather_singapore_hu79e9c881b4f2af7a2e84506799a615ec_375308_1200x0_resize_box_2.png 1200w
    
    " src="https://d33wubrfki0l68.cloudfront.net/e7b871bd35bc00f2b1418ea6fbbd19d9959144d9/96199/blog/web-scraping-r/weather_singapore.png">
  
</p></div>
<p>Imagine if you want to scrape information that you can only get upon clicking on the dropdowns. What would you do in that case?</p>
<p>Well, I’ll be jumping a few steps forward and will show you a preview of rvest package while scraping this page. Our goal here is to scrape data from 2016 to 2020.</p>
<div><pre><code data-lang="r"><span>library</span>(rvest)

html_form_page <span>&lt;-</span> <span>'</span><span>http://www.weather.gov.sg/climate-historical-daily'</span> <span>%&gt;%</span> <span>read_html</span>()

weatherstation_identity <span>&lt;-</span> page <span>%&gt;%</span> <span>html_nodes</span>(<span>'</span><span>button#cityname + ul a'</span>) <span>%&gt;%</span> 

  <span>html_attr</span>(<span>'</span><span>onclick'</span>) <span>%&gt;%</span>  

  <span>sub</span>(<span>"</span><span>.*'(.*)'.*"</span>, <span>'</span><span>'</span>, .)

weatherdf <span>&lt;-</span> <span>expand.grid</span>(weatherstation_identity, 

                  month <span>=</span> <span>sprintf</span>(<span>'</span><span>%02d'</span>, <span>1</span><span>:</span><span>12</span>),

                  year <span>=</span> <span>2016</span><span>:</span><span>2020</span>)
</code></pre></div><p>Let’s check what type of data have been able to scrape. Here’s what our data frame looks like:</p>
<div><pre><code data-lang="r"><span>str</span>(weatherdf)

<span>&gt;</span> <span>'</span><span>data.frame'</span><span>:</span>	<span>3780</span> obs. of  <span>3</span> variables<span>:</span>

 <span>$</span> Var1 <span>:</span> Factor w<span>/</span> <span>63</span> levels <span>"</span><span>S104"</span>,<span>"</span><span>S105"</span>,..<span>:</span> <span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>5</span> <span>6</span> <span>7</span> <span>8</span> <span>9</span> <span>10</span> <span>...</span>

 <span>$</span> month<span>:</span> Factor w<span>/</span> <span>12</span> levels <span>"</span><span>01"</span>,<span>"</span><span>02"</span>,<span>"</span><span>03"</span>,..<span>:</span> <span>1</span> <span>1</span> <span>1</span> <span>1</span> <span>1</span> <span>1</span> <span>1</span> <span>1</span> <span>1</span> <span>1</span> <span>...</span>

 <span>$</span> year <span>:</span> int  <span>2016</span> <span>2016</span> <span>2016</span> <span>2016</span> <span>2016</span> <span>2016</span> <span>2016</span> <span>2016</span> <span>2016</span> <span>2016</span> <span>...</span>

 <span>-</span> <span>attr</span>(<span>*</span>, <span>"</span><span>out.attrs"</span>)<span>=</span>List of <span>2</span>

  ..<span>$</span> dim     <span>:</span> Named num  <span>63</span> <span>12</span> <span>5</span>

  .. ..<span>-</span> <span>attr</span>(<span>*</span>, <span>"</span><span>names"</span>)<span>=</span> chr  <span>"</span><span>"</span> <span>"</span><span>month"</span> <span>"</span><span>year"</span>

  ..<span>$</span> dimnames<span>:</span>List of <span>3</span>

  .. ..<span>$</span> Var1 <span>:</span> chr  <span>"</span><span>Var1=S104"</span> <span>"</span><span>Var1=S105"</span> <span>"</span><span>Var1=S109"</span> <span>"</span><span>Var1=S86"</span> <span>...</span>

  .. ..<span>$</span> month<span>:</span> chr  <span>"</span><span>month=01"</span> <span>"</span><span>month=02"</span> <span>"</span><span>month=03"</span> <span>"</span><span>month=04"</span> <span>...</span>

  .. ..<span>$</span> year <span>:</span> chr  <span>"</span><span>year=2016"</span> <span>"</span><span>year=2017"</span> <span>"</span><span>year=2018"</span> <span>"</span><span>year=2019"</span> <span>...</span>
</code></pre></div><p>From the dataframe above, we can now easily generate URLs that provide direct access to data of our interest.</p>
<div><pre><code data-lang="r">urlPages <span>&lt;-</span> <span>paste0</span>(<span>'</span><span>http://www.weather.gov.sg/files/dailydata/DAILYDATA_'</span>, 
weatherdf<span>$</span>Var1, <span>'</span><span>_'</span>, weatherdf<span>$</span>year, weatherdf<span>$</span>month, <span>'</span><span>.csv'</span>)
</code></pre></div><p>Now, we can download those files at scale using lappy().</p>
<div><pre><code data-lang="r"><span>lapply</span>(urlPages, <span>function</span>(url){<span>download.file</span>(url, <span>basename</span>(url), method <span>=</span> <span>'</span><span>curl'</span>)})
</code></pre></div><p>Note: This is going to download a ton of data once you execute it.</p>
<h2 id="web-scraping-using-rvest">Web scraping using Rvest</h2>
<p>Inspired by libraries like BeautifulSoup, rvest is probably one of most popular packages in R that we use to scrape the web. While it is simple enough that it makes scraping with R look effortless, it is complex enough to enable any scraping operation.</p>
<p>Let’s see rvest in action now. I will scrape information from IMDB and we will scrape Sharknado (because it is the best movie in the world!) <a href="https://www.imdb.com/title/tt8031422/"></a><a href="https://www.imdb.com/title/tt8031422/">https://www.imdb.com/title/tt8031422/</a></p>
<div><pre><code data-lang="r"><span>library</span>(rvest)

sharknado <span>&lt;-</span> <span>html</span>(<span>"</span><span>[https://www.imdb.com/title/tt8031422/](https://www.imdb.com/title/tt8031422/)"</span>)
</code></pre></div><p>Awesome movie, awesome cast! Let's find out what was the cast of this movie.</p>
<div><pre><code data-lang="r">sharknado <span>%&gt;%</span>

  <span>html_nodes</span>(<span>"</span><span>table"</span>) <span>%&gt;%</span>

  .[[1]] <span>%&gt;%</span>

  <span>html_table</span>()

X1                                X2

<span>1</span>  Cast overview, first billed only<span>:</span> Cast overview, first billed only<span>:</span>

<span>2</span>                                                           Ian Ziering

<span>3</span>                                                            Tara Reid

<span>4</span>                                                     Cassandra Scerbo

<span>5</span>                                                    Judah Friedlander

<span>6</span>                                                        Vivica A. Fox

<span>7</span>                                                     Brendan Petrizzo

<span>8</span>                                                      M. Steven Felty

<span>9</span>                                                         Matie Moncea

<span>10</span>                                                            Todd Rex

<span>11</span>                                                        Debra Wilson

<span>12</span>                                                  Alaska Thunderfuck

<span>13</span>                                                 Neil deGrasse Tyson

<span>14</span>                                                       Marina Sirtis

<span>15</span>                                                         Audrey Latt

<span>16</span>                                              Ana Maria Varty Mihail
</code></pre></div><p>Awesome cast! Probably that’s why it was such a huge hit. Who knows.</p>
<p>Still, there are skeptics of Sharknado. I guess the rating would prove them wrong? Here’s how you extract ratings of Sharknado from IMDB</p>
<div><pre><code data-lang="r">sharknado <span>%&gt;%</span>

  <span>html_node</span>(<span>"</span><span>strong span"</span>) <span>%&gt;%</span>

  <span>html_text</span>() <span>%&gt;%</span>

  <span>as.numeric</span>()

[1] <span>3.5</span>
</code></pre></div><p>I still stand by my words. But I hope you get the point, right? See how easy it is for us to scrape information using rvest, while we were writing 10+ lines of code in much simpler scraping scenarios.</p>
<p>Next on our list is Rcrawler.</p>
<h2 id="web-scraping-using-rcrawler">Web Scraping using Rcrawler</h2>
<p>Rcrawler is another R package that helps us harvest information from the web. But unlike rvest, we use Rcrawler for network graph related scraping tasks a lot more. For example, if you wish to scrape a very large website, you might want to try Rcrawler in a bit more depth.</p>
<p>Note: Rcrawler is more about crawling than scraping.</p>
<p>We will go back to Wikipedia and we will try to find the date of birth, date of death and other details of scientists.</p>
<div><pre><code data-lang="r"><span>library</span>(Rcrawler)

List_of_scientists <span>&lt;-</span> <span>c</span>(<span>"</span><span>Niels Bohr"</span>, <span>"</span><span>Max Born"</span>, <span>"</span><span>Albert Einstein"</span>, <span>"</span><span>Enrico Fermi"</span>)

pages_of_interest <span>=</span> <span>paste0</span>(<span>'</span><span>https://en.wikipedia.org/wiki/Special:Search/'</span>, <span>gsub</span>(<span>"</span><span> "</span>, <span>"</span><span>_"</span>, list_of_scientists))

scientist_data <span>&lt;-</span> <span>ContentScraper</span>(Url <span>=</span> target_pages , 
        XpathPatterns <span>=</span> <span>c</span>(<span>"</span><span>//th"</span>,<span>"</span><span>//tr[(((count(preceding-sibling::*) + 1) = 5) and parent::*)]//td"</span>,<span>"</span><span>//tr[(((count(preceding-sibling::*) + 1) = 6) and parent::*)]//td"</span>),
        PatternsName <span>=</span> <span>c</span>(<span>"</span><span>scientist"</span>, <span>"</span><span>dob"</span>, <span>"</span><span>dod"</span>), 
        asDataFrame <span>=</span> <span>TRUE</span>)
</code></pre></div><p>Output looks like this:</p>
<div><pre><code data-lang="r">
<span>#    Scientist  	         dob  	                                                          dod</span>

<span>1</span>    Niels Bohr          <span>7</span> October <span>1885</span>Copenhagen, Denmark          <span>18</span> November <span>1962</span> (aged <span>77</span>)

Copenhagen, Denmark

<span>2</span>    Max Born           <span>11</span> December <span>1882</span>                                          <span>5</span> January <span>1970</span> (aged <span>87</span>)

<span>3</span>    Albert Einstein   <span>14</span> March <span>1879</span>                                                <span>18</span> April <span>1955</span>

<span>4</span>    Enrico Fermi      <span>29</span> September <span>1901</span>                                        <span>28</span> November <span>1954</span>
</code></pre></div><p>And that’s it!</p>
<p>You pretty much know everything you need to get started with Web Scraping in R.</p>
<p>Try challenging yourself with interesting use cases and uncover challenges. Scraping the web with R can be really fun!</p>

        </div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>