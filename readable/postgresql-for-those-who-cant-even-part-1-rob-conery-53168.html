<!DOCTYPE html>
<html lang="en">
<head>
    <title>
PostgreSQL For Those Who Can&#x2019;t Even, Part 1 - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="PostgreSQL For Those Who Can&#x2019;t Even, Part 1 - linksfor.dev(s)"/>
    <meta property="og:description" content="Just yesterday I was talking to a friend about Postgres (not uncommon) and he said something that I found shocking: I can&#x2019;t even with Postgres, I know JACK SQUAT This person calls themself my&#x2026;"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://rob.conery.io/2020/01/24/postgresql-for-those-who-cant-even-part-1/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">ğŸ‰</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - PostgreSQL For Those Who Can&#x2019;t Even, Part 1</title>
<div class="readable">
        <h1>PostgreSQL For Those Who Can&#x2019;t Even, Part 1</h1>
            <div>Reading time: 10-13 minutes</div>
        <div>Posted here: 06 Feb 2020</div>
        <p><a href="https://rob.conery.io/2020/01/24/postgresql-for-those-who-cant-even-part-1/">https://rob.conery.io/2020/01/24/postgresql-for-those-who-cant-even-part-1/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div><p>Just yesterday I was talking to a friend about Postgres (not uncommon) and he said something that I found <em>shocking</em>:</p>
<blockquote>
<p>I canâ€™t even with Postgres, I know JACK SQUAT</p>
</blockquote>
<p>This person calls themself my <em>friend</em> too! I just donâ€™t even know whatâ€™s real anymore.</p>
<p>So, <strong>Friendo</strong> is a Node person who enjoys using a document database. Canâ€™t blame him â€“ itâ€™s easy to setup, easy to run and you donâ€™t need to stress out about SQL and relational theory. That said, there are benefits to wrapping structure and rules around your data â€“ it <em>is</em> the lifeblood of your business after all.</p>
<p>If youâ€™re like Friendo and you want to start from the very beginning with Postgres, read on! Iâ€™ll use his questions to me for the rest of this post. He has <em>a lot</em> of questions, so Iâ€™m going to break this up into parts:</p>
<ul>
<li>Part 1 (this post) is for people whoâ€™ve never thought about a database before, let alone set one up and run a query</li>
<li>Part 2 (next post) will be for Node people wondering what/why/how they could work with Postgres</li>
</ul>
<p>I encourage you to play along if youâ€™re curious. If youâ€™re having fun and want to do more, <a href="https://bigmachine.io/products/a-curious-moon/">I wrote a really fun book</a> about Postgres and the data from the Cassini mission (which youâ€™ll see below) that youâ€™re welcome to check out too!</p>
<h2>Where is Postgres? How do I get it and run it?</h2>
<p>The easiest possible thing you can do is to run a docker image, which you can do by executing:</p>
<pre><code><span>docker</span> <span>run</span> <span>-p</span> 5432<span>:5432</span> <span>postgres</span><span>:12.1</span>
</code></pre>
<p>That will download and run a Postgres image, exposing the default Postgres port of 5432.</p>
<p>If youâ€™re not a Docker person and are on a Mac, you can also <a href="https://postgresapp.com/">head over to postgresapp.com</a> where you can download a free executable app.</p>
<h2>How do I manage it with a tool?</h2>
<p>Tooling for Postgres is both abundant and wanting. There is no clear cut answer to this question other than to offer the following options for a given context.</p>
<p><strong>Just playing around: Mac</strong>
If youâ€™re on a Mac go get yourself a free copy of <a href="https://eggerapps.at/postico/">Postico</a>. Itâ€™s easy and you can quickly connect and start playing.</p>
<p><img src="https://paper-attachments.dropbox.com/s_1FC55FF691E3C173A43C1C315DD0B563BE10884F81292ABAC9C59C8E67BDDA03_1579124251449_table-content-view.png" alt=""></p>
<p><strong>Just playing around: Windows (and Mac)</strong></p>
<p>Thereâ€™s the free <a href="https://docs.microsoft.com/en-us/sql/azure-data-studio/download-azure-data-studio?view=sql-server-ver15">Azure Data Studio</a> which uses the same interface as VS Code. There are extensions and all kinds of goodies you can download if you want as well.</p>
<p>To hook up to Postgres, make sure you grab the <a href="https://docs.microsoft.com/en-us/sql/azure-data-studio/postgres-extension?view=sql-server-ver15">Postgres extension</a>. You can install it right from the IDE by clicking on the square thingies in the bottom left of the left-most pane.</p>
<p><img src="https://paper-attachments.dropbox.com/s_1FC55FF691E3C173A43C1C315DD0B563BE10884F81292ABAC9C59C8E67BDDA03_1579124323609_image.png" alt=""></p>
<p><strong>Something substantial and youâ€™re willing to pay for it (Windows and Mac)</strong>
My go-to tool for working with Postgres is <a href="https://www.navicat.com/en/products/navicat-for-postgresql">Navicat</a>. Itâ€™s a bit on the spendy side but you can do all kinds of cool things, including reports, charting, import/export, data modeling and more. I love this thing.</p>
<p><img src="https://paper-attachments.dropbox.com/s_1FC55FF691E3C173A43C1C315DD0B563BE10884F81292ABAC9C59C8E67BDDA03_1579124634184_image.png" alt=""></p>
<p>Donâ€™t know what to choose? Just download <strong>Azure Data Studio</strong> and letâ€™s get to work!</p>
<p><strong>Our first login</strong>
Letâ€™s connect to our new shiny Postgres server. Open up Azure Data Studio and make sure you have the Postgres extension installed. Youâ€™ll know if you do because youâ€™ll see the option to connect to PostgreSQL in the connection dialog:</p>
<p><img src="https://paper-attachments.dropbox.com/s_1FC55FF691E3C173A43C1C315DD0B563BE10884F81292ABAC9C59C8E67BDDA03_1579209401730_shot_05.jpg" alt=""></p>
<p>The server name is â€œlocalhostâ€ and the Docker image comes with the login preset â€“ â€œpostgresâ€ as the user name and â€œpostgresâ€ as the password.</p>
<p>Weâ€™ll go with the default database and, finally, name our connection â€œLocal Dockerâ€. Click â€œConnectâ€ and youâ€™re good to go.</p>
<p><strong>Our first database</strong>
Most GUI tools have some way of creating a database right through the UI. Azure Data Studio doesnâ€™t (for Postgres at least) but thatâ€™s OK, weâ€™ll create one for ourselves.</p>
<p>If youâ€™ve connected already, you might be wondering â€œwhat, exactly, am I connected toâ€? Good question Friendo! Youâ€™re connected to the default database, â€œpostgresâ€:</p>
<p><img src="https://paper-attachments.dropbox.com/s_1FC55FF691E3C173A43C1C315DD0B563BE10884F81292ABAC9C59C8E67BDDA03_1579209663733_shot_06.jpg" alt=""></p>
<p>This is the admin playground, where you can do DBA stuff and feel rad. Weâ€™re going to use our connection to this database to create another one, where weâ€™re going to drop some data. To do that, we need to write a new query. Click that button that says â€œNew Queryâ€:</p>
<p><img src="https://paper-attachments.dropbox.com/s_1FC55FF691E3C173A43C1C315DD0B563BE10884F81292ABAC9C59C8E67BDDA03_1579209798287_shot_07.jpg" alt=""></p>
<p>In the new query window add the following:</p>
<pre><code><span>create</span> <span>database</span> cassini;
</code></pre>
<p>Now hit â€œF5â€ to run the query. You should see a success message like so:</p>
<p><img src="https://paper-attachments.dropbox.com/s_1FC55FF691E3C173A43C1C315DD0B563BE10884F81292ABAC9C59C8E67BDDA03_1579209996613_shot_08.jpg" alt=""></p>
<p>If you see a syntax error, check your SQL code and make sure there are no errors. Youâ€™ll also notice that nothing changed in the left information pane â€“ thereâ€™s no â€œcassiniâ€ database! What gives!</p>
<p>Ease up Friendo! Just right click on the â€œDatabasesâ€ folder and refresh â€“ you should see your new database. Once you see, double-click it and in we go!</p>
<p><strong>Our first table</strong>
Our database is going to hold some fun information from the Cassini Mission, the probe that we sent to Saturn back in 1997. All of the data generated by the project is public domain, and itâ€™s pretty fun to use <em>that data</em> rather then some silly blog posts donâ€™t ya think?</p>
<p>Thereâ€™s <a href="https://pds-atmospheres.nmsu.edu/data_and_services/atmospheres_data/Cassini/Cassini.html">a whole lot of data</a> you can download, but letâ€™s keep things reasonable and go with the â€œMaster Planâ€ â€“ the dates, times and descriptions of everything Cassini did during itâ€™s 20 year mission to Saturn. I trimmed it just a bit to bring the file size down, so if you want to play along you can <a href="https://www.dropbox.com/s/fno2olahpdoh3r7/master_plan.csv?dl=0">download the CSV from here</a>.</p>
<p><img src="https://paper-attachments.dropbox.com/s_1FC55FF691E3C173A43C1C315DD0B563BE10884F81292ABAC9C59C8E67BDDA03_1579210762545_shot_09.jpg" alt=""></p>
<p>Weâ€™ll load this gorgeous data in just one second. We have to create a table for it first! Letâ€™s do that now by opening a new query window in Azure Data Explorer (which I hope you remember how to do). Make sure youâ€™re connected to the â€œcassiniâ€ database, and then enter the following SQL:</p>
<pre><code><span>create</span> <span>table</span> master_plan(
  <span>date</span> <span>text</span>,
  team <span>text</span>,
  target <span>text</span>,
  title <span>text</span>,
  description <span>text</span>
);
</code></pre>
<p>This command will, as you might be able to guess, create a table called â€œmaster_planâ€. A few things to note:</p>
<ul>
<li>Postgres likes things in lower case and will do it for you unless you force it to do otherwise, which we wonâ€™t.</li>
<li>We donâ€™t have a primary key defined, this is intentional and youâ€™ll see why in a second.</li>
<li>There are a number of ways to store strings in Postgres, but the simplest is <code>text</code>, without a length description. This is counterintuitive for people coming from other databases who think this will take up space. It wonâ€™t, Postgres is much smarter than that.</li>
<li>Why are we storing a field called â€œdateâ€ as <code>text</code>? For a very good reason which Iâ€™ll go over in just a minute.</li>
</ul>
<p>OK, run this and we should have a table. Letâ€™s load some data!</p>
<h2>How do I load data into it?</h2>
<p>Weâ€™re going to load data directly from a CSV, which Postgres can do using the <code>COPY</code> command. For this to work properly, however, we need to be sure of a few things:</p>
<ul>
<li>We need to have the absolute path to the CSV file.</li>
<li>The structure of the file needs to match the structure of our table.</li>
<li>The data types need to match, in terms of format, the data types of our table.</li>
</ul>
<p>That last bit is the toughest part. CSV (and spreadsheets in general) tend to be a minefield of poorly chewed data-droppings, mostly because spreadsheet programs suck at enforcing data rules.</p>
<p>We have two ways to get around this: suffer the pain and correct the data when we import it or <strong>make sure all the import columns in our database table are</strong> <code>**text**</code>. The latter is the easiest because correcting the data using database queries tends to be easier than editing a CSV file, so thatâ€™s what weâ€™ll do. Also: i<em>tâ€™s a good idea not to edit the source of an import.</em></p>
<p>Right â€“ letâ€™s get to it! If youâ€™re running Docker youâ€™ll need to copy the <code>master_plan</code> CSV file into your running container. I put my file in my home directory on my host. If youâ€™ve done the same, you can use this command to copy the file into your container:</p>
<pre><code><span>docker</span> cp ~/master_plan.csv [CONTAINER ID]:master_plan.csv
</code></pre>
<p>Once itâ€™s there, you can execute the <code>COPY</code> command to push data into the <code>master_plan</code> table:</p>
<pre><code>COPY master_plan
FROM '/master_plan.csv'
WITH DELIMITER ',' HEADER CSV;
</code></pre>
<p>This command will grab the CSV file from our containerâ€™s root directory (as thatâ€™s where we copied it) and pop the data in positionally into our table. We just have to be sure that the columns align, which they do!</p>
<p>The last line specifies our delimiter (which is a comma) and that there are column headers. The final bit tells Postgres this is a CSV file.</p>
<p>Letâ€™s make sure the data is there and looks right. Right-click on the table and select â€œSelect top 1000 rowsâ€ and you should see something like this:</p>
<p><img src="https://paper-attachments.dropbox.com/s_1FC55FF691E3C173A43C1C315DD0B563BE10884F81292ABAC9C59C8E67BDDA03_1579725726323_shot_24.jpg" alt=""></p>
<p>Yay data! Before we do anything else, letâ€™s add a primary key so I donâ€™t freak out:</p>
<pre><code><span>alter</span> <span>table</span> master_plan
<span>add</span> <span>id</span> <span>serial</span> primary <span>key</span>;
</code></pre>
<p>Great! Now weâ€™re ready to connect from Node.</p>
<h2>How do I connect to it from Node?</h2>
<p>Letâ€™s keep this as simple as possible, for now. Start by creating a directory for the code weâ€™re about to write and then initializing a Node project. Feel free to use Yarn or NPM or whatever!</p>
<p>Open up a terminal and:</p>
<pre><code>mkdir pg_demo
cd pg_demo
<span>npm</span> init -y
<span>npm</span> install pg-promise
touch index.js
</code></pre>
<p>These commands should work in Powershell on Windows just fine.</p>
<p>Weâ€™ll be using the <a href="https://github.com/vitaly-t/pg-promise">promise-based Postgres driver</a> from Vitaly Tomalev called <code>pg-promise</code>, one of my favorites. The default Node driver for Postgres works with standard callbacks, and we want promises! There are also a few enhancements that Vitaly thew in which are quite nice, but Iâ€™ll leave that for you to explore.</p>
<p>The first step is to require the library and connect:</p>
<pre><code><span>const</span> pgp = <span>require</span>(<span>'pg-promise'</span>)({});
<span>const</span> db = pgp(<span>"postgres://postgres:postgres@localhost/cassini"</span>);
</code></pre>
<p>Iâ€™m connecting to Postgres using a URL-based connection string that has the format:</p>
<pre><code>postgres:
</code></pre>
<p>Since weâ€™re using Docker, our default username and password is â€œpostgresâ€. You can, of course, change that as needed.</p>
<p>Once weâ€™ve set up the connection, letâ€™s execute a query using some very simple SQL:</p>
<pre><code><span>const</span> query = <span>async</span> () =&gt; {
  <span>const</span> res = <span>await</span> db.any(<span>"select * from master_plan limit 10"</span>);
  <span>return</span> res;
}
</code></pre>
<p>Because pg-promise is promise-based, I can use the <code>async</code> and <code>await</code> keywords to run a simple query. <code>db.any</code> will return a list of results and all I need to do is to pass in a SQL string, as you see i did. I made sure to <code>limit</code> the results to 10 because I donâ€™t want all 60,000 records bounding back at me.</p>
<p>To execute the query, I call the method and handle the returned promise. Iâ€™ll pop the result out to the console:</p>
<pre><code>query().then(<span><span>res</span> =&gt;</span> {
  <span>console</span>.log(res)
})
.catch(<span><span>err</span> =&gt;</span> {
  <span>console</span>.error(err)
})
.finally(<span><span>()</span> =&gt;</span> {
  db.$pool.end()
})
</code></pre>
<p>The last line in the <code>finally</code> block closes off the default connection pool, which isnâ€™t required but the Node process wonâ€™t terminate unless you do (youâ€™ll have to ctrl-c to stop it otherwise).</p>
<p>You can run the file using <code>node index.js</code> from the terminal, and you should see something like this:</p>
<p><img src="https://paper-attachments.dropbox.com/s_1FC55FF691E3C173A43C1C315DD0B563BE10884F81292ABAC9C59C8E67BDDA03_1579728450821_shot_25.jpg" alt=""></p>
<p>Glorious data! Notice it all comes back in lovely, formatted JSON, just as we like.</p>
<p>Thereâ€™s a lot more we can do, but this post is already quite long and I think Friendo might have a few more questions for me. Iâ€™ll see if he does and Iâ€™ll follow up next time!</p>
</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>