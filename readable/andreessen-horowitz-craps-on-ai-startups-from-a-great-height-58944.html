<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Andreessen-Horowitz craps on &#x201C;AI&#x201D; startups from a great height - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Andreessen-Horowitz craps on &#x201C;AI&#x201D; startups from a great height - linksfor.dev(s)"/>
    <meta property="og:description" content="Andreessen-Horowitz has always been the most levelheaded of the major current year VC firms. While other firms were levering up on &#x201C;cleantech&#x201D; and nonsensical biotech startups that viol&#x2026;"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://scottlocklin.wordpress.com/2020/02/21/andreessen-horowitz-craps-on-ai-startups-from-a-great-height/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Andreessen-Horowitz craps on &#x201C;AI&#x201D; startups from a great height</title>
<div class="readable">
        <h1>Andreessen-Horowitz craps on &#x201C;AI&#x201D; startups from a great height</h1>
            <div>Reading time: 15-19 minutes</div>
        <div>Posted here: 24 Feb 2020</div>
        <p><a href="https://scottlocklin.wordpress.com/2020/02/21/andreessen-horowitz-craps-on-ai-startups-from-a-great-height/">https://scottlocklin.wordpress.com/2020/02/21/andreessen-horowitz-craps-on-ai-startups-from-a-great-height/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
		<p>Andreessen-Horowitz has always been the most levelheaded of the major current year VC firms. While other firms were levering up on ‚Äúcleantech‚Äù and nonsensical biotech startups that violate physical law, they quietly continued to invest in sane companies (also hot garbage bugman products like soylent).&nbsp; I assume they actually listen to people on the front lines, rather than what their VC pals are telling them. Maybe they‚Äôre just smarter than everyone else; definitely more independent minded. Their recent review on how ‚ÄúAI‚Äù differs from software company investments is absolutely brutal. I am pretty sure most people didn‚Äôt get the point, so I‚Äôll quote it emphasizing the important bits.</p>
<p><a href="https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software/">https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software/</a></p>
<p>They use all the buzzwords (my personal <em>bete-noir</em>; the term ‚ÄúAI‚Äù when they mean ‚Äúmachine learning‚Äù), but they‚Äôve finally publicly noticed certain things which are abundantly obvious to anyone who works in the field. For example, gross margins are low for deep learning startups that use ‚Äúcloud‚Äù compute. Mostly because they use cloud compute.</p>

<blockquote>
<h2><strong>Gross Margins, Part 1: Cloud infrastructure is a substantial ‚Äì and sometimes hidden ‚Äì cost for AI companies</strong>&nbsp;üè≠</h2>
<p>In the old days of on-premise software, delivering a product meant stamping out and shipping physical media ‚Äì the cost of running the software, whether on servers or desktops, was borne by the buyer. Today, with the dominance of SaaS, that cost has been pushed back to the vendor. Most software companies pay big AWS or Azure bills every month ‚Äì the more demanding the software, the higher the bill.</p>
<p>AI, it turns out, is pretty demanding:</p>
<ul>
<li><b>Training&nbsp;</b>a single AI model can cost hundreds of thousands of dollars (or&nbsp;<a href="https://twitter.com/eturner303/status/1223976313544773634">more</a>) in&nbsp;<i>compute</i>&nbsp;resources. While it‚Äôs tempting to treat this as a one-time cost, retraining is increasingly recognized as an ongoing cost, since the data that feeds AI models tends to change over time (a phenomenon known as ‚Äúdata drift‚Äù).</li>
<li><b>Model inference&nbsp;</b>(the process of generating predictions in production) is also more computationally complex than operating traditional software. Executing a long series of matrix multiplications just requires more math than, for example, reading from a database.</li>
<li>AI applications are more likely than traditional software to operate on&nbsp;<b>rich media&nbsp;</b>like images, audio, or video. These types of data consume higher than usual&nbsp;<i>storage&nbsp;</i>resources, are expensive to process, and often suffer from region of interest issues ‚Äì an application may need to process a large file to find a small, relevant snippet.</li>
<li>We‚Äôve had AI companies tell us that<b>&nbsp;cloud operations&nbsp;</b>can be more complex and costly than traditional approaches, particularly because there aren‚Äôt good tools to scale AI models globally. As a result, some AI companies have to routinely transfer trained models across cloud regions ‚Äì racking up big ingress and egress costs ‚Äì to improve reliability, latency, and compliance.</li>
</ul>
<p>Taken together, these forces contribute to the 25% or more of revenue that AI companies often spend on cloud resources. In extreme cases, startups tackling particularly complex tasks have actually found manual data processing cheaper than executing a trained model.</p></blockquote>
<p>This is something which is true of pretty much all machine learning with heavy compute and data problems. The pricing structure of ‚Äúcloud‚Äù bullshit is designed to extract maximum blood from people with heavy data or compute requirements. Cloud companies would prefer to sell the time on a piece of hardware to 5 or 10 customers. If you‚Äôre lucky enough to have a startup that runs on a few million rows worth of data and a GBM or Random Forest, it‚Äôs probably not true at all, but precious few startups are so lucky. Those who use the latest DL woo on the huge data sets they require will have huge compute bills unless they buy their own hardware. For reasons that make no sense to me, most of them don‚Äôt buy hardware.</p>
<blockquote><p>In many problem domains, exponentially more processing and data are needed to get incrementally more accuracy. This means ‚Äì as we‚Äôve <a href="https://a16z.com/2019/12/17/anyscale/">noted before</a>&nbsp;‚Äì that model complexity is growing at an incredible rate, and it‚Äôs unlikely processors will be able to keep up. Moore‚Äôs Law is not enough. (For example, the compute resources required to train state-of-the-art AI models has grown over 300,000x since 2012, while the transistor count of NVIDIA GPUs has grown only ~4x!) Distributed computing is a compelling solution to this problem, but it primarily addresses speed ‚Äì not cost.</p></blockquote>
<p>Beyond what they‚Äôre saying about the size of Deep Learning models which is doubtless true for interesting new results, admitting that the computational power of GPU chips hasn‚Äôt exactly been growing apace is something rarely heard (though more often lately). Everyone thinks Moore‚Äôs law will save us. NVIDIA actually does have obvious performance improvements that could be made, but the scale of things is such that the only way to grow significantly bigger models is by lining up more GPUs. Doing this in a ‚Äúcloud‚Äù you‚Äôre renting from a profit making company is financial suicide.</p>

<blockquote>
<h2><strong>Gross Margins, Part 2: Many AI applications rely on ‚Äúhumans in the loop‚Äù to function at a high level of accuracy üë∑</strong></h2>
<p>Human-in-the-loop systems take two forms, both of which contribute to lower gross margins for many AI startups.</p>
<p>First: training most of today‚Äôs state-of-the-art AI models involves the manual cleaning and labeling of large datasets. This process is laborious, expensive, and among the biggest barriers to more widespread adoption of AI. Plus, as we discussed above, training doesn‚Äôt end once a model is deployed. To maintain accuracy, new training data needs to be continually captured, labeled, and fed back into the system. Although techniques like drift detection and active learning can reduce the burden, anecdotal data shows that many companies spend up to 10-15% of revenue on this process ‚Äì usually not counting core engineering resources ‚Äì and suggests ongoing development work exceeds typical bug fixes and feature additions.</p>
<p>Second: for many tasks, especially those requiring greater cognitive reasoning, humans are often plugged into AI systems in real time. Social media companies, for example, employ thousands of human reviewers to augment AI-based moderation systems. Many autonomous vehicle systems include remote human operators, and most AI-based medical devices interface with physicians as joint decision makers. More and more startups are adopting this approach as the capabilities of modern AI systems are becoming better understood. A number of AI companies that planned to sell pure software products are increasingly bringing a services capability in-house and booking the associated costs.</p></blockquote>
<p>Everyone in the business knows about this. If you‚Äôre working with interesting models, even assuming the presence of infinite accurately labeled training data, the ‚Äúhuman in the loop‚Äù problem doesn‚Äôt ever completely go away. A machine learning model is generally ‚Äúman amplified.‚Äù If you need someone (or, more likely, several someone‚Äôs) making a half million bucks a year to keep your neural net producing reasonable results, you might reconsider your choices. If the thing makes human level decisions a few hundred times a year, it might be easier and cheaper for humans to make those decisions manually, using a better user interface. Better user interfaces are sorely underappreciated. Have a look at Labview, Delphi or Palantir‚Äôs offerings for examples of highly productive user interfaces.</p>

<blockquote><p>&nbsp;Since the range of possible input values is so large, each new customer deployment is likely to generate data that has never been seen before. Even customers that appear similar ‚Äì two auto manufacturers doing defect detection, for example ‚Äì may require substantially different training data, due to something as simple as the placement of video cameras on their assembly lines.</p></blockquote>

<p>Software which solves a business problem generally scales to new customers. You do some database back end grunt work, plug it in, and you‚Äôre done.&nbsp; Sometimes you have to adjust processes to fit the accepted uses of the software; or spend absurd amounts of labor adjusting the software to work with your business processes: SAP is notorious for this. Such cycles are hugely time and labor consuming. Obviously they must be worth it at least some of the time. But while SAP is notorious (to the point of <a href="https://www.computerworld.com/article/2530405/sap-project-costs-cited-in-jeweler-s-bankruptcy-filing.html">causing bankruptcy</a> in otherwise healthy companies), most people haven‚Äôt figured out that ML oriented processes almost never scale like a simpler application would. You will be confronted with the same problem as using SAP; there is a ton of work done up front; all of it custom. I‚Äôll go out on a limb and assert that most of the up front data pipelining and organizational changes which allow for it are probably more valuable than the actual machine learning piece.</p>

<blockquote><p>In the AI world, technical differentiation is harder to achieve. New model architectures are being developed mostly in open, academic settings. Reference implementations (pre-trained models) are available from open-source libraries, and model parameters can be optimized automatically. Data is the core of an AI system, but it‚Äôs often owned by customers, in the public domain, or over time becomes a commodity.</p></blockquote>
<p>That‚Äôs right; that‚Äôs why a lone wolf like me, or a <a href="http://www.win-vector.com/site/">small team</a> can do as good or better a job than some firm with 100x the head count and 100m in VC backing. I know what the strengths and weaknesses of the latest woo is. Worse than that: I know that, from a business perspective, something dumb like Naive Bayes or a linear model might solve the customer‚Äôs problem just as well as the latest gigawatt neural net atrocity. The VC backed startup might be betting on their ‚Äúspecial tool‚Äù as its moaty IP. A few percent difference on a ROC curve won‚Äôt matter if the data is hand wavey and not really labeled properly, which describes most data you‚Äôll encounter in the wild. ML is undeniably useful, but it is extremely rare that a startup have ‚Äúspecial sauce‚Äù that works 10x or 100x better than somthing you could fork in a git repo. People won‚Äôt pay a premium over in-house ad-hoc data science solutions unless it represents <strong><em>truly game changing results</em></strong>. The technology could impress the shit out of everyone else, but if it‚Äôs only getting 5% better MAPE (or whatever); it‚Äôs irrelevant. A lot of ‚ÄúAI‚Äù doesn‚Äôt really work better than a histogram via ‚Äúgroup by‚Äù query. Throwing complexity at it won‚Äôt make it better: sometimes there‚Äôs no data in your data.</p>

<p>Some good bullet points for would be ‚ÄúAI‚Äù technologists:</p>
<blockquote><p><b>Eliminate&nbsp;</b><b><i>model complexity</i></b><b>&nbsp;as much as possible.</b> We‚Äôve seen a massive difference in COGS between startups that train a unique model per customer versus those that are able to share a single model (or set of models) among all customers‚Ä¶.</p></blockquote>
<p>Nice to be able to do, but super rare. If you‚Äôve found a problem like this, you better hope you have a special, moaty solution, or a unique data set which makes it possible.</p>
<blockquote><p><b>Choose problem domains carefully ‚Äì and often narrowly ‚Äì to reduce&nbsp;</b><b><i>data complexity</i></b><b>.&nbsp;</b>Automating human labor is a fundamentally hard thing to do. Many companies are finding that the minimum viable task for AI models is narrower than they expected. &nbsp;Rather than offering general text suggestions, for instance, some teams have found success offering short suggestions in email or job postings. Companies working in the CRM space have found highly valuable niches for AI based just around updating records. There is a large class of problems, like these, that are hard for humans to perform but relatively easy for AI. They tend to involve high-scale, low-complexity tasks, such as moderation, data entry/coding, transcription, etc.</p></blockquote>
<p>This is a huge admission of ‚ÄúAI‚Äù failure. All the sugar plum fairy bullshit about ‚ÄúAI replacing jobs‚Äù evaporates in the puff of pixie dust it always was. Really, they‚Äôre talking about cheap overseas labor when lizard man fixers like Yang regurgitate the ‚ÄúAI coming for your jobs‚Äù meme; AI actually stands for ‚ÄúAlien (or) Immigrant‚Äù in this context. Yes they do hold out the possibility of ML being used in some limited domains; I agree, but the hockey stick required for VC backing, and the army of Ph.D.s required to make it work doesn‚Äôt really mix well with those limited domains, which have a limited market.</p>
<blockquote><p><b>Embrace services.</b>&nbsp;There are huge opportunities to meet the market where it stands. That may mean offering a full-stack translation service rather than translation software or running a taxi service rather than selling self-driving cars.</p></blockquote>
<p>In other words; you probably can‚Äôt build a brain in a can that can solve all kinds of problems: you‚Äôre probably going to be a consulting and services company. In case you aren‚Äôt familiar with valuations math: services companies are worth something like 2x yearly revenue; where software and ‚Äútechnology‚Äù companies are worth 10-20x revenue. That‚Äôs why the wework weasel kept trying to position his pyramid scheme as a software company. The implications here are huge: ‚ÄúAI‚Äù raises done by A16z and people who think like them are going to be at much lower valuations. If it weren‚Äôt clear enough by now, they said it again:</p>
<blockquote><p>To summarize: most AI systems today aren‚Äôt&nbsp;<i>quite</i>&nbsp;software, in the traditional sense. And AI businesses, as a result, don‚Äôt look exactly like software businesses. They involve ongoing human support and material variable costs. They often don‚Äôt scale quite as easily as we‚Äôd like. And strong defensibility ‚Äì critical to the ‚Äúbuild once / sell many times‚Äù software model ‚Äì doesn‚Äôt seem to come for free.</p>
<p>These traits make AI feel, to an extent, like a services business. Put another way: you can replace the services firm, but you can‚Äôt (completely) replace the services.</p></blockquote>
<p>I‚Äôll say it again since they did: services companies are not valued like software businesses are. VCs love software businesses; work hard up front to solve a problem, print money forever. That‚Äôs why they get the 10-20x revenues valuations. Services companies? Why would you invest in a services company? Their growth is inherently constrained by labor costs and weird addressable market issues.</p>
<p>This isn‚Äôt exactly an announcement of a new ‚ÄúAI winter,‚Äù but it‚Äôs autumn and<em> the winter is coming</em> for startups who claim to be offering world beating ‚ÄúAI‚Äù solutions. The promise of ‚ÄúAI‚Äù has always been to replace human labor and increase human power over nature. People who actually think ML is ‚ÄúAI‚Äù think the machine will just teach itself somehow; no humans needed. Yet, that‚Äôs not the financial or physical reality. The reality is, there are interesting models which can be applied to business problems by armies of well trained DBAs, data engineers, statisticians and technicians. These sorts of things are often best grown inside a large existing company to increase productivity. If the company is sclerotic, it can hire outside consultants, just as they‚Äôve always done. A16z‚Äôs portfolio reflects this. Putting aside their autonomous vehicle bets (which look like they don‚Äôt have a large ‚ÄúAI‚Äù component to them), and some health tech bets that have at least linear regression tier data science, I can only identify only <a href="https://www.shield.ai/products-all">two</a> overtly data <a href="https://sigopt.com/solution/">science related</a> startup they‚Äôve funded. They‚Äôre vastly more long crypto currency and blockchain than ‚ÄúAI.‚Äù Despite having <a href="https://www.vox.com/new-money/2016/10/5/13081058/marc-andreessen-ai-future">said otherwise</a>, their money says ‚ÄúAI‚Äù companies don‚Äôt look so hot.</p>
<p>My TLDR summary:</p>
<ol>
<li>&nbsp;Deep learning costs a lot in compute, for marginal payoffs</li>
<li>Machine learning startups generally have no moat or meaningful special sauce</li>
<li>Machine learning startups are mostly services businesses, not software businesses</li>
<li>Machine learning will be most productive inside large organizations that have data and process inefficiencies</li>
</ol>


	</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>