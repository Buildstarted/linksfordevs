<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Andreessen-Horowitz craps on &#x201C;AI&#x201D; startups from a great height - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Andreessen-Horowitz craps on &#x201C;AI&#x201D; startups from a great height - linksfor.dev(s)"/>
    <meta property="og:description" content="Andreessen-Horowitz has always been the most levelheaded of the major current year VC firms. While other firms were levering up on &#x201C;cleantech&#x201D; and nonsensical biotech startups that viol&#x2026;"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://scottlocklin.wordpress.com/2020/02/21/andreessen-horowitz-craps-on-ai-startups-from-a-great-height/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Andreessen-Horowitz craps on &#x201C;AI&#x201D; startups from a great height</title>
<div class="readable">
        <h1>Andreessen-Horowitz craps on &#x201C;AI&#x201D; startups from a great height</h1>
            <div>Reading time: 15-19 minutes</div>
        <div>Posted here: 24 Feb 2020</div>
        <p><a href="https://scottlocklin.wordpress.com/2020/02/21/andreessen-horowitz-craps-on-ai-startups-from-a-great-height/">https://scottlocklin.wordpress.com/2020/02/21/andreessen-horowitz-craps-on-ai-startups-from-a-great-height/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
		<p>Andreessen-Horowitz has always been the most levelheaded of the major current year VC firms. While other firms were levering up on â€œcleantechâ€ and nonsensical biotech startups that violate physical law, they quietly continued to invest in sane companies (also hot garbage bugman products like soylent).&nbsp; I assume they actually listen to people on the front lines, rather than what their VC pals are telling them. Maybe theyâ€™re just smarter than everyone else; definitely more independent minded. Their recent review on how â€œAIâ€ differs from software company investments is absolutely brutal. I am pretty sure most people didnâ€™t get the point, so Iâ€™ll quote it emphasizing the important bits.</p>
<p><a href="https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software/">https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software/</a></p>
<p>They use all the buzzwords (my personal <em>bete-noir</em>; the term â€œAIâ€ when they mean â€œmachine learningâ€), but theyâ€™ve finally publicly noticed certain things which are abundantly obvious to anyone who works in the field. For example, gross margins are low for deep learning startups that use â€œcloudâ€ compute. Mostly because they use cloud compute.</p>

<blockquote>
<h2><strong>Gross Margins, Part 1: Cloud infrastructure is a substantial â€“ and sometimes hidden â€“ cost for AI companies</strong>&nbsp;ğŸ­</h2>
<p>In the old days of on-premise software, delivering a product meant stamping out and shipping physical media â€“ the cost of running the software, whether on servers or desktops, was borne by the buyer. Today, with the dominance of SaaS, that cost has been pushed back to the vendor. Most software companies pay big AWS or Azure bills every month â€“ the more demanding the software, the higher the bill.</p>
<p>AI, it turns out, is pretty demanding:</p>
<ul>
<li><b>Training&nbsp;</b>a single AI model can cost hundreds of thousands of dollars (or&nbsp;<a href="https://twitter.com/eturner303/status/1223976313544773634">more</a>) in&nbsp;<i>compute</i>&nbsp;resources. While itâ€™s tempting to treat this as a one-time cost, retraining is increasingly recognized as an ongoing cost, since the data that feeds AI models tends to change over time (a phenomenon known as â€œdata driftâ€).</li>
<li><b>Model inference&nbsp;</b>(the process of generating predictions in production) is also more computationally complex than operating traditional software. Executing a long series of matrix multiplications just requires more math than, for example, reading from a database.</li>
<li>AI applications are more likely than traditional software to operate on&nbsp;<b>rich media&nbsp;</b>like images, audio, or video. These types of data consume higher than usual&nbsp;<i>storage&nbsp;</i>resources, are expensive to process, and often suffer from region of interest issues â€“ an application may need to process a large file to find a small, relevant snippet.</li>
<li>Weâ€™ve had AI companies tell us that<b>&nbsp;cloud operations&nbsp;</b>can be more complex and costly than traditional approaches, particularly because there arenâ€™t good tools to scale AI models globally. As a result, some AI companies have to routinely transfer trained models across cloud regions â€“ racking up big ingress and egress costs â€“ to improve reliability, latency, and compliance.</li>
</ul>
<p>Taken together, these forces contribute to the 25% or more of revenue that AI companies often spend on cloud resources. In extreme cases, startups tackling particularly complex tasks have actually found manual data processing cheaper than executing a trained model.</p></blockquote>
<p>This is something which is true of pretty much all machine learning with heavy compute and data problems. The pricing structure of â€œcloudâ€ bullshit is designed to extract maximum blood from people with heavy data or compute requirements. Cloud companies would prefer to sell the time on a piece of hardware to 5 or 10 customers. If youâ€™re lucky enough to have a startup that runs on a few million rows worth of data and a GBM or Random Forest, itâ€™s probably not true at all, but precious few startups are so lucky. Those who use the latest DL woo on the huge data sets they require will have huge compute bills unless they buy their own hardware. For reasons that make no sense to me, most of them donâ€™t buy hardware.</p>
<blockquote><p>In many problem domains, exponentially more processing and data are needed to get incrementally more accuracy. This means â€“ as weâ€™ve <a href="https://a16z.com/2019/12/17/anyscale/">noted before</a>&nbsp;â€“ that model complexity is growing at an incredible rate, and itâ€™s unlikely processors will be able to keep up. Mooreâ€™s Law is not enough. (For example, the compute resources required to train state-of-the-art AI models has grown over 300,000x since 2012, while the transistor count of NVIDIA GPUs has grown only ~4x!) Distributed computing is a compelling solution to this problem, but it primarily addresses speed â€“ not cost.</p></blockquote>
<p>Beyond what theyâ€™re saying about the size of Deep Learning models which is doubtless true for interesting new results, admitting that the computational power of GPU chips hasnâ€™t exactly been growing apace is something rarely heard (though more often lately). Everyone thinks Mooreâ€™s law will save us. NVIDIA actually does have obvious performance improvements that could be made, but the scale of things is such that the only way to grow significantly bigger models is by lining up more GPUs. Doing this in a â€œcloudâ€ youâ€™re renting from a profit making company is financial suicide.</p>

<blockquote>
<h2><strong>Gross Margins, Part 2: Many AI applications rely on â€œhumans in the loopâ€ to function at a high level of accuracy ğŸ‘·</strong></h2>
<p>Human-in-the-loop systems take two forms, both of which contribute to lower gross margins for many AI startups.</p>
<p>First: training most of todayâ€™s state-of-the-art AI models involves the manual cleaning and labeling of large datasets. This process is laborious, expensive, and among the biggest barriers to more widespread adoption of AI. Plus, as we discussed above, training doesnâ€™t end once a model is deployed. To maintain accuracy, new training data needs to be continually captured, labeled, and fed back into the system. Although techniques like drift detection and active learning can reduce the burden, anecdotal data shows that many companies spend up to 10-15% of revenue on this process â€“ usually not counting core engineering resources â€“ and suggests ongoing development work exceeds typical bug fixes and feature additions.</p>
<p>Second: for many tasks, especially those requiring greater cognitive reasoning, humans are often plugged into AI systems in real time. Social media companies, for example, employ thousands of human reviewers to augment AI-based moderation systems. Many autonomous vehicle systems include remote human operators, and most AI-based medical devices interface with physicians as joint decision makers. More and more startups are adopting this approach as the capabilities of modern AI systems are becoming better understood. A number of AI companies that planned to sell pure software products are increasingly bringing a services capability in-house and booking the associated costs.</p></blockquote>
<p>Everyone in the business knows about this. If youâ€™re working with interesting models, even assuming the presence of infinite accurately labeled training data, the â€œhuman in the loopâ€ problem doesnâ€™t ever completely go away. A machine learning model is generally â€œman amplified.â€ If you need someone (or, more likely, several someoneâ€™s) making a half million bucks a year to keep your neural net producing reasonable results, you might reconsider your choices. If the thing makes human level decisions a few hundred times a year, it might be easier and cheaper for humans to make those decisions manually, using a better user interface. Better user interfaces are sorely underappreciated. Have a look at Labview, Delphi or Palantirâ€™s offerings for examples of highly productive user interfaces.</p>

<blockquote><p>&nbsp;Since the range of possible input values is so large, each new customer deployment is likely to generate data that has never been seen before. Even customers that appear similar â€“ two auto manufacturers doing defect detection, for example â€“ may require substantially different training data, due to something as simple as the placement of video cameras on their assembly lines.</p></blockquote>

<p>Software which solves a business problem generally scales to new customers. You do some database back end grunt work, plug it in, and youâ€™re done.&nbsp; Sometimes you have to adjust processes to fit the accepted uses of the software; or spend absurd amounts of labor adjusting the software to work with your business processes: SAP is notorious for this. Such cycles are hugely time and labor consuming. Obviously they must be worth it at least some of the time. But while SAP is notorious (to the point of <a href="https://www.computerworld.com/article/2530405/sap-project-costs-cited-in-jeweler-s-bankruptcy-filing.html">causing bankruptcy</a> in otherwise healthy companies), most people havenâ€™t figured out that ML oriented processes almost never scale like a simpler application would. You will be confronted with the same problem as using SAP; there is a ton of work done up front; all of it custom. Iâ€™ll go out on a limb and assert that most of the up front data pipelining and organizational changes which allow for it are probably more valuable than the actual machine learning piece.</p>

<blockquote><p>In the AI world, technical differentiation is harder to achieve. New model architectures are being developed mostly in open, academic settings. Reference implementations (pre-trained models) are available from open-source libraries, and model parameters can be optimized automatically. Data is the core of an AI system, but itâ€™s often owned by customers, in the public domain, or over time becomes a commodity.</p></blockquote>
<p>Thatâ€™s right; thatâ€™s why a lone wolf like me, or a <a href="http://www.win-vector.com/site/">small team</a> can do as good or better a job than some firm with 100x the head count and 100m in VC backing. I know what the strengths and weaknesses of the latest woo is. Worse than that: I know that, from a business perspective, something dumb like Naive Bayes or a linear model might solve the customerâ€™s problem just as well as the latest gigawatt neural net atrocity. The VC backed startup might be betting on their â€œspecial toolâ€ as its moaty IP. A few percent difference on a ROC curve wonâ€™t matter if the data is hand wavey and not really labeled properly, which describes most data youâ€™ll encounter in the wild. ML is undeniably useful, but it is extremely rare that a startup have â€œspecial sauceâ€ that works 10x or 100x better than somthing you could fork in a git repo. People wonâ€™t pay a premium over in-house ad-hoc data science solutions unless it represents <strong><em>truly game changing results</em></strong>. The technology could impress the shit out of everyone else, but if itâ€™s only getting 5% better MAPE (or whatever); itâ€™s irrelevant. A lot of â€œAIâ€ doesnâ€™t really work better than a histogram via â€œgroup byâ€ query. Throwing complexity at it wonâ€™t make it better: sometimes thereâ€™s no data in your data.</p>

<p>Some good bullet points for would be â€œAIâ€ technologists:</p>
<blockquote><p><b>Eliminate&nbsp;</b><b><i>model complexity</i></b><b>&nbsp;as much as possible.</b> Weâ€™ve seen a massive difference in COGS between startups that train a unique model per customer versus those that are able to share a single model (or set of models) among all customersâ€¦.</p></blockquote>
<p>Nice to be able to do, but super rare. If youâ€™ve found a problem like this, you better hope you have a special, moaty solution, or a unique data set which makes it possible.</p>
<blockquote><p><b>Choose problem domains carefully â€“ and often narrowly â€“ to reduce&nbsp;</b><b><i>data complexity</i></b><b>.&nbsp;</b>Automating human labor is a fundamentally hard thing to do. Many companies are finding that the minimum viable task for AI models is narrower than they expected. &nbsp;Rather than offering general text suggestions, for instance, some teams have found success offering short suggestions in email or job postings. Companies working in the CRM space have found highly valuable niches for AI based just around updating records. There is a large class of problems, like these, that are hard for humans to perform but relatively easy for AI. They tend to involve high-scale, low-complexity tasks, such as moderation, data entry/coding, transcription, etc.</p></blockquote>
<p>This is a huge admission of â€œAIâ€ failure. All the sugar plum fairy bullshit about â€œAI replacing jobsâ€ evaporates in the puff of pixie dust it always was. Really, theyâ€™re talking about cheap overseas labor when lizard man fixers like Yang regurgitate the â€œAI coming for your jobsâ€ meme; AI actually stands for â€œAlien (or) Immigrantâ€ in this context. Yes they do hold out the possibility of ML being used in some limited domains; I agree, but the hockey stick required for VC backing, and the army of Ph.D.s required to make it work doesnâ€™t really mix well with those limited domains, which have a limited market.</p>
<blockquote><p><b>Embrace services.</b>&nbsp;There are huge opportunities to meet the market where it stands. That may mean offering a full-stack translation service rather than translation software or running a taxi service rather than selling self-driving cars.</p></blockquote>
<p>In other words; you probably canâ€™t build a brain in a can that can solve all kinds of problems: youâ€™re probably going to be a consulting and services company. In case you arenâ€™t familiar with valuations math: services companies are worth something like 2x yearly revenue; where software and â€œtechnologyâ€ companies are worth 10-20x revenue. Thatâ€™s why the wework weasel kept trying to position his pyramid scheme as a software company. The implications here are huge: â€œAIâ€ raises done by A16z and people who think like them are going to be at much lower valuations. If it werenâ€™t clear enough by now, they said it again:</p>
<blockquote><p>To summarize: most AI systems today arenâ€™t&nbsp;<i>quite</i>&nbsp;software, in the traditional sense. And AI businesses, as a result, donâ€™t look exactly like software businesses. They involve ongoing human support and material variable costs. They often donâ€™t scale quite as easily as weâ€™d like. And strong defensibility â€“ critical to the â€œbuild once / sell many timesâ€ software model â€“ doesnâ€™t seem to come for free.</p>
<p>These traits make AI feel, to an extent, like a services business. Put another way: you can replace the services firm, but you canâ€™t (completely) replace the services.</p></blockquote>
<p>Iâ€™ll say it again since they did: services companies are not valued like software businesses are. VCs love software businesses; work hard up front to solve a problem, print money forever. Thatâ€™s why they get the 10-20x revenues valuations. Services companies? Why would you invest in a services company? Their growth is inherently constrained by labor costs and weird addressable market issues.</p>
<p>This isnâ€™t exactly an announcement of a new â€œAI winter,â€ but itâ€™s autumn and<em> the winter is coming</em> for startups who claim to be offering world beating â€œAIâ€ solutions. The promise of â€œAIâ€ has always been to replace human labor and increase human power over nature. People who actually think ML is â€œAIâ€ think the machine will just teach itself somehow; no humans needed. Yet, thatâ€™s not the financial or physical reality. The reality is, there are interesting models which can be applied to business problems by armies of well trained DBAs, data engineers, statisticians and technicians. These sorts of things are often best grown inside a large existing company to increase productivity. If the company is sclerotic, it can hire outside consultants, just as theyâ€™ve always done. A16zâ€™s portfolio reflects this. Putting aside their autonomous vehicle bets (which look like they donâ€™t have a large â€œAIâ€ component to them), and some health tech bets that have at least linear regression tier data science, I can only identify only <a href="https://www.shield.ai/products-all">two</a> overtly data <a href="https://sigopt.com/solution/">science related</a> startup theyâ€™ve funded. Theyâ€™re vastly more long crypto currency and blockchain than â€œAI.â€ Despite having <a href="https://www.vox.com/new-money/2016/10/5/13081058/marc-andreessen-ai-future">said otherwise</a>, their money says â€œAIâ€ companies donâ€™t look so hot.</p>
<p>My TLDR summary:</p>
<ol>
<li>&nbsp;Deep learning costs a lot in compute, for marginal payoffs</li>
<li>Machine learning startups generally have no moat or meaningful special sauce</li>
<li>Machine learning startups are mostly services businesses, not software businesses</li>
<li>Machine learning will be most productive inside large organizations that have data and process inefficiencies</li>
</ol>


	</div></div></div>
    </div>
    <footer>
        <div>created by <a href="https://buildstarted.com">buildstarted</a> &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>