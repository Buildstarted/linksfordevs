<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Depth Precision Visualized &#x2013; Nathan Reed&#x2019;s coding blog -
linksfor.dev(s)
    </title>
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta charset="utf-8">
    <meta name="Description" content="A curated source of links that devs might find interesting. Updated around the clock." />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        
<div class="readable">
    <div id="readOverlay" class="style-ebook" xmlns=""><div id="readInner" class="margin-medium size-medium"><h1>Depth Precision Visualized – Nathan Reed’s coding blog</h1><div><div id="" class=""><header xmlns="http://www.w3.org/1999/xhtml"><p>July 3, 2015 · <a href="/blog/category/graphics/">Graphics</a>, <a href="/blog/category/gpu/">GPU</a>, <a href="/blog/category/math/">Math</a> · <a href="/blog/depth-precision-visualized/#comments" class="disqus-comment-count" data-disqus-identifier="/blog/depth-precision-visualized/">Comments</a></p></header><p xmlns="http://www.w3.org/1999/xhtml">Depth precision is a pain in the ass that every graphics programmer has to struggle with sooner or
later.  Many articles and papers have been written on the topic, and a variety of different depth
buffer formats and setups are found across different games, engines, and devices.</p><p xmlns="http://www.w3.org/1999/xhtml">Because of the way it interacts with perspective projection, GPU hardware depth mapping is a little
recondite and studying the equations may not make things immediately obvious.  To get an intuition
for how it works, it’s helpful to draw some pictures.</p><p xmlns="http://www.w3.org/1999/xhtml">This article has three main parts.  In the first part, I try to provide some motivation for nonlinear
depth mapping.  Second, I present some diagrams to help understand how nonlinear depth mapping works
in different situations, intuitively and visually.  The third part is a discussion and reproduction
of the main results of <a href="http://www.geometry.caltech.edu/pubs/UD12.pdf">Tightening the Precision of Perspective Rendering</a>
by Paul Upchurch and Mathieu Desbrun (2012), concerning the effects of floating-point roundoff error
on depth precision.</p><p xmlns="http://www.w3.org/1999/xhtml">GPU hardware depth buffers don’t typically store a linear representation of the distance an object
lies in front of the camera, contrary to what one might naïvely expect when encountering this for
the first time.  Instead, the depth buffer stores a value proportional to the reciprocal of world-space
depth.  I want to briefly motivate this convention.</p><p xmlns="http://www.w3.org/1999/xhtml">In this article, I’ll use $d$ to represent the value stored in the depth buffer (in [0, 1]), and
$z$ to represent world-space depth, i.e. distance along the view axis, in world units such
as meters.  In general, the relationship between them is of the form
$$
    d = a \frac{1}{z} + b
$$
where $a, b$ are constants related to the near and far plane settings.  In other words, $d$ is
always some linear remapping of $1/z$.</p><p xmlns="http://www.w3.org/1999/xhtml">On the face of it, you can imagine taking $d$ to be any function of $z$ you like.  So why this
particular choice?  There are two main reasons.</p><p xmlns="http://www.w3.org/1999/xhtml">First, $1/z$ fits naturally into the framework of perspective projections.  This is the most
general class of transformation that is guaranteed to preserve straight lines—which makes it
convenient for hardware rasterization, since straight edges of triangles stay straight in screen
space.  We can generate linear remappings of $1/z$ by taking advantage of the perspective divide
that the hardware already performs:
$$
    \begin{bmatrix}\cdot \\ \cdot \\ z_c \\ w_c \end{bmatrix} =
    \begin{bmatrix}
        \cdot &amp;&amp;&amp; \\
        &amp; \cdot &amp;&amp; \\
        &amp;&amp; b &amp; a \\
        &amp;&amp; 1 &amp; 0 \\
    \end{bmatrix}
    \begin{bmatrix}\cdot \\ \cdot \\ z \\ 1 \end{bmatrix},
    \qquad
    \begin{aligned}
        d &amp;\equiv \frac{z_c}{w_c} \\
          &amp;= \frac{a + bz}{z} \\
          &amp;= a \frac{1}{z} + b \\
    \end{aligned}
$$
The real power in this approach, of course, is that the projection matrix can be multiplied with
other matrices, allowing you to combine many transformation stages together in one.</p><p xmlns="http://www.w3.org/1999/xhtml">The second reason is that $1/z$ is linear in screen space, <a href="http://www.humus.name/index.php?ID=255">as noted by Emil Persson</a>.
So it’s easy to interpolate $d$ across a triangle while rasterizing, and
things like hierarchical Z-buffers, early Z-culling, and depth buffer compression are all a lot
easier to do.</p><p xmlns="http://www.w3.org/1999/xhtml">Equations are hard; let’s look at some pictures!</p><p xmlns="http://www.w3.org/1999/xhtml"><img alt="Standard depth mapping" src="01-standard-with-lines.png" title="Standard depth mapping"></p><p xmlns="http://www.w3.org/1999/xhtml">The way to read these graphs is left to right, then down to the bottom.  Start with $d$, plotted
on the left axis.  Because $d$ can be an arbitrary linear remapping of $1/z$, we can place 0 and
1 wherever we wish on this axis.  The tick marks indicate distinct depth buffer values.  For
illustrative purposes, I’m simulating a 4-bit normalized integer depth buffer, so there are 16
evenly-spaced tick marks.</p><p xmlns="http://www.w3.org/1999/xhtml">Trace the tick marks horizontally to where they hit the $1/z$ curve, then down to the bottom axis.
That’s where the distinct values fall in the world-space depth range.</p><p xmlns="http://www.w3.org/1999/xhtml">The graph above shows the “standard”, vanilla depth mapping used in D3D and similar APIs.  You
can immediately see how the $1/z$ curve leads to bunching up values close to the near plane, and
the values close to the far plane are quite spread out.</p><p xmlns="http://www.w3.org/1999/xhtml">It’s also easy to see why the near plane has such a profound effect on depth precision.  Pulling in
the near plane will make the $d$ range skyrocket up toward the asymptote of the $1/z$ curve, leading
to an even more lopsided distribution of values:</p><p xmlns="http://www.w3.org/1999/xhtml"><img alt="Too near. A little too near!" src="02-a-little-too-near.png" title="Too near. A little too near!"></p><p xmlns="http://www.w3.org/1999/xhtml">Similarly, it’s easy to see in this context why pushing the far plane all the way out to infinity
doesn’t have that much effect.  It just means extending the $d$ range slightly down to $1/z = 0$:</p><p xmlns="http://www.w3.org/1999/xhtml"><img alt="Infinite far plane" src="03-infinite-far-plane.png" title="Infinite far plane"></p><p xmlns="http://www.w3.org/1999/xhtml">What about floating-point depth?  The following graph adds tick marks corresponding to a simulated
float format with 3 exponent bits and 3 mantissa bits:</p><p xmlns="http://www.w3.org/1999/xhtml"><img alt="Floating-point depth buffer" src="04-fp.png" title="Floating-point depth buffer"></p><p xmlns="http://www.w3.org/1999/xhtml">There are now 40 distinct values in [0, 1]—quite a bit more than the 16 values previously, but
most of them are uselessly bunched up at the near plane where we didn’t really need more precision.</p><p xmlns="http://www.w3.org/1999/xhtml">A now-widely-known trick is to reverse the depth range, mapping the near plane to $d = 1$ and the
far plane to $d = 0$:</p><p xmlns="http://www.w3.org/1999/xhtml"><img alt="Reversed-Z depth buffer" src="05-fp-reversed.png" title="Reversed-Z depth buffer"></p><p xmlns="http://www.w3.org/1999/xhtml">Much better!  Now the quasi-logarithmic distribution of floating-point somewhat cancels the $1/z$
nonlinearity, giving us similar precision at the near plane to an integer depth buffer, and vastly
improved precision everywhere else.  The precision worsens only very slowly as you move farther out.</p><p xmlns="http://www.w3.org/1999/xhtml">The reversed-Z trick has probably been independently reinvented several times, but goes at least
as far back as <a href="https://dl.acm.org/citation.cfm?id=311579">a SIGGRAPH ‘99 paper</a> by
Eugene Lapidous and Guofang Jiao (no open-access link available, unfortunately).  It was more recently
re-popularized in blog posts by <a href="https://mynameismjp.wordpress.com/2010/03/22/attack-of-the-depth-buffer/">Matt Pettineo</a>
and <a href="http://outerra.blogspot.com/2012/11/maximizing-depth-buffer-range-and.html">Brano Kemen</a>,
and by Emil Persson’s <a href="http://www.humus.name/Articles/Persson_CreatingVastGameWorlds.pdf">Creating Vast Game Worlds</a>
SIGGRAPH 2012 talk.</p><p xmlns="http://www.w3.org/1999/xhtml">All the previous diagrams assumed [0, 1] as the post-projection depth range, which is the D3D
convention.  What about OpenGL?</p><p xmlns="http://www.w3.org/1999/xhtml"><img alt="Floating-point with OpenGL-style [−1, 1] depth range" src="07-fp-opengl-style.png" title="Floating-point with OpenGL-style [−1, 1] depth range"></p><p xmlns="http://www.w3.org/1999/xhtml">OpenGL by default assumes a [−1, 1] post-projection depth range.  This doesn’t make a difference for integer formats, but with
floating-point, all the precision is stuck uselessly in the middle.  (The value gets mapped into
[0, 1] for storage in the depth buffer later, but that doesn’t help, since the initial mapping to
[−1, 1] has already destroyed all the precision in the far half of the range.)  And by symmetry, the
reversed-Z trick will not do anything here.</p><p xmlns="http://www.w3.org/1999/xhtml">Fortunately, in desktop OpenGL you can fix this with the widely-supported <a href="https://www.opengl.org/registry/specs/ARB/clip_control.txt">ARB_clip_control</a>
extension (now also core in OpenGL 4.5 as <a href="http://docs.gl/gl4/glClipControl"><code>glClipControl</code></a>).
Unfortunately, in GL ES you’re out of luck.</p><p xmlns="http://www.w3.org/1999/xhtml">The $1/z$ mapping and the choice of float versus integer depth buffer are a big part of the precision
story, but not all of it.  Even if you have enough depth precision to represent the scene
you’re trying to render, it’s easy to end up with your precision controlled by error in the
arithmetic of the vertex transformation process.</p><p xmlns="http://www.w3.org/1999/xhtml">As mentioned earlier, <a href="http://www.geometry.caltech.edu/pubs/UD12.pdf">Upchurch and Desbrun</a>
studied this and came up with two main recommendations to minimize roundoff error:</p><ol xmlns="http://www.w3.org/1999/xhtml"><li>Use an infinite far plane.</li><li>Keep the projection matrix separate from other matrices, and apply it in a separate operation
in the vertex shader, rather than composing it into the view matrix.</li></ol><p xmlns="http://www.w3.org/1999/xhtml">Upchurch and Desbrun came up with these recommendations through an analytical technique, based on
treating roundoff errors as small random perturbations introduced at each arithmetic operation, and
keeping track of them to first order through the transformation process.  I decided to check the
results using direct simulation.</p><p xmlns="http://www.w3.org/1999/xhtml">My <a href="https://gist.github.com/Reedbeta/ae437a9acb5dc137eabf">source code is here</a>—Python 3.4 with numpy.  It works
by generating a sequence of random points, ordered by depth, spaced either linearly or logarithmically
between the near and far planes.  Then it passes the points through view and projection matrices and
the perspective divide, using 32-bit float precision throughout, and optionally quantizes the final result
to 24-bit integer.  Finally, it runs through the sequence and counts how many times two
adjacent points (which originally had distinct depths) have either become indistiguishable
because they mapped to the same depth value, or have actually swapped order.  In other words, it
measures the rate at which depth comparison errors occur—which corresponds to issues like
Z-fighting—under different scenarios.</p><p xmlns="http://www.w3.org/1999/xhtml">Here are the results obtained for near = 0.1, far = 10K, with 10K linearly spaced depths.  (I tried
logarithmic depth spacing and other near/far ratios as well, and while the detailed numbers varied,
the general trends in the results were the same.)</p><p xmlns="http://www.w3.org/1999/xhtml">In the table, “indist” means indistinguishable (two nearby depths mapped to the same final depth
buffer value), and “swap” means that two nearby depths swapped order.</p><table xmlns="http://www.w3.org/1999/xhtml"><thead><tr><th></th><th colspan="2">Precomposed view-<br>projection matrix</th><th colspan="2">Separate view and<br>projection matrices</th></tr><tr><th></th><th>float32</th><th>int24</th><th>float32</th><th>int24</th></tr></thead><tbody><tr><th>Unaltered Z values<br>(control test)</th><td>0% indist<br>0% swap</td><td>0% indist<br>0% swap</td><td>0% indist<br>0% swap</td><td>0% indist<br>0% swap</td></tr><tr><th>Standard projection</th><td>45% indist<br>18% swap</td><td>45% indist<br>18% swap</td><td>77% indist<br>0% swap</td><td>77% indist<br>0% swap</td></tr><tr><th>Infinite far plane</th><td>45% indist<br>18% swap</td><td>45% indist<br>18% swap</td><td>76% indist<br>0% swap</td><td>76% indist<br>0% swap</td></tr><tr><th>Reversed Z</th><td>0% indist<br>0% swap</td><td>76% indist<br>0% swap</td><td>0% indist<br>0% swap</td><td>76% indist<br>0% swap</td></tr><tr><th>Infinite + reversed-Z</th><td>0% indist<br>0% swap</td><td>76% indist<br>0% swap</td><td>0% indist<br>0% swap</td><td>76% indist<br>0% swap</td></tr><tr><th>GL-style standard</th><td>56% indist<br>12% swap</td><td>56% indist<br>12% swap</td><td>77% indist<br>0% swap</td><td>77% indist<br>0% swap</td></tr><tr><th>GL-style infinite</th><td>59% indist<br>10% swap</td><td>59% indist<br>10% swap</td><td>77% indist<br>0% swap</td><td>77% indist<br>0% swap</td></tr></tbody></table><p xmlns="http://www.w3.org/1999/xhtml">Apologies for not graphing these, but there are too many dimensions to make it easy to graph!
In any case, looking at the numbers, a few general results are clear.</p><ul xmlns="http://www.w3.org/1999/xhtml"><li>There is no difference between float and integer depth buffers in most setups.  The arithmetic
    error swamps the quantization error.  In part this is because float32 and int24 have almost the
    same-sized ulp in [0.5, 1] (because float32 has a 23-bit mantissa), so there actually is
    almost no additional quantization error over the vast majority of the depth range.</li><li>In many cases, separating the view and projection matrices (following Upchurch and Desbrun’s
    recommendation) does make some improvement.  While it doesn’t lower the overall error rate, it
    does seem to turn swaps into indistinguishables, which is a step in the right direction.</li><li>An infinite far plane makes only a miniscule difference in error rates.  Upchurch and Desbrun
    predicted a 25% reduction in absolute <em>numerical</em> error, but it doesn’t seem to translate
    into a reduced rate of <em>comparison</em> errors.</li></ul><p xmlns="http://www.w3.org/1999/xhtml">The above points are practically irrelevant, though, because the real result that matters here is:
<strong>the reversed-Z mapping is basically magic</strong>. Check it out:</p><ul xmlns="http://www.w3.org/1999/xhtml"><li>Reversed-Z with a float depth buffer gives a <em>zero error rate</em> in this test.  Now, of
    course you can make it generate some errors if you keep tightening the spacing of the input
    depth values.  Still, reversed-Z with float is ridiculously more accurate than any of the other options.</li><li>Reversed-Z with an integer depth buffer is as good as any of the other integer options.</li><li>Reversed-Z erases the distinctions between precomposed versus separate view/projection matrices,
    and finite versus infinite far planes.  In other words, with reversed-Z you can compose your
    projection matrix with other matrices, and you can use whichever far plane you like, without
    affecting precision at all.</li></ul><p xmlns="http://www.w3.org/1999/xhtml">I think the conclusion here is clear.  In any perspective projection situation, just use a
floating-point depth buffer with reversed-Z!  And if you can’t use a floating-point depth buffer,
you should still use reversed-Z.  It isn’t a panacea for all precision woes, especially if you’re
building an open-world environment that contains extreme depth ranges.  But it’s a great start.</p><footer xmlns="http://www.w3.org/1999/xhtml"><hr></footer></div></div></div></div>
</div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script>
        (function () {
            var COLLECT_URL = "https://dna.buildstarted.com/t";
            var SITE_ID = "linksfor.devs";
            var GLOBAL_VAR_NAME = "__DNA__";

            window[GLOBAL_VAR_NAME] = {};

            window[GLOBAL_VAR_NAME].sendPageView = function () {
                var path = location.pathname;
                var referrer = document.referrer;

                var url = COLLECT_URL + "?siteid=" + SITE_ID + "&p=" + encodeURIComponent(path) + "&r=" + encodeURIComponent(referrer);

                try { fetch(url, { method: "GET" }); } catch (e) { }
            };

            window[GLOBAL_VAR_NAME].sendPageView();
        })();
    </script>
</body>
</html>