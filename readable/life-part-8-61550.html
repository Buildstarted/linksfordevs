<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Life, part 8 - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Life, part 8 - linksfor.dev(s)"/>
    <meta property="og:description" content="Last time on FAIC we took a look at Scholes&#x2019; extremely concise Life algorithm, which treats a grid as an array that you can treat as a mathematical value with some unusual but entirely straig&#x2026;"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://ericlippert.com/2020/05/11/life-part-8/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
	<div class="devring" style="background: #222">
		<div class="grid">
			<div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
				<span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
				<a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
				<a href="https://devring.club/random" class="devring-random">Random</a>
				<a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
			</div>
		</div>
	</div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Life, part 8</title>
<div class="readable">
        <h1>Life, part 8</h1>
            <div>Reading time: 6-7 minutes</div>
        <div>Posted here: 11 May 2020</div>
        <p><a href="https://ericlippert.com/2020/05/11/life-part-8/">https://ericlippert.com/2020/05/11/life-part-8/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
		<p data-adtags-visited="true"><a href="https://ericlippert.com/2020/05/07/life-part-7/">Last time on FAIC</a> we took a look at Scholes’ extremely concise Life algorithm, which treats a grid as an array that you can treat as a mathematical value with some unusual but entirely straightforward manipulations. We didn’t get the same concision in C# as you would in APL, but I’m OK with that.</p>
<p data-adtags-visited="true">I won’t go through the same level of detail discussing the asymptotic performance of this algorithm as I did for the naïve algorithm. If we have n cells in the array then we do eight array manipulations, each of which allocates an array of size n and fills it in; each of these operations will be O(n). Similarly, the “Where” and “or” operations are O(n), and so the whole thing is O(n).</p>
<p data-adtags-visited="true">This shouldn’t be a surprise; this is in many ways just the naïve algorithm again! We do almost exactly the same work — we compute the sum of the living neighbors of every single cell, and set the new cell state based on that sum and each cell’s current state. We just do the operations in a slightly different order.</p>
<p data-adtags-visited="true">What about actual time and memory performance?</p>
<p data-adtags-visited="true">Plainly this algorithm as I have implemented it takes more temporary memory; it allocates <em>thirteen</em> arrays as it goes, and those arrays are then garbage that needs to be collected. The optimized version of the naive algorithm allocates only two arrays and it keeps both of them alive, so neither becomes garbage.</p>
<p data-adtags-visited="true">The garbage is at least short-lived and so will be collected quickly. But in my example of an 8-quad (256×256) byte array, we get in under the limit for allocation on the Large Object Heap. Things might be different if we moved up to a 9-quad because then all these temporary arrays would be large objects, and the GC assumes that large objects live longer. I haven’t tried it out to see what the impact is.</p>
<p data-adtags-visited="true">What about time?</p>
<p data-adtags-visited="true">As I said in a previous episode, when I make a performance prediction I am on average dead wrong maybe a third of the time. We saw that on my machine, after some small amount of very straightforward performance tuning the naïve algorithm took about 4 seconds to do 5000 ticks of an 8-quad; my prediction was that since Scholes’ algorithm is doing all the same amount of work, and allocating 13 temporary arrays as it goes, that it would be around the same but slightly slower due to all the copying.</p>
<p data-adtags-visited="true">Imagine my astonishment then when I discovered that my implementation of Scholes algorithm without any perf work at all took<strong> 3.25 seconds</strong> to do the same problem. Nearly 20% faster! I must confess, I do not know what is going on here, but I do know that those array copy steps are extremely fast. Unfortunately I do not have the time right now do to a detailed perf analysis to figure out what is going on here; if anyone has insights, please leave a comment.</p>
<p data-adtags-visited="true">Let me finish up this episode with three additional thoughts:</p>
<hr>
<p data-adtags-visited="true">First, I noted last time that the algorithm I implemented is inspired by Scholes’ APL algorithm but is not exactly the same. How is it different?</p>
<p data-adtags-visited="true">The big thing is that my “array shift” operations are different than the array “rotations” used in the APL algorithm. That is, my “shift left” would transform an array like this:</p>
<pre>1 2 3                      2 3 0
4 5 6  --shift left-&gt;      5 6 0
7 8 9                      8 9 0</pre>
<p data-adtags-visited="true">Whereas I believe — any APL aficionados reading this please confirm or deny — that the APL rotation is:</p>
<pre>1 2 3                      2 3 1
4 5 6  --rotate left-&gt;     5 6 4
7 8 9                      8 9 7</pre>
<p data-adtags-visited="true">And similarly for shifting right, up and down.</p>
<p data-adtags-visited="true">I mentioned several episodes back that a standard technique for implementing Life algorithms is to make the edges of a finite grid “wrap around”, effectively making the board a torus. That’s what this algorithm does if you use this array rotation, and if you watch the video I linked in the previous episode you will see that in fact the given code implements wrap-around Life.</p>
<hr>
<p data-adtags-visited="true">Second, I implemented the byte block data type in the least sophisticated manner possible: allocate an array on every operation. There are other ways to store data to make the sorts of operations we’re doing involve fewer array copies, and those could possibly reduce the time and memory consumption further. If you are clever (and the arrays are immutable) then you can instead of making a copy, instead just keep the original array and do a little extra math on every array read.</p>
<p data-adtags-visited="true">Though it would be interesting to know how much of an improvement (or regression!) those kinds of optimizations would achieve, I don’t want to spend too much time digging into this one algorithm. If anyone wants to do the experiment, please do and report back.</p>
<hr>
<p data-adtags-visited="true">Third, one of the themes of this series that is emerging is that there are two basic ways to attack a performance problem:</p>
<ul>
<li>Keep the algorithm basically the same but find a <em>marginally</em> faster way to implement it. For instance: avoid array bounds checks by using unsafe pointer arithmetic, or throw specialized libraries or hardware at the problem. This does not improve asymptotic performance or scalability but it can lead to small or large wins in raw performance on problems of a specific size.</li>
<li>Find some characteristic of the specific problem under investigation that enables us to come up with a new algorithm that does less work or uses less space or has less GC burden. This often gives us an improvement in asymptotic performance, and therefore changes how we can scale up to larger problems.</li>
</ul>
<p data-adtags-visited="true">So far we’ve been concentrating entirely on the first family of techniques; we will get to the second soon!</p>
<p data-adtags-visited="true">I intended in this episode to talk a bit about the “use specialized hardware to attack the problem” technique, but I think this episode is long enough for today, so let’s pick up there next time.</p>
<p data-adtags-visited="true"><strong>Next time on FAIC:&nbsp; </strong>I’ll present an implementation submitted by a reader that uses specialized hardware instructions to implement Scholes’ algorithm on a 4-quad.</p>
			
			
						</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
		<div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>