<!DOCTYPE html>
<html lang="en">
<head>
    <title>
TensorFlow, Keras and deep learning, without a PhD - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="TensorFlow, Keras and deep learning, without a PhD - linksfor.dev(s)"/>
    <meta property="og:description" content="We will first watch a neural network train. Please open the notebook below and run through all the cells. Do not pay attention to the code yet, we will start explaining it later."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - TensorFlow, Keras and deep learning, without a PhD</title>
<div class="readable">
        <h1>TensorFlow, Keras and deep learning, without a PhD</h1>
            <div>Reading time: 29-37 minutes</div>
        <div>Posted here: 17 Jul 2020</div>
        <p><a href="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0">https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div label="Train a neural network" duration="10" step="3"><div><div><h2 is-upgraded="">3. Train a neural network</h2>
        <p>We will first watch a neural network train. Please open the notebook below and run through all the cells. Do not pay attention to the code yet, we will start explaining it later.</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/c3df49e90e5a654f.png"><a href="https://colab.research.google.com/github/GoogleCloudPlatform/tensorflow-without-a-phd/blob/master/tensorflow-mnist-tutorial/keras_01_mnist.ipynb" target="_blank"><strong><code>keras_01_mnist.ipynb</code></strong></a></p>
<p>As you execute the notebook, focus on the visualizations. See below for explanations.</p>
<h2 is-upgraded=""><strong>Training data</strong></h2>
<p>We have a dataset of handwritten digits which have been labeled so that we know what each picture represents, i.e. a number between 0 and 9. In the notebook, you will see an excerpt:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/ad83f98e56054737.png"></p>
<p>The neural network we will build classifies the handwritten digits in their 10 classes (0, .., 9). It does so based on internal parameters that need to have a correct value for the classification to work well. This "correct value" is learned through a training process which requires a "labeled dataset" with images and the associated correct answers.</p>
<p>How do we know if the trained neural network performs well or not? Using the training dataset to test the network would be cheating. It has already seen that dataset multiple times during training and is most certainly very performant on it. We need another labeled dataset, never seen during training, to evaluate the "real-world" performance of the network. It is called an "<strong>validation dataset</strong>"</p>

<h2 is-upgraded=""><strong>Training</strong></h2>
<p>As training progresses, one batch of training data at a time, internal model parameters get updated and the model gets better and better at recognizing the handwritten digits. You can see it on the training graph:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/3f7b405649301ea.png"></p>
<p>On the right, the "accuracy" is simply the percentage of correctly recognized digits. It goes up as training progresses, which is good.</p>
<p>On the left, we can see the<strong> "loss"</strong>. To drive the training, we will define a "loss" function, which represents how badly the system recognises the digits, and try to minimise it. What you see here is that the loss goes down on both the training and the validation data as the training progresses: that is good. It means the neural network is learning.</p>
<p>The X-axis represents the number of "epochs" or iterations through the entire dataset.</p>
<h2 is-upgraded=""><strong>Predictions</strong></h2>
<p>When the model is trained, we can use it to recognize handwritten digits. The next visualization shows how well it performs on a few digits rendered from local fonts (first line) and then on the 10,000 digits of the validation dataset. The predicted class appears under each digit, in red if it was wrong.</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/c0699216ba0effdb.png"></p>
<p>As you can see, this initial model is not very good but still recognizes some digits correctly. Its final validation accuracy is around 90% which is not so bad for the simplistic model we are starting with, but it still means that it misses 1000 validation digits out of the 10,000. That is far more that can be displayed, which is why it looks like all the answers are wrong (red).</p>
<h2 is-upgraded=""><strong>Tensors</strong></h2>
<p>Data is stored in matrices. A 28x28 pixel grayscale image fits into a 28x28 two-dimensional matrix. But for a color image, we need more dimensions. There are 3 color values per pixel (Red, Green, Blue), so a three-dimensional table will be needed with dimensions [28, 28, 3]. And to store a batch of 128 color images, a four-dimensional table is needed with dimensions [128, 28, 28, 3].</p>
<p>These multi-dimensional tables are called <strong>"tensors"</strong> and the list of their dimensions is their <strong>"shape"</strong>.</p>


      </div></div></div><div label="[INFO]: neural networks 101" duration="10" step="4"><div><div><h2 is-upgraded="">4. [INFO]: neural networks 101</h2>
        <h2 is-upgraded=""><strong>In a nutshell</strong></h2>
<p>If all the terms in <strong>bold</strong> in the next paragraph are already known to you, you can move to the next exercise. If your are just starting in deep learning then welcome, and please read on.</p>

<p><img alt="witch.png" src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/8ba4c58c4e3aeb14.png"></p>
<p>For models built as a sequence of layers Keras offers the Sequential API. For example, an image classifier using three dense layers can be written in Keras as:</p>
<pre><code><span>model </span><span>=</span><span> tf</span><span>.</span><span>keras</span><span>.</span><span>Sequential</span><span>([</span><span>
    tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Flatten</span><span>(</span><span>input_shape</span><span>=[</span><span>28</span><span>,</span><span> </span><span>28</span><span>,</span><span> </span><span>1</span><span>]),</span><span>
    tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Dense</span><span>(</span><span>200</span><span>,</span><span> activation</span><span>=</span><span>"relu"</span><span>),</span><span>
    tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Dense</span><span>(</span><span>60</span><span>,</span><span> activation</span><span>=</span><span>"relu"</span><span>),</span><span>
    tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Dense</span><span>(</span><span>10</span><span>,</span><span> activation</span><span>=</span><span>'softmax'</span><span>)</span><span> </span><span># classifying into 10 classes</span><span>
</span><span>])</span><span>

</span><span># this configures the training of the model. Keras calls it "compiling" the model.</span><span>
model</span><span>.</span><span>compile</span><span>(</span><span>
  optimizer</span><span>=</span><span>'adam'</span><span>,</span><span>
  loss</span><span>=</span><span> </span><span>'categorical_crossentropy'</span><span>,</span><span>
  metrics</span><span>=[</span><span>'accuracy'</span><span>])</span><span> </span><span># % of correct answers</span><span>

</span><span># train the model</span><span>
model</span><span>.</span><span>fit</span><span>(</span><span>dataset</span><span>,</span><span> </span><span>...</span><span> </span><span>)</span></code></pre>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/688858c21e3beff2.png"></p>
<h2 is-upgraded="">A single dense layer</h2>
<p>Handwritten digits in the MNIST dataset are 28x28 pixel grayscale images. The simplest approach for classifying them is to use the 28x28=784 pixels as inputs for a 1-layer neural network.</p>
<p><img alt="Screen Shot 2016-07-26 at 12.32.24.png" src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/e218e6eee9da4e.png"></p>
<p>Each <strong>"neuron" </strong>in a neural network does a weighted sum of all of its inputs, adds a constant called the "bias" and then feeds the result through some non-linear <strong>"activation function"</strong>. The <strong>"weights"</strong> and<strong> "biases"</strong> are parameters that will be determined through training. They are initialized with random values at first.</p>
<p>The picture above represents a 1-layer neural network with 10 output neurons since we want to classify digits into 10 classes (0 to 9).</p>
<h2 is-upgraded=""><strong>With a matrix multiplication</strong></h2>
<p>Here is how a neural network layer, processing a collection of images, can be represented by a matrix multiplication:</p>
<p><img alt="matmul.gif" src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/706248ddefae07f0.gif"></p>
<p>Using the first column of weights in the weights matrix W, we compute the weighted sum of all the pixels of the first image. This sum corresponds to the first neuron. Using the second column of weights, we do the same for the second neuron and so on until the 10th neuron. We can then repeat the operation for the remaining 99 images. If we call X the matrix containing our 100 images, all the weighted sums for our 10 neurons, computed on 100 images are simply X.W, a matrix multiplication.</p>
<p>Each neuron must now add its bias (a constant). Since we have 10 neurons, we have 10 bias constants. We will call this vector of 10 values b. It must be added to each line of the previously computed matrix. Using a bit of magic called "broadcasting" we will write this with a simple plus sign.</p>

<p>We finally apply an activation function, for example "softmax" (explained below) and obtain the formula describing a 1-layer neural network, applied to 100 images:</p>
<p><img alt="Screen Shot 2016-07-26 at 16.02.36.png" src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/a49ddecea0ee8f52.png"></p>
<h2 is-upgraded=""><strong>In Keras</strong></h2>
<p>With high-level neural network libraries like Keras, we will not need to implement this formula. However, it is important to understand that a neural network layer is just a bunch of multiplications and additions. In Keras, a dense layer would be written as:</p>
<pre><code><span>tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Dense</span><span>(</span><span>10</span><span>,</span><span> activation</span><span>=</span><span>'softmax'</span><span>)</span></code></pre>
<h2 is-upgraded=""><strong>Go deep</strong></h2>
<p>It is trivial to chain neural network layers. The first layer computes weighted sums of of pixels. Subsequent layers compute weighted sums of the outputs of the previous layers. </p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/fba0638cc213a29.png"></p>
<p>The only difference, apart from the number of neurons, will be the choice of activation function.</p>
<h2 is-upgraded=""><strong>Activation functions: relu, softmax and sigmoid</strong></h2>
<p>You would typically use the "relu" activation function for all layers but the last. The last layer, in a classifier, would use "softmax" activation.</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/644f4213a4ee70e5.png"></p>
<p>Again, a "neuron" computes a weighted sum of all of its inputs, adds a value called "bias" and feeds the result through the activation function.</p>
<p>The most popular activation function is called <strong>"RELU"</strong> for Rectified Linear Unit. It is a very simple function as you can see on the graph above.</p>
<p>The traditional activation function in neural networks was the <strong>"sigmoid"</strong> but the "relu" was shown to have better convergence properties almost everywhere and is now preferred.</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/41fc82288c4aff5d.png"></p>
<h2 is-upgraded=""><strong>Softmax activation for classification</strong></h2>
<p>The last layer of our neural network has 10 neurons because we want to classify handwritten digits into 10 classes (0,..9). It should output 10 numbers between 0 and 1 representing the probability of this digit being a 0, a 1, a 2 and so on. For this, on the last layer, we will use an activation function called <strong>"softmax"</strong>.</p>
<p>Applying softmax on a vector is done by taking the exponential of each element and then normalising the vector, typically by dividing it by its "L1" norm (i.e. sum of absolute values) so that normalized values add up to 1 and can be interpreted as probabilities.</p>
<p>The output of the last layer, before activation is sometimes called <strong>"logits"</strong>. If this vector is L = [L0, L1, L2, L3, L4, L5, L6, L7, L8, L9], then:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/ef0d98c0952c262d.png"><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/d51252f75894479e.gif"></p>

<h2 is-upgraded=""><strong>Cross-entropy loss</strong></h2>
<p>Now that our neural network produces predictions from input images, we need to measure how good they are, i.e. the distance between what the network tells us and the correct answers, often called "labels". Remember that we have correct labels for all the images in the dataset.</p>
<p>Any distance would work, but for classification problems the so-called "cross-entropy distance" is the <a href="https://jamesmccaffrey.wordpress.com/2013/11/05/why-you-should-use-cross-entropy-error-instead-of-classification-error-or-mean-squared-error-for-neural-network-classifier-training/" target="_blank">most effective</a>. We will call this our error or "loss" function:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/6dbba1bce3cadc36.png"></p>

<h2 is-upgraded=""><strong>Gradient descent</strong></h2>
<p>"Training" the neural network actually means using training images and labels to adjust weights and biases so as to minimise the cross-entropy loss function. Here is how it works.</p>
<p>The cross-entropy is a function of weights, biases, pixels of the training image and its known class.</p>
<p>If we compute the partial derivatives of the cross-entropy relatively to all the weights and all the biases we obtain a "gradient", computed for a given image, label, and present value of weights and biases. Remember that we can have millions of weights and biases so computing the gradient sounds like a lot of work. Fortunately, TensorFlow does it for us. The mathematical property of a gradient is that it points "up". Since we want to go where the cross-entropy is low, we go in the opposite direction. We update weights and biases by a fraction of the gradient. We then do the same thing again and again using the next batches of training images and labels, in a training loop. Hopefully, this converges to a place where the cross-entropy is minimal although nothing guarantees that this minimum is unique.</p>
<p><img alt="gradient descent2.png" src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/9d3ab44f06bb0f7a.png"></p>

<h2 is-upgraded=""><strong>Mini-batching and momentum</strong></h2>
<p>You can compute your gradient on just one example image and update the weights and biases immediately, but doing so on a batch of, for example, 128 images gives a gradient that better represents the constraints imposed by different example images and is therefore likely to converge towards the solution faster. The size of the mini-batch is an adjustable parameter.</p>
<p>This technique, sometimes called "stochastic gradient descent"  has another, more pragmatic benefit: working with batches also means working with larger matrices and these are usually easier to optimise on GPUs and TPUs.</p>
<p>The convergence can still be a little chaotic though and it can even stop if the gradient vector is all zeros. Does that mean that we have found a minimum? Not always. A gradient component can be zero on a minimum or a maximum. With a gradient vector with millions of elements, if they are all zeros, the probability that every zero corresponds to a minimum and none of them to a maximum point is pretty small. In a space of many dimensions, saddle points are pretty common and we do not want to stop at them.</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/cc544924671fa208.png"></p>
<p><em>Illustration: a saddle point. The gradient is 0 but it is not a minimum in all directions. (Image attribution </em><a href="https://commons.wikimedia.org/w/index.php?curid=20570051" target="_blank"><em>Wikimedia: By Nicoguaro - Own work, CC BY 3.0</em></a><em>)</em></p>
<p>The solution is to add some momentum to the optimization algorithm so that it can sail past saddle points without stopping.</p>

<h2 is-upgraded=""><strong>Glossary</strong></h2>
<p><strong>batch </strong>or<strong> mini-batch</strong>: training is always performed on batches of training data and labels. Doing so helps the algorithm converge. The "batch" dimension is typically the first dimension of data tensors. For example a tensor of shape [100, 192, 192, 3] contains 100 images of 192x192 pixels with three values per pixel (RGB).</p>
<p><strong>cross-entropy loss</strong>: a special loss function often used in classifiers.</p>
<p><strong>dense layer</strong>: a layer of neurons where each neuron is connected to all the neurons in the previous layer.</p>
<p><strong>features</strong>: the inputs of a neural network are sometimes called "features". The art of figuring out which parts of a dataset (or combinations of parts) to feed into a neural network to get good predictions is called "feature engineering".</p>
<p><strong>labels</strong>: another name for "classes" or correct answers in a supervised classification problem</p>
<p><strong>learning rate</strong>: fraction of the gradient by which weights and biases are updated at each iteration of the training loop. </p>
<p><strong>logits</strong>: the outputs of a layer of neurons before the activation function is applied are called "logits". The term comes from the "logistic function" a.k.a. the "sigmoid function" which used to be the most popular activation function. "Neuron outputs before logistic function" was shortened to "logits".</p>
<p><strong>loss</strong>: the error function comparing neural network outputs to the correct answers</p>
<p><strong>neuron</strong>: computes the weighted sum of its inputs, adds a bias and feeds the result through an activation function.</p>
<p><strong>one-hot encoding</strong>: class 3 out of 5 is encoded as a vector of 5 elements, all zeros except the 3rd one which is 1.</p>
<p><strong>relu</strong>: rectified linear unit. A popular activation function for neurons.</p>
<p><strong>sigmoid</strong>: another activation function that used to be popular and is still useful in special cases.</p>
<p><strong>softmax</strong>: a special activation function that acts on a vector, increases the difference between the largest component and all others, and also normalizes the vector to have a sum of 1 so that it can be interpreted as a vector of probabilities. Used as the last step in classifiers.</p>
<p><strong>tensor</strong>: A "tensor" is like a matrix but with an arbitrary number of dimensions. A 1-dimensional tensor is a vector. A 2-dimensions tensor is a matrix. And then you can have tensors with 3, 4, 5 or more dimensions.</p>


      </div></div></div><div label="Let's jump into the code" duration="15" step="5"><div><div><h2 is-upgraded="">5. Let's jump into the code</h2>
        <p>Back to the study notebook and this time, let's read the code.</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/c3df49e90e5a654f.png"><a href="https://colab.research.google.com/github/GoogleCloudPlatform/tensorflow-without-a-phd/blob/master/tensorflow-mnist-tutorial/keras_01_mnist.ipynb" target="_blank"><strong><code>keras_01_mnist.ipynb</code></strong></a></p>

<p>Let's go through all the cell in this notebook.</p>
<h2 is-upgraded=""><strong>Cell "Parameters"</strong></h2>
<p>The batch size, number of training epochs and location of the data files is defined here. Data files are hosted in a Google Cloud Storage (GCS) bucket which is why their address starts with <code>gs://</code></p>
<h2 is-upgraded=""><strong>Cell "Imports"</strong></h2>
<p>All the necessary Python libraries are imported here, including TensorFlow and also matplotlib for visualizations.</p>
<h2 is-upgraded="">Cell "<strong>visualization utilities [RUN ME]</strong><strong>"</strong></h2>
<p>This cell contains uninteresting visualization code. It is collapsed by default but you can open it and look at the code when you have the time by double-clicking on it.</p>

<h2 is-upgraded=""><strong>Cell "</strong><strong>tf.data.Dataset: parse files and prepare training and validation datasets</strong><strong>"</strong></h2>
<p>This cell used the tf.data.Dataset API to load the MNIST dataset form the data files. It is not necessary to spend too much time on this cell. If you are interested in the tf.data.Dataset API, here is a tutorial that explains it: <a href="https://codelabs.developers.google.com/codelabs/keras-flowers-data/#0" target="_blank">TPU-speed data pipelines</a>. For now, the basics are:</p>
<p>Images and labels (correct answers) from the MNIST dataset are stored in fixed length records in 4 files. The files can be loaded with the dedicated fixed record function:<br></p>
<pre><code><span>imagedataset </span><span>=</span><span> tf</span><span>.</span><span>data</span><span>.</span><span>FixedLengthRecordDataset</span><span>(</span><span>image_filename</span><span>,</span><span> </span><span>28</span><span>*</span><span>28</span><span>,</span><span> header_bytes</span><span>=</span><span>16</span><span>)</span></code></pre>
<p>We now have a dataset of image bytes. They need to be decoded into images. We define a function for doing so. The image is not compressed so the function does not need to decode anything (<code>decode_raw</code> does basically nothing). The image is then converted to floating point values between 0 and 1. We could reshape it here as a 2D image but actually we keep it as a flat array of pixels of size 28*28 because that is what our initial dense layer expects.</p>
<pre><code><span>def</span><span> read_image</span><span>(</span><span>tf_bytestring</span><span>):</span><span>
    image </span><span>=</span><span> tf</span><span>.</span><span>io</span><span>.</span><span>decode_raw</span><span>(</span><span>tf_bytestring</span><span>,</span><span> tf</span><span>.</span><span>uint8</span><span>)</span><span>
    image </span><span>=</span><span> tf</span><span>.</span><span>cast</span><span>(</span><span>image</span><span>,</span><span> tf</span><span>.</span><span>float32</span><span>)/</span><span>256.0</span><span>
    image </span><span>=</span><span> tf</span><span>.</span><span>reshape</span><span>(</span><span>image</span><span>,</span><span> </span><span>[</span><span>28</span><span>*</span><span>28</span><span>])</span><span>
    </span><span>return</span><span> image</span></code></pre>
<p>We apply this function to the dataset using <code>.map</code> and obtain a dataset of images:</p>
<pre><code><span>imagedataset </span><span>=</span><span> imagedataset</span><span>.</span><span>map</span><span>(</span><span>read_image</span><span>,</span><span> num_parallel_calls</span><span>=</span><span>16</span><span>)</span></code></pre>
<p>We do the same kind of reading and decoding for labels and we <code>.zip</code> images and labels together:</p>
<pre><code><span>dataset </span><span>=</span><span> tf</span><span>.</span><span>data</span><span>.</span><span>Dataset</span><span>.</span><span>zip</span><span>((</span><span>imagedataset</span><span>,</span><span> labelsdataset</span><span>))</span></code></pre>
<p>We now have a dataset of pairs (image, label). This is what our model expects. We are not quite ready to use it in the training function yet:</p>
<pre><code><span>dataset </span><span>=</span><span> dataset</span><span>.</span><span>cache</span><span>()</span><span>
dataset </span><span>=</span><span> dataset</span><span>.</span><span>shuffle</span><span>(</span><span>5000</span><span>,</span><span> reshuffle_each_iteration</span><span>=</span><span>True</span><span>)</span><span>
dataset </span><span>=</span><span> dataset</span><span>.</span><span>repeat</span><span>()</span><span>
dataset </span><span>=</span><span> dataset</span><span>.</span><span>batch</span><span>(</span><span>batch_size</span><span>)</span><span>
dataset </span><span>=</span><span> dataset</span><span>.</span><span>prefetch</span><span>(</span><span>tf</span><span>.</span><span>data</span><span>.</span><span>experimental</span><span>.</span><span>AUTOTUNE</span><span>)</span></code></pre>
<p>The tf.data.Dataset API has all the necessary utility function for preparing datasets:</p>
<p><code>.cache</code> caches the dataset in RAM. This is a tiny dataset so it will work. <code>.shuffle</code> shuffles it with a buffer of 5000 elements. It is important that training data are well shuffled. <code>.repeat</code> loops the dataset. We will be training on it multiple times (multiple epochs). <code>.batch</code> pulls multiple images and labels together into a mini-natch. Finally, <code>.prefetch</code> can use the CPU to prepare the next batch while the current batch is being trained on the GPU.</p>
<p>The validation dataset is prepared in a similar way. We are now ready to define a model and use this dataset to train it.</p>
<h2 is-upgraded=""><strong>Cell "Keras Model"</strong></h2>
<p>All of our models will be straight sequences of layers so we can use the <code>tf.keras.Sequential</code> style to create them. Initially here, it's a single dense layer. It has 10 neurons because we are classifying handwritten digits into 10 classes. It uses "softmax" activation because it is the last layer in a classifier.</p>
<p>A Keras model also needs to know the shape of its inputs. <code>tf.keras.layers.Input</code> can be used to define it. Here, input vectors are flat vectors of pixel values of length 28*28.</p>
<pre><code><span>model </span><span>=</span><span> tf</span><span>.</span><span>keras</span><span>.</span><span>Sequential</span><span>(</span><span>
  </span><span>[</span><span>
    tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Input</span><span>(</span><span>shape</span><span>=(</span><span>28</span><span>*</span><span>28</span><span>,)),</span><span>
    tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Dense</span><span>(</span><span>10</span><span>,</span><span> activation</span><span>=</span><span>'softmax'</span><span>)</span><span>
  </span><span>])</span><span>

model</span><span>.</span><span>compile</span><span>(</span><span>optimizer</span><span>=</span><span>'sgd'</span><span>,</span><span>
              loss</span><span>=</span><span>'categorical_crossentropy'</span><span>,</span><span>
              metrics</span><span>=[</span><span>'accuracy'</span><span>])</span><span>

</span><span># print model layers</span><span>
model</span><span>.</span><span>summary</span><span>()</span><span>

</span><span># utility callback that displays training curves</span><span>
plot_training </span><span>=</span><span> </span><span>PlotTraining</span><span>(</span><span>sample_rate</span><span>=</span><span>10</span><span>,</span><span> zoom</span><span>=</span><span>1</span><span>)</span></code></pre>
<p>Configuring the model is done in Keras using the <code>model.compile</code> function. Here we use the basic optimizer <code>'sgd'</code> (Stochastic Gradient Descent). A classification model requires a cross-entropy loss function, called <code>'categorical_crossentropy'</code> in Keras. Finally, we ask the model to compute the <code>'accuracy'</code> metric, which is the percentage of correctly classified images.</p>
<p>Keras offers the very nice <code>model.summary()</code> utility that prints the details of the model you have created. Your kind instructor has added the <code>PlotTraining</code> utility (defined in the "visualization utilities" cell) which will display various training curves during the training.</p>
<h2 is-upgraded=""><strong>Cell "Train and validate the model"</strong></h2>
<p>This is where the training happens, by calling <code>model.fit</code> and passing in both the training and validation datasets. By default, Keras runs a round of validation at the end of each epoch.</p>
<pre><code><span>model</span><span>.</span><span>fit</span><span>(</span><span>training_dataset</span><span>,</span><span> steps_per_epoch</span><span>=</span><span>steps_per_epoch</span><span>,</span><span> epochs</span><span>=</span><span>EPOCHS</span><span>,</span><span>
          validation_data</span><span>=</span><span>validation_dataset</span><span>,</span><span> validation_steps</span><span>=</span><span>1</span><span>,</span><span>
          callbacks</span><span>=[</span><span>plot_training</span><span>])</span></code></pre>
<p>In Keras, it is possible to add custom behaviors during training by using callbacks. That is how the dynamically updating training plot was implemented for this workshop.</p>
<h2 is-upgraded=""><strong>Cell "Visualize predictions"</strong></h2>
<p>Once the model is trained, we can get predictions from it by calling <code>model.predict()</code>: </p>
<pre><code><span>probabilities </span><span>=</span><span> model</span><span>.</span><span>predict</span><span>(</span><span>font_digits</span><span>,</span><span> steps</span><span>=</span><span>1</span><span>)</span><span>
predicted_labels </span><span>=</span><span> np</span><span>.</span><span>argmax</span><span>(</span><span>probabilities</span><span>,</span><span> axis</span><span>=</span><span>1</span><span>)</span></code></pre>
<p>Here we have prepared a set of printed digits rendered from local fonts, as a test. Remember that the neural network returns a vector of 10 probabilities from its final "softmax". To get the label, we have to find out which probability is the highest. <code>np.argmax</code> from the numpy library does that.</p>
<p>To understand why the <code>axis=1</code> parameter is needed, please remember that we have processed a batch of 128 images and therefore the model returns 128 vectors of probabilities. The shape of the output tensor is [128, 10]. We are computing the argmax across the 10 probabilities returned for each image, thus <code>axis=1</code> (the first axis being 0).</p>
<p>This simple model already recognises 90% of the digits. Not bad, but you will now improve this significantly.</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/396c54ef66fad27f.png"></p>


      </div></div></div><div label="Special care for deep networks" duration="10" step="7"><div><div><h2 is-upgraded="">7. Special care for deep networks</h2>
        <p>You have just experienced neural networks, as people used to design them in the 80's and 90's. No wonder they gave up on the idea, ushering the so-called "AI winter". Indeed, as you add layers, neural networks have more and more difficulties to converge.</p>
<p>It turns out that deep neural networks with many layers (20, 50, even 100 today) can work really well, provided a couple of mathematical dirty tricks to make them converge. The discovery of these simple tricks is one of the reasons for the renaissance of deep learning in the 2010's.</p>
<h2 is-upgraded=""><strong>RELU activation</strong></h2>
<p><img alt="relu.png" src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/35a0e96b3da8a465.png"></p>
<p>The sigmoid activation function is actually quite problematic in deep networks. It squashes all values between 0 and 1 and when you do so repeatedly, neuron outputs and their gradients can vanish entirely. It was mentioned for historical reasons, but modern networks use the RELU (Rectified Linear Unit) which looks like this:</p>

<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/1abce89f7143a69c.png"></p>

<p>The relu on the other hand has a derivative of 1, at least on its right side. With RELU activation, even if the gradients coming from some neurons can be zero, there will always be others giving a clear non-zero gradient and training can continue at a good pace.</p>
<h2 is-upgraded=""><strong>A better optimizer</strong></h2>
<p>In very high-dimensional spaces like here — we have on the order of 10K weights and biases — "saddle points" are frequent. These are points that are not local minima, but where the gradient is nevertheless zero and the gradient descent optimizer stays stuck there. TensorFlow has a full array of available optimizers, including some that work with an amount of inertia and will safely sail past saddle points.</p>

<h2 is-upgraded=""><strong>Random initializations</strong></h2>
<p>The art of initializing weights biases before training is an area of research in itself, with numerous papers published on the topic. You can have a look at all the initializers available in Keras <a href="https://keras.io/initializers/" target="_blank">here</a>. Fortunately, Keras does the right thing by default and uses the <code>'glorot_uniform'</code> initializer which is the best in almost all cases.</p>
<p>There is nothing for you to do, since Keras already does the right thing.</p>
<h2 is-upgraded=""><strong>NaN ???</strong></h2>
<p>The cross-entropy formula involves a logarithm and log(0) is Not a Number (NaN, a numerical crash if you prefer). Can the input to the cross-entropy be 0? The input comes from softmax which is essentially an exponential and an exponential is never zero. So we are safe!</p>
<p>Really? In the beautiful world of mathematics, we would be safe, but in the computer world, exp(-150), represented in float32 format, is as ZERO as it gets and the cross-entropy crashes.</p>
<p>Fortunately, there is nothing for you to do here either, since Keras takes care of this and computes softmax followed by the cross-entropy in an especially careful way to ensure numerical stability and avoid the dreaded NaNs.</p>
<h2 is-upgraded=""><strong>Success?</strong></h2>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/e1521c9dd936d9bc.png"></p>
<p>You should now be getting to 97% accuracy. The goal in this workshop is to get significantly above 99% so let's keep going.</p>
<p>If you are stuck, here is the solution at this point:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/c3df49e90e5a654f.png"><a href="https://colab.research.google.com/github/GoogleCloudPlatform/tensorflow-without-a-phd/blob/master/tensorflow-mnist-tutorial/keras_02_mnist_dense.ipynb" target="_blank"><strong><code>keras_02_mnist_dense.ipynb</code></strong></a></p>


      </div></div></div><div label="Dropout, overfitting" duration="10" step="9"><div><div><h2 is-upgraded="">9. Dropout, overfitting</h2>
        <p>The model seems to be converging nicely now. Let's try to go even deeper.</p>

<p>Does it help?</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/e36c09a3088104c6.png"></p>
<p>Not really, the accuracy is still stuck at 98% and look at the validation loss. It is going up! The learning algorithm works on training data only and optimises the training loss accordingly. It never sees validation data so it is not surprising that after a while its work no longer has an effect on the validation loss which stops dropping and sometimes even bounces back up.</p>
<p>This does not immediately affect the real-world recognition capabilities of your model, but it will prevent you from running many iterations and is generally a sign that the training is no longer having a positive effect.</p>
<p><img alt="dropout.png" src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/ff192183d1cf2023.png"></p>
<p>This disconnect is usually called "overfitting" and when you see it, you can try to apply a regularisation technique called "dropout". The dropout technique shoots random neurons at each training iteration.</p>



<p>Did it work?</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/43fd33801264743f.png"></p>
<p>Noise reappears (unsurprisingly given how dropout works). The validation loss does not seem to be creeping up anymore, but it is higher overall than without dropout. And the validation accuracy went down a bit. This is a fairly disappointing result.</p>
<p>It looks like dropout was not the correct solution, or maybe "overfitting" is a more complex concept and some of its causes are not amenable to a "dropout" fix?</p>
<p>What is "overfitting"? Overfitting happens when a neural network learns "badly", in a way that works for the training examples but not so well on real-world data. There are regularisation techniques like dropout that can force it to learn in a better way but overfitting also has deeper roots.</p>
<p><img alt="overfitting.png" src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/3291d60208e7ce7f.png"> </p>
<p>Basic overfitting happens when a neural network has too many degrees of freedom for the problem at hand. Imagine we have so many neurons that the network can store all of our training images in them and then recognise them by pattern matching. It would fail on real-world data completely. A neural network must be somewhat constrained so that it is forced to generalise what it learns during training.</p>
<p>If you have very little training data, even a small network can learn it by heart and you will see "overfitting". Generally speaking, you always need lots of data to train neural networks.</p>
<p>Finally, if you have done everything by the book, experimented with different sizes of network to make sure its degrees of freedom are constrained, applied dropout, and trained on lots of data you might still be stuck at a performance level that nothing seems to be able to improve. This means that your neural network, in its present shape, is not capable of extracting more information from your data, as in our case here.</p>
<p>Remember how we are using our images, flattened into a single vector? That was a really bad idea. Handwritten digits are made of shapes and we discarded the shape information when we flattened the pixels. However, there is a type of neural network that can take advantage of shape information: convolutional networks. Let us try them.</p>
<p>If you are stuck, here is the solution at this point:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/c3df49e90e5a654f.png"><a href="https://colab.research.google.com/github/GoogleCloudPlatform/tensorflow-without-a-phd/blob/master/tensorflow-mnist-tutorial/keras_03_mnist_dense_lrdecay_dropout.ipynb" target="_blank"><strong><code>keras_03_mnist_dense_lrdecay_dropout.ipynb</code></strong></a></p>


      </div></div></div><div label="[INFO] convolutional networks" duration="15" step="10"><div><div><h2 is-upgraded="">10. [INFO] convolutional networks</h2>
        <h2 is-upgraded=""><strong>In a nutshell</strong></h2>
<p>If all the terms in <strong>bold</strong> in the next paragraph are already known to you, you can move to the next exercise. If your are just starting out with convolutional neural networks, please read on.</p>
<p><img alt="convolutional.gif" src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/ca8f34f3d28ea528.gif"></p>
<p><em>Illustration: filtering an image with two successive filters made of 4x4x3=48 learnable weights each.</em></p>

<p>This is how a simple convolutional neural network looks in Keras:</p>
<pre><code><span>model </span><span>=</span><span> tf</span><span>.</span><span>keras</span><span>.</span><span>Sequential</span><span>([</span><span>
    tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Reshape</span><span>(</span><span>input_shape</span><span>=(</span><span>28</span><span>*</span><span>28</span><span>,),</span><span> target_shape</span><span>=(</span><span>28</span><span>,</span><span> </span><span>28</span><span>,</span><span> </span><span>1</span><span>)),</span><span>
    tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Conv2D</span><span>(</span><span>kernel_size</span><span>=</span><span>3</span><span>,</span><span> filters</span><span>=</span><span>12</span><span>,</span><span> activation</span><span>=</span><span>'relu'</span><span>),</span><span>
    tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Conv2D</span><span>(</span><span>kernel_size</span><span>=</span><span>6</span><span>,</span><span> filters</span><span>=</span><span>24</span><span>,</span><span> strides</span><span>=</span><span>2</span><span>,</span><span> activation</span><span>=</span><span>'relu'</span><span>),</span><span>
    tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Conv2D</span><span>(</span><span>kernel_size</span><span>=</span><span>6</span><span>,</span><span> filters</span><span>=</span><span>32</span><span>,</span><span> strides</span><span>=</span><span>2</span><span>,</span><span> activation</span><span>=</span><span>'relu'</span><span>),</span><span>
    tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Flatten</span><span>(),</span><span>
    tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Dense</span><span>(</span><span>10</span><span>,</span><span> activation</span><span>=</span><span>'softmax'</span><span>)</span><span>
</span><span>])</span></code></pre>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/688858c21e3beff2.png"></p>
<p>In a layer of a convolutional network, one "neuron" does a weighted sum of the pixels just above it, across a small region of the image only. It adds a bias and feeds the sum through an activation function, just as a neuron in a regular dense layer would. This operation is then repeated across the entire image using the same weights. Remember that in dense layers, each neuron had its own weights. Here, a single "patch" of weights slides across the image in both directions (a "convolution"). The output has as many values as there are pixels in the image (some padding is necessary at the edges though). It is a filtering operation. In the illustration above, it uses a filter of 4x4x3=48 weights.</p>
<p>However, 48 weights will not be enough. To add more degrees of freedom, we repeat the same operation with a new set of weights. This produces a new set of filter outputs. Let's call it a "channel" of outputs by analogy with the R,G,B channels in the input image.</p>
<p><img alt="Screen Shot 2016-07-29 at 16.02.37.png" src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/bd9f83d6cb62b5fb.png"></p>
<p>The two (or more) sets of weights can be summed up as one tensor by adding a new dimension. This gives us the generic shape of the weights tensor for a convolutional layer. Since the number of input and output channels are parameters, we can start stacking and chaining convolutional layers.</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/d1b557707bcd1cb9.png"></p>
<p><em>Illustration: a convolutional neural network transforms "cubes" of data into other "cubes" of data.</em></p>
<h2 is-upgraded=""><strong>Strided convolutions, max pooling</strong></h2>
<p>By performing the convolutions with a stride of 2 or 3, we can also shrink the resulting data cube in its horizontal dimensions. There are two common ways of doing this:</p>
<ul>
<li>Strided convolution: a sliding filter as above but with a stride &gt;1</li>
<li>Max pooling: a sliding window applying the MAX operation (typically on 2x2 patches, repeated every 2 pixels)</li>
</ul>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/2b2d4263bb8470b.gif"></p>
<p><em>Illustration: sliding the computing window by 3 pixels results in fewer output values. Strided convolutions or max pooling (max on a 2x2 window sliding by a stride of 2) are a way of shrinking the data cube in the horizontal dimensions.</em></p>

<h3 is-upgraded=""><strong>The final layer</strong></h3>
<p>After the last convolutional layer, the data is in the form of a  "cube". There are two ways of feeding it through the final dense layer.</p>
<p>The first one is to flatten the cube of data into a vector and then feed it to the softmax layer. Sometimes, you can even add a dense layer before the softmax layer. This tends to be expensive in terms of the number of weights. A dense layer at the end of a convolutional network can contain more than half the weights of the whole neural network.</p>
<p>Instead of using an expensive dense layer, we can also split the incoming data "cube" into as many parts as we have classes, average their values and feed these through a softmax activation function. This way of building the classification head costs 0 weights. In Keras, there is a layer for this: <code>tf.keras.layers.GlobalAveragePooling2D()</code>.</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/a44aa392c7b0e32a.png"></p>

<p>Jump to the next section to build a convolutional network for the problem at hand.</p>


      </div></div></div><div label="A convolutional network" duration="15" step="11"><div><div><h2 is-upgraded="">11. A convolutional network</h2>
        <p>Let us build a convolutional network for handwritten digit recognition. We will use three convolutional layers at the top, our traditional softmax readout layer at the bottom and connect them with one fully-connected layer:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/e1a214a170957da1.png"></p>
<p>Notice that the second and third convolutional layers have a stride of two which explains why they bring the number of output values down from 28x28 to 14x14 and then 7x7.</p>
<p>Let's write the Keras code.</p>
<p>Special attention is needed before the first convolutional layer. Indeed, it expects a 3D ‘cube' of data but our dataset has so far been set up for dense layers and all the pixels of the images are flattened into a vector. We need to reshape them back into 28x28x1 images (1 channel for grayscale images):</p>
<pre><code><span>tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Reshape</span><span>(</span><span>input_shape</span><span>=(</span><span>28</span><span>*</span><span>28</span><span>,),</span><span> target_shape</span><span>=(</span><span>28</span><span>,</span><span> </span><span>28</span><span>,</span><span> </span><span>1</span><span>))</span></code></pre>
<p>You can use this line instead of the <code>tf.keras.layers.Input</code> layer you had up to now.</p>
<p>In Keras, the syntax for a ‘relu'-activated convolutional layer is:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/140f80336b0e653b.png"></p>
<pre><code><span>tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Conv2D</span><span>(</span><span>kernel_size</span><span>=</span><span>3</span><span>,</span><span> filters</span><span>=</span><span>12</span><span>,</span><span> padding</span><span>=</span><span>'same'</span><span>,</span><span> activation</span><span>=</span><span>'relu'</span><span>)</span></code></pre>

<p>For a strided convolution, you would write:</p>
<pre><code><span>tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Conv2D</span><span>(</span><span>kernel_size</span><span>=</span><span>6</span><span>,</span><span> filters</span><span>=</span><span>24</span><span>,</span><span> padding</span><span>=</span><span>'same'</span><span>,</span><span> activation</span><span>=</span><span>'relu'</span><span>,</span><span> strides</span><span>=</span><span>2</span><span>)</span></code></pre>
<p>To flatten a cube of data into a vector so that it can be consumed by a dense layer:</p>
<pre><code><span>tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Flatten</span><span>()</span></code></pre>
<p>And for dense layer, the syntax has not changed:</p>
<pre><code><span>tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Dense</span><span>(</span><span>200</span><span>,</span><span> activation</span><span>=</span><span>'relu'</span><span>)</span></code></pre>

<p>Did your model break the 99% accuracy barrier? Pretty close...  but look at the validation loss curve. Does this ring a bell?</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/ecc5972814885226.png"></p>
<p>Also look at the predictions. For the first time, you should see that most of the 10,000 test digits are now correctly recognized. Only about 4½ rows of misdetections remain (about 110 digits out of 10,000)</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/37e4cbd3f390c89e.png"></p>
<p>If you are stuck, here is the solution at this point:</p>
<p><img src="https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/img/c3df49e90e5a654f.png"><a href="https://colab.research.google.com/github/GoogleCloudPlatform/tensorflow-without-a-phd/blob/master/tensorflow-mnist-tutorial/keras_04_mnist_convolutional.ipynb" target="_blank"><strong><code>keras_04_mnist_convolutional.ipynb</code></strong></a></p>


      </div></div></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>