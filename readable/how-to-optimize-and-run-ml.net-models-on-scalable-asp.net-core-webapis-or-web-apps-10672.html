<!DOCTYPE html>
<html lang="en">
<head>
    <title>linksfor.dev(s)</title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    
    <meta property="article:author" content="Buildstarted"/>
    <meta property="og:site_name" content="linksfor.dev(s)" />
    <meta property="og:title" content="linksfor.dev(s)" />
    <meta property="og:type" content="website" />
    <meta property="og:description" content="A curated list of sources of development information including c#, c++, and other dev related links." />
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">🎉</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - How to optimize and run ML.NET models on scalable ASP.NET Core WebAPIs or web apps | Cesar de la Torre</title>
<div class="readable">
        <h1>How to optimize and run ML.NET models on scalable ASP.NET Core WebAPIs or web apps | Cesar de la Torre</h1>
        <p>
by Cesar De la TorrePrincipal Program Manager,&#xA0;.NETFollow Cesar <br/>Reading time: 21-26 minutes        </p>
        <p><a href="https://devblogs.microsoft.com/cesardelatorre/how-to-optimize-and-run-ml-net-models-on-scalable-asp-net-core-webapis-or-web-apps/">https://devblogs.microsoft.com/cesardelatorre/how-to-optimize-and-run-ml-net-models-on-scalable-asp-net-core-webapis-or-web-apps/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="featured"><div><div><div><div><p><img src="https://secure.gravatar.com/avatar/e58f2727f49ef3410ff517abf0161683?s=58&amp;d=mm&amp;r=g" width="58" height="58" alt="Avatar"></p><p>Cesar</p></div></div></div><p>March 24th, 2019</p><h2>Context</h2><p>——</p><p><strong>UPDATE on May 13th 2019: The recommended way to deploy/run an ML.NET model into ASP.NET Core web apps or WebAPI services is by using the ‘Microsoft.Extensions.ML’ Integration package. Read about it in this tutorial: </strong></p><p>– <a href="https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/serve-model-web-api-ml-net" rel="nofollow" target="_blank">Deploy an ML.NET model in an ASP.NET Core Web API</a></p><p>The tutorial above uses optimized code based on an <em>.NET Core Integration Package</em> comparable to integration packages targeting Entity Framework, SignalR, etc. so it’s transparent and a lot easier for you than the explained blog post below.</p><p><strong>This article below was written before that mentioned integration package was created by Microsoft. It explains the reasons why some ML.NET classes can run as singleton and why the PredictionEngine (not threadsafe) needs more advanced deployment such as using object pooling.<br> </strong></p><p>In fact, the code explained in this blog post is very similar to the final implementation of the Microsoft.Extensions.ML package which took it as a baseline for the official component.</p><p><strong>BUT YOU DON’T NEED TO IMPLEMENT THIS BY YOURSELF SINCE WE’RE TAKING CARE OF IT WITH THE .NET CORE INTEGRATION PACKAGE EXPLAINED IN THE ABOVE TUTORIAL’s LINK</strong></p><p>——</p><p><strong>ML.NET model used</strong>: The ML.NET model used in this example is the  model you can train/create with the <a href="https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/BinaryClassification_SentimentAnalysis" target="_blank">Sentiment Analysis Getting Started sample</a>. But for your convenience, that model is already serialized as a .zip file and already available in this sample code which only focuses on how to better run/score a model in scalable apps.</p><p><strong>Model running on WebAPI</strong>: Although the ML scenario is not really important in this case (execution optimization), the sample implemented is about running a Sentiment Analysis model on a WebAPI, as show in the following image:</p><p><img src="https://github.com/CESARDELATORRE/MLNET-Posts/raw/master/Posts/001-Running-MLNET-Models-in-ASPNETCore/images/Browser-WebAPI-screenshot.png" alt="alt text" title="Browser with model execution screenshot"></p><p>If the provided text in the URL ‘sentimentText’ parameter was rude, then the % of toxicity would be he high.</p><p><strong>Show me the code!</strong>: The sample WebAPI and code explained in this blog post is published <a href="https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/end-to-end-apps/ScalableMLModelOnWebAPI" target="_blank">here as an ML.NET Sample</a></p><p><strong>The goal is to be able to make predictions with an ML.NET model while optimizing the executions by sharing objects across Http requests and implementing code which should be very easy to use/consume by the user when predicting</strong>, like the following line of code that you could write on any ASP.NET Core controller’s method or custom service class:</p><div id="crayon-5e3a42da44571462584108" data-settings=" minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="hide"></td><td><div><p><span>SamplePrediction </span><span>prediction</span><span> </span>=<span> </span><span>_modelEngine</span><span>.</span><span>Predict</span><span>(</span><span>sampleData</span><span>)</span><span>;</span></p></div></td></tr></tbody></table></div></div><p>That’s it. Very simple. A single line. The object _modelEngine will be injected into your WebAPI controller’s constructor or into your custom class, so you just need to use it.</p><p>Internally, it will be optimized so the object dependencies are cached and shared across Http requests with minimized overhead when creating those objects.</p><p>ASP.NET Core services and apps are multithreaded applications so they can serve many HTTP requests at the same time.</p><p>.NET Core provides a managed thread pool that is managed by the system. As a developer, you don’t need to deal with the thread management.</p><p>As shown in the simplified image below, and ASP.NET Core WebAPI or web app accepts many Http requests which will be handled by that thread pool.</p><p><img src="https://github.com/CESARDELATORRE/MLNET-Posts/raw/master/Posts/001-Running-MLNET-Models-in-ASPNETCore/images/Simplified-threading-in-ASPNETCore-app.png" alt="alt text" title="Multi-threads in ASP.NET Core apps"></p><p>The specifics of the architecture are not exactly the same if you deploy your application into <em>IIS</em> or selfhosted by using <em>Kestrel</em>, but those differences are not important in this case.</p><p>The bottom line here is that when writing code for a multithreaded application such as ASP.NET Core services or apps <strong>your code and objects used in your code need to be <em>thread-safe</em> if the same object is going to be shared across multiple threads while updating data in-memory</strong>. The reason is because if you update data within the same shared object from multiple threads, those multiple threads can access to the same address space at the same time. So, they can write to the exact same memory location at the same time causing data corruption and application mal-function.</p><p>A code is called <em>thread-safe</em> if it is being called from multiple threads concurrently without the breaking of functionalities.</p><h3>This is usually not a problem in regular ASP.NET Core apps</h3><p>Usually, most of the code and objects you use in an ASP.NET Core WebAPI or app, for instance, objects you instanciate in a controller, are not shared across Http requests because the most common pattern is to use objects you create for each Http requests scope, either with <code>new</code> or with <a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-2.2#service-lifetimes" rel="nofollow" target="_blank">transient lifetime</a> when using dependency injection in .NET Core, as shown in the following image. Not a problem here:</p><p> <img src="https://github.com/CESARDELATORRE/MLNET-Posts/raw/master/Posts/001-Running-MLNET-Models-in-ASPNETCore/images/Transient-Objects-in-ASPNETCore-app.png" alt="alt text" title="Multi-threads in ASP.NET Core apps"></p><p>However, issues can happen if you share objects across threads, for example by using <a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/static-classes-and-static-class-members#static-members" rel="nofollow" target="_blank">static member variables</a> or <a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-2.2#service-lifetimes" rel="nofollow" target="_blank">singleton lifetime</a> objects in Dependency Injection, as explained later on in this post.</p><p>As you can check out on may ML.NET getting started samples at the <a href="https://github.com/dotnet/machinelearning-samples" target="_blank">ML.NET Samples GitHub repo</a>, the basic code you need for loading an already trained and serialized ML.NET model and do a single prediction with it (usually called ‘ML model scoring code’), is the following:</p><div id="crayon-5e3a42da44588397708248" data-settings=" minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="hide"></td><td><div><p><span>// (*Expensive*) Load ML model from serialized .zip file </span></p><p><span>ITransformer </span><span>mlModel</span><span>;</span></p><p><span>using</span><span> </span><span>(</span><span>var</span><span> </span><span>stream</span><span> </span>=<span> </span><span>new</span><span> </span><span>FileStream</span><span>(</span><span>modelFilePath</span><span>,</span><span> </span><span>FileMode</span><span>.</span><span>Open</span><span>,</span><span> </span><span>FileAccess</span><span>.</span><span>Read</span><span>,</span><span> </span><span>FileShare</span><span>.</span><span>Read</span><span>)</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>mlModel</span><span> </span>=<span> </span><span>mlContext</span><span>.</span><span>Model</span><span>.</span><span>Load</span><span>(</span><span>stream</span><span>)</span><span>;</span></p><p><span>}</span></p><p><span>// Create sample data to do a single prediction with it </span></p><p><span>SampleObservation </span><span>sampleData</span><span> </span>=<span> </span><span>CreateMySingleDataSample</span><span>(</span><span>)</span><span>;</span></p><p><span>// (*Expensive*) Create Prediction Engine</span></p><p><span>var</span><span> </span><span>predictionEngine</span><span> </span>=<span> </span><span>mlModel</span><span>.</span><span>CreatePredictionEngine</span><span>&lt;</span><span>SampleObservation</span><span>,</span><span> </span><span>SamplePrediction</span><span>&gt;</span><span>(</span><span>mlContext</span><span>)</span><span>;</span></p><p><span>// Try a single prediction</span></p><p><span>SamplePrediction </span><span>predictionResult</span><span> </span>=<span> </span><span>predictionEngine</span><span>.</span><span>Predict</span><span>(</span><span>sampleData</span><span>)</span><span>;</span></p></div></td></tr></tbody></table></div></div><p>This code looks very atraightforward and simple to use. If you just copy that code and run it on any application (console, desktop, web, etc.) it’ll work okay.</p><p>However, the lines of code marked with <code>(*Expensive*)</code> in the comments are object instantiations that are significantly ‘expensive’, meaning that it takes significant time to execute such as a few hundred miliseconds per each call if usign small models (i.e. half a second), but that can increase significantly depending on the size of the ML model.</p><h2>You need to improve your ML.NET model scoring code when targeting scalable apps</h2><p>As you would initially think, improving that execution for a multi-threaded application that will run multiple predictions could be as simple as ‘caching’ the ML model (<code>ITransformer</code>) object and the <code>PredictionEngine</code> object, so those objects are instantiaated just once and shared across the upcoming requests, right?</p><p>Well, that is partially true, but there are important caveats here and this is the reason why I created this blog post, precisely. 😉</p><p>Therefore, the first optimization you could do would be to cache in memory the ML model object that you loaded from the .zip file, so it can be re-used across many Http requests.</p><p>Since the <strong>ML model (ITransformer) object is <em>thread-safe</em></strong>, this is not an issue and can be done very easily.</p><p>The recommended way to share the ITransfomer object across Http requests is to register it as <a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-2.2#service-lifetimes" rel="nofollow" target="_blank">singleton lifetime</a> object in your IoC container for Dependency Injection usage, as shown in the code below:</p><div id="crayon-5e3a42da44596399022293" data-settings=" minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="hide"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p></div></td><td><div><p><span>Startup</span><span>.</span><span>cs</span></p><p><span>public</span><span> </span><span>void</span><span> </span><span>ConfigureServices</span><span>(</span><span>IServiceCollection </span><span>services</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//..Other code..</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>// Register Types in IoC container for DI</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//MLContext created as singleton for the whole ASP.NET Core app</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>services</span><span>.</span><span>AddSingleton</span><span>&lt;</span><span>MLContext</span><span>&gt;</span><span>(</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//ML Model (ITransformed) created as singleton for the whole ASP.NET Core app. Loads from .zip file here.</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>services</span><span>.</span><span>AddSingleton</span><span>&lt;</span><span>ITransformer</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>TransformerChain</span><span>&lt;</span><span>ITransformer</span><span>&gt;</span><span>&gt;</span><span> </span><span>(</span><span>(</span><span>ctx</span><span>)</span><span> </span>=<span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>MLContext </span><span>mlContext</span><span> </span>=<span> </span><span>ctx</span><span>.</span><span>GetRequiredService</span><span>&lt;</span><span>MLContext</span><span>&gt;</span><span>(</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>string</span><span> </span><span>modelFilePathName</span><span> </span>=<span> </span><span>Configuration</span><span>[</span><span>"MLModel:MLModelFilePath"</span><span>]</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>ITransformer </span><span>mlModel</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>using</span><span> </span><span>(</span><span>var</span><span> </span><span>fileStream</span><span> </span>=<span> </span><span>File</span><span>.</span><span>OpenRead</span><span>(</span><span>modelFilePathName</span><span>)</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>mlModel</span><span> </span>=<span> </span><span>mlContext</span><span>.</span><span>Model</span><span>.</span><span>Load</span><span>(</span><span>fileStream</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>(</span><span>TransformerChain</span><span>&lt;</span><span>ITransformer</span><span>&gt;</span><span>)</span><span> </span><span>mlModel</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//..Other code..</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><p>Okay, that would be ready for you so you can inject and use the ML model (ITransformer) object on any object, for instance, by injecting it into any controller’s constructor, like in the following code:</p><div id="crayon-5e3a42da445a3739671300" data-settings=" minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="hide"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p></div></td><td><div><p><span>MyController</span><span>.</span><span>cs</span></p><p><span>[</span><span>Route</span><span>(</span><span>"api/[controller]"</span><span>)</span><span>]</span></p><p><span>[</span><span>ApiController</span><span>]</span></p><p><span>public</span><span> </span><span>class</span><span> </span><span>MyController</span><span> </span><span>:</span><span> </span><span>ControllerBase</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>private</span><span> </span><span>readonly </span><span>MLContext </span><span>_mlContext</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>private</span><span> </span><span>readonly </span><span>ITransformer </span><span>_mlModel</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>public</span><span> </span><span>MyController</span><span>(</span><span>MLContext </span><span>mlContext</span><span>,</span><span> </span><span>ITransformer </span><span>mlModel</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>// Get the injected objects</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>_mlContext</span><span> </span>=<span> </span><span>mlContext</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>_mlModel</span><span> </span>=<span> </span><span>mlModel</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//...Other code using the ML model (ITransformer) object...</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><p>If later on, you create a <code>PredictionEngine</code> object whenever you need to call <code>predictionEngine.Predict()</code>, either by explicitely creating it with <code>new</code> or registering it as <code>Transient</code> lifetime, that would be safe in ASP.NET Core.</p><p>This is approximately the approach taken by this ML.NET tutorial named <a href="https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/serve-model-web-api-ml-net" rel="nofollow" target="_blank">How-To: Serve Machine Learning Model Through ASP.NET Core Web API</a></p><p>However, you can do a lot better because with that initial approach it won’t be fully optimized since whenever you get an Http request you’ll be creating a new <code>PredictionEngine</code> object which, as previously mentioned, is also a pretty ‘expensive’ operation for scalable applications.</p><p>For achieving better performance in your application when predicting simultaneosuly from multiple threads (like when you handle multiple Http requests from many users) you will need, somehow, to cache the <code>PredictionEngine</code> object. But as mentioned, there are important caveats and problems here to solve.</p><p>This approach requires some more coding and complexity (Object Pooling) for several reasons. So, before talking about its design and related implementation, let’s talk about the problem to solve.</p><h2>The problem when running/scoring an ML.NET model in multi-threaded applications</h2><p>The problem when running/scoring an ML.NET model in multi-threaded applications comes when you want to do single predictions with the PredictionEngine object and you want to cache that object (i.e. as Singleton) so it is being reused by multiple Http requests (therefore it would be accessed by multiple threads). That’s is a problem because <strong>the Prediction Engine is not thread-safe</strong> (<a href="https://github.com/dotnet/machinelearning/issues/1718" target="_blank">ML.NET issue, Nov 2018</a>).</p><p>Here’s a diagram showing the important ML.NET classes you need to use, the dependecies between them and what kind of object lifetimes are recommended:</p><p><img src="https://github.com/CESARDELATORRE/MLNET-Posts/raw/master/Posts/001-Running-MLNET-Models-in-ASPNETCore/images/MLNET-classes-dependencies-for-scoring.png" alt="alt text" title="ML.NET classes dependencies for scoring code with prediction engine"></p><p>If you register the Prediction Engine object as Singleton or Static, you will get into trouble because it is not thread-safe.</p><p>You could then think, okay, let’s make it static while thread-safe with the <a href="https://docs.microsoft.com/en-us/dotnet/api/system.threadstaticattribute?view=netcore-2.2" rel="nofollow" target="_blank">[ThreadStatic] attribute</a>? – Well, using the <code>[ThreadStatic]</code> attribute in ASP.NET apps is pretty dangerous. It might initially look that it is working, but write some async code (async/await) in your code and it’ll probably stop working. Also, the mainstream approach for object’s lifetime in ASP.NET Core is to use DI (Dependency Injection). Using static objects usage sometimes and DI other times would be very confusing, as well.</p><p>If you want to learn more about it, see <a href="https://github.com/aspnet/AspNetCore/issues/1371" target="_blank">this discussion with David Fowler</a> recommending not to use <code>[ThreadStatic]</code> in ASP.NET Core apps.</p><p>Other possible approaches could be to use <a href="https://docs.microsoft.com/en-us/dotnet/standard/threading/overview-of-synchronization-primitives" rel="nofollow" target="_blank">multi-threading synchronization primitives</a> such as <em>critical sections</em>, <em>locks</em>, <em>mutex</em>, etc., but those locks would create a bottleneck in your code which won’t be optimized for high-scalable scenarios.</p><h2>The solution: Use Object Pooling for PredictionEngine objects</h2><p>Since a PredictionEngine object cannot be singleton because it is not ‘thread safe’, a good solution for being able to have ‘ready to use’ PredictionEngine objects  is to use an object pooling-based approach.</p><p>When it is necessary to work with a number of objects that are particularly expensive to instantiate and each object is only needed for a short period of time, the performance of an entire application may be adversely affected. This issue will happen if you instantiate a Prediction Engine object whenever you get an Http request.</p><p>An object pool design pattern can be very effective in such cases.</p><p>The <a href="https://en.wikipedia.org/wiki/Object_pool_pattern" rel="nofollow" target="_blank">object pool pattern</a> is a design pattern that uses a set of initialized objects kept ready to use (a ‘pool’) rather than allocating and destroying them on demand.</p><p>This ‘pooling strategy; is also applicable to othe ‘expensive creation resources’ like database connections and connection pool solution.</p><p>The solution’s implementation is based on a higher level class (named MLModelEngine) which is instantiated as singleton and creates the needed infrastructure for such an object pool solution, as shown in the following diagram.</p><p><img src="https://github.com/CESARDELATORRE/MLNET-Posts/raw/master/Posts/001-Running-MLNET-Models-in-ASPNETCore/images/MLModelEngine-class-Diagram.png" alt="alt text" title="MLModelEngine class diagram"></p><p>This approach achieves the original goal mentioned at the begining of this article by offering a very simple interface for making predictions: <code>.Predict()</code>, like the following line of code that you could write on any ASP.NET Core controller’s method or custom service class:</p><div id="crayon-5e3a42da445b1116475310" data-settings=" minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="hide"></td><td><div><p><span>SamplePrediction </span><span>prediction</span><span> </span>=<span> </span><span>_modelEngine</span><span>.</span><span>Predict</span><span>(</span><span>sampleData</span><span>)</span><span>;</span></p></div></td></tr></tbody></table></div></div><h2>Implementing the MLModelEngine and object pool</h2><p>The class MLModelEngine has three main member objects:</p><ul><li><code>MLContext</code> member object.<ul><li>Singleton, since MLModelEngine will be used as singleton</li></ul></li><li><code>ITransformer</code> member object. This is the ML model.<ul><li>Singleton, since MLModelEngine will be used as singleton</li></ul></li><li><code>ObjectPool&lt;PredictionEngine&gt;</code> member object: Object Pool of PredictionEngine objects.<ul><li>The ObjectPool is singleton, but each PredictionEngine within the pool will only be used by one thread when needed, then will be returned to the pool when the prediction is done.</li></ul></li></ul><p>The MLModelEngine class implementation is as follows:</p><div id="crayon-5e3a42da445bf036080010" data-settings=" minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="hide"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p><p>41</p><p>42</p><p>43</p><p>44</p><p>45</p><p>46</p><p>47</p><p>48</p><p>49</p><p>50</p><p>51</p><p>52</p><p>53</p><p>54</p><p>55</p><p>56</p><p>57</p><p>58</p><p>59</p><p>60</p><p>61</p><p>62</p><p>63</p><p>64</p><p>65</p><p>66</p><p>67</p><p>68</p><p>69</p><p>70</p><p>71</p><p>72</p><p>73</p><p>74</p><p>75</p><p>76</p></div></td><td><div><p><span>MLModelEngine</span><span>.</span><span>cs</span></p><p><span>public</span><span> </span><span>class</span><span> </span><span>MLModelEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span> </span><span>:</span><span> </span><span>IMLModelEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>where </span><span>TData</span><span> </span><span>:</span><span> </span><span>class</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>where </span><span>TPrediction</span><span> </span><span>:</span><span> </span><span>class</span><span>,</span><span> </span><span>new</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>private</span><span> </span><span>readonly </span><span>MLContext </span><span>_mlContext</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>private</span><span> </span><span>readonly </span><span>ITransformer </span><span>_mlModel</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>private</span><span> </span><span>readonly </span><span>ObjectPool</span><span>&lt;</span><span>PredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span>&gt;</span><span> </span><span>_predictionEnginePool</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>private</span><span> </span><span>readonly </span><span>int</span><span> </span><span>_maxObjectsRetained</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>/// &lt;summary&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>/// Exposing the ML model allowing additional ITransformer operations such as Bulk predictions', etc.</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>/// &lt;/summary&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>public</span><span> </span><span>ITransformer</span><span> </span><span>MLModel</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>get</span><span> </span>=<span>&gt;</span><span> </span><span>_mlModel</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>/// &lt;summary&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>/// Constructor with modelFilePathName to load from</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>/// &lt;/summary&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>public</span><span> </span><span>MLModelEngine</span><span>(</span><span>string</span><span> </span><span>modelFilePathName</span><span>,</span><span> </span><span>int</span><span> </span><span>maxObjectsRetained</span><span> </span>=<span> </span>-<span>1</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//Create the MLContext object to use under the scope of this class </span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>_mlContext</span><span> </span>=<span> </span><span>new</span><span> </span><span>MLContext</span><span>(</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//Load the ProductSalesForecast model from the .ZIP file</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>using</span><span> </span><span>(</span><span>var</span><span> </span><span>fileStream</span><span> </span>=<span> </span><span>File</span><span>.</span><span>OpenRead</span><span>(</span><span>modelFilePathName</span><span>)</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>_mlModel</span><span> </span>=<span> </span><span>_mlContext</span><span>.</span><span>Model</span><span>.</span><span>Load</span><span>(</span><span>fileStream</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>_maxObjectsRetained</span><span> </span>=<span> </span><span>maxObjectsRetained</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//Create PredictionEngine Object Pool</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>_predictionEnginePool</span><span> </span>=<span> </span><span>CreatePredictionEngineObjectPool</span><span>(</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>private</span><span> </span><span>ObjectPool</span><span>&lt;</span><span>PredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span>&gt;</span><span> </span><span>CreatePredictionEngineObjectPool</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>var</span><span> </span><span>predEnginePolicy</span><span> </span>=<span> </span><span>new</span><span> </span><span>PooledPredictionEnginePolicy</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span>(</span><span>_mlContext</span><span>,</span><span> </span><span>_mlModel</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>DefaultObjectPool</span><span>&lt;</span><span>PredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span>&gt;</span><span> </span><span>pool</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>_maxObjectsRetained</span><span> </span><span>!</span>=<span> </span>-<span>1</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>pool</span><span> </span>=<span> </span><span>new</span><span> </span><span>DefaultObjectPool</span><span>&lt;</span><span>PredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span>&gt;</span><span>(</span><span>predEnginePolicy</span><span>,</span><span> </span><span>_maxObjectsRetained</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>else</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//default maximumRetained is Environment.ProcessorCount * 2, if not explicitly provided</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>pool</span><span> </span>=<span> </span><span>new</span><span> </span><span>DefaultObjectPool</span><span>&lt;</span><span>PredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span>&gt;</span><span>(</span><span>predEnginePolicy</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>pool</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>public</span><span> </span><span>TPrediction </span><span>Predict</span><span>(</span><span>TData </span><span>dataSample</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//Get PredictionEngine object from the Object Pool</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>PredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span> </span><span>predictionEngine</span><span> </span>=<span> </span><span>_predictionEnginePool</span><span>.</span><span>Get</span><span>(</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>try</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//Predict</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>TPrediction </span><span>prediction</span><span> </span>=<span> </span><span>predictionEngine</span><span>.</span><span>Predict</span><span>(</span><span>dataSample</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>prediction</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>finally</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//Release used PredictionEngine object into the Object Pool</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>_predictionEnginePool</span><span>.</span><span>Return</span><span>(</span><span>predictionEngine</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><p>What’s related to the MLContext and ITransformer objects is pretty straightforward. The ‘special code’ here is related to the Object Pool.</p><h3>Object Pool implementation: ObjectPool</h3><p>The implementation of the object pool is not using a custom object pool approach but an official class provided by Microsoft in the <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.objectpool" rel="nofollow" target="_blank">Microsoft.Extensions.ObjectPool namespace</a> which is part of .NET Core.</p><p>The object pool class used is the <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.objectpool.objectpool-1" rel="nofollow" target="_blank">ObjectPool</a>, so we can use it as:</p><div id="crayon-5e3a42da445cd109255857" data-settings=" minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="hide"></td><td><div><p><span>ObjectPool</span><span>&lt;</span><span>PredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span>&gt;</span><span> </span><span>_predictionEnginePool</span><span>;</span></p></div></td></tr></tbody></table></div></div><p>Meaning an object pool of <code>PredictionEngine</code> objects using generics so you can provide your particular <code>SampleObservation</code> and <code>SamplePrediction</code> data classes.</p><p>The object pool usage is pretty straightforward in the Predict() method:</p><div id="crayon-5e3a42da445e0160441135" data-settings=" minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="hide"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p></div></td><td><div><p><span>public</span><span> </span><span>TPrediction </span><span>Predict</span><span>(</span><span>TData </span><span>dataSample</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//Get PredictionEngine object from the Object Pool</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>PredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span> </span><span>predictionEngine</span><span> </span>=<span> </span><span>_predictionEnginePool</span><span>.</span><span>Get</span><span>(</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>try</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//Predict</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>TPrediction </span><span>prediction</span><span> </span>=<span> </span><span>predictionEngine</span><span>.</span><span>Predict</span><span>(</span><span>dataSample</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>prediction</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>finally</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//Release used PredictionEngine object into the Object Pool</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>_predictionEnginePool</span><span>.</span><span>Return</span><span>(</span><span>predictionEngine</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><p>Basically, whenever the Predict() method is called, you take a PredictionEngine from the pool, use it to predict and then return it to the pool so it is available for any upcoming request.</p><p>If there’s not any PredictionEngine object available in the pool (that will happen the first time you use the pool or if under pressure with many Http requests), then the pool needs to create a PredictionEngine object.</p><p>Basically, you have now to solve the following question:</p><p><em>“How do you tell the object pool how the PredictionEngine object has to be created whenever a new instance is needed in the object pool?”</em></p><p>You do that by using an ObjectPool <em>Policy</em> specified when creating the object pool in the <code>CreatePredictionEngineObjectPool()</code> method which is run once from the constructor, as in the following simplified code:</p><div id="crayon-5e3a42da445ee288476983" data-settings=" minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="hide"></td><td><div><p><span>private</span><span> </span><span>ObjectPool</span><span>&lt;</span><span>PredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span>&gt;</span><span> </span><span>CreatePredictionEngineObjectPool</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>var</span><span> </span><span>predEnginePolicy</span><span> </span>=<span> </span><span>new</span><span> </span><span>PooledPredictionEnginePolicy</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span>(</span><span>_mlContext</span><span>,</span><span> </span><span>_mlModel</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>var</span><span> </span><span>pool</span><span>&nbsp;&nbsp;</span>=<span> </span><span>new</span><span> </span><span>DefaultObjectPool</span><span>&lt;</span><span>PredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span>&gt;</span><span>(</span><span>predEnginePolicy</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>pool</span><span>;</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><p>Then, in the Policy class you define how the PredictionEngine will be created, which is by invoking our ‘well known’ <code>ITransformer.CreatePredictionEngine()</code> method:</p><div id="crayon-5e3a42da445fb612601911" data-settings=" minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="hide"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p></div></td><td><div><p><span>public</span><span> </span><span>class</span><span> </span><span>PooledPredictionEnginePolicy</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span> </span><span>:</span><span> </span><span>IPooledObjectPolicy</span><span>&lt;</span><span>PredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>where </span><span>TData</span><span> </span><span>:</span><span> </span><span>class</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>where </span><span>TPrediction</span><span> </span><span>:</span><span> </span><span>class</span><span>,</span><span> </span><span>new</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>private</span><span> </span><span>readonly </span><span>MLContext </span><span>_mlContext</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>private</span><span> </span><span>readonly </span><span>ITransformer </span><span>_model</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>public</span><span> </span><span>PooledPredictionEnginePolicy</span><span>(</span><span>MLContext </span><span>mlContext</span><span>,</span><span> </span><span>ITransformer </span><span>model</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>_mlContext</span><span> </span>=<span> </span><span>mlContext</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>_model</span><span> </span>=<span> </span><span>model</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>public</span><span> </span><span>PredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span> </span><span>Create</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>var</span><span> </span><span>predictionEngine</span><span> </span>=<span> </span><span>_model</span><span>.</span><span>CreatePredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span>(</span><span>_mlContext</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>predictionEngine</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>public</span><span> </span><span>bool</span><span> </span><span>Return</span><span>(</span><span>PredictionEngine</span><span>&lt;</span><span>TData</span><span>,</span><span> </span><span>TPrediction</span><span>&gt;</span><span> </span><span>obj</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>obj</span><span> </span>==<span> </span><span>null</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>false</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>true</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><h2>Registering the MLModelEngine class as singleton for DI (Dependency Injection)</h2><p>For using this system in your ASP.NET Core WebAPI or web app you just need to register the MLModelEngine class as singleton in the DI system through the <code>services</code> collection at the <code>Startup.cs</code> like in the following code:</p><div id="crayon-5e3a42da44608454013015" data-settings=" minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="hide"></td><td><div><p><span>public</span><span> </span><span>void</span><span> </span><span>ConfigureServices</span><span>(</span><span>IServiceCollection </span><span>services</span><span>)</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>// ...Other code...</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>// Register as singleton in the IoC container for DI</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>services</span><span>.</span><span>AddSingleton</span><span>&lt;</span><span>MLModelEngine</span><span>&lt;</span><span>SampleObservation</span><span>,</span><span> </span><span>SamplePrediction</span><span>&gt;</span><span>&gt;</span><span>(</span><span>(</span><span>ctx</span><span>)</span><span> </span>=<span>&gt;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>string</span><span> </span><span>modelFilePathName</span><span> </span>=<span> </span><span>GetAbsolutePath</span><span>(</span><span>Configuration</span><span>[</span><span>"MLModel:MLModelFilePath"</span><span>]</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>new</span><span> </span><span>MLModelEngine</span><span>&lt;</span><span>SampleObservation</span><span>,</span><span> </span><span>SamplePrediction</span><span>&gt;</span><span>(</span><span>modelFilePathName</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span><span>)</span><span>;</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><p>Since we need the filepath pointing to the model’s .ZIP, we’re using a lambda function as a factory to be able to provide that info to the constructor.</p><h2>Using the injected MLModelEngine object from your WebAPI controllers to make predictions</h2><p>Using the injected MLModelEngine object from your WebAPI controllers to make predictions is very simple.</p><p>First, the MLModelEngine object is injected in the controller’s constructor.</p><p>Second, you simple use it by calling the .Predict() method, as in the following controller’s code for a sentiment prediction example:</p><div id="crayon-5e3a42da44615724126042" data-settings=" minimize scroll-mouseover wrap"><div><table><tbody><tr><td data-settings="hide"><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p></div></td><td><div><p><span>[</span><span>Route</span><span>(</span><span>"api/[controller]"</span><span>)</span><span>]</span></p><p><span>[</span><span>ApiController</span><span>]</span></p><p><span>public</span><span> </span><span>class</span><span> </span><span>PredictorController</span><span> </span><span>:</span><span> </span><span>ControllerBase</span></p><p><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>private</span><span> </span><span>readonly </span><span>MLModelEngine</span><span>&lt;</span><span>SampleObservation</span><span>,</span><span> </span><span>SamplePrediction</span><span>&gt;</span><span> </span><span>_modelEngine</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>public</span><span> </span><span>PredictorController</span><span>(</span><span>MLModelEngine</span><span>&lt;</span><span>SampleObservation</span><span>,</span><span> </span><span>SamplePrediction</span><span>&gt;</span><span> </span><span>modelEngine</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>// Get the ML Model Engine injected, for scoring</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>_modelEngine</span><span> </span>=<span> </span><span>modelEngine</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>// GET api/predictor/sentimentprediction?sentimentText=ML.NET is awesome!</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>[</span><span>HttpGet</span><span>]</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>[</span><span>Route</span><span>(</span><span>"sentimentprediction"</span><span>)</span><span>]</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>public</span><span> </span><span>ActionResult</span><span>&lt;</span><span>string</span><span>&gt;</span><span> </span><span>PredictSentiment</span><span>(</span><span>[</span><span>FromQuery</span><span>]</span><span>string</span><span> </span><span>sentimentText</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>{</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>SampleObservation </span><span>sampleData</span><span> </span>=<span> </span><span>new</span><span> </span><span>SampleObservation</span><span>(</span><span>)</span><span> </span><span>{</span><span> </span><span>SentimentText</span><span> </span>=<span> </span><span>sentimentText</span><span> </span><span>}</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>//Predict sentiment</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>SamplePrediction </span><span>prediction</span><span> </span>=<span> </span><span>_modelEngine</span><span>.</span><span>Predict</span><span>(</span><span>sampleData</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>retVal</span><span> </span>=<span> </span><span>prediction</span><span>.</span><span>IsToxic</span><span>.</span><span>ToString</span><span>(</span><span>)</span><span>;</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>}</span></p><p><span>}</span></p></div></td></tr></tbody></table></div></div><p>With that, we achieved our original goal of <em>‘making super simple to predict with an ML.NET model while having good performance in scalable ASP.NET Core apps’</em> thanks to the explained optimizations.</p><p>To recap, here’s a high level end-to-end architecture diagram of the Web API using the MLModelEngine with the Object Pool of PredictionEngine objects.</p><p><img src="https://github.com/CESARDELATORRE/MLNET-Posts/raw/master/Posts/001-Running-MLNET-Models-in-ASPNETCore/images/WebAPI-MLModelEngine-Architecture.png" alt="alt text" title="End-to-end-simplified-architecture"></p><p>Feel free to provide your feedback if you implement this approach in your end-user applications.</p><p>Happy coding! 🙂</p><p><a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection" rel="nofollow" target="_blank">Dependency injection in ASP.NET Core</a></p><p><a href="https://docs.microsoft.com/en-us/dotnet/standard/threading/managed-threading-best-practices" rel="nofollow" target="_blank">Managed threading best practices</a></p><p><a href="https://docs.microsoft.com/en-us/dotnet/standard/threading/overview-of-synchronization-primitives" rel="nofollow" target="_blank">Overview of synchronization primitives</a></p><p><a href="https://docs.microsoft.com/en-us/dotnet/machine-learning/how-to-guides/single-predict-model-ml-net" rel="nofollow" target="_blank">Use the PredictionEngine to make one prediction at a time – ML.NET</a></p></div></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>