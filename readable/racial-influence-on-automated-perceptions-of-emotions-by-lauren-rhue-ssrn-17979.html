<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Racial Influence on Automated Perceptions of Emotions by Lauren Rhue :: SSRN - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Racial Influence on Automated Perceptions of Emotions by Lauren Rhue :: SSRN - linksfor.dev(s)"/>
    <meta property="article:author" content="See all articles by Lauren Rhue"/>
    <meta property="og:description" content="The practical applications of artificial intelligence are expanding into various elements of society, leading to a growing interest in the potential biases of s"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3281765"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Racial Influence on Automated Perceptions of Emotions by Lauren Rhue :: SSRN</title>
<div class="readable">
        <h1>Racial Influence on Automated Perceptions of Emotions by Lauren Rhue :: SSRN</h1>
            <div>by See all articles by Lauren Rhue</div>
            <div>Reading time: 3 minutes</div>
        <div>Posted here: 27 Apr 2019</div>
        <p><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3281765">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3281765</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
	
	
		
	

	
	
		
		
	

	
	
	
	
	
    
        
    

	

	
	<p>
		
		
			<span>11 Pages</span>
		
		

		<span>Posted: 6 Dec 2018</span>
		
			<span>Last revised: 17 Dec 2018</span>
		
		
				
	</p>
	
		<div>
			
			




	<h2><a href="https://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=1563757" target="_blank" title="View other papers by this author">Lauren Rhue</a></h2><p>University of Maryland - Robert H. Smith School of Business</p>

		</div>
	
	
	
	
	



	
	
	
	
		
		
	
	
		
			<p>Date Written: November 9, 2018</p>
		
	

	
	
		
		
		
		
		
	

	
	
		
	
	<div>
		<h3>Abstract</h3>
		<div><p>The practical applications of artificial intelligence are expanding into various elements of society, leading to a growing interest in the potential biases of such algorithms. Facial analysis, one application of artificial intelligence, is increasingly used in real-word situations. For example, some organizations tell candidates to answer predefined questions in a recorded video and use facial recognition to analyze the potential applicant faces. In addition, some companies are developing facial recognition software to scan the faces in crowds and assess threats, specifically mentioning doubt and anger as emotions that indicate threats.  </p><p>This study provides evidence that facial recognition software interprets emotions differently based on the person’s race. Using a publically available data set of professional basketball players’ pictures, I compare the emotional analysis from two different facial recognition services, Face   and Microsoft's Face API. Both services interpret black players as having more negative emotions than white players; however, there are two different mechanisms. Face   consistently interprets black players as angrier than white players, even controlling for their degree of smiling. Microsoft registers contempt instead of anger, and it interprets black players as more contemptuous when their facial expressions are ambiguous. As the players’ smile widens, the disparity disappears. </p><p>This finding has implications for individuals, organizations, and society, and it contributes to the growing literature of bias and/or disparate impact in AI. </p></div>
	</div>
	

	<center>
		
		


	

	
	

		
		

	
	


	</center>

	
	
	
		
	
	
	

	
	
		
		
			
				
			
		
		<p><strong>Keywords:</strong> artificial intelligence, race, bias, econometrics, coarsened exact matching, facial recognition</p>
	
	

		

	
	
	

	
	

	
	




	








	



























    	
	
		
	
	
	
   	
	
	
	
	
	            
	

















	








	







	



    

	


	<p>
		<strong>Suggested Citation:</strong>
		<a href="#">Suggested Citation<i></i></a>
	</p>

	
	

	
	
	

	
	

	
	
		
	

	
	
	
</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
		<div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>