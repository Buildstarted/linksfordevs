<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Making CPU configuration better for GC on machines with &gt; 64 CPUs | .NET Blog - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Making CPU configuration better for GC on machines with &gt; 64 CPUs | .NET Blog - linksfor.dev(s)"/>
    <meta property="article:author" content="Maoni StephensFollow Maoni"/>
    <meta property="og:description" content="If you are running Windows on a machine with 64 CPUs, you&#x2019;ll need to use this feature called the CPU groups for your process to be able to use more than 64 CPUs. At some point in the far distant past,"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://blogs.msdn.microsoft.com/maoni/2019/04/03/making-cpu-configuration-better-for-gc-on-machines-with-64-cpus/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Making CPU configuration better for GC on machines with &gt; 64 CPUs | .NET Blog</title>
<div class="readable">
        <h1>Making CPU configuration better for GC on machines with &gt; 64 CPUs | .NET Blog</h1>
            <div>by Maoni StephensFollow Maoni</div>
            <div>Reading time: 6-8 minutes</div>
        <div>Posted here: 03 Apr 2019</div>
        <p><a href="https://blogs.msdn.microsoft.com/maoni/2019/04/03/making-cpu-configuration-better-for-gc-on-machines-with-64-cpus/">https://blogs.msdn.microsoft.com/maoni/2019/04/03/making-cpu-configuration-better-for-gc-on-machines-with-64-cpus/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="featured"><div><div><div><div><p><img src="https://devblogs.microsoft.com/dotnet/wp-content/uploads/sites/10/2019/05/twitter-profile-150x150.jpg" width="58" height="58" alt="maoni"></p><p>Maoni</p></div></div></div><p>April 3rd, 2019</p><p>If you are running Windows on a machine with &gt; 64 CPUs, you’ll need to use this feature called the CPU groups for your process to be able to use more than 64 CPUs. At some point in the far distant past, people thought having more than 64 processors on a machine was inconceivable so they used a 64-bit number for the processor mask. And when 64-proc machines became available, Windows invented this <a href="https://docs.microsoft.com/en-us/windows/desktop/ProcThread/processor-groups" target="_blank">CPU group</a> concept for such machines which says processors are now belong to different CPU groups where each group has no more than 64 procs. Eg, on a machine with 96 procs you will see 2 groups with 48 procs each. When a process starts, it always starts in a single CPU group. The only way to use processors from other groups is for this process to set its thread affinity so it will run on processors from other groups. When machines with &gt; 64 procs became available, we added a config called <a href="https://docs.microsoft.com/en-us/dotnet/framework/configure-apps/file-schema/runtime/gccpugroup-element" target="_blank">GCCpuGroup</a>. The default for it is 0 (ie, enabled=false) meaning without this config, if you are using Server GC, the process would create at most N Server GC threads/heaps where N is the # of processors in the single group it started in. When this is set to 1, GC will create Server GC threads that span all active processors in all available CPU groups on the machine. Then our runtime started to run on Linux and with that we introduced an OS layer that GC calls via GCToOSInterface which abstracted away the OS functionalities GC needed, eg, VirtualAlloc and processor affinity. And we had our Linux OS layer simulated the Windows behavior. For the most part this was desired but there’s one thing that became more and more a thorny point – it’s the CPU group concept. Linux does not have this concept – if you have &gt; 64 processors you will get to use 64 procs without doing anything special. And we had to write all this code in our Linux OS layer to group processors into CPU groups. Recently we decided to pull the plug on this and no longer have Linux simulate the Windows behavior ‘cause we like the Linux behavior better for this particular case. I’ve been working with <a href="https://github.com/janvorli" target="_blank">Jan Vorlicek </a>on this (he’s doing all the work). The main pieces of this work are the following – 1) GC will no longer have the concept of CPU groups. Checks like this: </p><div id="gist95509502">
    <div>
      <div>
        <div>
  <div id="file-cpugroup-cpp">
    

  <div itemprop="text">
      
<table data-tab-size="8">
      <tbody><tr>
        <td id="file-cpugroup-cpp-L1" data-line-number="1"></td>
        <td id="file-cpugroup-cpp-LC1">        <span>if</span> (GCToOSInterface::CanEnableGCCPUGroups())</td>
      </tr>
      <tr>
        <td id="file-cpugroup-cpp-L2" data-line-number="2"></td>
        <td id="file-cpugroup-cpp-LC2">            <span>set_thread_group_affinity_for_heap</span>(heap-&gt;heap_number, &amp;affinity);</td>
      </tr>
      <tr>
        <td id="file-cpugroup-cpp-L3" data-line-number="3"></td>
        <td id="file-cpugroup-cpp-LC3">        <span>else</span></td>
      </tr>
      <tr>
        <td id="file-cpugroup-cpp-L4" data-line-number="4"></td>
        <td id="file-cpugroup-cpp-LC4">            <span>set_thread_affinity_mask_for_heap</span>(heap-&gt;heap_number, &amp;affinity);</td>
      </tr>
      <tr>
        <td id="file-cpugroup-cpp-L5" data-line-number="5"></td>
        <td id="file-cpugroup-cpp-LC5">
</td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      
    </div>
</div><p>
 will be removed. If the process needs to use &gt; 64 procs it will be handled by the OS layer automatically. In fact, we are even thinking about changing the default of the GCCpuGroup from 0 to 1 so on coreclr on Windows you will no longer need to specify this config to have your process using more than 64 processors. As always, we welcome your feedback on this. 2) Previously, I explained the <span color="blue">GCHeapAffinitizeMask</span> config in my blog. Since that’s also a 64-bit number (on 64-bit OSs), it was designed for the single CPU group case. We are adding a new config, <span color="blue">GCHeapAffinitizeRanges</span>, that allows you to specify processor ranges instead of a mask and it allows you to specify more than 64 procs if you wish. From Jan’s <a href="https://github.com/dotnet/coreclr/pull/23537" target="_blank">PR</a>:</p><pre><span>// Unix:</span><span>
</span><span>//  The cpu index ranges is a comma separated list of indices or ranges of indices (e.g. 1-5).</span><span>
</span><span>//  Example 1,3,5,7-9,12</span><span>
</span><span>// Windows:</span><span>
</span><span>//  The cpu index ranges is a comma separated list of group-annotated indices or ranges of indices.</span><span>
</span><span>//  The group number always prefixes index or range and is followed by colon.</span><span>
</span><span>//  Example 0:1,0:3,0:5,1:7-9,1:12</span></pre><p>We need different formats for Windows and Linux because Windows simply does not expose global indices of processors – they have to be relative to the group they belong to. Previously on Windows, if you specified an affinity mask it would simply be ignored when you also specified to use CPU groups. With the new</p><p><span color="blue">GCHeapAffinitizeRanges</span> config you will be able to specify any processors on the machine, whether it has more than 64 procs or not, and whether you want to have your process use more than 64 procs or not. On Windows, if we do change the default of <span color="blue">GCCpuGroup</span> to 1, it means you will automatically using processors in all CPU groups. And if you want the previous behavior you can just set <span color="blue">GCCpuGroup</span> to 0. So our proposed new behavior would be –<br> *   When <span color="blue">GCCpuGroup</span> is 0, we read the <span color="blue">GCHeapAffinitizeMask</span> config;<br> *   When <span color="blue">GCCpuGroup</span> is 1, we read the <span color="blue">GCHeapAffinitizeRanges</span> config.<br> * <span color="blue">GCCpuGroup</span> will be default to 1 and only be applicable on Windows.  Specifically –</p><p><span color="blue">On Windows</span> <span face="Lucida Console"></span></p><ul><li><span face="Lucida Console"> When <span color="blue">GCCpuGroup</span> is 1, <span color="blue">GCHeapAffinitizeRanges</span> will be used to pick the processors to run on and <span color="blue">GCHeapAffinitizeMask</span> is ignored.</span></li><li><span face="Lucida Console"> When <span color="blue">GCCpuGroup</span> is 0 (default), <span color="blue">GCHeapAffinitizeMask</span> will be used to pick the processors within the CPU group the process runs in, and <span color="blue">GCHeapAffinitizeRanges</span> is ignored</span></li></ul><p><span color="blue">On Linux</span> <span face="Lucida Console"></span></p><ul><span face="Lucida Console"> Our Linux OS layer will not have the CPU group concept anymore (all code there will be removed). So the <span color="blue">GCCpuGroup</span> config is ignored on Linux, which *also* means the <span color="blue">GCHeapAffinitizeMask</span> config is ignored. Note that on 2.2 and prior, our Linux OS layer only supported running on the first 64 procs that you process is allowed to run on. So essentially it was run with always <span color="blue">GCCpuGroup</span> as false. The new behavior will always automatically use &gt; 64 procs and you can use the <span color="blue">GCHeapAffinitizeRanges</span> config to specify &lt;= 64 procs if you wish.</span></ul><p> Curious minds will also notice in the vicinity of the</p><p><span color="blue">GCCpuGroup</span> config in src\clrconfigvalues.h there’s a config called <span color="blue">GCNumaAware</span>. This was added the same time when we added the <span color="blue">GCCpuGroup</span> config. By default we always enabled NUMA. This means we allocate memory on the proper NUMA node and when we do heap balancing we will try to balance allocations to heaps that live on the same NUMA node first before we look at heaps on remote nodes. I’m thinking of just getting rid of this config altogether – we had it for testing when we made GC NUMA aware years ago but I don’t see any reason why anyone would want to be NUMA unware so there’s no need for it anymore.</p><p>EDIT on 04/04/2019 – we needed 2 different formats for on Windows and Linux for the GCHeapAffinitizeRanges config.<br> EDIT on 09/23/2019 – on Windows we kept the default as disabled for GCCpuGroup.</p></div></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>