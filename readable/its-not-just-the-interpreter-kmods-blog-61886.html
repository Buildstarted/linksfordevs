<!DOCTYPE html>
<html lang="en">
<head>
    <title>
it&#x2019;s not just the interpreter &#xAB; kmod&#x27;s blog - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="it&#x2019;s not just the interpreter &#xAB; kmod&#x27;s blog - linksfor.dev(s)"/>
    <meta property="og:description" content="19May/203"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="http://blog.kevmod.com/2020/05/python-performance-its-not-just-the-interpreter/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - it&#x2019;s not just the interpreter &#xAB; kmod&#x27;s blog</title>
<div class="readable">
        <h1>it&#x2019;s not just the interpreter &#xAB; kmod&#x27;s blog</h1>
            <div>Reading time: 9-12 minutes</div>
        <div>Posted here: 20 May 2020</div>
        <p><a href="http://blog.kevmod.com/2020/05/python-performance-its-not-just-the-interpreter/">http://blog.kevmod.com/2020/05/python-performance-its-not-just-the-interpreter/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="post-1037">
<p><span><span>19</span>May/20</span><span><a href="http://blog.kevmod.com/2020/05/python-performance-its-not-just-the-interpreter/#comments">3</a></span></p>
<h2><a title="Python performance: it’s not just the interpreter" href="http://blog.kevmod.com/2020/05/python-performance-its-not-just-the-interpreter/" rel="bookmark">Python performance: it’s not just the interpreter</a></h2>
<p>I have a particular view of Python performance from my experience on the <a href="https://blog.pyston.org/">Pyston</a>&nbsp;project, and since this view is somewhat nonstandard I wanted to take some time to explain it and give a motivating example.</p>
<p><a href="https://www.tutorialspoint.com/why-is-python-slower-than-other-languages">A</a> <a href="https://hackernoon.com/why-is-python-so-slow-e5074b6fe55b">common</a> <a href="https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/">explanation</a> for Python's low performance is that it is an interpreted language.&nbsp; In this post I hope to show that while the interpreter adds overhead, it is not the dominant factor for even a small microbenchmark.&nbsp; Instead we'll see that dynamic features -- particularly, features inside the runtime -- are to blame.</p>
<p>People often consider the interpreter and runtime together since they are tightly linked and are included together, but in the context of Python optimization they are somewhat different.  There isn't an official delineation between the two, but in my mind the Python interpreter is the code in ceval.c which evaluates and dispatches Python opcodes.  (You may also consider the parser and compiler as part of the interpreter, but they are typically ignored.)  The runtime is the code that implements Python semantics.  It surprises some people that the interpreter knows relatively little about how Python objects behave: it simply knows that a BINARY_ADD opcode corresponds to a call to the runtime PyNumber_Add function.  (It does have some fast paths for common cases but those still largely call into the runtime for their implementation.)</p>
<p>There have been many attempts to optimize the Python interpreter, which aim to eliminate the bytecode dispatching and temporary variable management overheads.  In contrast, this post is about the potential gains from optimizing the execution of Python semantics.</p>
<h3>tldr</h3>
<p>In this particular microbenchmark, the time goes to:</p>
<ul>
<li>31% argument passing</li>
<li>31% "real work"</li>
<li>13% int boxing</li>
<li>11% interpreter overhead</li>
<li>8% recursion-limit checking</li>
<li>6% dynamic type checking</li>
</ul>
<p>[I've excluded some "easily avoidable" overheads from this list.]</p>
<p>I picked a particular microbenchmark that I knew had inefficient argument passing, but it's still interesting to see that that cost is almost 3x the cost of using an interpreter.  I was also surprised that recursion-limit checking played such a role since it is not often mentioned.</p>
<p>I'm calling argument passing a "dynamic feature" because in this case it is completely avoidable.  Python argument passing can be expensive because it requires packing up arguments into a tuple allocated for this purpose, as well as interpretation of a format string to determine how to parse the arguments on the callee side.</p>
<h3>The microbenchmark</h3>
<p>I've collected these numbers from a simple microbenchmark which&nbsp;I pulled from a real-world use case (django templating); I'm not claiming that it's particularly representative, just that it's illustrative and an interesting data point.</p>
<p>Typically a program's performance is analyzed by running a profiler to see what parts of the program take the most time.  I'm going to take a bit of a different approach: I'm going to iteratively optimize the benchmark and see how much each optimization helps.  I believe this gives a much clearer view of the cost of each feature that we optimize away, as well as providing hints as to what it would take to do these optimizations automatically.</p>
<p>The benchmark is converting numbers to strings, which in Python is remarkably expensive for reasons we'll get into.&nbsp;The motivation for this is to imagine that you have a template with many variables in it, all of which need to be converted to strings for rendering.</p>
<p>Here's the <a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str00.py">code</a>:</p>
<div><ol start="1"><li><span><span>def</span><span>&nbsp;main():&nbsp;&nbsp;</span></span></li><li><span>&nbsp;<span>for</span><span>&nbsp;j&nbsp;</span><span>in</span><span>&nbsp;range(</span><span>20</span><span>):&nbsp;&nbsp;</span></span></li><li><span>&nbsp;&nbsp;&nbsp;<span>for</span><span>&nbsp;i&nbsp;</span><span>in</span><span>&nbsp;range(</span><span>1000000</span><span>):&nbsp;&nbsp;</span></span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;str(i)&nbsp;&nbsp;</span></li><li><span>main()&nbsp;&nbsp;</span></li></ol></div>
<p>(You can find all the versions on my <a href="https://github.com/kmod/nitrous/tree/sum/python/test/str">github</a>)</p>
<p>The doubly-nested loops will become handy later.</p>
<p>In terms of methodology, I'm simply running all of these benchmarks on my development machine, doing three runs of each benchmark and reporting the median.  The performance differences are pretty stark so we don't need extremely precise or accurate benchmarking, so I kept it simple.  Unless mentioned otherwise, I'm running all benchmarks via my Ubuntu-provided python3 binary, which is Python 3.7.3.</p>
<h3>Results</h3>
<p>On my machine, the benchmark takes <b>2.33s</b></p>
<p>We can do a <a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str01.py">simple optimization</a>: referencing <code>str</code> every iteration of the loop forces the interpreter to do a somewhat-expensive global variable lookup, which is slower than a local variable lookup.  We can cache the <code>str</code> object into a local variable, and this brings the benchmark down to <b>2.07s</b>.</p>
<p>The next goal is to move the for loop out of Python and into C, and in this case we can do that with the <code>map()</code> function.  <a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str04.py">The benchmark is now</a></p>
<div><ol start="1"><li><span><span>for</span><span>&nbsp;j&nbsp;</span><span>in</span><span>&nbsp;range(</span><span>20</span><span>):&nbsp;&nbsp;</span></span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;list(map(str,&nbsp;range(<span>1000000</span><span>)))&nbsp;&nbsp;</span></span></li></ol></div>
<p>This version does more work since it is creating a list of all the strings.  Perhaps surprisingly, the wins from removing the interpreter almost outweigh this extra work, and this new version comes in at <b>2.11s</b></p>
<p>As a point of reference, if we <a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str03.py">create the same list via a list comprehension</a>, the benchmark takes <b>2.34s</b>.  The optimization from 2.34s to 2.11s by using map lets us calculate the "interpreter overhead" as 10% of the program's execution.  10% is large in many situations, but is not nearly enough to explain Python's reputation for being slow.</p>
<p>To proceed further, we're going to need to move into C extension territory. I ran Cython (a Python-&gt;C converter) on the previous benchmark, and <a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str04_cython.c">it</a> runs in exactly the same amount of time: <b>2.11s</b>.  I wrote a <a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str05.c">simplified C extension</a> in 36 lines compared to Cython's 3600, and it too runs in <b>2.11s</b>. [The variance in the benchmark runs is about 0.03s, so getting the same exact median time seems lucky.]</p>
<p>For reference here's the C <a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str05.c">code</a>.</p>
<div><ol start="1"><li><span><span>for</span><span>&nbsp;(</span><span>int</span><span>&nbsp;i&nbsp;=&nbsp;0;&nbsp;i&nbsp;&lt;&nbsp;20;&nbsp;i++)&nbsp;{&nbsp;&nbsp;</span></span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;PyObject*&nbsp;a&nbsp;=&nbsp;PyTuple_Pack(1,&nbsp;PyLong_FromLong(1000000));&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;PyObject*&nbsp;r&nbsp;=&nbsp;PyObject_Call((PyObject*)&amp;PyRange_Type,&nbsp;a,&nbsp;NULL);&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;Py_DECREF(a);&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;=&nbsp;PyTuple_Pack(2,&nbsp;(PyObject*)&amp;PyUnicode_Type,&nbsp;r);&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;Py_DECREF(r);&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;PyObject*&nbsp;m&nbsp;=&nbsp;PyObject_Call((PyObject*)&amp;PyMap_Type,&nbsp;a,&nbsp;NULL);&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;Py_DECREF(a);&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;a&nbsp;=&nbsp;PyTuple_Pack(1,&nbsp;m);&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;Py_DECREF(m);&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;PyObject*&nbsp;l&nbsp;=&nbsp;PyObject_Call((PyObject*)&amp;PyList_Type,&nbsp;a,&nbsp;NULL);&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;Py_DECREF(a);&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;</span></li><li><span>&nbsp;&nbsp;&nbsp;&nbsp;Py_DECREF(l);&nbsp;&nbsp;</span></li><li><span>}&nbsp;&nbsp;</span></li></ol></div>
<p><a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str06.c">The next thing I did</a> was to eliminate the list again, and simply iterate through the map object.  This brings the time down to <b>1.86s</b></p>
<p><a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str07.c">Then I included and inlined the map iteration function</a>.  This didn't affect the runtime, which is now <b>1.87s</b>.</p>
<p><a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str08.c">The next thing to optimize</a> is the feature that <code>map()</code> can take a variable number of arguments, which slows down its processing slightly.  Hard-coding that this map has exactly one argument reduces the time slightly to <b>1.82s</b>.</p>
<p>The <a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str10.c">next thing I did</a> is to hoist some of the map iteration code out of the loop: map_next() typically has to reread the relevant variables from memory every iteration, so I thought doing that once outside the loop would help.  Surprisingly the runtime is the same: <b>1.82s</b>.</p>
<p><a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str11.c">Next I copied</a> and inlined <code>_PyObject_FastCallDict</code> and <code>rangeiter_next</code>.  Surprisingly, switching to the copied version of <code>_PyObject_FastCallDict</code> slowed the program down noticeably, to <b>1.88s</b>.  My hypothesis is that this is because my extension module doesn't have PGO enabled, whereas I believe the Ubuntu Python build does have PGO enabled, so the copied code now has fewer optimizations.</p>
<p><a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str12.c">Next I optimized</a> <code>_PyObject_FastCallDict</code> for this particular case, removing some checks that are constant once we know the function we are calling.  This simulates static typing, or speculative type inference in the case of a JIT.  This didn't make much of a difference: <b>1.87s</b>.</p>
<p>Now we're getting to the heart of the problem.  <code>str()</code> is slow because it's not a function: it's a type.  And types in Python have complex calling behavior since they execute Python's two-phase construction, allowing overrides at each step.  This is rather unfortunate for common type conversions, since they do not do much work but invoke fairly expensive constructor behavior.  <a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str16.c">I inlined type_call as well as unicode_new</a>, and the performance is roughly the same: <b>1.86s</b>.</p>
<p>Now that we have all the code in one place, we can see both the argument packing and parsing+unpacking.  Python has a traditional calling convention, and a faster newer calling convention.  Unfortunately calling a type falls back to the slower calling convention, requiring the allocation of an args tuple, and parsing it on the receiving side.  <a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str19.c">I optimized</a> the current benchmark by hard-coding the argument parsing.  This had a large impact: the runtime is now <b>1.46s</b>.</p>
<p><a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str21.c">I inlined <code>PyObject_Str</code></a>, and this again slowed performance down: <b>1.52s</b>.  Again, I think this is due to the lack of PGO.</p>
<p><a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str24.c">Next I optimized</a> based on the assumption that <code>str(int)</code> returns a string object.  This reduced the runtime to <b>1.40s</b></p>
<p>Now that we've removed enough code we can finally make another big optimization: <a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str25.c">no longer allocating the args tuple</a>  This cuts runtime down to <b>1.15s</b>.</p>
<p><a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str25.c">Next</a> I hoisted the recursion-checking code out of the loop: <b>0.98s</b></p>
<p><a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str27.c">Including and inlining long_to_decimal_string</a>: <b>0.94s</b></p>
<p><a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str28.c">Converting the range iteration to a C for loop</a>: <b>0.91s</b></p>
<p><a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str29.c">Removing the unicode conversion (the real work)</a>: <b>0.27s</b></p>
<p><a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str30.c">Not allocating a Python int for each iteration of the loop</a>: <b>0.0s</b></p>
<p>So that's everything</p>
<p>For reference: NodeJS takes <b>1.38s</b> to run an <a href="https://github.com/kmod/nitrous/blob/sum/python/test/str/str.js">equivalent benchmark</a>.  And impressively, PyPy [PyPy3 v7.3.1] only takes <b>0.31s</b> to run the original version of the benchmark.  So not only do they get rid of most of the overheads, but they are significantly faster at unicode conversion as well.</p>
<h3>To be continued...</h3>
<p>I believe that these findings point towards a certain direction for Python optimization.  I have some ideas in this space and hopefully you'll hear more about them on this blog!</p>







</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>