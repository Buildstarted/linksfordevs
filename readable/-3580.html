<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Wayve &#x2014; Learning to drive in a day - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Wayve &#x2014; Learning to drive in a day - linksfor.dev(s)"/>
    <meta property="article:author" content="Alex Kendall"/>
    <meta property="og:description" content="The first example of deep reinforcement learning on-board an autonomous car."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://wayve.ai/blog/learning-to-drive-in-a-day-with-reinforcement-learning"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">ðŸŽ‰</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Wayve &#x2014; Learning to drive in a day</title>
<div class="readable">
        <h1>Wayve &#x2014; Learning to drive in a day</h1>
            <div>by Alex Kendall</div>
            <div>Reading time: 7-8 minutes</div>
        <div>Posted here: 27 Feb 2019</div>
        <p><a href="https://wayve.ai/blog/learning-to-drive-in-a-day-with-reinforcement-learning">https://wayve.ai/blog/learning-to-drive-in-a-day-with-reinforcement-learning</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout" id="yui_3_17_2_1_1581879406012_115" data-controllers-bound="AncillaryLayout">
      

      

      <div id="yui_3_17_2_1_1581879406012_114">

        

        <div id="yui_3_17_2_1_1581879406012_113">
          

          <main id="yui_3_17_2_1_1581879406012_112">
            
              <section data-content-field="main-content" id="yui_3_17_2_1_1581879406012_111">
                <article id="post-5adc49eb0e2e722020070343" data-item-id="5adc49eb0e2e722020070343">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1524386316681" id="item-5adc49eb0e2e722020070343"><div id="yui_3_17_2_1_1581879406012_110"><div id="yui_3_17_2_1_1581879406012_109"><div data-block-type="2" id="block-yui_3_17_2_1_1530232652839_87523"><p><h3>The first example of deep reinforcement learning on-board an autonomous car.</h3></p></div><div><div><div data-block-type="2" id="block-058ff62a6230a2fabf8f"><div><p>Do you remember learning to ride a bicycle as a child? Excited and mildly anxious, you probably sat on a bicycle for the first time and pedalled while an adult hovered over you, prepared to catch you if you lost balance. After some wobbly attempts, you perhaps managed to balance for a few metres. Several hours in, you probably were zipping around the park on gravel and grass alike.</p><p>The adult would have only given you brief tips along the way. You did not need a dense 3D map of the park nor a high fidelity laser on your head. You did not need a long list of rules to follow to be able to balance on the bicycle. The adult simply gave you a safe environment for you to <strong>learn</strong> how to map what you see to what you should do, to successfully ride a bicycle.</p><p>Todayâ€™s self-driving cars have been packed with a large array of sensors, and are <strong>told</strong> how to drive with a long list of carefully hand-engineered rules through slow development cycles. In this blogpost, we go back to basics, and let a car <strong>learn</strong> to follow a lane from scratch, with clever trial and error, much like how you learnt to ride a bicycle. Have a look at what we did:</p></div></div></div></div><div><div><div data-block-json="{&quot;blockAnimation&quot;:&quot;none&quot;,&quot;layout&quot;:&quot;caption-hidden&quot;,&quot;overlay&quot;:false,&quot;description&quot;:{&quot;html&quot;:&quot;&quot;,&quot;raw&quot;:false},&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;html&quot;:&quot;<iframe src=\&quot;//www.youtube.com/embed/eRwTbRtnT1I?wmode=opaque&amp;amp;enablejsapi=1\&quot; height=\&quot;480\&quot; width=\&quot;854\&quot; scrolling=\&quot;no\&quot; frameborder=\&quot;0\&quot; allowfullscreen=\&quot;\&quot;>\n</iframe>&quot;,&quot;url&quot;:&quot;https://www.youtube.com/watch?v=eRwTbRtnT1I&quot;,&quot;thumbnailUrl&quot;:&quot;https://i.ytimg.com/vi/eRwTbRtnT1I/hqdefault.jpg&quot;,&quot;resolvedBy&quot;:&quot;youtube&quot;}" data-block-type="32" id="block-yui_3_17_2_1_1529703246970_3845"><div id="yui_3_17_2_1_1581879406012_62"><div data-html="<iframe src=&quot;//www.youtube.com/embed/eRwTbRtnT1I?wmode=opaque&amp;enablejsapi=1&quot; height=&quot;480&quot; width=&quot;854&quot; scrolling=&quot;no&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;><br/></iframe>" data-provider-name="" id="yui_3_17_2_1_1581879406012_69"><div><p><iframe src="https://www.youtube.com/embed/eRwTbRtnT1I?wmode=opaque&amp;enablejsapi=1" height="480" width="854" scrolling="no" frameborder="0" allowfullscreen="" id="yui_3_17_2_1_1581879406012_73"><br/></iframe></p></div></div></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1530392641518_73575"><p>In just 15-20 minutes, we were able to teach a car to follow a lane from scratch, only by using when the safety driver took over as training feedback.</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1530392641518_65464"><p><h3>No dense 3D map.<br>No hand-written rules.</h3></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1529703246970_25509"><div><p>This is the first example where an autonomous car has learnt online, getting better with every trial. So, how did we do it?</p><p>We adapted a popular model-free deep reinforcement learning algorithm (deep deterministic policy gradients, DDPG) to solve the lane following task. Our model input was a single monocular camera image. Our system iterated through 3 processes: exploration, optimisation and evaluation.</p></div></div></div></div><div id="yui_3_17_2_1_1581879406012_108"><div id="yui_3_17_2_1_1581879406012_107"><div data-block-type="5" id="block-yui_3_17_2_1_1530272075168_52114"><div id="yui_3_17_2_1_1581879406012_106">
  
  

    
      <div id="yui_3_17_2_1_1581879406012_105">
      
        <div id="yui_3_17_2_1_1581879406012_104">
          
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530527738286-ERWS06EBGJYY1Y8EGB96/ke17ZwdGBToddI8pDm48kINEacJFbtissQyGVIU9k6R7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmhfyonCSWcqU7nHWetMij8mCO2TOWGmaxeFBrc3NSper7zhyDDd4KmPrV1Ab8mCtB/ltdiad_training_flow_v5.png" data-image="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530527738286-ERWS06EBGJYY1Y8EGB96/ke17ZwdGBToddI8pDm48kINEacJFbtissQyGVIU9k6R7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmhfyonCSWcqU7nHWetMij8mCO2TOWGmaxeFBrc3NSper7zhyDDd4KmPrV1Ab8mCtB/ltdiad_training_flow_v5.png" data-image-dimensions="1395x1273" data-image-focal-point="0.5,0.5" data-load="false" data-image-id="5b39fff870a6ad2e8ae70595" data-type="image" alt="ltdiad_training_flow_v5.png" data-image-resolution="750w" src="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530527738286-ERWS06EBGJYY1Y8EGB96/ke17ZwdGBToddI8pDm48kINEacJFbtissQyGVIU9k6R7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTmhfyonCSWcqU7nHWetMij8mCO2TOWGmaxeFBrc3NSper7zhyDDd4KmPrV1Ab8mCtB/ltdiad_training_flow_v5.png?format=750w">
            </p>
          

          

        </div>
      
      </div>
    

  


</div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1530235888717_57907"><p>Our network architecture was a deep network with 4 convolutional layers and 3 fully connected layers with a total of just under 10k parameters. For comparison, state of the art image classification architectures have 10s of millions of parameters.</p></div></div></div><div id="yui_3_17_2_1_1581879406012_135"><div id="yui_3_17_2_1_1581879406012_134"><div data-block-type="5" id="block-yui_3_17_2_1_1529703246970_33722"><div id="yui_3_17_2_1_1581879406012_133">
  
  

    
      <div id="yui_3_17_2_1_1581879406012_132">
      
        <div id="yui_3_17_2_1_1581879406012_131">
          
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530400789521-LOH4EXVSIR5YG6HRRWD4/ke17ZwdGBToddI8pDm48kKAL4VB4TfT6MwmlxJnRyCVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIE4DIzELIw-ZrHUyQ7wyKIdJyWqkfVyOzPA4hQYwOIUM/l2diad_model_compress.gif" data-image="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530400789521-LOH4EXVSIR5YG6HRRWD4/ke17ZwdGBToddI8pDm48kKAL4VB4TfT6MwmlxJnRyCVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIE4DIzELIw-ZrHUyQ7wyKIdJyWqkfVyOzPA4hQYwOIUM/l2diad_model_compress.gif" data-image-dimensions="800x426" data-image-focal-point="0.5,0.5" data-load="false" data-image-id="5b38100d70a6ad2e8ab4b45d" data-type="image" alt="l2diad_model_compress.gif" data-image-resolution="1000w" src="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530400789521-LOH4EXVSIR5YG6HRRWD4/ke17ZwdGBToddI8pDm48kKAL4VB4TfT6MwmlxJnRyCVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIE4DIzELIw-ZrHUyQ7wyKIdJyWqkfVyOzPA4hQYwOIUM/l2diad_model_compress.gif?format=1000w">
            </p>
          

          

        </div>
      
      </div>
    

  


</div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1530232652839_26832"><div><p>All processing was performed on one graphics processing unit (GPU) on-board the car.</p><p>Working on a real robot in a dangerous real environment poses many new problems. In order to better understand the task at hand and find suitable model architectures and hyperparameters, we did a lot of testing in simulation.</p></div></div></div></div><div id="yui_3_17_2_1_1581879406012_154"><div id="yui_3_17_2_1_1581879406012_153"><div data-block-type="5" id="block-yui_3_17_2_1_1530268686198_27045"><div id="yui_3_17_2_1_1581879406012_152">
  
  

    
      <div id="yui_3_17_2_1_1581879406012_151">
      
        <div id="yui_3_17_2_1_1581879406012_150">
          
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530271345948-JW80W7V0U156SK0HZ6Q5/ke17ZwdGBToddI8pDm48kCvj40u_wAoIO7Ukt9ezroMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcX6OYtiNLgNq2suwiRLE98le2JLS96fbF9GrlincLXAE0ISYsigSxs4TZYcEoxFgY/ningaloo_8+episodes_compressed.gif" data-image="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530271345948-JW80W7V0U156SK0HZ6Q5/ke17ZwdGBToddI8pDm48kCvj40u_wAoIO7Ukt9ezroMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcX6OYtiNLgNq2suwiRLE98le2JLS96fbF9GrlincLXAE0ISYsigSxs4TZYcEoxFgY/ningaloo_8+episodes_compressed.gif" data-image-dimensions="1020x255" data-image-focal-point="0.5,0.5" data-load="false" data-image-id="5b36160caa4a99232a668595" data-type="image" alt="ningaloo_8 episodes_compressed.gif" data-image-resolution="1000w" src="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530271345948-JW80W7V0U156SK0HZ6Q5/ke17ZwdGBToddI8pDm48kCvj40u_wAoIO7Ukt9ezroMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcX6OYtiNLgNq2suwiRLE98le2JLS96fbF9GrlincLXAE0ISYsigSxs4TZYcEoxFgY/ningaloo_8+episodes_compressed.gif?format=1000w">
            </p>
          

          

        </div>
      
      </div>
    

  


</div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1530232652839_46206"><p>Above is an example of our lane following simulated environment shown from different angles. The algorithm only sees the driver perspective i.e. the image with the teal border. At every episode, we randomly generate a curved lane to follow, as well as the road texture and lane markings. The agent explores until it leaves the lane, when the episode terminates. Then the policy optimises based on collected data and we repeat.</p></div></div></div><div id="yui_3_17_2_1_1581879406012_173"><div id="yui_3_17_2_1_1581879406012_172"><div data-block-type="5" id="block-yui_3_17_2_1_1530232652839_104326"><div id="yui_3_17_2_1_1581879406012_171">
  
  

    
      <div id="yui_3_17_2_1_1581879406012_170">
      
        <div id="yui_3_17_2_1_1581879406012_169">
          
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530570690258-OW9NYMY4HGBA285EQXU5/ke17ZwdGBToddI8pDm48kFRPJyVvlTv0jPELCb_4XtBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIiq40Ep27bL747XC7CMBidI7IVQL6umBuk1iJd06r6gU/car_results.png" data-image="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530570690258-OW9NYMY4HGBA285EQXU5/ke17ZwdGBToddI8pDm48kFRPJyVvlTv0jPELCb_4XtBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIiq40Ep27bL747XC7CMBidI7IVQL6umBuk1iJd06r6gU/car_results.png" data-image-dimensions="800x543" data-image-focal-point="0.5,0.5" data-load="false" data-image-id="5b3aa7a4562fa70eb7825260" data-type="image" alt="Distance travelled by the car before a safety driver takeover against number of exploration episodes." data-image-resolution="1000w" src="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530570690258-OW9NYMY4HGBA285EQXU5/ke17ZwdGBToddI8pDm48kFRPJyVvlTv0jPELCb_4XtBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIiq40Ep27bL747XC7CMBidI7IVQL6umBuk1iJd06r6gU/car_results.png?format=1000w">
            </p>
          

          

        </div>
      
      </div>
    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1530271017229_114987"><p><strong>Distance travelled by the car before&nbsp; a safety driver takeover against number of exploration episodes.</strong></p></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1530232652839_120038"><p>We used simulated tests to try out different neural network architectures and hyperparameters until we found settings which consistently solved the task of lane following in very few training episodes i.e. with little data. For example, one of our findings was that training the convolutional layers using an auto-encoder reconstruction loss significantly improved stability and data-efficiency of training. See our full technical report for more details.</p></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1530232652839_162184"><p><h3>The potential implications of our approach are huge.</h3></p></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1530232652839_163964"><div><p>Imagine deploying a fleet of autonomous cars, with a driving algorithm which initially is 95% the quality of a human driver. Such a system would not be wobbly like the randomly initialised model in our demonstration video, but rather would be almost capable of dealing with traffic lights, roundabouts, intersections, etc. After a full day of driving and on-line improvement from human-safety driver take over, perhaps the system would improve to 96%. After a week, 98%. After a month, 99%. After a few months, the system may be super-human, having benefited from the feedback of many different safety drivers.</p><p>Todayâ€™s self-driving cars are stuck at good but not good enough performance levels. Here, we have provided evidence for the first viable framework to quickly improving driving algorithms from being mediocre to being roadworthy. The ability to quickly learn to solve tasks through clever trial and error is what has made humans incredibly versatile machines capable of evolution and survival. We learn through a mixture of imitation, and lots of trial and error for everything from riding a bicycle, to learning how to cook.</p><p>DeepMind have shown us that deep reinforcement learning methods can lead to super-human performance in many games including Go, Chess and computer games, almost always outperforming any rule based system. We here show that a similar philosophy is also possible in the real world, and in particular, in autonomous vehicles. &nbsp;A crucial point to note is that DeepMindâ€™s Atari playing algorithms required millions of trials to solve a task. It is remarkable that we consistently learnt to lane-follow in under 20 trials.</p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1530232652839_174552"><div><h3>We learnt to follow lanes from scratch in 20 minutes.</h3><h3>Imagine what we could learn to do in a dayâ€¦?</h3><ul data-rte-list="default"><li></li></ul></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1530252673143_74828"><p>Wayve has a philosophy that to build robotic intelligence we do not need massive models, fancy sensors and endless data. What we need is a clever training process that learns rapidly and efficiently, like in our video above. Hand-engineered approaches to the self-driving problem have reached an unsatisfactory glass ceiling in performance. Wayve is attempting to unlock autonomous driving capabilities with smarter machine learning.</p></div></div></div><div id="yui_3_17_2_1_1581879406012_193"><div id="yui_3_17_2_1_1581879406012_192"><div data-block-type="5" id="block-yui_3_17_2_1_1530392641518_218903"><div id="yui_3_17_2_1_1581879406012_191">
  
  

    
      <div id="yui_3_17_2_1_1581879406012_190">
      
        <div id="yui_3_17_2_1_1581879406012_189">
          
            <a href="https://arxiv.org/pdf/1807.00412.pdf" target="_blank" id="yui_3_17_2_1_1581879406012_188">
          
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530394268926-0DPOCRPOQN2EE140VGNH/ke17ZwdGBToddI8pDm48kA8-Zwq0Rqesn4ppBK2-kEZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIW2c_ZYiQwpVYwAOsGG_ZunWkYgoDP7UnwJidTA-GQRoKMshLAGzx4R3EDFOm1kBS/paper.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530394268926-0DPOCRPOQN2EE140VGNH/ke17ZwdGBToddI8pDm48kA8-Zwq0Rqesn4ppBK2-kEZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIW2c_ZYiQwpVYwAOsGG_ZunWkYgoDP7UnwJidTA-GQRoKMshLAGzx4R3EDFOm1kBS/paper.jpg" data-image-dimensions="800x410" data-image-focal-point="0.5,0.5" data-load="false" data-image-id="5b37f69bf950b774333171d1" data-type="image" alt="paper.jpg" data-image-resolution="1000w" src="https://images.squarespace-cdn.com/content/v1/5ad2f82cb27e394f7bd1f1ed/1530394268926-0DPOCRPOQN2EE140VGNH/ke17ZwdGBToddI8pDm48kA8-Zwq0Rqesn4ppBK2-kEZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIW2c_ZYiQwpVYwAOsGG_ZunWkYgoDP7UnwJidTA-GQRoKMshLAGzx4R3EDFOm1kBS/paper.jpg?format=1000w">
            </p>
          
            </a>
          

          

        </div>
      
      </div>
    

  


</div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1530232652839_56287"><p><strong>Special thanks:</strong> We would like &nbsp;to thank <a href="https://streetdrone.com/">StreetDrone</a> for building us an awesome robotic vehicle, <a href="https://www.admiral.com/">Admiral</a> for insuring our vehicle trials and the <a href="http://www.haggisfarmpolo.com/">Cambridge Polo Club</a> for granting us access to their private land for our lane-following research.</p></div></div></div></div></div></div>

    

    

    

  </article>





  
              </section>
            
          </main>

        </div>
      </div>

      


    </div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
</body>
</html>