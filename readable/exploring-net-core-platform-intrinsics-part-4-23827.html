<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Exploring .NET Core platform intrinsics: Part 4 - Alignment and pipelining - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Exploring .NET Core platform intrinsics: Part 4 - Alignment and pipelining - linksfor.dev(s)"/>
    <meta property="og:description" content="Previous posts in the series:"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://mijailovic.net/2018/07/20/alignment-and-pipelining/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">ðŸŽ‰</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Exploring .NET Core platform intrinsics: Part 4 - Alignment and pipelining</title>
<div class="readable">
        <h1>Exploring .NET Core platform intrinsics: Part 4 - Alignment and pipelining</h1>
            <div>Reading time: 11-14 minutes</div>
        <div>Posted here: 16 May 2019</div>
        <p><a href="https://mijailovic.net/2018/07/20/alignment-and-pipelining/">https://mijailovic.net/2018/07/20/alignment-and-pipelining/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Previous posts in the series:</p>
<ul>
  <li><a href="https://mijailovic.net/2018/06/06/sha256-armv8/">Exploring .NET Core platform intrinsics: Part 1 - Accelerating SHA-256 on ARMv8</a></li>
  <li><a href="https://mijailovic.net/2018/06/18/aes-armv8/">Exploring .NET Core platform intrinsics: Part 2 - Accelerating AES encryption on ARMv8</a></li>
  <li><a href="https://mijailovic.net/2018/07/05/generated-code/">Exploring .NET Core platform intrinsics: Part 3 - Viewing the code generated by the JIT</a></li>
</ul>

<p>Youâ€™ve implemented some of your performance critical code using the
new platform intrinsics API. The code is now running 10x or even 100x
faster than before, and you might think that it canâ€™t get any faster.
This post will show you some less obvious (but almost universally
applicable) techniques for improving the performance even further.</p>

<h2 id="the-code">The code</h2>

<p>This time we are going to analyze the function that calculates the
sum of an array of integers:</p>

<div><div><pre><code><span>public</span> <span>static</span> <span>int</span> <span>Sum</span><span>(</span><span>int</span><span>[]</span> <span>source</span><span>)</span>
<span>{</span>
  <span>const</span> <span>int</span> <span>VectorSizeInInts</span> <span>=</span> <span>8</span><span>;</span>

  <span>fixed</span> <span>(</span><span>int</span><span>*</span> <span>ptr</span> <span>=</span> <span>&amp;</span><span>source</span><span>[</span><span>0</span><span>])</span>
  <span>{</span>
    <span>var</span> <span>pos</span> <span>=</span> <span>0</span><span>;</span>
    <span>var</span> <span>sum</span> <span>=</span> <span>Avx</span><span>.</span><span>SetZeroVector256</span><span>&lt;</span><span>int</span><span>&gt;();</span>

    <span>for</span> <span>(;</span> <span>pos</span> <span>&lt;=</span> <span>source</span><span>.</span><span>Length</span> <span>-</span> <span>VectorSizeInInts</span><span>;</span> <span>pos</span> <span>+=</span> <span>VectorSizeInInts</span><span>)</span>
    <span>{</span>
      <span>var</span> <span>current</span> <span>=</span> <span>Avx</span><span>.</span><span>LoadVector256</span><span>(</span><span>ptr</span> <span>+</span> <span>pos</span><span>);</span>
      <span>sum</span> <span>=</span> <span>Avx2</span><span>.</span><span>Add</span><span>(</span><span>current</span><span>,</span> <span>sum</span><span>);</span>
    <span>}</span>

    <span>var</span> <span>temp</span> <span>=</span> <span>stackalloc</span> <span>int</span><span>[</span><span>VectorSizeInInts</span><span>];</span>
    <span>Avx</span><span>.</span><span>Store</span><span>(</span><span>temp</span><span>,</span> <span>sum</span><span>);</span>

    <span>var</span> <span>final</span> <span>=</span> <span>Sum</span><span>(</span><span>temp</span><span>,</span> <span>VectorSizeInInts</span><span>);</span>
    <span>final</span> <span>+=</span> <span>Sum</span><span>(</span><span>ptr</span> <span>+</span> <span>pos</span><span>,</span> <span>source</span><span>.</span><span>Length</span> <span>-</span> <span>pos</span><span>);</span>

    <span>return</span> <span>final</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Nothing fancy hereâ€”it just follows the pattern that we see very often
when dealing with vectorized code. Letâ€™s see how well it performs.</p>

<h2 id="benchmarking-take-one">Benchmarking, take one</h2>

<p>We will measure how long it takes to sum an array of 32K integers.
Our benchmarking setup is going to be very simple:</p>

<div><div><pre><code><span>public</span> <span>class</span> <span>SumBenchmark</span>
<span>{</span>
  <span>private</span> <span>const</span> <span>int</span> <span>Length</span> <span>=</span> <span>32</span> <span>*</span> <span>1024</span><span>;</span>
  <span>private</span> <span>int</span><span>[]</span> <span>data</span><span>;</span>

  <span>[</span><span>GlobalSetup</span><span>]</span>
  <span>public</span> <span>void</span> <span>GlobalSetup</span><span>()</span>
  <span>{</span>
    <span>data</span> <span>=</span> <span>Enumerable</span><span>.</span><span>Range</span><span>(</span><span>0</span><span>,</span> <span>Length</span><span>).</span><span>ToArray</span><span>();</span>
  <span>}</span>

  <span>[</span><span>Benchmark</span><span>]</span>
  <span>public</span> <span>int</span> <span>Sum</span><span>()</span> <span>=&gt;</span> <span>FastMath</span><span>.</span><span>Sum</span><span>(</span><span>data</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This benchmark produces the following numbers on my machine:</p>

<table>
  <thead>
    <tr>
      <th>Method</th>
      <th>Mean</th>
      <th>Error</th>
      <th>StdDev</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Sum</td>
      <td>2.264 us</td>
      <td>0.0352 us</td>
      <td>0.0329 us</td>
    </tr>
  </tbody>
</table>

<p>The results look fantastic, beating the naive implementation
by one order of magnitude (if you are interested in the exact
numbers, take a look <a href="https://github.com/EgorBo/IntrinsicsPlayground#1-arraysum">here</a>).</p>

<p>You want to be sure that there are no variations, so you run
the benchmark several times to increase your confidence in the
results, but you get pretty much the same numbers on each run.
Is it time to call it a day? Not just yet: even though the
<strong>SumBenchmark</strong> class looks completely reasonable, it contains
one very subtle flaw.</p>

<h2 id="benchmarking-take-two">Benchmarking, take two</h2>

<p>Letâ€™s modify our benchmarking code slightly:</p>

<div><div><pre><code><span>[</span><span>GlobalSetup</span><span>]</span>
<span>public</span> <span>void</span> <span>GlobalSetup</span><span>()</span>
<span>{</span>
  <span>data1</span> <span>=</span> <span>Enumerable</span><span>.</span><span>Range</span><span>(</span><span>0</span><span>,</span> <span>Length</span><span>).</span><span>ToArray</span><span>();</span>
  <span>data2</span> <span>=</span> <span>Enumerable</span><span>.</span><span>Range</span><span>(</span><span>0</span><span>,</span> <span>Length</span><span>).</span><span>ToArray</span><span>();</span>
<span>}</span>

<span>[</span><span>Benchmark</span><span>(</span><span>Baseline</span> <span>=</span> <span>true</span><span>)]</span>
<span>public</span> <span>int</span> <span>Sum1</span><span>()</span> <span>=&gt;</span> <span>FastMath</span><span>.</span><span>Sum</span><span>(</span><span>data1</span><span>);</span>

<span>[</span><span>Benchmark</span><span>]</span>
<span>public</span> <span>int</span> <span>Sum2</span><span>()</span> <span>=&gt;</span> <span>FastMath</span><span>.</span><span>Sum</span><span>(</span><span>data2</span><span>);</span>
</code></pre></div></div>

<p>You would probably expect both <strong>Sum1</strong> and <strong>Sum2</strong> to
have the identical performance characteristics. After all, we are
calling the same function on two arrays with the exact same contents.
But if you run the benchmark, you will see that <strong>Sum2</strong> actually
performs 13% worse!</p>

<table>
  <thead>
    <tr>
      <th>Method</th>
      <th>Mean</th>
      <th>Error</th>
      <th>StdDev</th>
      <th>Scaled</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Sum1</td>
      <td>2.283 us</td>
      <td>0.0211 us</td>
      <td>0.0198 us</td>
      <td>1.00</td>
    </tr>
    <tr>
      <td>Sum2</td>
      <td>2.589 us</td>
      <td>0.0241 us</td>
      <td>0.0214 us</td>
      <td>1.13</td>
    </tr>
  </tbody>
</table>

<p>What is going on here?</p>

<h2 id="alignment">Alignment</h2>

<p>When working with most of AVX instructions, you initially have
to load the data from the memory into 32-byte registers. The CPU
does that in the most efficient way when the data is aligned in
memory on a 32-byte boundary. How does that apply to our situation?</p>

<p>In one of the runs of the modified benchmark, the <strong>data1</strong> array
was located at the address <strong>0x19aa99ce0</strong>, while the <strong>data2</strong> was
placed at <strong>0x19aab9d18</strong>. The first number is divisible by 32; the
second one is not. That was not just a coincidence: each time I ran
the benchmark, the first allocation ended up on a properly aligned
address, but the second one didnâ€™t (I guess that the heap segments
are aligned, which would mean that the first allocated object in the
program would also be aligned, but I didnâ€™t bother to check that
hypothesis, so it might be terribly wrong).</p>

<p>Dealing with an alignment is burdensome, which is why the
<strong>LoadVector256</strong> function works with any memory locationâ€”it
just works slower when the location is unaligned. There is
also another variant of <strong>Load</strong> function, called
<strong>LoadAlignedVector256</strong>, which works the same in the aligned
case (itâ€™s not any faster), but throws an exception if the
input is not aligned on a 32-byte boundary. Itâ€™s useful mostly
as a signal that its input is expected to be aligned.</p>

<p>There are no guarantees that our input array is always going to
be correctly aligned, so you might think that we canâ€™t do anything
about the performance in the unaligned case. Luckily, we donâ€™t have
to start processing the array from the first elementâ€”instead we can
find the first <em>aligned</em> element, and proceed from there (that
means we have to calculate the sum of previous elements manually).
To do that, we just have to round up the address of our array to
the nearest multiple of 32:</p>

<div><div><pre><code><span>var</span> <span>aligned</span> <span>=</span> <span>(</span><span>int</span><span>*)(((</span><span>ulong</span><span>)</span><span>ptr</span> <span>+</span> <span>31U</span><span>L</span><span>)</span> <span>&amp;</span> <span>~</span><span>31U</span><span>L</span><span>);</span>
<span>var</span> <span>pos</span> <span>=</span> <span>(</span><span>int</span><span>)(</span><span>aligned</span> <span>-</span> <span>ptr</span><span>);</span>
<span>var</span> <span>final</span> <span>=</span> <span>Sum</span><span>(</span><span>ptr</span><span>,</span> <span>pos</span><span>);</span>
</code></pre></div></div>

<p>The rest of the code remains the same (we can also replace the call
to <strong>LoadVector256</strong> with the call to <strong>LoadAlignedVector256</strong> in
order to catch potential bugs in our code more easily). We can now
expect the best-case performance on any input, but we still have to
confirm that in practice:</p>

<table>
  <thead>
    <tr>
      <th>Method</th>
      <th>Alignment</th>
      <th>Mean</th>
      <th>Error</th>
      <th>StdDev</th>
      <th>Scaled</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Sum</strong></td>
      <td><strong>8</strong></td>
      <td><strong>2.508 us</strong></td>
      <td><strong>0.0353 us</strong></td>
      <td><strong>0.0313 us</strong></td>
      <td><strong>1.00</strong></td>
    </tr>
    <tr>
      <td>SumAligned</td>
      <td>8</td>
      <td>2.260 us</td>
      <td>0.0106 us</td>
      <td>0.0082 us</td>
      <td>0.90</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td><strong>Sum</strong></td>
      <td><strong>32</strong></td>
      <td><strong>2.254 us</strong></td>
      <td><strong>0.0187 us</strong></td>
      <td><strong>0.0166 us</strong></td>
      <td><strong>1.00</strong></td>
    </tr>
    <tr>
      <td>SumAligned</td>
      <td>32</td>
      <td>2.264 us</td>
      <td>0.0256 us</td>
      <td>0.0227 us</td>
      <td>1.00</td>
    </tr>
  </tbody>
</table>

<p>We are indeed getting the expected 10% performance improvement on
unaligned arrays! Nothing spectacular, but we are not stopping there.</p>

<h2 id="pipelining">Pipelining</h2>

<p>Iâ€™ve already talked briefly about
<a href="https://mijailovic.net/2018/06/18/aes-armv8/#pipelining">pipelining</a>
in the second post of this series, so you might want to take a look at it
if you want to refresh your memory. Now letâ€™s see if itâ€™s possible to apply
it somehow in our <strong>Sum</strong> function. Hereâ€™s what the documentation for the
<a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm256_loadu_si256&amp;expand=3166">_mm256_loadu_si256</a> intrinsic says (the page for the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=_mm256_load_si256&amp;expand=3104">_mm256_load_si256</a>
is almost the same):</p>

<p><img src="https://mijailovic.net/assets/img/throughput.png" alt=""></p>

<p>The properties we are interested in are latency and throughput. We can
see that the instruction has a latency of 1, which means it takes one
CPU cycle to complete. What is more interesting is that it has a
throughput of 0.25 (except on Ivy Bridge, where its throughput is 0.5),
which is just another way of saying that we can issue four instructions
in the same cycle! It means that if we changed our code to process four
32-byte blocks of input at the same time, we could expect at least <em>some</em>
performance improvement. Hereâ€™s the modified version of the code:</p>

<div><div><pre><code><span>const</span> <span>int</span> <span>VectorSizeInInts</span> <span>=</span> <span>8</span><span>;</span>
<span>const</span> <span>int</span> <span>BlockSizeInInts</span> <span>=</span> <span>32</span><span>;</span>

<span>for</span> <span>(;</span> <span>pos</span> <span>&lt;=</span> <span>source</span><span>.</span><span>Length</span> <span>-</span> <span>BlockSizeInInts</span><span>;</span> <span>pos</span> <span>+=</span> <span>BlockSizeInInts</span><span>)</span>
<span>{</span>
  <span>var</span> <span>block0</span> <span>=</span> <span>Avx</span><span>.</span><span>LoadVector256</span><span>(</span><span>ptr</span> <span>+</span> <span>pos</span> <span>+</span> <span>0</span> <span>*</span> <span>VectorSizeInInts</span><span>);</span>
  <span>var</span> <span>block1</span> <span>=</span> <span>Avx</span><span>.</span><span>LoadVector256</span><span>(</span><span>ptr</span> <span>+</span> <span>pos</span> <span>+</span> <span>1</span> <span>*</span> <span>VectorSizeInInts</span><span>);</span>
  <span>var</span> <span>block2</span> <span>=</span> <span>Avx</span><span>.</span><span>LoadVector256</span><span>(</span><span>ptr</span> <span>+</span> <span>pos</span> <span>+</span> <span>2</span> <span>*</span> <span>VectorSizeInInts</span><span>);</span>
  <span>var</span> <span>block3</span> <span>=</span> <span>Avx</span><span>.</span><span>LoadVector256</span><span>(</span><span>ptr</span> <span>+</span> <span>pos</span> <span>+</span> <span>3</span> <span>*</span> <span>VectorSizeInInts</span><span>);</span>

  <span>sum</span> <span>=</span> <span>Avx2</span><span>.</span><span>Add</span><span>(</span><span>block0</span><span>,</span> <span>sum</span><span>);</span>
  <span>sum</span> <span>=</span> <span>Avx2</span><span>.</span><span>Add</span><span>(</span><span>block1</span><span>,</span> <span>sum</span><span>);</span>
  <span>sum</span> <span>=</span> <span>Avx2</span><span>.</span><span>Add</span><span>(</span><span>block2</span><span>,</span> <span>sum</span><span>);</span>
  <span>sum</span> <span>=</span> <span>Avx2</span><span>.</span><span>Add</span><span>(</span><span>block3</span><span>,</span> <span>sum</span><span>);</span>
<span>}</span>

<span>for</span> <span>(;</span> <span>pos</span> <span>&lt;=</span> <span>source</span><span>.</span><span>Length</span> <span>-</span> <span>VectorSizeInInts</span><span>;</span> <span>pos</span> <span>+=</span> <span>VectorSizeInInts</span><span>)</span>
<span>{</span>
  <span>var</span> <span>current</span> <span>=</span> <span>Avx</span><span>.</span><span>LoadVector256</span><span>(</span><span>ptr</span> <span>+</span> <span>pos</span><span>);</span>
  <span>sum</span> <span>=</span> <span>Avx2</span><span>.</span><span>Add</span><span>(</span><span>current</span><span>,</span> <span>sum</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Notice that after the first loop is completed, we might still
have several vector-sized blocks of data remaining, so we have
to run the original loop to process the rest. We are ready to
run the benchmark again:</p>

<table>
  <thead>
    <tr>
      <th>Method</th>
      <th>Alignment</th>
      <th>Mean</th>
      <th>Error</th>
      <th>StdDev</th>
      <th>Scaled</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Sum</strong></td>
      <td><strong>8</strong></td>
      <td><strong>2.556 us</strong></td>
      <td><strong>0.0144 us</strong></td>
      <td><strong>0.0121 us</strong></td>
      <td><strong>1.00</strong></td>
    </tr>
    <tr>
      <td>SumPipelined</td>
      <td>8</td>
      <td>2.116 us</td>
      <td>0.0189 us</td>
      <td>0.0168 us</td>
      <td>0.83</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td><strong>Sum</strong></td>
      <td><strong>32</strong></td>
      <td><strong>2.264 us</strong></td>
      <td><strong>0.0127 us</strong></td>
      <td><strong>0.0113 us</strong></td>
      <td><strong>1.00</strong></td>
    </tr>
    <tr>
      <td>SumPipelined</td>
      <td>32</td>
      <td>1.654 us</td>
      <td>0.0133 us</td>
      <td>0.0124 us</td>
      <td>0.73</td>
    </tr>
  </tbody>
</table>

<p>The results are looking great! The next obvious step is to
combine both alignment and pipelining in the same function.</p>

<h2 id="combined-solution">Combined solution</h2>

<p>Hereâ€™s the complete source code of the ultimate version
of the <strong>Sum</strong> function:</p>

<div><div><pre><code><span>public</span> <span>static</span> <span>int</span> <span>SumAlignedPipelined</span><span>(</span><span>int</span><span>[]</span> <span>source</span><span>)</span>
<span>{</span>
  <span>const</span> <span>ulong</span> <span>AlignmentMask</span> <span>=</span> <span>31U</span><span>L</span><span>;</span>
  <span>const</span> <span>int</span> <span>VectorSizeInInts</span> <span>=</span> <span>8</span><span>;</span>
  <span>const</span> <span>int</span> <span>BlockSizeInInts</span> <span>=</span> <span>32</span><span>;</span>

  <span>fixed</span> <span>(</span><span>int</span><span>*</span> <span>ptr</span> <span>=</span> <span>&amp;</span><span>source</span><span>[</span><span>0</span><span>])</span>
  <span>{</span>
    <span>var</span> <span>aligned</span> <span>=</span> <span>(</span><span>int</span><span>*)(((</span><span>ulong</span><span>)</span><span>ptr</span> <span>+</span> <span>AlignmentMask</span><span>)</span> <span>&amp;</span> <span>~</span><span>AlignmentMask</span><span>);</span>
    <span>var</span> <span>pos</span> <span>=</span> <span>(</span><span>int</span><span>)(</span><span>aligned</span> <span>-</span> <span>ptr</span><span>);</span>
    <span>var</span> <span>sum</span> <span>=</span> <span>Avx</span><span>.</span><span>SetZeroVector256</span><span>&lt;</span><span>int</span><span>&gt;();</span>
    <span>var</span> <span>final</span> <span>=</span> <span>Sum</span><span>(</span><span>ptr</span><span>,</span> <span>pos</span><span>);</span>

    <span>for</span> <span>(;</span> <span>pos</span> <span>&lt;=</span> <span>source</span><span>.</span><span>Length</span> <span>-</span> <span>BlockSizeInInts</span><span>;</span> <span>pos</span> <span>+=</span> <span>BlockSizeInInts</span><span>)</span>
    <span>{</span>
      <span>var</span> <span>block0</span> <span>=</span> <span>Avx</span><span>.</span><span>LoadAlignedVector256</span><span>(</span><span>ptr</span> <span>+</span> <span>pos</span> <span>+</span> <span>0</span> <span>*</span> <span>VectorSizeInInts</span><span>);</span>
      <span>var</span> <span>block1</span> <span>=</span> <span>Avx</span><span>.</span><span>LoadAlignedVector256</span><span>(</span><span>ptr</span> <span>+</span> <span>pos</span> <span>+</span> <span>1</span> <span>*</span> <span>VectorSizeInInts</span><span>);</span>
      <span>var</span> <span>block2</span> <span>=</span> <span>Avx</span><span>.</span><span>LoadAlignedVector256</span><span>(</span><span>ptr</span> <span>+</span> <span>pos</span> <span>+</span> <span>2</span> <span>*</span> <span>VectorSizeInInts</span><span>);</span>
      <span>var</span> <span>block3</span> <span>=</span> <span>Avx</span><span>.</span><span>LoadAlignedVector256</span><span>(</span><span>ptr</span> <span>+</span> <span>pos</span> <span>+</span> <span>3</span> <span>*</span> <span>VectorSizeInInts</span><span>);</span>

      <span>sum</span> <span>=</span> <span>Avx2</span><span>.</span><span>Add</span><span>(</span><span>block0</span><span>,</span> <span>sum</span><span>);</span>
      <span>sum</span> <span>=</span> <span>Avx2</span><span>.</span><span>Add</span><span>(</span><span>block1</span><span>,</span> <span>sum</span><span>);</span>
      <span>sum</span> <span>=</span> <span>Avx2</span><span>.</span><span>Add</span><span>(</span><span>block2</span><span>,</span> <span>sum</span><span>);</span>
      <span>sum</span> <span>=</span> <span>Avx2</span><span>.</span><span>Add</span><span>(</span><span>block3</span><span>,</span> <span>sum</span><span>);</span>
    <span>}</span>

    <span>for</span> <span>(;</span> <span>pos</span> <span>&lt;=</span> <span>source</span><span>.</span><span>Length</span> <span>-</span> <span>VectorSizeInInts</span><span>;</span> <span>pos</span> <span>+=</span> <span>VectorSizeInInts</span><span>)</span>
    <span>{</span>
      <span>var</span> <span>current</span> <span>=</span> <span>Avx</span><span>.</span><span>LoadAlignedVector256</span><span>(</span><span>ptr</span> <span>+</span> <span>pos</span><span>);</span>
      <span>sum</span> <span>=</span> <span>Avx2</span><span>.</span><span>Add</span><span>(</span><span>current</span><span>,</span> <span>sum</span><span>);</span>
    <span>}</span>

    <span>var</span> <span>temp</span> <span>=</span> <span>stackalloc</span> <span>int</span><span>[</span><span>VectorSizeInInts</span><span>];</span>
    <span>Avx</span><span>.</span><span>Store</span><span>(</span><span>temp</span><span>,</span> <span>sum</span><span>);</span>

    <span>final</span> <span>+=</span> <span>Sum</span><span>(</span><span>temp</span><span>,</span> <span>VectorSizeInInts</span><span>);</span>
    <span>final</span> <span>+=</span> <span>Sum</span><span>(</span><span>ptr</span> <span>+</span> <span>pos</span><span>,</span> <span>source</span><span>.</span><span>Length</span> <span>-</span> <span>pos</span><span>);</span>

    <span>return</span> <span>final</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>And here are the final results:</p>

<table>
  <thead>
    <tr>
      <th>Method</th>
      <th>Alignment</th>
      <th>Mean</th>
      <th>Error</th>
      <th>StdDev</th>
      <th>Scaled</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Sum</strong></td>
      <td><strong>8</strong></td>
      <td><strong>2.501 us</strong></td>
      <td><strong>0.0284 us</strong></td>
      <td><strong>0.0251 us</strong></td>
      <td><strong>1.00</strong></td>
    </tr>
    <tr>
      <td>SumAligned</td>
      <td>8</td>
      <td>2.271 us</td>
      <td>0.0257 us</td>
      <td>0.0241 us</td>
      <td>0.91</td>
    </tr>
    <tr>
      <td>SumPipelined</td>
      <td>8</td>
      <td>2.103 us</td>
      <td>0.0276 us</td>
      <td>0.0258 us</td>
      <td>0.84</td>
    </tr>
    <tr>
      <td>SumAlignedPipelined</td>
      <td>8</td>
      <td>1.645 us</td>
      <td>0.0126 us</td>
      <td>0.0118 us</td>
      <td>0.66</td>
    </tr>
    <tr>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td><strong>Sum</strong></td>
      <td><strong>32</strong></td>
      <td><strong>2.255 us</strong></td>
      <td><strong>0.0243 us</strong></td>
      <td><strong>0.0227 us</strong></td>
      <td><strong>1.00</strong></td>
    </tr>
    <tr>
      <td>SumAligned</td>
      <td>32</td>
      <td>2.277 us</td>
      <td>0.0288 us</td>
      <td>0.0269 us</td>
      <td>1.01</td>
    </tr>
    <tr>
      <td>SumPipelined</td>
      <td>32</td>
      <td>1.661 us</td>
      <td>0.0219 us</td>
      <td>0.0205 us</td>
      <td>0.74</td>
    </tr>
    <tr>
      <td>SumAlignedPipelined</td>
      <td>32</td>
      <td>1.653 us</td>
      <td>0.0063 us</td>
      <td>0.0056 us</td>
      <td>0.73</td>
    </tr>
  </tbody>
</table>

<p>The <strong>SumAlignedPipelined</strong> shows a noticeable improvement over
the initial <strong>Sum</strong>: we are getting a 27% boost in performance
if the data is 32-byte aligned, and 34% if itâ€™s not.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Youâ€™ve seen how some very simple techniques can help you speed
up your intrinsics code with almost no effort. The complete C#
implementation of these performance exercises can be found in
my <a href="https://github.com/Metalnem/alignment-and-pipelining">alignment and pipelining</a> GitHub repository.</p>


  </div>
</article>

      </div>
    </div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>