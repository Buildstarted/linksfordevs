<!DOCTYPE html>
<html lang="en">
<head>
    <title>linksfor.dev(s)</title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">üéâ</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <div class="readable">
        <h1>Fixing Random, part 26</h1>
        <p>
Reading time: 7-9 minutes        </p>
        <p><a href="https://ericlippert.com/2019/04/29/fixing-random-part-26/">https://ericlippert.com/2019/04/29/fixing-random-part-26/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
		<p data-adtags-visited="true">We‚Äôve been mostly looking at small, discrete distributions in this series, but we started this series by looking at continuous distributions. Now that we have some understanding of how to solve probability problems on simple discrete distributions and Markov processes, let‚Äôs go back to continuous distributions and see if we can apply some of these learnings to them. (Code for this episode can be found <a href="https://github.com/ericlippert/probability/tree/episode26">here</a>.)</p>
<p data-adtags-visited="true">Let‚Äôs start with the basics. What exactly do we mean by a <em>probability distribution function</em>? So far in this series we‚Äôve mostly looked at the discrete analog, a <em>non-normalized probability mass function</em>. That is, for an <code>IDiscreteDistribution&lt;T&gt;</code> we have a weight function that gives us a value for each <code>T</code>. The probability of sampling a particular <code>T</code> is the weight divided by the total weight of all <code>T</code>s.</p>
<p data-adtags-visited="true">Of course, had we decided to go with double weights instead of integers, we could have made a normalized probability mass function: that is, the ‚Äúweight‚Äù of each particular <code>T</code> is automatically divided by the total weight, and we get the probability out. In this scenario, the total weight adds up to 1.0.</p>
<p data-adtags-visited="true">We know from our exploration of the weighted integer distribution that we can think of our probability distributions as making a rectangle where various sub-rectangles are associated with particular values; we then ‚Äúthrow a dart‚Äù at the rectangle to sample from the distribution; where it lands gives us the sample.</p>
<p data-adtags-visited="true">Continuous distributions can be thought of in much the same way. Suppose we have a function from double to double, always non-negative, such that the total area under the curve is 1.0. Here are some examples:</p>
<p data-adtags-visited="true"><span><span>double</span><span>&nbsp;</span><span>PDF1</span><span>(</span><span>double</span><span>&nbsp;</span><span>x</span><span>)</span><span>&nbsp;</span><span>=&gt;</span><span>&nbsp;</span><span>x</span><span>&nbsp;</span><span>&lt;</span><span>&nbsp;</span><span>0.0</span><span>&nbsp;</span><span>|</span><span>&nbsp;</span><span>x</span><span>&nbsp;</span><span>&gt;=</span><span>&nbsp;</span><span>1.0</span><span>&nbsp;</span><span>?</span><span>&nbsp;</span><span>0.0</span><span>&nbsp;</span><span>:</span><span>&nbsp;</span><span>1.0</span><span>;</span><br>
<span>double</span><span>&nbsp;</span><span>PDF2</span><span>(</span><span>double</span><span>&nbsp;</span><span>x</span><span>)</span><span>&nbsp;</span><span>=&gt;</span><span>&nbsp;</span><span>x</span><span>&nbsp;</span><span>&lt;</span><span>&nbsp;</span><span>0.0</span><span>&nbsp;</span><span>|</span><span>&nbsp;</span><span>x</span><span>&nbsp;</span><span>&gt;=</span><span>&nbsp;</span><span>1.0</span><span>&nbsp;</span><span>?</span><span>&nbsp;</span><span>0.0</span><span>&nbsp;</span><span>:</span><span>&nbsp;</span><span>2</span><span>&nbsp;</span><span>*</span><span>&nbsp;</span><span>x</span><span>;</span><br>
<span>double</span><span>&nbsp;</span><span>PDF3</span><span>(</span><span>double</span><span>&nbsp;</span><span>x</span><span>)</span><span>&nbsp;</span><span>=&gt;</span><span>&nbsp;</span><span>Exp</span><span>(</span><span>‚Äì</span><span>(</span><span>x</span><span>&nbsp;</span><span>*</span><span>&nbsp;</span><span>x</span><span>))</span><span>&nbsp;</span><span>/</span><span>&nbsp;</span><span>Sqrt</span><span>(</span><span>PI</span><span>);</span></span></p>
<p data-adtags-visited="true"><img data-attachment-id="5835" data-permalink="https://ericlippert.com/2019/04/29/fixing-random-part-26/three-pdfs/" data-orig-file="https://ericlippert.files.wordpress.com/2019/04/three-pdfs.png" data-orig-size="1164,642" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Three PDFs" data-image-description="" data-medium-file="https://ericlippert.files.wordpress.com/2019/04/three-pdfs.png?w=300" data-large-file="https://ericlippert.files.wordpress.com/2019/04/three-pdfs.png?w=584" src="https://ericlippert.files.wordpress.com/2019/04/three-pdfs.png?w=584" alt="Three PDFs.png" srcset="https://ericlippert.files.wordpress.com/2019/04/three-pdfs.png?w=584 584w, https://ericlippert.files.wordpress.com/2019/04/three-pdfs.png?w=150 150w, https://ericlippert.files.wordpress.com/2019/04/three-pdfs.png?w=300 300w, https://ericlippert.files.wordpress.com/2019/04/three-pdfs.png?w=768 768w, https://ericlippert.files.wordpress.com/2019/04/three-pdfs.png?w=1024 1024w, https://ericlippert.files.wordpress.com/2019/04/three-pdfs.png 1164w" sizes="(max-width: 584px) 100vw, 584px"></p>
<p data-adtags-visited="true">What is the meaning of these as probability distributions? Plainly the ‚Äúhigher‚Äù the function, the ‚Äúmore likely‚Äù any particular value is, but what does it even mean to say that in our PDF2 and PDF3 distributions, that 0.5 is ‚Äúless likely‚Äù than 0.6 but they are ‚Äúequally likely‚Äù in our PDF1 distribution?</p>
<p data-adtags-visited="true">One way to think of it is that again, we ‚Äúthrow a dart‚Äù at the area under the curve. Given any subset of that area, the probability of the dart landing inside it is proportional to the area of the subset, and the value sampled is the x coordinate of the dart.</p>
<p data-adtags-visited="true">We can make this a little bit more formal by restricting our areas to little rectangles:</p>
<ul>
<li>Take a value, say 0.5.</li>
<li>Now take a tiny offset, call it <code>Œµ</code>. Doesn‚Äôt matter what it is, so long as it is ‚Äúpretty small‚Äù.</li>
<li>The probability of getting a sample value between <code>0.5</code> and <code>0.5+Œµ</code> is <code>PDF(0.5)*</code><code>Œµ</code>. That is, the area of a thin rectangle.</li>
</ul>
<p data-adtags-visited="true">That‚Äôs it! Let‚Äôs say we‚Äôve got values 0.5 and 0.6, and an <code>Œµ</code> of 0.01. How do our three distributions compare with each other near these values?</p>
<ul>
<li>With <code>PDF1</code>, the probability of getting a sample between 0.5 and 0.51 is approximately 0.010, and the probability of getting a sample between 0.6 and 0.61 is also approximately 0.010.</li>
<li>With <code>PDF2</code>, the probability of getting a sample between 0.5 and 0.51 is approximately 0.010, and&nbsp;the probability of getting a sample between 0.6 and 0.61 is approximately 0.012.</li>
<li>With <code>PDF3</code>, the probability of getting a sample between 0.5 and 0.51 is approximately 0.006, and&nbsp;the probability of getting a sample between 0.6 and 0.61 is approximately 0.004</li>
</ul>
<p data-adtags-visited="true">And moreover, <em>the approximation becomes better as <code>Œµ</code> gets smaller</em>.</p>
<hr>
<p data-adtags-visited="true"><strong>Aside:</strong> What if we want to know the probability of getting a value between two doubles that are not ‚Äúreally close together‚Äù? In that case we can do ‚Äúquadrature‚Äù: divide it up into a bunch of regions that are all ‚Äúreally small‚Äù and sum up the areas of all those little rectangles to get an approximation of the area. Or, we can use integral calculus to find the exact answer. But for the purposes of this series, <strong>we‚Äôre going to try to find ways to sample from a distribution that has a particular PDF without doing any quadrature approximations or any integral calculus</strong>.</p>
<hr>
<p data-adtags-visited="true">All right, we understand what PDFs are. To summarize:</p>
<ul>
<li>A PDF is a pure function from double to double.</li>
<li>A PDF is defined over the entire range of doubles.</li>
<li><code>PDF(x) &gt;= 0.0</code> for all <code>x</code>.</li>
<li>Integrating the PDF over the entire real line gives us a total area of 1.0.</li>
<li>The probability that a sample is between <code>x</code> and <code>x+Œµ</code>&nbsp;is approximately <code>PDF(x)*</code><code>Œµ</code>, if <code>Œµ</code> is small.</li>
</ul>
<p data-adtags-visited="true">For our purposes though I‚Äôm going to relax those conditions a bit. In the code I want to explore, we‚Äôll assume that a ‚Äúnon-normalized‚Äù PDF has these properties:</p>
<ul>
<li>A PDF is a pure function from <code>T</code> to <code>double</code>‚Äã‚Ä¶</li>
<li>‚Ä¶ defined over the entire range of <code>T</code>.</li>
<li><code>PDF(t) &gt;= 0.0</code> for all <code>t</code>.</li>
<li>Integrating the PDF over all possible values of <code>T</code> gives us a total area of <code>A</code>, for some finite positive value <code>A</code>. That is, the distribution is not necessarily ‚Äúnormalized‚Äù to have an area of 1.0.&nbsp; (You‚Äôd think that we can ‚Äúeasily‚Äù get a normalized distribution from a non-normalized distribution by dividing every weight by <code>A</code>&nbsp;but it is not always easy to know what that area is. But perhaps sometimes we do not need to know! Foreshadowing!)</li>
<li>The probability that a sample is within <code>Œµ</code> of <code>t</code> is approximately <code>PDF(t)*Œµ/A</code> if <code>Œµ</code> is small. (Of course, as I noted above, we might not know the normalization constant.)</li>
</ul>
<hr>
<p data-adtags-visited="true"><strong>Aside:</strong> That last point is a little vague; what does it mean to be ‚Äúwithin <code>Œµ</code> of some <code>t</code>‚Äù if <code>t</code> is not <code>double</code>? We‚Äôre going to just not worry about that. It‚Äôll be fine. Particularly since we‚Äôre mostly going to look at situations where <code>T</code> is <code>double</code> anyways.</p>
<p data-adtags-visited="true">This becomes useful for cases like the multidimensional case where <code>T</code>&nbsp;is <code>(double, double)</code>, say, and by ‚Äúwithin <code>Œµ</code>‚Äù we mean ‚Äúinside a square of side <code>‚àöŒµ</code>‚Äù or some such thing. Putting this all on a solid mathematical footing would take us too far off topic; you get the idea and let‚Äôs move on. I don‚Äôt know if we‚Äôll get to multidimensional distributions in this series or not.</p>
<hr>
<p data-adtags-visited="true">As we‚Äôll see, <strong>continuous distributions are a much harder beast to tame than the small discrete distributions we‚Äôve looked at before.</strong> However, there are still things we can do with them. Let‚Äôs start by making a definition in the type system for a distribution that has one of our relaxed PDFs. It‚Äôs awfully familiar:</p>
<p data-adtags-visited="true"><span><span>public</span><span>&nbsp;</span><span>interface</span><span>&nbsp;</span><span>IWeightedDistribution</span><span>&lt;</span><span>T</span><span>&gt;</span><span>&nbsp;</span><span>:</span><span>&nbsp;</span><span>IDistribution</span><span>&lt;</span><span>T</span><span>&gt;</span><br>
<span>{</span><br>
<span>&nbsp; </span><span>double</span><span>&nbsp;</span><span>Weight</span><span>(</span><span>T</span><span>&nbsp;</span><span>t</span><span>);</span><br>
<span>}</span></span></p>
<p data-adtags-visited="true">This means that every discrete distribution gets to be a weighted distribution pretty much ‚Äúfor free‚Äù. Let‚Äôs implement that:</p>
<p data-adtags-visited="true"><span><span><span><span>public</span><span>&nbsp;</span><span>interface</span><span>&nbsp;</span><span>IDiscreteDistribution</span><span>&lt;</span><span>T</span><span>&gt;&nbsp;:&nbsp;</span><span>IWeightedDistribution</span><span>&lt;</span><span>T</span><span>&gt;</span>{</span><br>
<span><span>&nbsp;&nbsp;</span></span><span>IEnumerable</span><span>&lt;</span><span>T</span><span>&gt;&nbsp;Support();</span><br>
<span>&nbsp;&nbsp;</span><span>new</span><span>&nbsp;</span><span>int</span><span>&nbsp;Weight(</span><span>T</span><span>&nbsp;t);</span><br>
<span>}</span></span></span></p>
<p data-adtags-visited="true">And now we have some minor taxes to pay; we‚Äôll need to add</p>
<p data-adtags-visited="true"><span><span>double</span><span>&nbsp;</span><span>IWeightedDistribution</span><span>&lt;</span><span>R</span><span>&gt;</span><span>.</span><span>Weight</span><span>(T</span><span>&nbsp;t</span><span>)</span><span>&nbsp;</span><span>=&gt;</span><span>&nbsp;</span><span>this</span><span>.</span><span>Weight</span><span>(t</span><span>);</span><br>
</span></p>
<p data-adtags-visited="true">to all our existing discrete distributions, but that is easily done.</p>
<p data-adtags-visited="true">We can also go back and fill in weight functions in our <code>Normal</code>&nbsp;class:</p>
<p data-adtags-visited="true"><span><span>private</span><span>&nbsp;</span><span>static</span><span>&nbsp;</span><span>readonly</span><span>&nbsp;</span><span>double</span><span>&nbsp;</span><span>piroot</span><span>&nbsp;</span><span>=</span><span>&nbsp;</span><span>1.0</span><span>&nbsp;</span><span>/</span><span>&nbsp;</span><span>Sqrt</span><span>(</span><span>2</span><span>&nbsp;</span><span>*</span><span>&nbsp;</span><span>PI</span><span>);</span><br>
<span>public</span><span>&nbsp;</span><span>double</span><span>&nbsp;</span><span>Weight</span><span>(</span><span>double</span><span>&nbsp;</span><span>x</span><span>)</span><span>&nbsp;</span><span>=&gt;</span><span>&nbsp;</span><br>
<span>&nbsp;&nbsp;</span><span>Exp</span><span>(</span><span>‚Äì</span><span>(</span><span>x</span><span>&nbsp;</span><span>‚Äì</span><span>&nbsp;</span><span>Œº</span><span>)</span><span>&nbsp;</span><span>*</span><span>&nbsp;</span><span>(</span><span>x</span><span>&nbsp;</span><span>‚Äì</span><span>&nbsp;</span><span>Œº</span><span>)</span><span>&nbsp;</span><span>/</span><span>&nbsp;</span><span>(</span><span>2</span><span>&nbsp;</span><span>*</span><span>&nbsp;</span><span>œÉ * œÉ</span><span>))</span><span>&nbsp;</span><span>*</span><span>&nbsp;</span><span>piroot</span><span>&nbsp;</span><span>/</span><span>&nbsp;</span><span>œÉ</span><span>;</span></span></p>
<p data-adtags-visited="true">And our <code>StandardContinuousUniform</code>&nbsp;class:</p>
<p data-adtags-visited="true"><span><span>public</span><span>&nbsp;</span><span>double</span><span>&nbsp;</span><span>Weight</span><span>(</span><span>double</span><span>&nbsp;</span><span>x</span><span>)</span><span>&nbsp;</span><span>=&gt;</span><span><br>
</span><span>&nbsp; 0.0</span><span>&nbsp;</span><span>&lt;=</span><span>&nbsp;</span><span>x</span><span>&nbsp;</span><span>&amp;</span><span>&nbsp;</span><span>x</span><span>&nbsp;</span><span>&lt;</span><span>&nbsp;</span><span>1.0</span><span>&nbsp;</span><span>?</span><span>&nbsp;</span><span>1.0</span><span>&nbsp;</span><span>:</span><span>&nbsp;</span><span>0.0</span><span>;</span><br>
</span></p>
<p data-adtags-visited="true">Easy peasy.</p>
<p data-adtags-visited="true">We‚Äôve got a new variation on our old concept of weighting a distribution; <em>let‚Äôs see where we can go with this.</em></p>
<hr>
<p data-adtags-visited="true"><strong>Next time on FAIC:</strong> We know how to efficiently sample from any small, discrete distribution with integer weights, but distributions based on arbitrary PDFs are much harder beasts to tame. Given an arbitrary <em>non-normalized</em> PDF, can we sample from it?</p>

			
			
						</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>