<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Undefined Behavior Is Really Undefined - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Undefined Behavior Is Really Undefined - linksfor.dev(s)"/>
    <meta property="og:description" content="Cryptography Services is a dedicated team of consultants from NCC Group focused on cryptographic security assessments, protocol and design reviews, and tracking impactful developments in the space  of academia and industry."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://cryptoservices.github.io/fde/2018/11/30/undefined-behavior.html"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Undefined Behavior Is Really Undefined</title>
<div class="readable">
        <h1>Undefined Behavior Is Really Undefined</h1>
            <div>Reading time: 17-21 minutes</div>
        <div>Posted here: 27 Feb 2019</div>
        <p><a href="https://cryptoservices.github.io/fde/2018/11/30/undefined-behavior.html">https://cryptoservices.github.io/fde/2018/11/30/undefined-behavior.html</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p><strong>Undefined Behavior</strong> is the expression used in C and C++ to describe a
situation in which, basically, “anything goes”. Historically, UB covered
cases where existing C compilers (and architectures) would act in
irreconcilable ways, and the standard committee, in its infinite wisdom,
decided not to decide (that is, not to rule out any of the competing
implementations). UB was also applicable to possible scenarios in which
the standard, while usually quite exhaustive, would have failed to
define a prescribed behavior. A third and increasingly more important
meaning of UB is the following: UB represents opportunities for
optimizations. And C and C++ developers really <em>love</em> optimizations;
they demand with great insistence that compilers do their best to make
the code fast.</p>

<p>Here is a classic example. Consider the following code:</p>

<div><div><pre><code>void
foo(double *src, int *dst)
{
    int i;

    for (i = 0; i &lt; 4; i ++) {
        dst[i] = (int)src[i];
    }
}
</code></pre></div></div>

<p>Compile this code on a 64-bit x86 platform, running Linux, with GCC
(it’s an up-to-date Ubuntu 18.04, GCC version is 7.3.0). We want full
optimization, and then have a look at the assembly output, hence the
options are “<code>-W -Wall -O9 -S</code>” (the “<code>-O9</code>” argument selects the
maximum optimization level of GCC, which is in practice equivalent to
“<code>-O3</code>”, although there have been some GCC forks that defined higher
levels). Here is the result:</p>

<div><div><pre><code>        .file   "zap.c"
        .text
        .p2align 4,,15
        .globl  foo
        .type   foo, @function
foo:
.LFB0:
        .cfi_startproc
        movupd  (%rdi), %xmm0
        movupd  16(%rdi), %xmm1
        cvttpd2dq       %xmm0, %xmm0
        cvttpd2dq       %xmm1, %xmm1
        punpcklqdq      %xmm1, %xmm0
        movups  %xmm0, (%rsi)
        ret
        .cfi_endproc
.LFE0:
        .size   foo, .-foo
        .ident  "GCC: (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0"
        .section        .note.GNU-stack,"",@progbits
</code></pre></div></div>

<p>Each of the first two <code>movupd</code> opcodes reads two <code>double</code> values into a
128-bit SSE2 register (a <code>double</code> is 64 bits, an SSE2 register can
contain two of them). In other words, the four source values are read,
and only then the conversions to <code>int</code> occur (the <code>cvttpd2dq</code> opcodes).
The <code>punpcklqdq</code> moves around the four resulting 32-bit integers into a
single SSE2 register (<code>%xmm0</code>), which is then written into RAM
(<code>movups</code>). Notice the important bit: this C program nominally requests
the following sequence of accesses to RAM:</p>

<ul>
  <li>Read the first <code>double</code> value at <code>src[0]</code>.</li>
  <li>Write the first <code>int</code> value into <code>dst[0]</code>.</li>
  <li>Read the second <code>double</code> value at <code>src[1]</code>.</li>
  <li>Write the second <code>int</code> value into <code>dst[1]</code>.</li>
  <li>Read the third <code>double</code> value at <code>src[2]</code>.</li>
  <li>Write the third <code>int</code> value into <code>dst[2]</code>.</li>
  <li>Read the fourth <code>double</code> value at <code>src[3]</code>.</li>
  <li>Write the fourth <code>int</code> value into <code>dst[3]</code>.</li>
</ul>

<p>However, what the C program asks for is only within the context of the
<em>abstract machine</em> defined by the C standard; how things happen on the
physical machine may differ. The compiler is free to reorder or modify
the operations as long as the result still matches the semantics of the
abstract machine (it is known as the “as-if rule”). Notably, in this
case, the compiled code does things in a different order:</p>

<ul>
  <li>Read the first <code>double</code> value at <code>src[0]</code>.</li>
  <li>Read the second <code>double</code> value at <code>src[1]</code>.</li>
  <li>Read the third <code>double</code> value at <code>src[2]</code>.</li>
  <li>Read the fourth <code>double</code> value at <code>src[3]</code>.</li>
  <li>Write the first <code>int</code> value into <code>dst[0]</code>.</li>
  <li>Write the second <code>int</code> value into <code>dst[1]</code>.</li>
  <li>Write the third <code>int</code> value into <code>dst[2]</code>.</li>
  <li>Write the fourth <code>int</code> value into <code>dst[3]</code>.</li>
</ul>

<p>This is C: everything in memory is ultimately <em>bytes</em> (i.e. <code>unsigned
char</code> slots, in practice octets), and arbitrary pointer arithmetic is
supported. In particular, the <code>src</code> and <code>dst</code> pointers might be made by
the caller to point to memory areas that overlap in some way (this is
known as “aliasing”). Thus, the order of reads and writes may matter, in
case some bytes are written to then read back again. To fully conform to
the abstract behavior defined by the C program, the C compiler would
have to interleave the reads and writes, and make the code do a full
round-trip to RAM at each loop iteration. The resulting code would be
larger, and much slower. C developers would wail and whine.</p>

<p>Fortunately, <em>undefined behavior</em> comes to the rescue. The C standard
specifies that values “cannot” be accessed through pointers that do not
match the effective type of the value; in plain words, that if a value
is written into <code>dst[0]</code>, with <code>dst</code> being a pointer to <code>int</code>, the
corresponding bytes cannot be read back with <code>src[1]</code>, where <code>src</code> is a
pointer to <code>double</code>, because that would be accessing what has become an
<code>int</code> value through a pointer to an incompatible type. Such an access
would imply undefined behavior. In the ISO 9899:1999 standard (aka
“C99”), this is specified in section 6.5, subclause 7 (in the more
recent revision 9899:2018, aka “C17”, the wording is unchanged); this is
also known as <em>strict aliasing</em>. The consequence here is that the C
compiler is allowed to <em>assume</em> that accesses that imply UB by breaking
aliasing rules do not happen; thus, the compiler can reorder the reads
and writes in any way it wants, since they should not overlap. This is
how the code is optimized.</p>

<p>This is in a nutshell what UB means: the compiler can assume that UB
does not happen, and produce code under that assumption. In the case of
strict aliasing rules, UB allows for important optimizations to take
place, that would be hard to obtain otherwise, as long as aliasing can
occur. More generally, in the code generation routines used by the
compiler, each instruction has dependencies that restrict the opcode
scheduling algorithm: an instruction cannot be issued before the
instructions that it depends upon, or after the instructions that depend
on it. In the example above, UB removes the dependencies between the
writes to <code>dst[]</code>, and the “subsequent” reads from <code>src[]</code>: such a
dependency can exist only if an UB-implying access exists. In a similar
way, the notion of UB can allow the compiler to simply <em>remove</em> code
that cannot happen without going through an UB condition.</p>

<p>This is all well and dandy, but the same behavior is also occasionally
felt as the compiler backstabbing the developer. A commonly encountered
comment is that “the compiler uses UB as a pretext to crash my code”.
Suppose that somebody is writing code that adds integer values together,
and fears overflows; such things <a href="https://en.bitcoin.it/wiki/Value_overflow_incident">have happened in
Bitcoin</a>. The
developer might think along the following lines: the CPU uses two’s
complement representation of integers, and therefore, if an overflow
occurs, this will be because the result is truncated to the type width,
e.g. 32 bits. This means that the result of an overflow is predictable,
and can be tested. Our developer will write this:</p>

<div><div><pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int
add(int x, int y, int *z)
{
    int r = x + y;
    if (x &gt; 0 &amp;&amp; y &gt; 0 &amp;&amp; r &lt; x) {
        return 0;
    }
    if (x &lt; 0 &amp;&amp; y &lt; 0 &amp;&amp; r &gt; x) {
        return 0;
    }
    *z = r;
    return 1;
}

int
main(int argc, char *argv[])
{
    int x, y, z;
    if (argc != 3) {
        return EXIT_FAILURE;
    }
    x = atoi(argv[1]);
    y = atoi(argv[2]);
    if (add(x, y, &amp;z)) {
        printf("%d\n", z);
    } else {
        printf("overflow!\n");
    }
    return 0;
}
</code></pre></div></div>

<p>Now let’s try to compile that with GCC:</p>

<div><div><pre><code>$ gcc -W -Wall -O9 testadd.c
$ ./a.out 17 42
59
$ ./a.out 2000000000 1500000000
overflow!
</code></pre></div></div>

<p>OK, this seems to work. Let’s try again with another compiler, Clang
(version 6.0.0 on my system):</p>

<div><div><pre><code>$ clang -W -Wall -O3 testadd.c
$ ./a.out 17 42
59
$ ./a.out 2000000000 1500000000
-794967296
</code></pre></div></div>

<p>Wut?</p>

<p>It turns out that when an operation on signed integer types has a result
which is not representable in the target type, we enter UB territory.
But the compiler can assume that UB does not happen. In particular, when
optimizing the expression “<code>x &gt; 0 &amp;&amp; y &gt; 0 &amp;&amp; r &lt; x</code>”, the compiler
infers that since <code>x</code> and <code>y</code> are strictly positive, the third test
cannot be true (their sum cannot be lower than either), and the whole
thing can be skipped. In other words, the overflow being UB, it “cannot
happen” from the compiler perspective, and all instructions that depend
upon such a condition can be removed. The overflow detection mechanism
has simply disappeared.</p>

<p>The assumption that computations use “wraparound semantics” (as the CPU
opcodes actually do) has never been standard for signed types; it was
<em>traditional</em>, at a time when compilers were not smart enough to
optimize code based on range analysis. It is possible to force Clang and
GCC to enforce wraparound semantics on signed types with the special
flag <code>-fwrapv</code> (on Microsoft Visual C, you might use
<code>-d2UndefIntOverflow-</code>, as described in <a href="https://blogs.msdn.microsoft.com/vcblog/2016/05/04/new-code-optimizer/">this blog
entry</a>).
This is however relatively fragile, and that flag may disappear when the
code is reused in another project or on another architecture.</p>

<p>That overflows on signed types imply UB is not well-known. In the C99
and C17 standards, it is described in section 6.5, subclause 5:</p>

<blockquote>
  <p>If an <em>exceptional</em> condition occurs during the evaluation of an
expression (that is, if the result is not mathematically defined or
not in the range of representable values for its type), the behavior
is undefined.</p>
</blockquote>

<p>However, for unsigned types, modular semantics are guaranteed. Section
6.2.5, subclause 9, specifies that:</p>

<blockquote>
  <p>A computation involving unsigned operands can never overflow, because
a result that cannot be represented by the resulting unsigned integer
type is reduced modulo the number that is one greater than the largest
value that can be represented by the resulting type.</p>
</blockquote>

<p>Another example of UB with signed types happens with divisions. It is
well-known that division by zero is not mathematically defined, and thus
dividing by zero leads to undefined behavior, as per the standard. On
x86 CPU, if the <code>idiv</code> opcode is invoked with a denominator equal to
zero, a CPU exception happens. CPU exceptions are like interrupt
requests, they are handled by the operating system; on Unix-like systems
such as Linux, the CPU exception triggered by <code>idiv</code> is translated into
a <code>SIGFPE</code> signal delivered to the process, and the default handler
kills the process (nevermind that “FPE” means “floating-point
exception”, while <code>idiv</code> works with integers). However, there is another
situation that also implies UB. Consider this code:</p>

<div><div><pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

int
main(int argc, char *argv[])
{
    int x, y;
    if (argc != 3) {
        return EXIT_FAILURE;
    }
    x = atoi(argv[1]);
    y = atoi(argv[2]);
    printf("%d\n", x / y);
    return 0;
}
</code></pre></div></div>

<p>And then try it:</p>

<div><div><pre><code>$ gcc -W -Wall -O testdiv.c
$ ./a.out 42 17
2
$ ./a.out -2147483648 -1
zsh: floating point exception (core dumped)  ./a.out -2147483648 -1
</code></pre></div></div>

<p>Indeed, on that machine (still my common x86 running Linux), the <code>int</code>
type can represent values from -2147483648 to +2147483647. When dividing
-2147483648 by -1, I should get +2147483648. But this does not fit in an
<code>int</code>. Therefore, behavior is undefined. Anything can happen. In this
case, the process dies. On other systems, you could get a different
outcome, especially the small CPU that do not have a division opcode; on
such architectures, division is done in software, with a routine that is
normally provided by the compiler, and that one may do whatever it wants
on UB, because that’s exactly what UB means.</p>

<p>As a side-note, a <code>SIGFPE</code> can also be obtained under the same
conditions with the modulo operator (<code>%</code>). Indeed, internally, the same
<code>idiv</code> opcode is used to get both the quotient and remainder, hence the
same CPU exception is triggered. Interestingly, as per the C99 standard,
the “<code>INT_MIN % -1</code>” expression would not have invoked UB, because the
mathematical result is well defined (it is zero) and it certainly fits
into the representable range of the target type. In the C17 standard,
the wording of 6.5.5, subclause 6, was augmented to cover that case and
align the standard with the reality of common hardware platforms.</p>

<p>There are many subtle conditions that can lead to UB. Look at this
code:</p>

<div><div><pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;

unsigned short
mul(unsigned short x, unsigned short y)
{
    return x * y;
}

int
main(int argc, char *argv[])
{
    int x, y;
    if (argc != 3) {
        return EXIT_FAILURE;
    }
    x = atoi(argv[1]);
    y = atoi(argv[2]);
    printf("%d\n", mul(x, y));
    return 0;
}
</code></pre></div></div>

<p>As per the C standard, what is this C program allowed to print, if
invoked with parameters “45000” and “50000”?</p>

<ul>
  <li>A) 18048</li>
  <li>B) 2250000000</li>
  <li>C) God save the Queen</li>
</ul>

<p>And the answer is… all of the above! You might have told yourself that
since <code>unsigned short</code> is an unsigned type, it should work with
wraparound semantics, modulo 65536 because on an x86 CPU, that type
typically has size exactly 16 bits (as per the standard, it could be
larger than that, but in practice it will be a 16-bit type). And while
the product is mathematically 2250000000, it will be reduced modulo
65536, yielding 18048. <em>However</em>, this would be forgetting about the
<em>integer promotions</em>. As per the C standard (section 6.3.1.1, subclause
2), when the operands are of a type strictly smaller than <code>int</code>, and all
values of that type can be represented without loss in an <code>int</code> (which
is our case here: on my x86 running Linux, an <code>int</code> is 32 bits and can
certainly hold all values from 0 to 65535), then both operands are
converted to <code>int</code>, and the operation occurs on <code>int</code> values. In
particular, the product is computed as an <code>int</code>, and only <em>coerced</em> back
to the <code>unsigned short</code> type when returning from the function (this is
when the modulo 65536 occurs). The problem is that the mathematical
result before that coercion is 2250000000, and that value does not fit
in an <code>int</code>, which is a signed type. Hence UB. Therefore, anything can
happen afterwards, including a spontaneous display of British
patriotism.</p>

<p>In practice, though, you will get 18048 with usual compilers, because
there is no currently known and implemented optimization that could
leverage the UB to optimize things <em>in this specific program</em> (one can
imagine other more contrived scenarios where that UB really wreaks havoc
to execution).</p>

<p>A final example, this one in C++:</p>

<div><div><pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;array&gt;

int
main(int argc, char *argv[])
{
    std::array&lt;char, 16&gt; tmp;
    int i;

    if (argc &lt; 2) {
        return EXIT_FAILURE;
    }
    memset(tmp.data(), 0, 16);
    if (strlen(argv[1]) &lt; 16) {
        strcpy(tmp.data(), argv[1]);
    }
    for (i = 0; i &lt; 17; i ++) {
        printf(" %02x", tmp[i]);
    }
    printf("\n");
}
</code></pre></div></div>

<p>This is <em>not</em> a classic “<code>strcpy()</code> is bad bad bad” example. Indeed, in
the code above, the <code>strcpy()</code> is performed only if the source string is
small enough, including the terminating zero. Moreover, the array
contents are explicitly initialized to zero, so all array bytes have a
set value, whether the argument string is large or not. However, the
final loop is incorrect, in that it <em>reads</em> one more byte than it
should.</p>

<p>Let’s try it:</p>

<div><div><pre><code>$ g++ -W -Wall -O9 testvec.c
$ ./a.out foo
 66 6f 6f 00 00 00 00 00 00 00 00 00 00 00 00 00 10 58 ffffffca ff
ffffac ffffffc0 55 00 00 00 ffffff80 71 34 ffffff99 07 ffffffba ff
ffffea ffffffd0 ffffffe5 44 ffffff83 fffffffd 7f 00 00 00 00 00 00
 00 00 00 00 10 58 ffffffca ffffffac ffffffc0 55 00 00 ffffff97 7b
 12 1b ffffffa1 7f 00 00 02 00 00 00 00 00 00 00 ffffffd8 ffffffe5
 44 ffffff83 fffffffd 7f 00 00 00 ffffff80 00 00 02 00 00 00 60 56
(...)
62 64 3d 30 30
zsh: segmentation fault (core dumped)  ./a.out foo
</code></pre></div></div>

<p>Wut++?</p>

<p>Naively, you could say: OK, it is reading one byte out of bounds; but
that should be no big deal, that byte is still on the stack, memory is
mapped, there should be no issue except an extra seventeenth number with
a somewhat unpredictable value. The final loop will still print exactly
17 integers (in hexadecimal) and exit cleanly.</p>

<p>But the compiler sees things differently. It knows perfectly well that
the seventeenth access invokes UB. Within the logic of the compiler,
this means that any instruction beyond that one is then in limbo: things
after UB are not required to exist (technically, even <em>previous</em>
instructions can be affected, because UB can be retroactive). In
particular, it will simply skip the condition test on the loop, and the
loop will run forever; or, more accurately, until the reading goes
beyond the pages allocated for the stack, at which point a <code>SIGSEGV</code>
occurs.</p>

<p>Amusingly, if GCC is invoked with less aggressive optimizations, it will
warn in a quite explicit way:</p>

<div><div><pre><code>$ g++ -W -Wall -O1 testvec.c
testvec.c: In function ‘int main(int, char**)’:
testvec.c:20:15: warning: iteration 16 invokes undefined behavior [-Waggressive-loop-optimizations]
         printf(" %02x", tmp[i]);
         ~~~~~~^~~~~~~~~~~~~~~~~
testvec.c:19:19: note: within this loop
     for (i = 0; i &lt; 17; i ++) {
                 ~~^~~~
</code></pre></div></div>

<p>But at <code>-O9</code> level, somehow, the warning disappears. This may be related
to the more forcefull loop unrolling that happens at high optimization
levels. Arguably, this is a GCC bug (the lack of warning, that is; as
per the standard, what GCC does is fully conformant either way, and no
“diagnostic” is required by the standard in that situation).</p>

<p><strong>Conclusion:</strong> if you write code in C or C++, take <em>great care</em> that
you always avoid undefined behavior conditions, even in situations that
seem “obviously harmless”. Using unsigned integer types helps with
arithmetic computations, because they have guaranteed modular semantics
(but you can still run into trouble with integer promotions). Another
possible stance, but strangely unpopular, might be: don’t write code in
C or C++. This is not always an option, for a variety of reasons. But in
situations where you <em>can</em> choose between languages, e.g. when starting
a new project on a platform where Go or Rust or Java or other languages
are supported, then it can pay off to not necessarily go for C as the
“default language”. All choices of tools, including programming
languages, imply trade-offs; the pitfalls of C programming, notably UB
conditions on arithmetics on signed types, tend to imply maintenance
efforts in the long run that are often underestimated.</p>

  </article>
  
</div>

      </div>
    </div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
		<div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>