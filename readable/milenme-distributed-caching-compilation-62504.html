<!DOCTYPE html>
<html lang="en">
<head>
    <title>
milen.me &#x2014; Distributed Caching &amp; Compilation - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="milen.me &#x2014; Distributed Caching &amp; Compilation - linksfor.dev(s)"/>
    <meta property="og:description" content="Deterministic builds can be defined as:"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://milen.me/writings/distributed-caching-and-compilation/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - milen.me &#x2014; Distributed Caching &amp; Compilation</title>
<div class="readable">
        <h1>milen.me &#x2014; Distributed Caching &amp; Compilation</h1>
            <div>Reading time: 11-13 minutes</div>
        <div>Posted here: 07 Jun 2020</div>
        <p><a href="https://milen.me/writings/distributed-caching-and-compilation/">https://milen.me/writings/distributed-caching-and-compilation/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
		<h3>TL;DR</h3>

<ul>
  <li>Determinism plays an important role in the ability to cache output of compilation.</li>
  <li>Distributed caching and compilation enable quick iteration on large scale software.</li>
  <li>Computation of distributed cache keys is non-trivial as not all inputs are explicit.</li>
  <li>A suitable distributed cache fill strategy is required for consistently fast local builds.</li>
</ul>

<h3>Deterministic Builds</h3>
<p>Deterministic builds can be <a href="http://blog.llvm.org/2019/11/deterministic-builds-with-clang-and-lld.html">defined</a> as:</p>

<blockquote>
<p>A build is called <em>deterministic</em> or <em>reproducible</em> if running it twice produces exactly the same build outputs.</p>
</blockquote>

<p>The LLVM project outlines several levels of determinism:</p>
<ul>
  <li><em>Basic</em>: Doing a full build of the <em>same</em> source code in the <em>same</em> directory on the <em>same</em> machine produces exactly the <em>same</em> output every time.</li>
  <li><em>Incremental</em>: Like basic determinism, but the output binaries also do not change in <em>partial</em> rebuilds.</li>
  <li><em>Local</em>: Like incremental basic determinism, but builds are also <em>independent</em> of the name of the build directory. Builds of the <em>same</em> source code on the <em>same</em> machine produce exactly the same output every time, independent of the location of the source checkout directory or the build directory.</li>
  <li><em>Universal</em>:  Like local but builds are also <em>independent</em> of the machine the build runs on.</li>
</ul>

<h4>Large Scale Software</h4>

<p>Deterministic builds provide multiple benefits, mostly relating to security and caching. In this post, I cover how determinism enables the usage of techniques to speed up development of large scale software.</p>

<p>As software gets increasingly more complex, building <em>all</em> of the source code of a single program <em>locally</em> becomes impractical, especially as we want to support a <em>fast</em> development cycle<sup id="fnref:slow-incremental" data-footnote-backlink-ref="fnref:slow-incremental" data-footnote-ref="#fn:slow-incremental"><a href="#fn:slow-incremental" rel="footnote"></a></sup>. It’s too inefficient to expect engineers to wait hours to build the latest commit every morning.</p>

<p>Large scale software can arise in different ways:</p>
<ul><li><em>Self Contained Software</em>: The software itself is a single, self-contained product but it's very complex and large in scope. For example, Google Chrome and Photoshop would qualify as such software.
</li><li><em>Vertical Systems</em>: Even though an individual program might be small, the whole vertical system, including frameworks and system libraries, can be very large. Compiling whole vertical systems from source has multiple benefits<sup id="fnref:all-source" data-footnote-backlink-ref="fnref:all-source" data-footnote-ref="#fn:all-source"><a href="#fn:all-source" rel="footnote"></a></sup> (e.g., quicker vertical signal, lower integration cost, faster system iteration cycle) but compile times can escalate due to the sheer size of code being compiled.
</li></ul>

<h4>Distributed Caching</h4>

<p>One of the major benefits of having <em>universal deterministic builds</em> is that our CI and local development machines will be producing exactly the same artifacts, which allows us to leverage a <em>distributed cache</em>. This changes compile times from being a function of the total code size to being a function of the local code changes (i.e., <code>O(total code)</code> to <code>O(local code changes)</code>).</p>

<p>If you checkout a commit which has been built and cached by CI, almost all local computation would be replaced by fetching the remote artifacts. So, rather than waiting hours to compile everything, you can have a build ready in a few minutes.</p>

<p>Note that distributed caching is also known as remote caching.</p>

<h4>Distributed Compilation</h4>

<p>A problem that arises when working on large codebases is making local changes that require a large computational power. For example, imagine there’s a header file included almost <em>everywhere</em> and you make a change to that file locally (e.g., <code>Logging.h</code>).  A distributed cache will not help because CI machines have not built that revision: the file contains unique local changes. It would be extremely inefficient to have engineers stuck waiting for hours.</p>

<p>There’s another technique that can speedup development in such cases: distributed compilation. The technique is also known as remote execution as it's not just limited to compilation but applies more generally to execution of tools as part of the build process.</p>

<p>Distribution compilation is about leveraging the power of multiple machines to remotely execute compile commands. It’s like having 1000s of CPU cores instead of just a few dozen. Usually, build systems would schedule a certain amount of compilation jobs locally and distribute the rest over remote machines which will compile the input files and return the object files as a result.</p>

<p>Both <a href="https://buck.build/">Buck</a> and <a href="https://docs.bazel.build/versions/master/remote-execution.html">Bazel</a> support remote execution.</p>

<h3>Distributed Caching vs Distributed Compilation</h3>
<p>While both distributed caching and distributed compilation help speed up the development cycle of large scale software<sup id="fnref:iteration-time" data-footnote-backlink-ref="fnref:iteration-time" data-footnote-ref="#fn:iteration-time"><a href="#fn:iteration-time" rel="footnote"></a></sup>, they are fundamentally different techniques. Distributed caching is about <em>storing</em> the results of a computation and <em>retrieving</em> those same results later from other machines. Distributed compilation is about <em>leveraging the power of multiple machines</em> to perform a computation that's too expensive to perform locally.</p>

<p>The techniques are <em>orthogonal</em> and <em>complementary</em>. You could have a setup with just distributed caching or just distributed compilation (ideally both).</p>

<p>In a pure distributed compilation setting, the total amount of work stays roughly the same<sup id="fnref:distrib-cost" data-footnote-backlink-ref="fnref:distrib-cost" data-footnote-ref="#fn:distrib-cost"><a href="#fn:distrib-cost" rel="footnote"></a></sup>, it’s just spread across multiple machines. The main benefit is that we have the ability to perform expensive computations quickly but we are still bound by the total computational capacity across the fleet.</p>

<p>On the other hand, distributed caching is a classic example of the <a href="https://en.wikipedia.org/wiki/Space%E2%80%93time_tradeoff">space-time tradeoff</a> applied across a network of machines. In the end, as long cache hit rates are sufficiently high, we save a lot of CPU time in exchange for paying a storage cost.</p>

<h3>Cache Keys</h3>
<h4>Determinism</h4>
<p>Before we cover key computation, it’s important to note the requirements imposed by having a cache: cached command outputs <em>must</em> be deterministic. This property allows us to safely compute results on one machine and reuse them on others.</p>

<p>If cached commands are <em>not deterministic</em>, then this would lead to a very strange property: the output of a build would depend on the cache hits. Such a system would be very fragile and hard to reason about.</p>

<h4>Key Computation</h4>

<p>Caches are indexed by a key, so let’s explore how such keys could be computed. Assume we want to cache the results of a command:</p>

<figure><pre><code data-lang="text">compiler --some-option -L /some/directory --input-file /path/to/file @/path/to/argfile</code></pre></figure>

<p>If we were to hash the command itself, it would certainly not be enough to guarantee the output would be deterministic because the contents of the referenced directories and files can affect the output. At a minimum, we must include the following as part of the key:</p>

<ul><li><em>Referenced Files</em>: Need to include the contents of input files. For response files (argfiles), this needs to happen recursively.
</li><li><em>Directory Contents</em>: Need to include the state of referenced directories. For example, such directories could be used for header resolution.
</li><li><em>Command Parameters</em>: All parameters must be included, in the order they appear.
</li><li><em>Compiler Identity</em>: The exact compiler being used (e.g., hash of the binary).
</li></ul>

<h4>Compiler Identity</h4>

<p>The compiler identity needs to be included in the computation of the cache key because the output can vary between versions. For example, Clang 5 would most likely behave differently compared to Clang 11.</p>

<p>Unfortunately, determining the identity of the compiler is not as easy as just hashing the binary. That’s because the binary might just be a shim that redirects to another binary or even a set of binaries.</p>

<p>Furthermore, the shim might operate in a dynamic manner: e.g., redirect to different compiler versions depending on parameters, environmental variables or state of the filesystem. It’s practically impossible for the build system to guess how the compiler works internally.</p>

<h4>Implicit Inputs</h4>

<p>In addition to the visible inputs as part of the command, there are two other major sources of <em>implicit</em> inputs:</p>

<ul><li><em>Environmental Variables</em>: the compiler’s behaviour could be influenced by environment variables. Those variables might have been set at the shell level, build system level or somewhere else.
</li><li><em>Filesystem</em>: the compiler will inevitably end up using many more files than those explicitly specified. There might be implicit search paths, SDK paths and so on.
</li></ul>

<h4>Non-Existent Files</h4>

<p>One tricky aspect that can be easily missed are files which <em>do not exist</em> on the filesystem but which affect the output of the compiler. Imagine if the compiler had code like:</p>

<figure><pre><code data-lang="text">const char* lib_path = "/some/predefined/path.a";
if (static_lib_exists_as(lib_path)) {
  append_to(linked_libraries, lib_path);
}</code></pre></figure>


<p>This means the compiler will generate different outputs depending on the existence of <code>/some/predefined/path.a</code>. Consequently, the file <em>must</em> always be part of the cache key, even when it does not exist.</p>

<h4>Explicit Inputs</h4>

<p>Ultimately, the compiler itself truly knows all the inputs that were used to determine the output. Ideally, compilers would provide a way to output that information in a structured way, so that build systems can utilise it.</p>

<p>For example, <a href="https://clang.llvm.org/docs/ClangCommandLineReference.html#dependency-file-generation">Clang</a> and GCC support dependency files which list all the user and system header files that were used. MSVC supports a similar <a href="https://docs.microsoft.com/en-us/cpp/build/reference/showincludes-list-include-files?view=vs-2019"><code>/showIncludes</code></a> option.</p>

<h4>Parameters Not Affecting Determinism</h4>

<p>Sometimes, tools might support options which do not affect the output but change the internal operation of the tool (e.g., algorithms used, concurrency, etc).</p>

<p>While it’s possible to add custom handling to exclude such parameters from cache key computation, it’s safer to assume that all parameters affect the input and have CI machines (or a subset) always build the exact same local development configuration.</p>

<h3>Cache Availability</h3>
<p>An important aspect of a distributed cache is its hit rate: it should be very high. Assuming no local changes, the hit rate would usually depend on the particular commit being checked out, the cache retention policy and cache fill strategy.</p>

<p>For example, if the cache gets filled once an hour by a CI job, checking out the latest commit on master might result in a very slow build if a previous commit invalidated most artifacts.</p>

<p>In terms of fill and retention strategies, several aspects require careful consideration. For example:</p>
<ul><li>Does the cache get filled at every commit or only certain ones?
</li><li>Does the cache get filled before a commit gets pushed or afterwards?
</li><li>In a monorepo, for a specific commit, are caches for all targets filled or only a subset?
</li><li>Is the cache per-target or a global one?
</li><li>What eviction policy does the cache use? What’s the size of the cache?
</li></ul>

<p>There are no right or wrong answers: all of the above aspects represent different tradeoffs and will have associated benefits and costs. It will be down to the constraints and requirements within a company/project to make the appropriate choices and deliver the desired experience.</p>

<h4>Metrics</h4>

<p>Ultimately, the distributed cache should have a high hit rate for as many builds as possible. For example, that might be aiming for p95 miss rate of 1%: i.e., 95% of all builds will experience a miss rate of 1% or lower (i.e., hit rate of 99% or higher).</p>

<p>Adopting a data-driven approach in optimising the cache hit rate is an appropriate strategy.</p>


<p><a href="https://milen.me/writings/">← Back to Writings</a></p>













		<p>
Any opinions and viewpoints expressed, explicitly or implicitly, are not endorsed by and do not represent any of my previous, current or future employers.
</p>
	</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>