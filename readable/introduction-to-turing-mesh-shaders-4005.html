<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Introduction to Turing Mesh Shaders | NVIDIA Developer Blog - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Introduction to Turing Mesh Shaders | NVIDIA Developer Blog - linksfor.dev(s)"/>
    <meta property="article:author" content="View all posts by Christoph Kubisch"/>
    <meta property="og:description" content="Turing introduces a new programmable geometric shading pipeline, mesh shaders,, enabling threads to cooperatively generate compact meshes on the chip."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://devblogs.nvidia.com/introduction-turing-mesh-shaders/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Introduction to Turing Mesh Shaders | NVIDIA Developer Blog</title>
<div class="readable">
        <h1>Introduction to Turing Mesh Shaders | NVIDIA Developer Blog</h1>
            <div>by View all posts by Christoph Kubisch</div>
            <div>Reading time: 23-29 minutes</div>
        <div>Posted here: 27 Feb 2019</div>
        <p><a href="https://devblogs.nvidia.com/introduction-turing-mesh-shaders/">https://devblogs.nvidia.com/introduction-turing-mesh-shaders/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="pf-post-view">
    <div>

                  <article id="post-11828">
                

                <div>
                  <p>The Turing architecture introduces a new programmable geometric shading pipeline through the use of <strong>mesh shaders</strong>. The new shaders bring the compute programming model to the graphics pipeline as threads are used cooperatively to generate compact meshes (<strong>meshlets</strong>) directly on the chip for consumption by the rasterizer. Applications and games dealing with high-geometric complexity benefit from the flexibility of the two-stage approach, which allows efficient culling, level-of-detail techniques as well as procedural generation.</p>
<p>This blog introduces the new pipeline and gives some concrete examples in GLSL for OpenGL or Vulkan rendering. The new capabilities are accessible through extensions in OpenGL, Vulkan and via NVAPI in DX12.</p>
<p>Most of the following content is taken from this <a href="http://on-demand.gputechconf.com/siggraph/2018/video/sig1811-3-christoph-kubisch-mesh-shaders.html">recorded presentation</a>, for which the full slide deck will be available at a later date.</p>


<center></center><p>The real world is a visually rich, geometrically complex place. Outdoor scenes in particular can be composed of hundreds of thousands of elements (rocks, trees, small plants, etc.). CAD models present similar challenges with both complex shaped surfaces as well as machinery made of many small parts. In visual effects large structures, for example spaceships, are often detailed with “greebles”. Figure 1 shows several examples where today’s graphics pipeline with vertex, tessellation, and geometry shaders, instancing and multi draw indirect, while very effective, can still be limited when the full resolution geometry reaches hundreds of millions of triangles and hundreds of thousands of objects.</p>
<figure id="attachment_11837" aria-labelledby="figcaption_attachment_11837"><a href="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_motivation.png"><img src="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_motivation-625x402.png" alt="Turing mesh shaders geometric complexity motivation" width="625" height="402" srcset="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_motivation-625x402.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_motivation-179x115.png 179w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_motivation-300x193.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_motivation-768x494.png 768w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_motivation-466x300.png 466w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_motivation-140x90.png 140w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_motivation-362x233.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_motivation-171x110.png 171w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_motivation.png 892w" sizes="(max-width: 625px) 100vw, 625px"></a><figcaption id="figcaption_attachment_11837">Figure 1. The need for increasing realism drives massive increases in geometric complexity.</figcaption></figure>
<p>Other use-cases not shown above include geometries found in scientific computing (particles, glyphs, proxy objects, point clouds) or procedural shapes (electric engineering layouts, vfx particles, ribbons and trails, path rendering).</p>
<p>In this post we look at <em>mesh shaders</em> to accelerate rendering of heavy triangle meshes. The original mesh is segmented into smaller <strong>meshlets</strong> as figure 2 shows. Each meshlet ideally optimizes the vertex re-use within it. Using the new hardware stages and this segmentation scheme, we can render more geometry in parallel while fetching less overall data.</p>


<p>For example CAD data can reach tens to hundreds of millions of triangles. Even after <a href="https://github.com/nvpro-samples/gl_occlusion_culling">occlusion culling</a>&nbsp;a significant amount of triangles can exist. Some fixed-function steps in the pipeline may do wasteful work and memory loads in this scenario:</p>
<ul>
<li>Vertex batch creation by the hardware’s <em>primitive distributor</em> scanning the indexbuffer each time even if the topolgy doesn’t change</li>
<li>Vertex and attribute fetch for data that is not visible (backface, frustum, or sub-pixel culling)</li>
</ul>
<p>The <em>mesh shader</em> gives developers new possibilities to avoid such bottlenecks. The new approach allows the memory to be read once and kept on-chip as opposed to previous approaches, such as <em>compute shader</em>-based primitive culling (see [3],[4],[5]), where index buffers of visible triangles are computed and drawn indirectly.</p>
<p>The mesh shader stage produces triangles for the rasterizer, but uses a cooperative thread model internally instead of using a single-thread program model, similar to compute shaders. Ahead of the mesh shader in the pipeline is the task shader. The task shader operates similarly to the control stage of tessellation, in that it is able to dynamically generate work. However, like the mesh shader, it uses a cooperative thread model and instead of having to take a patch as input and tessellation decisions as output, its input and output are user defined.</p>
<p>This simplifies on-chip geometry creation compared to the previous rigid and limited tessellation and geometry shaders, where threads had to be used for specific tasks only, as shown in figure 3.</p>
<figure id="attachment_11834" aria-labelledby="figcaption_attachment_11834"><a href="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_comparison.png"><img src="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_comparison-1024x524.png" alt="" width="1024" height="524" srcset="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_comparison-1024x524.png 1024w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_comparison-300x154.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_comparison-768x393.png 768w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_comparison-625x320.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_comparison-500x256.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_comparison-160x82.png 160w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_comparison-362x185.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_comparison-215x110.png 215w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_comparison.png 1066w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption id="figcaption_attachment_11834">Figure 3. Mesh shaders represent the next step in handling geometric complexity</figcaption></figure>


<p>A new, two-stage pipeline alternative supplements the classic attribute fetch, <em>vertex, tessellation, geometry shader</em> pipeline. This new pipeline consists of a <em>task shader</em> and&nbsp;<em>mesh shader:</em></p>
<ul>
<li><strong>Task shader</strong> : a programmable unit that operates in workgroups and allows each to emit (or not) mesh shader workgroups</li>
<li><strong>Mesh shader</strong> : a programmable unit that operates in workgroups and allows each to generate primitives</li>
</ul>
<p>The mesh shader stage produces triangles for the rasterizer using the above-mentioned cooperative thread model internally. The task shader operates similarly to the hull shader stage of tessellation, in that it is able to dynamically generate work. However, like the mesh shader, the task shader also uses a cooperative thread mode. Its input and output are user defined instead of having to take a patch as input and tessellation decisions as output.</p>
<p>The interfacing with the <em>pixel/fragment shader</em> is unaffected. The traditional pipeline is still available and can provide very good results depending on the use-case. Figure 4 highlights the differences in the pipeline styles.</p>
<figure id="attachment_11838" aria-labelledby="figcaption_attachment_11838"><a href="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline.png"><img src="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline.png" alt="" width="677" height="348" srcset="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline.png 677w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline-300x154.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline-625x321.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline-500x257.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline-160x82.png 160w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline-362x186.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline-214x110.png 214w" sizes="(max-width: 677px) 100vw, 677px"></a><figcaption id="figcaption_attachment_11838">Figure 4. Differences in the traditional versus task/mesh geometry pipeline</figcaption></figure>
<p>The new mesh shader pipeline provides a number of benefits for developers:</p>
<ul>
<li><strong>Higher scalability</strong> through shader units by reducing fixed-function impact in primitive processing. The generic purpose use of modern GPUs helps a greater variety of applications to add more cores and improve shader’s generic memory and arithmetic performance.</li>
<li><strong>Bandwidth-reduction</strong>, as de-duplication of vertices (vertex re-use) can be done upfront, and reused over many frames. The current API model means the index buffers have to be scanned by the hardware every time. Larger meshlets mean higher vertex re-use, also lowering bandwidth requirements. Furthermore developers can come up with their own compression or procedural generation schemes.<br>
The optional expansion/filtering via <em>task shaders</em> allows to skip fetching more data entirely.</li>
<li><strong>Flexibility</strong> in defining the mesh topology and creating graphics work. The previous <em>tessellation shaders</em> were limited to fixed tessellation patterns while&nbsp;<em>geometry shaders</em> suffered from an inefficient threading, unfriendly programming model which created triangle strips per-thread.</li>
</ul>
<p>Mesh shading follows the programming model of <em>compute shaders</em>, giving developers the freedom to use threads for different purposes and share data among them. When rasterization is disabled, the two stages can also be used to do generic compute work with one level of expansion.</p>
<figure id="attachment_11840" aria-labelledby="figcaption_attachment_11840"><a href="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline3.png"><img src="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline3.png" alt="Turing GPU mesh shader execution architecture" width="675" height="357" srcset="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline3.png 675w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline3-300x159.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline3-625x331.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline3-500x264.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline3-160x85.png 160w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline3-362x191.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline3-208x110.png 208w" sizes="(max-width: 675px) 100vw, 675px"></a><figcaption id="figcaption_attachment_11840">Figure 5. Mesh shaders behave similarly to compute shaders in using a cooperative thread model.</figcaption></figure>
<p>Both <em>mesh and task shaders</em> follow the programming model of <em>compute shaders</em>, using cooperative thread groups to compute their results and having <strong>no inputs other than a workgroup index</strong>. These execute on the graphics pipeline; therefore the hardware directly manges memory passed between stages and kept on-chip.</p>
<p>We will show an example of how this can be used to do primitive culling, as the threads can access all vertices within a workgroup later. Figure 6 illustrates the ability of task shaders to take care of early culling.</p>
<figure id="attachment_11839" aria-labelledby="figcaption_attachment_11839"><a href="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline2.png"><img src="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline2.png" alt="" width="676" height="347" srcset="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline2.png 676w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline2-300x154.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline2-625x321.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline2-500x257.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline2-160x82.png 160w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline2-362x186.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_pipeline2-214x110.png 214w" sizes="(max-width: 676px) 100vw, 676px"></a><figcaption id="figcaption_attachment_11839">Figure 6. While optional, task shaders enable early culling to improve throughput.</figcaption></figure>
<p>The optional expansion via <em>task shaders</em> allows early culling of a group of primitives or making LOD decisions upfront. The mechanism scales across the GPU and is therefore superseding instancing or multi draw indirect for small meshes. This configuration is similar to the <em>tessellation control shader</em> setting up how much a patch (~task workgroup) is tessellated and then influencing how many <em>tessellation evaluation</em> invocations (~mesh workgroups) are created.</p>
<p>There is a limitation on how many <em>mesh workgroups</em> a single <em>task workgroup</em> can emit. The first generation hardware supports a maximum of 64K children that can be generated <em>per task</em>. There is no limit on the total number of mesh children across all tasks within the same draw call. Likewise if no <em>task shader</em> is used, no limits exist on the amount of mesh workgroups generated by the draw call. Figure 7 illustrates how this works.</p>
<figure id="attachment_11842" aria-labelledby="figcaption_attachment_11842"><a href="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_tree.png"><img src="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_tree.png" alt="NVIDIA Turing GPU mesh shaders workgroup flow" width="635" height="336" srcset="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_tree.png 635w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_tree-300x159.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_tree-625x331.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_tree-500x265.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_tree-160x85.png 160w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_tree-362x192.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_tree-208x110.png 208w" sizes="(max-width: 635px) 100vw, 635px"></a><figcaption id="figcaption_attachment_11842">Figure 7. Mesh shader workgroup flow</figcaption></figure>
<p>Children of the task T are guaranteed to be launched after children of task T-1. However, task and mesh workgroups are fully pipelined, so that there is no waiting for the completion of previous children or tasks.</p>
<p>The <em>task shader</em> should be used for dynamic work generation or filtering. Static setups benefit from using the <em>mesh shaders</em> alone.</p>
<p>The rasterization output ordering of the meshes and the primitives within them is preserved. With rasterization disabled, both task and mesh shaders can be used to implement basic compute-trees.</p>


<p>Each meshlet represents a variable number of vertices and primitives. There are no restrictions regarding the connectivity of these primitives. However, they must stay below a maximum amount, specified within the shader code.</p>
<p>We recommend using up to 64 vertices and 126 primitives. The ‘6’ in 126 is not a typo. The first generation hardware allocates primitive indices in 128 byte granularity and and needs to reserve 4 bytes for the primitive count. Therefore <code>3 * 126 + 4</code> maximizes the fit into a <code>3 * 128 = 384</code> bytes block. Going beyond 126 triangles would allocate the next 128 bytes. 84 and 40 are other maxima that work well for triangles.</p>
<p>In each GLSL <em>mesh-shader</em> code, a fixed amount of mesh memory per workgroup is allocated in the graphics pipeline for every workgroup.</p>
<p>Maximums and sizes and primitive output are defined as follows:</p>
<p>The allocation size of each meshlet depends on the compile-time sizing information as well as which output attributes are referenced by the shader. The smaller the allocation, the more workgroups can be executed in parallel on the hardware. As with&nbsp;<em>compute</em>, workgroups share a common section of on-chip memory they can access. Therefore we recommend you be as efficient as possible in the way all outputs or shared memory is used. This is already true for current shaders. However, the memory footprint can be higher since we allow a greater number of vertices and primitives than in the current programming.</p>
<pre><span>// Set the number of threads per workgroup (always one-dimensional).</span>
  <span>// The limitations may be different than in actual compute shaders.</span>
  layout(local_size_x=32) in;

  <span>// the primitive type (points,lines or triangles)</span>
  layout(triangles) out;
  <span>// maximum allocation size for each meshlet</span>
  layout(max_vertices=64, max_primitives=126) out;

  <span>// the actual amount of primitives the workgroup outputs ( &lt;= max_primitives)</span>
  out uint gl_PrimitiveCountNV;
  <span>// an index buffer, using list type indices (strips are not supported here)</span>
  out uint gl_PrimitiveIndicesNV[]; <span>// [max_primitives * 3 for triangles]</span>
</pre>
<p>Turing supports another new GLSL extension, <code>NV_fragment_shader_barycentric</code>, which enables the fragment shader to fetch the raw data of the three vertices that make a primitive and interpolate it manually. This raw access means we can output “uint” vertex attributes, but use the various pack/unpack functions to store floats as fp16, unorm8 or snorm8. This can greatly reduce the per-vertex footprint again for normals, texture coordinates, and basic color values and benefits both standard as well as the mesh shading pipeline.</p>
<p>Additional attributes for vertices and primitives are defined as follows:</p>
<pre>out gl_MeshPerVertexNV {
     vec4  gl_Position;
     <span>float</span> gl_PointSize;
     <span>float</span> gl_ClipDistance[];
     <span>float</span> gl_CullDistance[];
  } gl_MeshVerticesNV[];            <span>// [max_vertices]</span>

  <span>// define your own vertex output blocks as usual</span>
  out Interpolant {
    vec2 uv;
  } OUT[];                          <span>// [max_vertices]</span>

  <span>// special purpose per-primitive outputs</span>
  perprimitiveNV out gl_MeshPerPrimitiveNV {
    <span>int</span> gl_PrimitiveID;
    <span>int</span> gl_Layer;
    <span>int</span> gl_ViewportIndex;
    <span>int</span> gl_ViewportMask[];          <span>// [1]</span>
  } gl_MeshPrimitivesNV[];          <span>// [max_primitives]</span>
</pre>
<p>One goal is to have the smallest number of meshlets, therefore maximizing vertex re-use within the meshlets, and hence wasting fewer allocations. It can be beneficial to apply a vertex cache optimizer on the indexbuffer prior to the generation of the meshlet data. For example, <a href="https://tomforsyth1000.github.io/papers/fast_vert_cache_opt.html">Tom Forsyth’s linear-speed optimizer</a> can be used for this. Optimizing the vertex locations along with the index buffer is also beneficial, as the ordering of original triangles will be preserved when using the <em>mesh shaders</em>. CAD models often are often “naturally” generated with strips and therefore can already have good data locality. Changing the indexbuffers can have negative side effects on the cluster culling properties of a meshlet for such data (see task-level culling).</p>


<p>As an example, we render static content where the <em>index buffers</em> are not changing for many frames. Therefore the cost of generating the meshlet data can be hidden during upload of vertices/indices to device memory. Additional benefits can be achieved when the <em>vertex</em> data is also static (no per-vertex animation; no changes in vertex positions), allowing precomputing data useful for quickly culling entire meshlets.<br>
<a name="datastructures"></a>&nbsp;<a name="toc4.1"></a></p>
<h2>Data Structures</h2>
<p>In future samples we will provide a meshlet builder that contains a basic implementation that scans the provided indices and creates a new meshlet every time either of the the size limitations (vertex or primitive count) are hit.</p>
<p>For an input triangle mesh it generates the following data:</p>
<pre><span>struct</span> MeshletDesc {
    uint32_t vertexCount; <span>// number of vertices used</span>
    uint32_t primCount;   <span>// number of primitives (triangles) used</span>
    uint32_t vertexBegin; <span>// offset into vertexIndices</span>
    uint32_t primBegin;   <span>// offset into primitiveIndices</span>
  }

  std::<span>vector</span>&lt;meshletdesc&gt;  meshletInfos;
  std::<span>vector</span>&lt;uint8_t&gt;      primitiveIndices;

  <span>// use uint16_t when shorts are sufficient</span>
  std::<span>vector</span>&lt;uint32_t&gt;     vertexIndices;
</pre>
<p><strong>Why are there two index buffers?</strong></p>
<p>The following original triangle index buffer sequence</p>
<pre><span>// let's look at the first two triangles of a batch of many more triangleIndices = { 4,5,6, 8,4,6, ...}</span>
</pre>
<p>is split into two new indexbuffers.</p>
<p>We build a set of unique vertex indices as we iterate through the triangle indices. This process is also known as <strong>vertex de-duplication</strong>.</p>
<pre>vertexIndices = { 4,5,6,  8, ...}
<span>// For the second triangle only vertex 8 must be added</span>
<span>// and the other vertices are re-used.</span>
</pre>
<p>The primitive indices are adjusted relative to the <code>vertexIndices</code> entries.</p>
<pre><span>// original data</span>
triangleIndices  = { 4,5,6,  8,4,6, ...}
<span>// new data</span>
primitiveIndices = { 0,1,2,  3,0,2, ...}
<span>// the primitive indices are local per meshlet</span>
</pre>
<p>Once the appropriate size limitation is hit (either too many unique vertices, or too many primitives), a new meshlet is started. Subsequent meshlets will then create their own set of unique vertices.</p>

<h2>Rendering Resources and Data Flow</h2>
<p>During rendering we use the original vertex buffers. However, instead of the original triangle indexbuffer we use three new buffers, shown in figure 8 below:</p>
<ul>
<li><strong>Vertex Index Buffer</strong> as explained above. Each meshlet references a set of unique vertices. The indices for those vertices are stored in a buffer for all meshlets sequentially.</li>
<li><strong>Primitive Index Buffer</strong> as explained above. Each meshlet represents a varying number of primitives. Every triangle requires three primitive indices which are stored in a single buffer. <em>Note</em>: Extra indices may be added to get four byte alignment after each meshlet.</li>
<li><strong>Meshlet Desc Buffer.</strong>&nbsp;Stores the information of workload and buffer offsets for each meshlet, as well as cluster culling information.</li>
</ul>
<p>These three buffers are actually smaller than the original index-buffers due to the higher vertex re-use that mesh shading allows. We noticed a reduction to around 75% of the original index-buffer sizes typically occurred.</p>

<figure id="attachment_11835" aria-labelledby="figcaption_attachment_11835"><a href="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_data.png"><img src="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_data.png" alt="NVIDIA Turing GPU mesh shader buffer structure" width="632" height="161" srcset="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_data.png 632w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_data-300x76.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_data-625x159.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_data-500x127.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_data-160x41.png 160w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_data-362x92.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_data-432x110.png 432w" sizes="(max-width: 632px) 100vw, 632px"></a><figcaption id="figcaption_attachment_11835">Figure 8. Meshlet buffer structure</figcaption></figure>

<ul>
<li><strong>Meshlet Vertices:</strong> <code>vertexBegin</code> stores the starting location from where we will start fetching vertex indices. <code>vertexCount</code> stores the number of contiguous vertices involved. The vertices are unique within a meshlet; there are no duplicate index values.</li>
<li><strong>Meshlet Primitives:</strong> <code>primBegin</code> stores the starting location for the primitive indices from where we will start fetching indices. <code>primCount</code> stores the amount of primitives involved in the meshlet. Note that the number of indices depends on the primitive type (here: 3 for triangles). It is important to notice that the indices are referencing vertices relative to <code>vertexBegin</code>, meaning that index ‘0’ would refer to the vertex index located at <code>vertexBegin</code>.</li>
</ul>
<p>The following pseudo code describes what each <em>mesh shader</em> workgroup performs in principle. It is serial only for illustration purposes.</p>
<pre><span>// This code is just a serial pseudo code,</span>
  <span>// and doesn't reflect actual GLSL code that would</span>
  <span>// leverage the workgroup's local thread invocations.</span>

  <span>for</span> (<span>int</span> v = 0; v &lt; meshlet.vertexCount; v++){
    <span>int</span> vertexIndex = texelFetch(vertexIndexBuffer, meshlet.vertexBegin + v).x;
    vec4 vertex = texelFetch(vertexBuffer, vertexIndex);
    gl_MeshVerticesNV[v].gl_Position = <span>transform</span> * vertex;
  }

  <span>for</span> (<span>int</span> p = 0; p &lt; meshlet.primCount; p++){
    uvec3 triangle = getTriIndices(primitiveIndexBuffer, meshlet.primBegin + p);
    gl_PrimitiveIndicesNV[p * 3 + 0] = triangle.x;
    gl_PrimitiveIndicesNV[p * 3 + 1] = triangle.y;
    gl_PrimitiveIndicesNV[p * 3 + 2] = triangle.z;
  }

  <span>// one thread writes the output primitives</span>
  gl_PrimitiveCountNV = meshlet.primCount;
</pre>
<p>The mesh shader could look something like this when written in parallel fashion:</p>
<pre><span>void</span> <span>main</span>() {
  ...

  <span>// As the workgoupSize may be less than the max_vertices/max_primitives</span>
  <span>// we still require an outer loop. Given their static nature</span>
  <span>// they should be unrolled by the compiler in the end.</span>

  <span>// Resolved at compile time</span>
  <span>const</span> uint vertexLoops =
    (MAX_VERTEX_COUNT + GROUP_SIZE - 1) / GROUP_SIZE;

  <span>for</span> (uint loop = 0; loop &lt; vertexLoops; loop++){
    <span>// distribute execution across threads</span>
    uint v = gl_LocalInvocationID.x + loop * GROUP_SIZE;

    <span>// Avoid branching to get pipelined memory loads.</span>
    <span>// Downside is we may redundantly compute the last</span>
    <span>// vertex several times</span>
    v = <span>min</span>(v, meshlet.vertexCount-1);
    {
      <span>int</span> vertexIndex = texelFetch( vertexIndexBuffer, 
                                    <span>int</span>(meshlet.vertexBegin + v)).x;
      vec4 vertex = texelFetch(vertexBuffer, vertexIndex);
      gl_MeshVerticesNV[v].gl_Position = <span>transform</span> * vertex;
    }
  }

  <span>// Let's pack 8 indices into RG32 bit texture</span>
  uint primreadBegin = meshlet.primBegin / 8;
  uint primreadIndex = meshlet.primCount * 3 - 1;
  uint primreadMax   = primreadIndex / 8;

  <span>// resolved at compile time and typically just 1</span>
  <span>const</span> uint primreadLoops =
    (MAX_PRIMITIVE_COUNT * 3 + GROUP_SIZE * 8 - 1) 
      / (GROUP_SIZE * 8);

  <span>for</span> (uint loop = 0; loop &lt; primreadLoops; loop++){
    uint p = gl_LocalInvocationID.x + loop * GROUP_SIZE;
    p = <span>min</span>(p, primreadMax);

    uvec2 topology = texelFetch(primitiveIndexBuffer, 
                                <span>int</span>(primreadBegin + p)).rg;

    <span>// use a built-in function, we took special care before when </span>
    <span>// sizing the meshlets to ensure we don't exceed the </span>
    <span>// gl_PrimitiveIndicesNV array here</span>

    writePackedPrimitiveIndices4x8NV(p * 8 + 0, topology.x);
    writePackedPrimitiveIndices4x8NV(p * 8 + 4, topology.y);
  }

  <span>if</span> (gl_LocalInvocationID.x == 0) {
    gl_PrimitiveCountNV = meshlet.primCount;
  }
</pre>
<p>This example is just a straight-forward implementation. Due to all data fetching being done by the developer, custom encodings, decompression via subgroup intrinsics or shared memory, or temporarly using the vertex outputs are possible to save additional bandwidth.</p>

<h2>Cluster Culling with Task Shader</h2>
<p>We try to squeeze more information into a meshlet descriptor to perform early culling. We have experimented with using 128-bit descriptors that encode the previous mentioned values, as well as relative bbox and a cone for backface-cluster culling as presented by <a href="https://frostbite-wp-prd.s3.amazonaws.com/wp-content/uploads/2016/03/29204330/GDC_2016_Compute.pdf">G.Wihlidal</a>. When generating meshlets, one needs to balance good cluster-culling properties with improved vertex re-use. One may influence the other negatively.</p>
<p>The task shader below culls up to 32 meshlets.</p>
<pre>layout(local_size_x=32) in;

taskNV out Task {
  uint      baseID;
  uint8_t   subIDs[GROUP_SIZE];
} OUT;

<span>void</span> <span>main</span>() {
  <span>// we padded the buffer to ensure we don't access it out of bounds</span>
  uvec4 desc = meshletDescs[gl_GlobalInvocationID.x];

  <span>// implement some early culling function</span>
  <span>bool</span> render = gl_GlobalInvocationID.x &lt; meshletCount &amp;&amp; !earlyCull(desc);

  uvec4 vote  = subgroupBallot(render);
  uint  tasks = subgroupBallotBitCount(vote);

  <span>if</span> (gl_LocalInvocationID.x == 0) {
    <span>// write the number of surviving meshlets, i.e. </span>
    <span>// mesh workgroups to spawn</span>
    gl_TaskCountNV = tasks;

    <span>// where the meshletIDs started from for this task workgroup</span>
    OUT.baseID = gl_WorkGroupID.x * GROUP_SIZE;
  }

  {
    <span>// write which children survived into a compact array</span>
    uint idxOffset = subgroupBallotExclusiveBitCount(vote);
    <span>if</span> (render) {
      OUT.subIDs[idxOffset] = uint8_t(gl_LocalInvocationID.x);
    }
  }
}
</pre>
<p>The corresponding mesh shader now uses the information form the task shader to identify which meshlet to generate.</p>
<pre>taskNV in Task {
  uint      baseID;
  uint8_t   subIDs[GROUP_SIZE];
} IN;

<span>void</span> <span>main</span>() {
  <span>// We can no longer use gl_WorkGroupID.x directly</span>
  <span>// as it now encodes which child this workgroup is.</span>
  uint meshletID = IN.baseID + IN.subIDs[gl_WorkGroupID.x];
  uvec4 desc = meshletDescs[meshletID];
  ...
}
</pre>
<p>We only culled the meshlets in the task shader in the context of rendering large triangle models. Other scenarios may involve picking different meshlet data later on depending on level-of-detail decision making, or completely generating the geometry (particles, ribbons etc.). Figure 9 below is from a demo that uses task shaders for level-of-detail computation.</p>
<figure id="attachment_11836" aria-labelledby="figcaption_attachment_11836"><a href="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_lod.png"><img src="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_lod-1024x592.png" alt="NVIDIA Turing GPU mesh shader demo" width="1024" height="592" srcset="https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_lod-1024x592.png 1024w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_lod-300x174.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_lod-768x444.png 768w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_lod-625x362.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_lod-500x289.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_lod-156x90.png 156w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_lod-362x209.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2018/09/meshlets_lod-190x110.png 190w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption id="figcaption_attachment_11836">Figure 9. NVIDIA Asteroids demo uses mesh shading</figcaption></figure>
<center></center>

<p>Some of the key takeaways:</p>
<ul>
<li>A triangle mesh can be converted into meshlets by scanning the index buffer once. Vertex cache optimizers that help classic rendering also help improve meshlet packing efficiency. More sophisticated clustering allows improved early rejection in the task shader stage (tighter bounding boxes, coherent triangle normals etc.).</li>
<li>The <em>task shader</em> allows skipping of a group of primitives early, before the hardware needs to allocate vertex/primitive memory for a <em>mesh shader</em> invocation on-chip. It also enables generating more than one child invocation if necessary.</li>
<li>Vertices are processed in parallel across the workgroup’s threads, just like the original <em>vertex shaders</em>.</li>
<li><em>Vertex shaders</em> can be made mostly compatible with <em>mesh shaders</em> with a few preprocessor insertions.</li>
<li>Less data needs to be fetched due to greater vertex re-use (classic vertex shaders operate with a limit of max_vertices = 32 and max_primitives = 32). Average triangle mesh valences suggest that using twice the amount of triangles as vertices is beneficial.</li>
<li>All data loads are handled via shader instructions instead of the classic fixed function primitive fetch and therefore scales better with more <em>Streaming Multiprocessors</em>. It also allows easier use of custom vertex encodings to further reduce bandwidth.</li>
<li>For heavy use of vertex attributes, a primitive culling phase that also operates in parallel may be beneficial. This allows us to skip loading vertex data for primitives that would be culled away. However, the best gains are made by efficient culling at the task-level.</li>
</ul>
<p>You can find more information on the Turing architecture <a href="https://devblogs.nvidia.com/nvidia-turing-architecture-in-depth/">here</a>. Please add your thoughts in the comments section, below. Sample code and driver support will soon be available.&nbsp; If you’re an NVIDIA developer working with Turing advanced shaders, check out the the <a href="https://devtalk.nvidia.com/default/board/60/visual-and-game-development/">game developer forums</a>, where you can interact with a community of NVIDIA developers.</p>

<h2>References</h2>
<ul>
<li>[1]: <a href="https://www.facebook.com/artbyrens">Art by Rens</a></li>
<li>[2]: <a href="https://www.flickr.com/photos/14136614@N03/6209344182">photo by Chris Christian – model by Russell Berkoff</a></li>
<li>[3]: <a href="https://frostbite-wp-prd.s3.amazonaws.com/wp-content/uploads/2016/03/29204330/GDC_2016_Compute.pdf">Optimizing Graphics Pipeline with Compute – Graham Wihlidal</a></li>
<li>[4]: <a href="http://advances.realtimerendering.com/s2015/aaltonenhaar_siggraph2015_combined_final_footer_220dpi.pdf">GPU-Driven Rendering Pipelines – Ulrich Haar &amp; Sebastian Aaltonen</a></li>
<li>[5]: <a href="http://www.conffx.com/Visibility_Buffer_GDCE.pdf">The filtered and culled Visibility Buffer – Wolfgang Engel</a></li>
</ul>
<h2>Appendix: SIGGRAPH Presentation</h2>
<p>Here is the full SIGGRAPH presentation upon which this blog post builds, for your viewing pleasure.</p>
<p><iframe width="500" height="281" src="https://www.youtube.com/embed/Ge427_2VORo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>


                    

                    
                </div>
            </article>
        
    </div>
</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
		<div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>