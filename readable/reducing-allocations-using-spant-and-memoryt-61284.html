<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Reducing allocations using Span&lt;T&gt; and Memory&lt;T&gt; - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Reducing allocations using Span&lt;T&gt; and Memory&lt;T&gt; - linksfor.dev(s)"/>
    <meta property="article:author" content="Stef&#xE1;n J&#xF6;kull Sigur&#xF0;arson"/>
    <meta property="og:description" content="I decided to look at the RabbitMQ .NET Client source code to make improvements. During that exploration I saw opportunities to reduce memory allocations."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://stebet.net/real-world-example-of-reducing-allocations-using-span-t-and-memory-t/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
	<div class="devring" style="background: #222">
		<div class="grid">
			<div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
				<span class="devring-title">devring.club</span>
				<a href="https://devring.club/site/1/previous" class="devring-previous">Previous</a>
				<a href="https://devring.club/random" class="devring-random">Random</a>
				<a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
			</div>
		</div>
	</div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Reducing allocations using Span&lt;T&gt; and Memory&lt;T&gt;</title>
<div class="readable">
        <h1>Reducing allocations using Span&lt;T&gt; and Memory&lt;T&gt;</h1>
            <div>by Stef&#xE1;n J&#xF6;kull Sigur&#xF0;arson</div>
            <div>Reading time: 14-17 minutes</div>
        <div>Posted here: 02 May 2020</div>
        <p><a href="https://stebet.net/real-world-example-of-reducing-allocations-using-span-t-and-memory-t/">https://stebet.net/real-world-example-of-reducing-allocations-using-span-t-and-memory-t/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p>I have been planning to write this post for a few months now but always seem to have found something new to add. This all started when I decided to look at the <a href="https://github.com/rabbitmq/rabbitmq-dotnet-client">RabbitMQ .NET Client source code</a> to see if I could make improvements to the asynchronous logic and add support for <a href="https://devblogs.microsoft.com/dotnet/system-io-pipelines-high-performance-io-in-net/">System.IO.Pipelines</a>. During that exploration I saw some opportunities for improvements that could be made to memory allocations. This was quite a learning project for myself as I both had to relearn a lot of things I had already learned and a lot of new things as well.</p><h2 id="brief-introduction-to-the-amqp-0-9-1-protocol">Brief introduction to the AMQP 0.9.1 Protocol</h2><p>RabbitMQ uses the AMQP 0.9.1 protocol by default. In overly broad terms, every AMQP operation is defined as a command. Before transmission, commands are split into frames of a specified maximum size (often dictated by the server), and these frames are then serialized to bytes for transmission on the wire when the client and server communicate. AMQP uses network byte order representation/big-endian for its data types so you have to be careful when serializing them on little-endian systems like Windows, so you don't corrupt data and the client can be interoperable with other operating systems. Now there are certain nuances to the protocol, and I am oversimplifying things here, but this is the gist of how the AMQP protocol works.</p><h2 id="binary-serialization">Binary Serialization</h2><p>To serialize data to/from RabbitMQ we need to be able to translate data into a binary format. This is called serialization and as I mentioned above, RabbitMQ uses network-byte-order.</p><p>Previously the library used a class called NetworkBinaryReader which inherited from BinaryReader and overrode certain methods. BinaryReader is a very old class in the .NET BCL and does not take endianness into account, and the library also assumed that it was running on little-endian systems so quite a lot of overhead went into serializing doubles and floats.</p><p>Here is an example of how NetworkBinaryReader previously implemented the ReadDouble method:</p><pre><code><span>public</span> <span>override</span> <span>double</span> <span>ReadDouble</span><span>(</span><span>)</span>
<span>{</span>
    <span>byte</span><span>[</span><span>]</span> bytes <span>=</span> <span>ReadBytes</span><span>(</span><span>8</span><span>)</span><span>;</span>
    <span>byte</span> temp <span>=</span> bytes<span>[</span><span>0</span><span>]</span><span>;</span>
    bytes<span>[</span><span>0</span><span>]</span> <span>=</span> bytes<span>[</span><span>7</span><span>]</span><span>;</span>
    bytes<span>[</span><span>7</span><span>]</span> <span>=</span> temp<span>;</span>
    temp <span>=</span> bytes<span>[</span><span>1</span><span>]</span><span>;</span>
    bytes<span>[</span><span>1</span><span>]</span> <span>=</span> bytes<span>[</span><span>6</span><span>]</span><span>;</span>
    bytes<span>[</span><span>6</span><span>]</span> <span>=</span> temp<span>;</span>
    temp <span>=</span> bytes<span>[</span><span>2</span><span>]</span><span>;</span>
    bytes<span>[</span><span>2</span><span>]</span> <span>=</span> bytes<span>[</span><span>5</span><span>]</span><span>;</span>
    bytes<span>[</span><span>5</span><span>]</span> <span>=</span> temp<span>;</span>
    temp <span>=</span> bytes<span>[</span><span>3</span><span>]</span><span>;</span>
    bytes<span>[</span><span>3</span><span>]</span> <span>=</span> bytes<span>[</span><span>4</span><span>]</span><span>;</span>
    bytes<span>[</span><span>4</span><span>]</span> <span>=</span> temp<span>;</span>
    <span>return</span> <span>TemporaryBinaryReader</span><span>(</span>bytes<span>)</span><span>.</span><span>ReadDouble</span><span>(</span><span>)</span><span>;</span>
<span>}</span>
</code></pre>
<p>This was changed to get rid of the temporary MemoryStreams (used in the TemporaryBinaryReader method above) and byte arrays to reduce allocations.</p><p>Here is an example of how we are now reading Double from a ReadOnlySpan&lt;byte&gt;:</p><pre><code><span>[</span><span>MethodImpl</span><span>(</span>MethodImplOptions<span>.</span>AggressiveInlining<span>)</span><span>]</span>
<span>internal</span> <span>static</span> <span>double</span> <span>ReadDouble</span><span>(</span>ReadOnlySpan<span>&lt;</span><span>byte</span><span>&gt;</span> span<span>)</span>
<span>{</span>
    <span>if</span> <span>(</span>span<span>.</span>Length <span>&lt;</span> <span>8</span><span>)</span>
    <span>{</span>
        <span>throw</span> <span>new</span> <span>ArgumentOutOfRangeException</span><span>(</span><span>nameof</span><span>(</span>span<span>)</span><span>,</span> <span>"Insufficient length to decode Double from memory."</span><span>)</span><span>;</span>
    <span>}</span>

    <span>uint</span> num1 <span>=</span> <span>(</span><span>uint</span><span>)</span><span>(</span><span>(</span>span<span>[</span><span>0</span><span>]</span> <span>&lt;</span><span>&lt;</span> <span>24</span><span>)</span> <span>|</span> <span>(</span>span<span>[</span><span>1</span><span>]</span> <span>&lt;</span><span>&lt;</span> <span>16</span><span>)</span> <span>|</span> <span>(</span>span<span>[</span><span>2</span><span>]</span> <span>&lt;</span><span>&lt;</span> <span>8</span><span>)</span> <span>|</span> span<span>[</span><span>3</span><span>]</span><span>)</span><span>;</span>
    <span>uint</span> num2 <span>=</span> <span>(</span><span>uint</span><span>)</span><span>(</span><span>(</span>span<span>[</span><span>4</span><span>]</span> <span>&lt;</span><span>&lt;</span> <span>24</span><span>)</span> <span>|</span> <span>(</span>span<span>[</span><span>5</span><span>]</span> <span>&lt;</span><span>&lt;</span> <span>16</span><span>)</span> <span>|</span> <span>(</span>span<span>[</span><span>6</span><span>]</span> <span>&lt;</span><span>&lt;</span> <span>8</span><span>)</span> <span>|</span> span<span>[</span><span>7</span><span>]</span><span>)</span><span>;</span>
    <span>ulong</span> val <span>=</span> <span>(</span><span>(</span><span>ulong</span><span>)</span>num1 <span>&lt;</span><span>&lt;</span> <span>32</span><span>)</span> <span>|</span> num2<span>;</span>
    <span>return</span> Unsafe<span>.</span><span><span>As</span><span>&lt;</span><span>ulong</span><span>,</span> <span>double</span><span>&gt;</span></span><span>(</span><span>ref</span> val<span>)</span><span>;</span>
<span>}</span>
</code></pre>
<p>This resulted in a dramatic decrease in allocations as well as CPU savings. Here is an example of BenchmarkDotNet benchmarks I created for verification.</p><h3 id="double">Double</h3><table>
<thead>
<tr>
<th>Method</th>
<th>Runtime</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
<th>Gen 0</th>
<th>Gen 1</th>
<th>Gen 2</th>
<th>Allocated</th>
</tr>
</thead>
<tbody>
<tr>
<td>ReadBefore</td>
<td>.NET 4.8</td>
<td>150.351 ns</td>
<td>1.2760 ns</td>
<td>0.9962 ns</td>
<td>0.1147</td>
<td>-</td>
<td>-</td>
<td>361 B</td>
</tr>
<tr>
<td>ReadAfter</td>
<td>.NET 4.8</td>
<td>8.116 ns</td>
<td>0.1166 ns</td>
<td>0.1090 ns</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>ReadBefore</td>
<td>Core 3.1</td>
<td>67.239 ns</td>
<td>0.9648 ns</td>
<td>0.8553 ns</td>
<td>0.0739</td>
<td>-</td>
<td>-</td>
<td>232 B</td>
</tr>
<tr>
<td>ReadAfter</td>
<td>Core 3.1</td>
<td>4.080 ns</td>
<td>0.1625 ns</td>
<td>0.1441 ns</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>WriteBefore</td>
<td>.NET 4.8</td>
<td>160.946 ns</td>
<td>4.3261 ns</td>
<td>4.0467 ns</td>
<td>0.1249</td>
<td>-</td>
<td>-</td>
<td>393 B</td>
</tr>
<tr>
<td>WriteAfter</td>
<td>.NET 4.8</td>
<td>7.788 ns</td>
<td>0.1187 ns</td>
<td>0.1110 ns</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>WriteBefore</td>
<td>Core 3.1</td>
<td>84.995 ns</td>
<td>2.0234 ns</td>
<td>2.6311 ns</td>
<td>0.0815</td>
<td>-</td>
<td>-</td>
<td>256 B</td>
</tr>
<tr>
<td>WriteAfter</td>
<td>Core 3.1</td>
<td>3.576 ns</td>
<td>0.0498 ns</td>
<td>0.0465 ns</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
</tbody>
</table>
<h2 id="single">Single</h2><table>
<thead>
<tr>
<th>Method</th>
<th>Runtime</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
<th>Median</th>
<th>Gen 0</th>
<th>Gen 1</th>
<th>Gen 2</th>
<th>Allocated</th>
</tr>
</thead>
<tbody>
<tr>
<td>ReadBefore</td>
<td>.NET 4.8</td>
<td>142.165 ns</td>
<td>2.0497 ns</td>
<td>1.9172 ns</td>
<td>141.090 ns</td>
<td>0.1147</td>
<td>-</td>
<td>-</td>
<td>361 B</td>
</tr>
<tr>
<td>ReadAfter</td>
<td>.NET 4.8</td>
<td>2.322 ns</td>
<td>0.0520 ns</td>
<td>0.0406 ns</td>
<td>2.328 ns</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>ReadBefore</td>
<td>Core 3.1</td>
<td>65.098 ns</td>
<td>1.3230 ns</td>
<td>1.4705 ns</td>
<td>64.897 ns</td>
<td>0.0739</td>
<td>-</td>
<td>-</td>
<td>232 B</td>
</tr>
<tr>
<td>ReadAfter</td>
<td>Core 3.1</td>
<td>1.772 ns</td>
<td>0.0738 ns</td>
<td>0.0789 ns</td>
<td>1.771 ns</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>WriteBefore</td>
<td>.NET 4.8</td>
<td>151.188 ns</td>
<td>1.4721 ns</td>
<td>1.2293 ns</td>
<td>150.984 ns</td>
<td>0.1249</td>
<td>-</td>
<td>-</td>
<td>393 B</td>
</tr>
<tr>
<td>WriteAfter</td>
<td>.NET 4.8</td>
<td>3.101 ns</td>
<td>0.0603 ns</td>
<td>0.0564 ns</td>
<td>3.101 ns</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>WriteBefore</td>
<td>Core 3.1</td>
<td>75.557 ns</td>
<td>0.9762 ns</td>
<td>0.9131 ns</td>
<td>75.431 ns</td>
<td>0.0815</td>
<td>-</td>
<td>-</td>
<td>256 B</td>
</tr>
<tr>
<td>WriteAfter</td>
<td>Core 3.1</td>
<td>1.188 ns</td>
<td>0.0991 ns</td>
<td>0.2697 ns</td>
<td>1.093 ns</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
</tbody>
</table>
<h2 id="serializing-data-and-reusing-buffers">Serializing data and reusing buffers</h2><p>Serializing data types is one thing. Serializing the AMQP data structures composed of that data is another thing. Messages are serialized into what's called Frames. Frames consist of a frame header, channel number, frame size and then the eventual frame payload (our data) and ends with a frame-end marker byte.</p><p>This brings up an interesting problem, which stems from the frame size. The frame size appears in the structure before the actual payload does, which makes sense because we need the consumers of the protocol to know how many bytes are in the payload they are about to read. But, since our payload can contain all sorts of data as well as header properties, and data types are serialized differently, it's hard for us to know the size of the serialized payload before we have actually serialized all the data in the message.</p><h3 id="the-obvious-solution-memorystream">The obvious solution: MemoryStream</h3><p>Previously, this was solved in a way many of us would think of. The client library created a MemoryStream, which was as the output stream for the NetworkBinaryWriter class used to serialize the data. After all the data had been written, it was easy to keep track of how many bytes had been written to the MemoryStream, seek back to the correct header position and write the payload size. Job done!</p><p>This method did its job, and most importantly did it correctly, but it had the drawback that the entire frame had to be buffered as it was being serialized, and as the MemoryStream grew bigger, new backing arrays needed to be allocated, memory copied etc. until the entire frame was correctly serialized and fit into the buffer, and eventually the resulting array was output to the network.</p><h3 id="a-better-solution-memorypoolbyte">A better solution: MemoryPool&lt;byte&gt;</h3><p>This was a noticeably big part of where allocations were being made so it became one of the focus points. When I looked at the code I figured, since I already had all the data, that I didn't need to serialize all of it to know how big it would be. I could simply walk through the data structure and calculate the required buffer size. We know a byte is one byte, a float is four bytes, int is four bytes etc. The biggest problem was strings. Given an arbitrary string, how do I know how many bytes it'll occupy when it's encoded using UTF8? Luckily for us, such a method already exists (<a href="https://docs.microsoft.com/en-us/dotnet/api/system.text.encoding.getmaxbytecount?view=netframework-4.8">Encoding.GetMaxByteCount</a>), so that problem was solved as well.</p><p>So, what I decided to do, was to simply calculate how big each frame would need be at minimum when serialized, utilize <a href="https://docs.microsoft.com/en-us/dotnet/api/system.buffers.memorypool-1?view=netcore-3.1">System.Buffers.MemoryPool&lt;T&gt;</a> from the <a href="https://www.nuget.org/packages/System.Memory/">System.Memory NuGet packages</a> to fetch a pooled byte array of the minimum size, and then serialize the data directly to that pooled array, write it to the network socket and eventually return the array to the pool to be reused later. This would allow the client to eliminate any memory churn when serializing the data since data would be serialized to reusable byte arrays.</p><blockquote><em>Now, you may wonder why I didn't use one of the many libraries that provide implementations of MemoryStream that reuse pooled arrays, like </em><a href="https://www.nuget.org/packages/Microsoft.IO.RecyclableMemoryStream/"><em>Microsoft.IO.RecyclableMemoryStream</em></a><em>? The answer is future proofing! Moving to System.Memory gives the library access to Memory&lt;T&gt; and Span&lt;T&gt;, which are a mainstay in .NET Core, and will make the migration to System.IO.Pipelines a lot easier. So, stay tuned because there is even more good stuff coming in later versions :)</em></blockquote><p>Armed with this knowledge and idea, let's take a closer look at some of the improvements made and the impact it had!</p><h3 id="converting-strings-to-utf8-bytes">Converting strings to UTF8 bytes</h3><p>One of the first things I noticed was that when strings were being serialized, they were converted directly to a UTF8 byte array. Obviously, this will create a new array to contain the UTF8 bytes. However, strings can also be serialized to an existing array and given an offset to where to start to write the bytes and we'll also know how many bytes are eventually written. This of course fit in extremely well with the pooled array idea.</p><p>This is how strings were serialized to a stream before:</p><pre><code><span>public</span> <span>static</span> <span>void</span> <span>WriteShortstr</span><span>(</span><span>NetworkBinaryWriter</span> writer<span>,</span> <span>string</span> <span>value</span><span>)</span>
<span>{</span>
    <span>byte</span><span>[</span><span>]</span> bytes <span>=</span> Encoding<span>.</span>UTF8<span>.</span><span>GetBytes</span><span>(</span><span>value</span><span>)</span><span>;</span>
    writer<span>.</span><span>Write</span><span>(</span><span>(</span><span>ushort</span><span>)</span> bytes<span>.</span>Length<span>)</span><span>;</span>
    writer<span>.</span><span>Write</span><span>(</span>bytes<span>)</span><span>;</span>            
<span>}</span>
</code></pre>
<p>And this is how it's now serialized to a Memory&lt;byte&gt; </p><pre><code><span>public</span> <span>static</span> <span>int</span> <span>WriteShortstr</span><span>(</span>Memory<span>&lt;</span><span>byte</span><span>&gt;</span> memory<span>,</span> <span>string</span> val<span>)</span>
<span>{</span>
    <span>int</span> stringBytesNeeded <span>=</span> Encoding<span>.</span>UTF8<span>.</span><span>GetByteCount</span><span>(</span>val<span>)</span><span>;</span>
    <span>if</span> <span>(</span>MemoryMarshal<span>.</span><span>TryGetArray</span><span>(</span>memory<span>.</span><span>Slice</span><span>(</span><span>1</span><span>,</span> stringBytesNeeded<span>)</span><span>,</span> <span>out</span> ArraySegment<span>&lt;</span><span>byte</span><span>&gt;</span> segment<span>)</span><span>)</span>
    <span>{</span>
        memory<span>.</span>Span<span>[</span><span>0</span><span>]</span> <span>=</span> <span>(</span><span>byte</span><span>)</span>stringBytesNeeded<span>;</span>
        Encoding<span>.</span>UTF8<span>.</span><span>GetBytes</span><span>(</span>val<span>,</span> <span>0</span><span>,</span> val<span>.</span>Length<span>,</span> segment<span>.</span>Array<span>,</span> segment<span>.</span>Offset<span>)</span><span>;</span>
        <span>return</span> stringBytesNeeded <span>+</span> <span>1</span><span>;</span>
    <span>}</span>

    <span>throw</span> <span>new</span> <span>WireFormattingException</span><span>(</span><span>"Unable to get array segment from memory."</span><span>)</span><span>;</span>
<span>}</span>
</code></pre>
<p>Now, granted, the new code is a little more verbose, but it is MUCH more efficient. Here is an example benchmark converting the first "Lorem Ipsum" paragraph to UTF8 bytes.</p><table>
<thead>
<tr>
<th>Method</th>
<th>Runtime</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
<th>Ratio</th>
<th>Gen 0</th>
<th>Gen 1</th>
<th>Gen 2</th>
<th>Allocated</th>
</tr>
</thead>
<tbody>
<tr>
<td>GetByteArray</td>
<td>.NET 4.8</td>
<td>1,115.2 ns</td>
<td>13.68 ns</td>
<td>12.79 ns</td>
<td>1.00</td>
<td>0.2823</td>
<td>-</td>
<td>-</td>
<td>891 B</td>
</tr>
<tr>
<td>WriteToMemory</td>
<td>.NET 4.8</td>
<td>625.6 ns</td>
<td>5.23 ns</td>
<td>4.89 ns</td>
<td>0.56</td>
<td>0.0076</td>
<td>-</td>
<td>-</td>
<td>24 B</td>
</tr>
<tr>
<td>GetByteArray</td>
<td>.NET Core 3.1</td>
<td>234.0 ns</td>
<td>4.11 ns</td>
<td>3.64 ns</td>
<td>1.00</td>
<td>0.2828</td>
<td>-</td>
<td>-</td>
<td>888 B</td>
</tr>
<tr>
<td>WriteToMemory</td>
<td>.NET Core 3.1</td>
<td>157.0 ns</td>
<td>2.36 ns</td>
<td>2.09 ns</td>
<td>0.67</td>
<td>0.0076</td>
<td>-</td>
<td>-</td>
<td>24 B</td>
</tr>
</tbody>
</table>
<h2 id="arrays">Arrays</h2><p>As we have seen, the benefits of pooling and reusing arrays on code hot paths can be quite dramatic. This is mostly the result of freeing up our precious CPU cycles from being used by the Garbage Collector, cleaning up all our temporary objects. Having a garbage collector is one of the benefits of a managed language such as C#, but not having to use the Garbage Collector is even better.</p><div><p>I was able to take advantage of pooled arrays in the RabbitMQ client in several places. One of them was in the serialization as I mentioned above, where we could estimate the minimum amount of memory we'd need to serialize a frame, "rent" that amount of memory from our array pool, serialize the data directly into the array instead of using a MemoryStream + BinaryWriter object, and then send that array directly to the network Socket where it was sent to the server. Then we could return the array to the pool, rinse, and repeat. ‌</p><p>But what about the messages received from the server? Could I take advantage of them there.</p></div><p>YES!</p><p>After thinking about it for a while, I realized the the message payloads were being sent and received as byte arrays (byte[]). After talking it over the the RabbitMQ client maintainers, we decided that we'd make the change to have the message payloads represented as Memory&lt;byte&gt; instead. That allows us to use pooled arrays for messages received, copy the payload into another pooled array before being sent to the message event handlers, and then we could return them to the pool once the consumers had processed the messages!</p><div><p>Thankfully this was easy to solve using the MemoryPool&lt;T&gt; type. It allows us to easily rent and return pooled arrays using the IDisposable pattern. To give you an example of how to use it, let's imagine that we need calculate the SHA1 hash for a UTF8 string. As an example we'll use the same first "Lorem Ipsum" paragraph as an example.</p><p>Using the easy and convenient way:</p></div><pre><code><span>private</span> <span>SHA1</span> hasher <span>=</span> SHA1<span>.</span><span>Create</span><span>(</span><span>)</span><span>;</span>

<span>public</span> <span>byte</span><span>[</span><span>]</span> <span>GetByteArray</span><span>(</span><span>)</span>
<span>{</span>
    <span>return</span> hasher<span>.</span><span>ComputeHash</span><span>(</span>Encoding<span>.</span>UTF8<span>.</span><span>GetBytes</span><span>(</span>LoremIpsum<span>)</span><span>)</span><span>;</span>
<span>}</span>
</code></pre>
<p><br>Using MemoryPool&lt;byte&gt;:</p><pre><code><span>private</span> <span>SHA1</span> hasher <span>=</span> SHA1<span>.</span><span>Create</span><span>(</span><span>)</span><span>;</span>

<span>private</span> Memory<span>&lt;</span><span>byte</span><span>&gt;</span> hashedBytes <span>=</span> <span>new</span> <span><span>Memory</span><span>&lt;</span><span>byte</span><span>&gt;</span></span><span>(</span><span>new</span> <span>byte</span><span>[</span><span>20</span><span>]</span><span>)</span><span>;</span>

<span>public</span> Memory<span>&lt;</span><span>byte</span><span>&gt;</span> <span>WriteToMemoryWithGetByteCount</span><span>(</span><span>)</span>
<span>{</span>
    <span>int</span> numCharactersNeeded <span>=</span> Encoding<span>.</span>UTF8<span>.</span><span>GetByteCount</span><span>(</span>LoremIpsum<span>)</span><span>;</span>
    
    
    
    <span>using</span> <span>(</span>IMemoryOwner<span>&lt;</span><span>byte</span><span>&gt;</span> memory <span>=</span> MemoryPool<span>&lt;</span><span>byte</span><span>&gt;</span><span>.</span>Shared<span>.</span><span>Rent</span><span>(</span>numCharactersNeeded<span>)</span><span>)</span>
    <span>{</span>
        <span>if</span> <span>(</span>MemoryMarshal<span>.</span><span>TryGetArray</span><span>(</span>memory<span>.</span>Memory<span>.</span><span>Slice</span><span>(</span><span>0</span><span>,</span> numCharactersNeeded<span>)</span><span>,</span> <span>out</span> ArraySegment<span>&lt;</span><span>byte</span><span>&gt;</span> segment<span>)</span><span>)</span>
        <span>{</span>
            Encoding<span>.</span>UTF8<span>.</span><span>GetBytes</span><span>(</span>LoremIpsum<span>,</span> <span>0</span><span>,</span> LoremIpsum<span>.</span>Length<span>,</span> segment<span>.</span>Array<span>,</span> segment<span>.</span>Offset<span>)</span><span>;</span>
            hasher<span>.</span><span>TryComputeHash</span><span>(</span>segment<span>,</span> hashedBytes<span>.</span>Span<span>,</span> <span>out</span> <span>int</span> _<span>)</span><span>;</span>
            <span>return</span> hashedBytes<span>;</span>
        <span>}</span>

        <span>throw</span> <span>new</span> <span>InvalidOperationException</span><span>(</span><span>"Failed to get memory"</span><span>)</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre>
<p>Now again, the code is more verbose, but it is much more memory friendly.</p><table>
<thead>
<tr>
<th>Method</th>
<th>Mean</th>
<th>Error</th>
<th>StdDev</th>
<th>Ratio</th>
<th>Gen 0</th>
<th>Gen 1</th>
<th>Gen 2</th>
<th>Allocated</th>
</tr>
</thead>
<tbody>
<tr>
<td>ByteArray</td>
<td>2.378 us</td>
<td>0.0241 us</td>
<td>0.0226 us</td>
<td>1.00</td>
<td>0.3090</td>
<td>-</td>
<td>-</td>
<td>984 B</td>
</tr>
<tr>
<td>MemoryPool</td>
<td>2.244 us</td>
<td>0.0219 us</td>
<td>0.0205 us</td>
<td>0.94</td>
<td>0.0076</td>
<td>-</td>
<td>-</td>
<td>24 B</td>
</tr>
</tbody>
</table>
<h2 id="results-">Results!</h2><div><p>After going a few rounds on this, finding more places where I could put this to practice, and <a href="https://github.com/rabbitmq/rabbitmq-dotnet-client/pulls?q=is%3Apr+is%3Aclosed+author%3Astebet">submitting several PRs</a>, this work was finally released in the 6.0.0 release of the RabbitMQ .NET Client NuGet package. I decided to write a small program to see the result and run it through the JetBrains dotMemory profiler to see the result. ‌</p><p>The program did the following:</p></div><ul><li>Set up two connections to RabbitMQ, one to publish messages and another to receive them.</li><li>Used publisher confirms</li><li>Sent 50.000 messages, in bathes of five hundred messages at a time.</li><li>Used 512 byte and 16kb message payloads to test memory usage.</li><li>Ran until it had received those 50.000 messages back.</li></ul><p>Here are the results:</p><table>
<thead>
<tr>
<th>Payload Size (KB)</th>
<th>Memory Allocated Before (MB)</th>
<th>Memory Allocated After (MB)</th>
<th>Savings</th>
</tr>
</thead>
<tbody>
<tr>
<td>512</td>
<td>470.03</td>
<td>99.43</td>
<td><strong>78.85%</strong></td>
</tr>
<tr>
<td>16,384</td>
<td>7,311.36</td>
<td>99.41</td>
<td><strong>98.64%</strong></td>
</tr>
</tbody>
</table>
<figure><img src="https://stebet.net/content/images/2020/04/512AllocsBefore.png"><figcaption>Before: 50,000 messages sent/received with a 512-byte payload</figcaption></figure><figure><img src="https://stebet.net/content/images/2020/04/16kAllocsBefore.png"><figcaption>Before: 50,000 messages sent/received with a 16,384-byte payload</figcaption></figure><figure><img src="https://stebet.net/content/images/2020/04/512AllocsAfter.png"><figcaption>After: 50,000 messages sent/received with a 512-byte payload</figcaption></figure><figure><img src="https://stebet.net/content/images/2020/04/16kAllocsAfter.png"><figcaption>After: 50.000 messages sent/received with a 16,384-byte payload</figcaption></figure><p>As you can see, the memory usage when sending and receiving the events is now pretty much constant, regardless of the payload size. This is a massive improvement and frees up a lot of valuable CPU cycles and memory churn for other tasks.</p><p>What really made me happy with this release, was the fact that the API change only very slightly, and in most cases required little or no changes at all for the consumers of the package.</p><p>This is however not the end of this performance work by any means. There are more improvements in the pipeline (hint hint) that are sure to bring even more gains, for the benefit of everyone, so stay tuned :)</p>
</div>
</section>

</article>
</div>
</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
		<div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>