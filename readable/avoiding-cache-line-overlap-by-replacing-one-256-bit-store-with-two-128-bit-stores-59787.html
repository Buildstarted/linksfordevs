<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Avoiding cache line overlap by replacing one 256-bit store with two 128-bit stores - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Avoiding cache line overlap by replacing one 256-bit store with two 128-bit stores - linksfor.dev(s)"/>
    <meta property="article:author" content="Published by"/>
    <meta property="og:description" content="Memory is organized in cache lines, frequently blocks of 64 bytes. On Intel and AMD processors, you can store and load memory in blocks of various sizes, such as 64 bits, 128 bits or 256 bits. In the old days, and on some limited devices today, reading and storing to memory required you to respect &#x2026; Continue reading Avoiding cache line overlap by replacing one 256-bit store with two 128-bit stores"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://lemire.me/blog/2020/03/18/avoiding-cache-line-overlap-by-replacing-one-256-bit-store-with-two-128-bit-stores/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
	<div class="devring" style="background: #222">
		<div class="grid">
			<div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
				<span class="devring-title">devring.club</span>
				<a href="https://devring.club/site/1/previous" class="devring-previous">Previous</a>
				<a href="https://devring.club/random" class="devring-random">Random</a>
				<a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
			</div>
		</div>
	</div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Avoiding cache line overlap by replacing one 256-bit store with two 128-bit stores</title>
<div class="readable">
        <h1>Avoiding cache line overlap by replacing one 256-bit store with two 128-bit stores</h1>
            <div>by Published by</div>
            <div>Reading time: 3-4 minutes</div>
        <div>Posted here: 18 Mar 2020</div>
        <p><a href="https://lemire.me/blog/2020/03/18/avoiding-cache-line-overlap-by-replacing-one-256-bit-store-with-two-128-bit-stores/">https://lemire.me/blog/2020/03/18/avoiding-cache-line-overlap-by-replacing-one-256-bit-store-with-two-128-bit-stores/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
<p>Memory is organized in cache lines, frequently blocks of 64 bytes. On Intel and AMD processors, you can store and load memory in blocks of various sizes, such as 64 bits, 128 bits or 256 bits.</p>
<p>In the old days, and on some limited devices today, reading and storing to memory required you to respect alignment. You could not simply write any block memory anywhere. Today you mostly can write wherever you like. There is a small penalty for misalignment but the penalty is typically under 10% as I argued in my 2012 post <a href="https://lemire.me/blog/2012/05/31/data-alignment-for-speed-myth-or-reality/">Data alignment for speed: myth or reality?</a></p>
<p>Yet writing or reading from two cache lines instead of a single one is likely to be more expensive at least some of the time. Let us explore an interesting scenario. It is sometimes possible to avoid crossing a cache line boundary by doing two memory accesses instead of a single large one. Is it worth it?</p>
<p>Cache lines in memory are aligned on addresses that are divisible by 64 bytes. Suppose that you would want to store 256 bits of data every 64 bytes, at just the right offset so that the 256 bits overlap two cache lines. You hit last 16 bytes of one cache line and the first 16 bytes of the second one. You can achieve the desired results by starting with an offset of 48 bytes. That is, you find find a memory address that is divisible by 64 bytes, and then you add 48 bytes.</p>
<p>In code, using Intel intrinsics, it looks as follow:</p>
<pre><span><span>char</span></span><span> </span><span><span>*</span></span><span> p </span><span><span>=</span></span><span> </span><span><span>.</span></span><span><span>.</span></span><span><span>.</span></span><span>
</span><span><span>for</span></span><span> </span><span><span>(</span></span><span><span>size_t</span></span><span> i </span><span><span>=</span></span><span> </span><span><span>0</span></span><span><span>;</span></span><span> i </span><span><span>&lt;</span></span><span> </span><span><span>.</span></span><span><span>.</span></span><span><span>.</span></span><span> </span><span><span>;</span></span><span> i</span><span><span>+</span></span><span><span>+</span></span><span><span>)</span></span><span> </span><span><span>{</span></span><span>
  _mm256_storeu_si256</span><span><span>(</span></span><span>p </span><span><span>+</span></span><span> i </span><span><span>*</span></span><span> </span><span><span>64</span></span><span><span>,</span></span><span> vec</span><span><span>)</span></span><span><span>;</span></span><span>
</span><span><span>}</span></span>
</pre>
<p>You can avoid entirely crossing the cache line bounding by first storing 128-bit of data at the 48-byte offset, and then storing another 128-bit of data. The first store is at the end of the first cache line and the second store is at the beginning of the second one.</p>
<pre><span><span>char</span></span><span> </span><span><span>*</span></span><span> p </span><span><span>=</span></span><span> </span><span><span>.</span></span><span><span>.</span></span><span><span>.</span></span><span>
</span><span><span>for</span></span><span> </span><span><span>(</span></span><span><span>size_t</span></span><span> i </span><span><span>=</span></span><span> </span><span><span>0</span></span><span><span>;</span></span><span> i </span><span><span>&lt;</span></span><span> </span><span><span>.</span></span><span><span>.</span></span><span><span>.</span></span><span> </span><span><span>;</span></span><span> i</span><span><span>+</span></span><span><span>+</span></span><span><span>)</span></span><span> </span><span><span>{</span></span><span>
      _mm_storeu_si128</span><span><span>(</span></span><span>p </span><span><span>+</span></span><span> i </span><span><span>*</span></span><span> </span><span><span>64</span></span><span><span>,</span></span><span> vec</span><span><span>)</span></span><span><span>;</span></span><span>
      _mm_storeu_si128</span><span><span>(</span></span><span>p </span><span><span>+</span></span><span> i </span><span><span>*</span></span><span> </span><span><span>64</span></span><span> </span><span><span>+</span></span><span> </span><span><span>16</span></span><span><span>,</span></span><span> vec</span><span><span>)</span></span><span><span>;</span></span><span>
</span><span><span>}</span></span>
</pre>
<p>How do these two approaches fare? I wrote a simple benchmark that stores many blocks of 256-bit at a 48-byte offset. It either stores it in one 256-bit step or in two 128-bit steps. I record the number of cycles per iteration on an AMD Rome processor. I rely on the the pre-installed RedHat LLVM compiler (clang version 3.4.2).</p>
<table>
<tbody>
<tr>
<td>A single 256-bit write</td>
<td>2.33 cycles</td>
</tr>
<tr>
<td>Two 128-bit writes</td>
<td>2.08 cycles</td>
</tr>
</tbody>
</table>
<p>It is a gain of slightly over 10% for the two 128-bit writes. What if you remove the 48-byte offset (or set it to zero)? Then both benchmark clock at 2.08 cycles per iteration. I expect that the 48-byte offset is a best-case scenario for the two 128-bit writes: if you change it then both approaches have the same cache-line overlap problems. So this 10% gain requires you to choose the alignment carefully.</p>
<p><a href="https://github.com/lemire/Code-used-on-Daniel-Lemire-s-blog/tree/master/2020/03/17">My source code is available</a>. Of course, your results will depend on the processor and to some extend on the compiler. You should be able to run my benchmark program on your own Linux x64 system.</p>
<p>Be mindful that if you are getting worse results on a per cycle basis on comparable hardware, you might be limited by your compiler. An analysis of the assembly might be required.</p>
</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
		<div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>