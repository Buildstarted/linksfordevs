<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Hyperion Publications - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Hyperion Publications - linksfor.dev(s)"/>
    <meta property="article:author" content="By Yining Karl Li"/>
    <meta property="og:description" content="The home of Code &amp; Visuals"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://blog.yiningkarlli.com/2019/07/hyperion-papers.html"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">🎉</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Hyperion Publications</title>
<div class="readable">
        <h1>Hyperion Publications</h1>
            <div>by By Yining Karl Li</div>
            <div>Watching time: 30-39 minutes</div>
        <div>Posted here: 11 Sep 2019</div>
        <p><a href="https://blog.yiningkarlli.com/2019/07/hyperion-papers.html">https://blog.yiningkarlli.com/2019/07/hyperion-papers.html</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div role="main">
    <article>

            
            <span>July 30, 2019 
                 | Tags: 
                     
                        Hyperion
                      
                </span>

            <section>
                <p>Every year at SIGGRAPH (and sometimes at other points in the year), members of the Hyperion team inevitably get asked if there is any publicly available information about <a href="https://www.disneyanimation.com/technology/innovations/hyperion">Disney’s Hyperion Renderer</a>.
The answer is: yes, there is actually a lot of publicly available information!</p>

<p><a href="https://blog.yiningkarlli.com/content/images/2019/Jul/FirstPagesv2.png"><div><p><img src="https://blog.yiningkarlli.com/content/images/2019/Jul/FirstPagesv2_prev.png" alt="Figure 1: Previews of the first page of every Hyperion-related publication from Disney Animation, Disney Research Studios, and other research partners."></p><p>Figure 1: Previews of the first page of every Hyperion-related publication from Disney Animation, Disney Research Studios, and other research partners.</p></div></a></p>

<p>One amazing aspect of working at Walt Disney Animation Studios is the huge amount of support and encouragement we get from our managers and the wider studio for publishing and sharing our work with the wider academic world and industry.
As part of this sharing, the Hyperion team has had the opportunity to publish a number of papers over the years detailing various interesting techniques used in the renderer.</p>

<p>I think it’s very important to mention here that another one of my favorite aspects of working on the Hyperion team is the deep collaboration we get to engage in with our sister rendering team at <a href="https://studios.disneyresearch.com/">Disney Research Studios</a> (formerly known as Disney Research Zürich).
The vast majority of the Hyperion team’s publications are joint works with Disney Research Studios, and I personally think it’s fair to say that all of Hyperion’s most interesting advanced features are just as much the result of research and work from Disney Research Studios as they are the result of our team’s own work.
Without a doubt, Hyperion, and by extension, our movies, would not be what they are today without Disney Research Studios.
Of course, we also collaborate closely with our sister rendering teams at <a href="https://www.pixar.com/">Pixar Animation Studios</a> and <a href="https://www.ilm.com/">Industrial Light &amp; Magic</a> as well, and there are numerous examples where collaboration between all of these teams has advanced the state of the art in rendering for the whole industry.</p>

<p>So without further ado, below are all of the papers that the Hyperion team has published or worked on or had involvement with over the years, either by ourselves or with our counterparts at Disney Research Studios, Pixar, ILM, and other research groups.
If you’ve ever been curious to learn more about Disney’s Hyperion Renderer, here are 32 publications with a combined 387 pages of material!
For each paper, I’ll link to a preprint version, link to the official publisher’s version, and link any additional relevant resources for the paper.
I’ll also give the citation information, give a brief description, list the teams involved, and note how the paper is relevant to Hyperion.
This post is meant to be a living document; I’ll come back and update it down the line with future publications. Publications are listed in chronological order.</p>

<ol>
  <li>
    <p><strong>Ptex: Per-Face Texture Mapping for Production Rendering</strong></p>

    <p><a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a> and <a href="https://www.linkedin.com/in/dylanlacewell/">Dylan Lacewell</a>. Ptex: Per-face Texture Mapping for Production Rendering. <em>Computer Graphics Forum (Proceedings of Eurographics Symposium on Rendering 2008)</em>, 27(4), June 2008.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1EdMYHhs4h_ICcSgGfA4GzZoRNI_yVryA">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1111/j.1467-8659.2008.01253.x">Official Publisher’s Version</a></li>
      <li><a href="http://ptex.us/">Open Source Project</a></li>
    </ul>

    <p>Internal project from Disney Animation. This paper describes per-face textures, a UV-free way of texture mapping. Ptex is the texturing system used in Hyperion for all non-procedural texture maps. Every Disney Animation film made using Hyperion is textured entirely with Ptex. Ptex is also available in many commercial renderers, such as <a href="https://renderman.pixar.com/">Pixar’s RenderMan</a>!</p>
  </li>
  <li>
    <p><strong>Physically-Based Shading at Disney</strong></p>

    <p><a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a>. Physically Based Shading at Disney. In <em>ACM SIGGRAPH 2012 Course Notes: Practical Physically-Based Shading in Film and Game Production</em>, August 2012.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1SwEWQadyMPo5m49kIACoFq2R6q0bZJz7">Preprint Version</a> (Updated compared to official version)</li>
      <li><a href="https://doi.org/10.1145/2343483.2343493">Official Publisher’s Version</a></li>
      <li><a href="https://blog.selfshadow.com/publications/s2012-shading-course/">Physically Based Shading SIGGRAPH 2012 Course</a></li>
    </ul>

    <p>Internal project from Disney Animation. This paper describes the Disney BRDF, a physically principled shading model with a artist-friendly parameterization and layering system. The Disney BRDF is the basis of Hyperion’s entire shading system. The Disney BRDF has also gained widespread industry adoption the basis of a wide variety of physically based shading systems, and has influenced the design of shading systems in a number of other production renderers. Every Disney Animation film made using Hyperion is shaded using the Disney BSDF (an extended version of the Disney BRDF, described in a later paper).</p>
  </li>
  <li>
    <p><strong>Sorted Deferred Shading for Production Path Tracing</strong></p>

    <p><a href="https://www.linkedin.com/in/christian-eisenacher-477ab983/">Christian Eisenacher</a>, <a href="https://www.linkedin.com/in/gregory-nichols/">Gregory Nichols</a>, <a href="http://www.andyselle.com/">Andrew Selle</a>, and <a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a>. Sorted Deferred Shading for Production Path Tracing. <em>Computer Graphics Forum (Proceedings of Eurographics Symposium on Rendering 2013)</em>, 32(4), June 2013.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1zha14cniwtvy8Xkn2Jv9jE5Y1T50VSJS">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1111/cgf.12158">Official Publisher’s Version</a></li>
    </ul>

    <p>Internal project from Disney Animation. Won the Best Paper Award at EGSR 2013! This paper describes the sorted deferred shading architecture that is at the very core of Hyperion. Along with the previous two papers in this list, this is one of the foundational papers for Hyperion; every film rendered using Hyperion is rendered using this architecture.</p>
  </li>
  <li>
    <p><strong>Residual Ratio Tracking for Estimating Attenuation in Participating Media</strong></p>

    <p><a href="http://drz.disneyresearch.com/~jnovak/">Jan Novák</a>, <a href="http://www.andyselle.com/">Andrew Selle</a>, and <a href="https://cs.dartmouth.edu/~wjarosz/">Wojciech Jarosz</a>. Residual Ratio Tracking for Estimating Attenuation in Participating Media. <em>ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia 2014)</em>, 33(6), November 2014.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1b1RkW3eFAgM-i6IZ_m0jmQcPfr7cOLEz">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/2661229.2661292">Official Publisher’s Version</a></li>
      <li><a href="http://drz.disneyresearch.com/~jnovak/publications/RRTracking/">Project Page</a></li>
    </ul>

    <p>Joint project between Disney Research Studios and Disney Animation. This paper described a pair of new, complementary techniques for evaluating transmittance in heterogeneous volumes. These two techniques made up the core of Hyperion’s first and second generation volume rendering implementations, used from <em>Big Hero 6</em> up through <em>Moana</em>.</p>
  </li>
  <li>
    <p><strong>Path-space Motion Estimation and Decomposition for Robust Animation Filtering</strong></p>

    <p><a href="https://graphics.ethz.ch/~hzimmer/">Henning Zimmer</a>, <a href="https://research.nvidia.com/person/fabrice-rousselle">Fabrice Rousselle</a>, <a href="http://rgl.epfl.ch/people/wjakob/">Wenzel Jakob</a>, <a href="http://zurich.disneyresearch.com/~owang/">Oliver Wang</a>, <a href="https://www.linkedin.com/in/david-adler-5ab7b21/">David Adler</a>, <a href="https://cs.dartmouth.edu/~wjarosz/">Wojciech Jarosz</a>, <a href="http://igl.ethz.ch/people/sorkine/">Olga Sorkine-Hornung</a>, and <a href="http://www.ahornung.net/">Alexander Sorkine-Hornung</a>. Path-space Motion Estimation and Decomposition for Robust Animation Filtering. <em>Computer Graphics Forum (Proceedings of Eurographics Symposium on Rendering 2015)</em>, 34(4), June 2015.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=19Me6xkA9jBIlydMMgEeC9Uor93MqBhtW">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1111/cgf.12685">Official Publisher’s Version</a></li>
      <li><a href="https://cs.dartmouth.edu/~wjarosz/publications/zimmer15path.html">Project Page</a></li>
    </ul>

    <p>Joint project between Disney Research Studios, ETH Zürich, and Disney Animation. This paper describes a denoising technique suitable for animated sequences. Not directly used in Hyperion’s denoiser, but both inspired by and influential towards Hyperion’s first generation denoiser.</p>
  </li>
  <li>
    <p><strong>Portal-Masked Environment Map Sampling</strong></p>

    <p><a href="https://benedikt-bitterli.me/">Benedikt Bitterli</a>, <a href="http://drz.disneyresearch.com/~jnovak/">Jan Novák</a>, and <a href="https://cs.dartmouth.edu/~wjarosz/">Wojciech Jarosz</a>. Portal-Masked Environment Map Sampling. <em>Computer Graphics Forum (Proceedings of Eurographics Symposium on Rendering 2015)</em>, 34(4), June 2015.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=14zzjee1MAhUPsQ2vUzPQyZFo-J8Gud7b">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1111/cgf.12674">Official Publisher’s Version</a></li>
      <li><a href="https://benedikt-bitterli.me/pmems.html">Project Page</a></li>
    </ul>

    <p>Joint project between Disney Research Studios and Disney Animation. This paper describes an efficient method for importance sampling environment maps. This paper was actually derived from the technique Hyperion uses for importance sampling lights with IES profiles, which has been used on all films rendered using Hyperion.</p>
  </li>
  <li>
    <p><strong>A Practical and Controllable Hair and Fur Model for Production Path Tracing</strong></p>

    <p><a href="https://dl.acm.org/author_page.cfm?id=99658729701&amp;coll=DL&amp;dl=ACM&amp;trk=0">Matt Jen-Yuan Chiang</a>, <a href="https://benedikt-bitterli.me/">Benedikt Bitterli</a>, <a href="https://www.linkedin.com/in/chuck-tappan-40762450/">Chuck Tappan</a>, and <a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a>. A Practical and Controllable Hair and Fur Model for Production Path Tracing. In <em>ACM SIGGRAPH 2015 Talks</em>, August 2015.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=19k6mnZMJXmgDSwy1Hcb7fFdMstALjTto">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/2775280.2792559">Official Publisher’s Version</a></li>
    </ul>

    <p>Joint project between Disney Research Studios and Disney Animation. This short paper gives an overview of Hyperion’s fur and hair model, originally developed for use on Zootopia. A full paper was published later with more details. This fur/hair model is Hyperion’s fur/hair model today, used on every film beginning with <em>Zootopia</em> to present.</p>
  </li>
  <li>
    <p><strong>Extending the Disney BRDF to a BSDF with Integrated Subsurface Scattering</strong></p>

    <p><a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a>. Extending the Disney BRDF to a BSDF with Integrated Subsurface Scattering. In <em>ACM SIGGRAPH 2015 Course Notes: Physically Based Shading in Theory and Practice</em>, August 2015.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1KJgmVRZqEI7rCdSSeT6_lZJerTTQ0AiH">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/2776880.2787670">Official Publisher’s Version</a></li>
      <li><a href="https://blog.selfshadow.com/publications/s2015-shading-course">Physically Based Shading SIGGRAPH 2015 Course</a></li>
    </ul>

    <p>Internal project from Disney Animation. This paper describes the full Disney BSDF (sometimes referred to in the wider industry as Disney BRDF v2) used in Hyperion, and also describes a novel subsurface scattering technique called normalized diffusion subsurface scattering. The Disney BSDF is the shading model for everything ever rendered using Hyperion, and normalized diffusion was Hyperion’s subsurface model from <em>Big Hero 6</em> up through <em>Moana</em>. For a public open-source implementation of the Disney BSDF, check out <a href="https://github.com/mmp/pbrt-v3">PBRT v3</a>’s implementation. Also, check out <a href="https://renderman.pixar.com/">Pixar’s RenderMan</a> for an implementation in a commercial renderer!</p>
  </li>
  <li>
    <p><strong>Approximate Reflectance Profiles for Efficient Subsurface Scattering</strong></p>

    <p><a href="https://www.seanet.com/~myandper/per.htm">Per H Christensen</a> and <a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a>. Approximate Reflectance Profiles for Efficient Subsurface Scattering. <em>Pixar Technical Memo</em>, #15-04, August 2015.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1kJfJId-I5DjhUnHH-Q6fgsrNc7ZW1MIq">Preprint Version</a></li>
      <li><a href="http://graphics.pixar.com/library/ApproxBSSRDF/">Official Pixar Research Version and Project Page</a></li>
      <li><a href="https://www.seanet.com/~myandper/abstract/memo1504.htm">Updates and Errata</a></li>
    </ul>

    <p>Joint project between Pixar and Disney Animation. This paper presents several useful parameterizations for the normalized diffusion subsurface scattering model presented in the previous paper in this list. These parameterizations are used for the normalized diffusion implementation in <a href="https://rmanwiki.pixar.com/display/REN/PxrSurface">Pixar’s RenderMan 21</a> and later.</p>
  </li>
  <li>
    <p><strong>Big Hero 6: Into the Portal</strong></p>

    <p><a href="https://www.linkedin.com/in/david-hutchins-21a9507/">David Hutchins</a>, <a href="https://www.linkedin.com/in/olun-riley/">Olun Riley</a>, <a href="https://www.linkedin.com/in/popsopdop/">Jesse Erickson</a>, <a href="http://alexey.stomakhin.com/">Alexey Stomakhin</a>, <a href="https://www.linkedin.com/in/ralf-habel-6a74bb2/">Ralf Habel</a>, and <a href="https://www.linkedin.com/in/michael-kaschalk-49b7683/">Michael Kaschalk</a>. Big Hero 6: Into the Portal. In <em>ACM SIGGRAPH 2015 Talks</em>, August 2015.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1cCDmWf6pKDaIarDRK0YkARhm5_kQlF4_">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/2775280.2792521">Official Publisher’s Version</a></li>
    </ul>

    <p>Internal project from Disney Animation. This short paper describes some interesting volume rendering challenges that Hyperion faced during the production of <em>Big Hero 6</em>’s climax sequence, set in a volumetric fractal portal world.</p>
  </li>
  <li>
    <p><strong>A Practical and Controllable Hair and Fur Model for Production Path Tracing</strong></p>

    <p><a href="https://dl.acm.org/author_page.cfm?id=99658729701&amp;coll=DL&amp;dl=ACM&amp;trk=0">Matt Jen-Yuan Chiang</a>, <a href="https://benedikt-bitterli.me/">Benedikt Bitterli</a>, <a href="https://www.linkedin.com/in/chuck-tappan-40762450/">Chuck Tappan</a>, and <a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a>. A Practical and Controllable Hair and Fur Model for Production Path Tracing. <em>Computer Graphics Forum (Proceedings of Eurographics 2016)</em>, 35(2), May 2016.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1cVxBWddi2yClj_A_bca_emRduPJ6GN8Q">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1111/cgf.12830">Official Publisher’s Version</a></li>
      <li><a href="https://benedikt-bitterli.me/pchfm/">Project Page</a></li>
      <li><a href="https://www.pbrt.org/hair.pdf">Implementation Guide by Matt Pharr</a></li>
    </ul>

    <p>Joint project between Disney Research Studios and Disney Animation. This paper gives an overview of Hyperion’s fur and hair model, originally developed for use on <em>Zootopia</em>. This fur/hair model is Hyperion’s fur/hair model today, used on every film beginning with <em>Zootopia</em> to present. This paper is now also implemented in the open source <a href="https://github.com/mmp/pbrt-v3/blob/master/src/materials/hair.h">PBRT v3</a> renderer, and also serves as the basis of the hair/fur shader in Chaos Group’s <a href="https://www.chaosgroup.com/blog/v-ray-next-the-science-behind-the-new-hair-shader">V-Ray Next</a> renderer.</p>
  </li>
  <li>
    <p><strong>Subdivision Next-Event Estimation for Path-Traced Subsurface Scattering</strong></p>

    <p><a href="https://www.linkedin.com/in/david-koerner-41233611">David Koerner</a>, <a href="http://drz.disneyresearch.com/~jnovak/">Jan Novák</a>, <a href="https://www.linkedin.com/in/peterkutz/">Peter Kutz</a>, <a href="https://www.linkedin.com/in/ralf-habel-6a74bb2/">Ralf Habel</a>, and <a href="https://cs.dartmouth.edu/~wjarosz/">Wojciech Jarosz</a>. Subdivision Next-Event Estimation for Path-Traced Subsurface Scattering. In <em>Proceedings of EGSR 2016, Experimental Ideas &amp; Implementations</em>, June 2016.
2016-06-24,</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1iMwNqPr-l-_xTViWqxXYIuP8S_he7t8k">Preprint Version</a></li>
      <li><a href="https://doi.org/10.2312/sre.20161214">Official Publisher’s Version</a></li>
      <li><a href="http://drz.disneyresearch.com/~jnovak/publications/SNEE/index.html">Project Page</a></li>
    </ul>

    <p>Joint project between Disney Research Studios, University of Stuttgart, Dartmouth College, and Disney Animation. This paper describes a method for accelerating brute force path traced subsurface scattering; this technique was developed during early experimentation in making path traced subsurface scattering practical for production in Hyperion.</p>
  </li>
  <li>
    <p><strong>Nonlinearly Weighted First-Order Regression for Denoising Monte Carlo Renderings</strong></p>

    <p><a href="https://benedikt-bitterli.me/">Benedikt Bitterli</a>, <a href="https://research.nvidia.com/person/fabrice-rousselle">Fabrice Rousselle</a>, <a href="http://sglab.kaist.ac.kr/~bcmoon/">Bochang Moon</a>, <a href="http://www.j4lley.com/">José A. Iglesias-Guitian</a>, <a href="https://www.linkedin.com/in/david-adler-5ab7b21/">David Adler</a>, <a href="http://www.disneyresearch.com/people/kenny-mitchel/">Kenny Mitchell</a>, <a href="https://cs.dartmouth.edu/~wjarosz/">Wojciech Jarosz</a>, and <a href="http://drz.disneyresearch.com/~jnovak/">Jan Novák</a>. Nonlinearly Weighted First-Order Regression for Denoising Monte Carlo Renderings. <em>Computer Graphics Forum (Proceedings of Eurographics Symposium on Rendering 2016)</em>, 35(4), July 2016.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1cwtHef8gq5m-oKbc2yKDY3jwnbJB1iLQ">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1111/cgf.12954">Official Publisher’s Version</a></li>
      <li><a href="https://benedikt-bitterli.me/nfor/">Project Page</a></li>
    </ul>

    <p>Joint project between Disney Research Studios, Edinburgh Napier University, Dartmouth College, and Disney Animation. This paper describes a high-quality, stable denoising technique based on a thorough analysis of previous technique. This technique was developed during a larger project to develop a state-of-the-art successor to Hyperion’s first generation denoiser.</p>
  </li>
  <li>
    <p><strong>Practical and Controllable Subsurface Scattering for Production Path Tracing</strong></p>

    <p><a href="https://dl.acm.org/author_page.cfm?id=99658729701&amp;coll=DL&amp;dl=ACM&amp;trk=0">Matt Jen-Yuan Chiang</a>, <a href="https://www.linkedin.com/in/peterkutz/">Peter Kutz</a>, and <a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a>. Practical and Controllable Subsurface Scattering for Production Path Tracing. In <em>ACM SIGGRAPH 2016 Talks</em>, July 2016.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1YzdsAbG60dCUkq6xo_HH8nBseILfHfZW">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/2897839.2927433">Official Publisher’s Version</a></li>
    </ul>

    <p>Internal project from Disney Animation. This short paper describes the novel parameterization and multi-wavelength sampling strategy used to make path traced subsurface scattering practical for production. Both of these are implemented in Hyperion’s path traced subsurface scattering system and have been in use on all shows beginning with <em>Olaf’s Frozen Adventure</em> to present.</p>
  </li>
  <li>
    <p><strong>Efficient Rendering of Heterogeneous Polydisperse Granular Media</strong></p>

    <p><a href="https://tom94.net/">Thomas Müller</a>, <a href="https://graphics.ethz.ch/~mpapas/">Marios Papas</a>, <a href="https://la.disneyresearch.com/people/markus-gross/">Markus Gross</a>, <a href="https://cs.dartmouth.edu/~wjarosz/">Wojciech Jarosz</a>, and <a href="http://drz.disneyresearch.com/~jnovak/">Jan Novák</a>. Efficient Rendering of Heterogeneous Polydisperse Granular Media. <em>ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia 2016)</em>, 35(6), November 2016.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1qFwr6_JL29uextdtyNurOFQId0CahvVc">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/2980179.2982429">Official Publisher’s Version</a></li>
      <li><a href="https://cs.dartmouth.edu/~wjarosz/publications/muller16efficient.html">Project Page</a></li>
    </ul>

    <p>External project from Disney Research Studios, ETH Zürich, and Dartmouth College, inspired in part by production problems encountered at Disney Animation related to rendering things like sand, snow, etc. This technique uses shell transport functions to accelerate path traced rendering of massive assemblies of grains. <a href="https://tom94.net/">Thomas Müller</a> implemented an experimental version of this technique in Hyperion, along with an interesting extension for applying the shell transport theory to volume rendering.</p>
  </li>
  <li>
    <p><strong>Practical Path Guiding for Efficient Light-Transport Simulation</strong></p>

    <p><a href="https://tom94.net/">Thomas Müller</a>, <a href="https://la.disneyresearch.com/people/markus-gross/">Markus Gross</a>, and <a href="http://drz.disneyresearch.com/~jnovak/">Jan Novák</a>. Practical Path Guiding for Efficient Light-Transport Simulation. <em>Computer Graphics Forum (Proceedings of Eurographics Symposium on Rendering 2017)</em>, 36(4), July 2017.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1xJeK76y7BjWHMHpIL31o08f9eJzytGNU">Preprint Version</a> (Updated compared to official version)</li>
      <li><a href="https://doi.org/10.1111/cgf.13227">Official Publisher’s Version</a></li>
      <li><a href="http://drz.disneyresearch.com/~jnovak/publications/PathGuide/index.html">Project Page</a></li>
    </ul>

    <p>External joint project between Disney Research Studios and ETH Zürich, inspired in part by challenges with handling complex light transport efficiently in Hyperion. Won the Best Paper Award at EGSR 2017! This paper describes a robust, unbiased technique for progressively learning complex indirect illumination in a scene during a render and intelligently guiding paths to better sample difficult indirect illumination effects. Implemented in Hyperion, along with a number of interesting improvements documented in a later paper. In use on <em>Frozen 2</em> and future films.</p>
  </li>
  <li>
    <p><strong>Kernel-predicting Convolutional Networks for Denoising Monte Carlo Renderings</strong></p>

    <p><a href="http://www.ece.ucsb.edu/~sbako/">Steve Bako</a>, <a href="https://tvogels.nl/">Thijs Vogels</a>, <a href="https://www.inf.ethz.ch/personal/mcbrian/">Brian McWilliams</a>, <a href="http://graphics.pixar.com/people/mmeyer/">Mark Meyer</a>, <a href="http://drz.disneyresearch.com/~jnovak/">Jan Novák</a>, <a href="https://graphics.pixar.com/library/indexAuthorAlex_Harvill.html">Alex Harvill</a>, <a href="http://www.ece.ucsb.edu/~psen/">Pradeep Sen</a>, <a href="http://graphics.pixar.com/people/derose/">Tony DeRose</a>, and <a href="https://research.nvidia.com/person/fabrice-rousselle">Fabrice Rousselle</a>. Kernel-predicting Convolutional Networks for Denoising Monte Carlo Renderings. <em>ACM Transactions on Graphics (Proceedings of SIGGRAPH 2017)</em>, 36(4), July 2017.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=18jrs2MPiZ5UUqNiSlrerzzb5JX1ba_zM">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/3072959.3073708">Official Publisher’s Version</a></li>
      <li><a href="http://drz.disneyresearch.com/~jnovak/publications/KPCN/index.html">Project Page</a></li>
    </ul>

    <p>External joint project between University of California Santa Barbara, Disney Research Studios, ETH Zürich, and Pixar, developed as part of the larger effort to develop a successor to Hyperion’s first generation denoiser. This paper describes a supervised learning approach for denoising filter kernels using deep convolutional neural networks. This technique is the basis of the modern Disney-Research-developed second generation deep-learning denoiser in use by the rendering teams at Pixar and ILM, and by the Hyperion iteam at Disney Animation.</p>
  </li>
  <li>
    <p><strong>Production Volume Rendering</strong></p>

    <p><a href="https://www.linkedin.com/in/jfong">Julian Fong</a>, <a href="http://magnuswrenninge.com/">Magnus Wrenninge</a>, <a href="https://fpsunflower.github.io/ckulla/">Christopher Kulla</a>, and <a href="https://www.linkedin.com/in/ralf-habel-6a74bb2/">Ralf Habel</a>. Production Volume Rendering. In <em>ACM SIGGRAPH 2017 Courses</em>, July 2017.</p>

    <ul>
      <li><a href="https://drive.google.com/file/d/1eFr_4IKzt796Ns4Iv3OjR3ni0Y7QigP5/view?usp=drivesdk">Preprint Version</a> (Updated compared to official version)</li>
      <li><a href="https://doi.org/10.1145/3084873.3084907">Official Publisher’s Version</a></li>
      <li><a href="https://graphics.pixar.com/library/ProductionVolumeRendering/index.html">Production Volume Rendering SIGGRAPH 2017 Course</a></li>
    </ul>

    <p>Joint publication from Pixar, Sony Pictures Imageworks, and Disney Animation. This course covers volume rendering in modern path tracing renderers, from basic theory all the way to practice. The last chapter details the inner workings of Hyperion’s first and second generation transmittance estimation based volume rendering system, used from <em>Big Hero 6</em> up through <em>Moana</em>.</p>
  </li>
  <li>
    <p><strong>Spectral and Decomposition Tracking for Rendering Heterogeneous Volumes</strong></p>

    <p><a href="https://www.linkedin.com/in/peterkutz/">Peter Kutz</a>, <a href="https://www.linkedin.com/in/ralf-habel-6a74bb2/">Ralf Habel</a>, <a href="https://www.yiningkarlli.com/">Yining Karl Li</a>, and <a href="http://drz.disneyresearch.com/~jnovak/">Jan Novák</a>. Spectral and Decomposition Tracking for Rendering Heterogeneous Volumes. <em>ACM Transactions on Graphics (Proceedings of SIGGRAPH 2017)</em>, 36(4), July 2017.</p>

    <ul>
      <li><a href="https://drive.google.com/file/d/198A1h93ZE7SuKEidx7FCwspJkAWqYG7e/view?usp=drivesdk">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/3072959.3073665">Official Publisher’s Version</a></li>
      <li><a href="https://www.yiningkarlli.com/projects/specdecomptracking.html">Project Page</a></li>
    </ul>

    <p>Joint project between Disney Research Studios and Disney Animation. This paper describes two complementary new null-collision tracking techniques: decomposition tracking and spectral tracking. The paper also introduces to computer graphics an extended integral formulation of null-collision algorithms, originally developed in the field of reactor physics. These two techniques are the basis of Hyperion’s modern third generation null-collision tracking based volume rendering system, in use beginning on <em>Olaf’s Frozen Adventure</em> to present.</p>
  </li>
  <li>
    <p><strong>The Ocean and Water Pipeline of Disney’s Moana</strong></p>

    <p><a href="https://www.linkedin.com/in/seanpalmer/">Sean Palmer</a>, <a href="https://www.imdb.com/name/nm3376120/">Jonathan Garcia</a>, <a href="https://www.linkedin.com/in/sara-drakeley-37290/">Sara Drakeley</a>, <a href="https://www.linkedin.com/in/patrick-kelly-1424b86/">Patrick Kelly</a>, and <a href="https://www.linkedin.com/in/ralf-habel-6a74bb2/">Ralf Habel</a>. The Ocean and Water Pipeline of Disney’s Moana. In <em>ACM SIGGRAPH 2017 Talks</em>, July 2017.</p>

    <ul>
      <li><a href="https://drive.google.com/file/d/1q4dum1dBhKTBK6fDqiIX-Bm9JrppAamm/view?usp=drivesdk">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/3084363.3085067">Official Publisher’s Version</a></li>
    </ul>

    <p>Internal project from Disney Animation. This short paper describes the water pipeline developed for <em>Moana</em>, including the level set compositing and rendering system that was implemented in Hyperion. This system has since found additional usage on shows since <em>Moana</em>.</p>
  </li>
  <li>
    <p><strong>Recent Advancements in Disney’s Hyperion Renderer</strong></p>

    <p><a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a>, <a href="https://www.linkedin.com/in/david-adler-5ab7b21/">David Adler</a>, <a href="https://dl.acm.org/author_page.cfm?id=99658729701&amp;coll=DL&amp;dl=ACM&amp;trk=0">Matt Jen-Yuan Chiang</a>, <a href="https://www.linkedin.com/in/ralf-habel-6a74bb2/">Ralf Habel</a>, <a href="https://www.linkedin.com/in/patrick-kelly-1424b86/">Patrick Kelly</a>, <a href="https://www.linkedin.com/in/peterkutz/">Peter Kutz</a>, <a href="https://www.yiningkarlli.com/">Yining Karl Li</a>, and <a href="https://www.linkedin.com/in/daniel-teece-2650358/">Daniel Teece</a>. Recent Advancements in Disney’s Hyperion Renderer. In <em>ACM SIGGRAPH 2017 Course Notes: Path Tracing in Production Part 1</em>, August 2017.</p>

    <ul>
      <li><a href="https://drive.google.com/file/d/1kFpp_7I8vH8LHsf1Si94pqMkHxwinMSU/view?usp=drivesdk">Preprint Version</a> (Updated compared to official version)</li>
      <li><a href="https://doi.org/10.1145/3084873.3084904">Official Publisher’s Version</a></li>
      <li><a href="https://jo.dreggn.org/path-tracing-in-production/2017/index.html">Path Tracing in Production SIGGRAPH 2017 Course</a></li>
    </ul>

    <p>Publication from Disney Animation. This paper describes various advancements in Hyperion since <em>Big Hero 6</em> up through <em>Moana</em>, with a particular focus towards replacing multiple scattering approximations with true, brute-force path-traced solutions for both better artist workflows and improved visual quality.</p>
  </li>
  <li>
    <p><strong>Denoising with Kernel Prediction and Asymmetric Loss Functions</strong></p>

    <p><a href="https://tvogels.nl/">Thijs Vogels</a>, <a href="https://research.nvidia.com/person/fabrice-rousselle">Fabrice Rousselle</a>, <a href="https://www.inf.ethz.ch/personal/mcbrian/">Brian McWilliams</a>, <a href="https://la.disneyresearch.com/people/gerhard-rothlin/">Gerhard Rothlin</a>, <a href="https://graphics.pixar.com/library/indexAuthorAlex_Harvill.html">Alex Harvill</a>, <a href="https://www.linkedin.com/in/david-adler-5ab7b21/">David Adler</a>, <a href="http://graphics.pixar.com/people/mmeyer/">Mark Meyer</a>, and <a href="http://drz.disneyresearch.com/~jnovak/">Jan Novák</a>. Denoising with Kernel Prediction and Asymmetric Loss Functions. <em>ACM Transactions on Graphics (Proceedings of SIGGRAPH 2018)</em>, 37(4), August 2017.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1qAu5DTDfxPPCFyGGzyoG4ggnz7877BEB">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/3197517.3201388">Official Publisher’s Version</a></li>
      <li><a href="http://drz.disneyresearch.com/~jnovak/publications/KPAL/index.html">Project Page</a></li>
    </ul>

    <p>Joint project between Disney Research Studios, Pixar, and Disney Animation. This paper describes a variety of improvements and extensions made to the 2017 <em>Kernel-predicting Convolutional Networks for Denoising Monte Carlo Renderings</em> paper; collectively, these improvements comprise the modern Disney-Research-developed second generation deep-learning denoiser in use in production at Pixar, ILM, and Disney Animation. At Disney Animation, used experimentally on <em>Ralph Breaks the Internet</em> and in full production beginning with <em>Frozen 2</em>.</p>
  </li>
  <li>
    <p><strong>Plausible Iris Caustics and Limbal Arc Rendering</strong></p>

    <p><a href="https://dl.acm.org/author_page.cfm?id=99658729701&amp;coll=DL&amp;dl=ACM&amp;trk=0">Matt Jen-Yuan Chiang</a> and <a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a>. Plausible Iris Caustics and Limbal Arc Rendering. <em>ACM SIGGRAPH 2018 Talks</em>, August 2018.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1Wibzqi9JIb4-DvXUyYKVfrbfrhu1bpQs">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/3214745.3214751">Official Publisher’s Version</a></li>
    </ul>

    <p>Internal project from Disney Animation. This paper describes a technique for rendering realistic, physically based eye caustics using manifold next-event estimation combined with a plausible procedural geometric eye model. This realistic eye model is implemented in Hyperion for use in future unannounced projects.</p>
  </li>
  <li>
    <p><strong>The Design and Evolution of Disney’s Hyperion Renderer</strong></p>

    <p><a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a>, <a href="https://www.linkedin.com/in/david-adler-5ab7b21/">David Adler</a>, <a href="https://dl.acm.org/author_page.cfm?id=99658729701&amp;coll=DL&amp;dl=ACM&amp;trk=0">Matt Jen-Yuan Chiang</a>, <a href="https://www.linkedin.com/in/hank-driskill-1a7140165/">Hank Driskill</a>, <a href="https://www.linkedin.com/in/ralf-habel-6a74bb2/">Ralf Habel</a>, <a href="https://www.linkedin.com/in/patrick-kelly-1424b86/">Patrick Kelly</a>, <a href="https://www.linkedin.com/in/peterkutz/">Peter Kutz</a>, <a href="https://www.yiningkarlli.com/">Yining Karl Li</a>, and <a href="https://www.linkedin.com/in/daniel-teece-2650358/">Daniel Teece</a>. The Design and Evolution of Disney’s Hyperion Renderer. <em>ACM Transactions on Graphics</em>, 37(3), August 2018.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1RbRr_rMJ1CIpcGsGWO4iuZKZ76utgMcd">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/3182159">Official Publisher’s Version</a></li>
      <li><a href="https://www.yiningkarlli.com/projects/hyperiondesign.html">Project Page</a></li>
    </ul>

    <p>Publication from Disney Animation. This paper is a systems architecture paper for the entirety of Hyperion. The paper describes the history of Disney’s Hyperion Renderer, the internal architecture, various systems such as shading, volumes, many-light sampling, emissive geometry, path simplification, fur rendering, photon-mapped caustics, subsurface scattering, and more. The paper also describes various challenges that had to be overcome for practical production use and artistic controllability. This paper covers everything in Hyperion beginning from <em>Big Hero 6</em> up through <em>Ralph Breaks the Internet</em>.</p>
  </li>
  <li>
    <p><strong>Clouds Data Set</strong></p>

    <p><a href="https://www.disneyanimation.com/">Walt Disney Animation Studios</a>. Clouds Data Set, August 2018.</p>

    <ul>
      <li><a href="https://www.technology.disneyanimation.com/clouds">Official Page</a></li>
      <li><a href="https://disney-animation.s3.amazonaws.com/uploads/production/data_set_asset/6/asset/License_Cloud.pdf">License</a></li>
    </ul>

    <p>Publicly released data set for rendering research, by Disney Animation. This data set was produced by our production artists as part of the development process for Hyperion’s modern third generation null-collision tracking based volume rendering system.</p>
  </li>
  <li>
    <p><strong><em>Moana</em> Island Scene Data Set</strong></p>

    <p><a href="https://www.disneyanimation.com/">Walt Disney Animation Studios</a>. <em>Moana</em> Island Scene Data Set, August 2018.</p>

    <ul>
      <li><a href="https://www.technology.disneyanimation.com/islandscene">Official Page</a></li>
      <li><a href="https://disney-animation.s3.amazonaws.com/uploads/production/data_set_asset/4/asset/License_Moana.pdf">License</a></li>
    </ul>

    <p>Publicly released data set for rendering research, by Disney Animation.
This data set is an actual production scene from <em>Moana</em>, originally rendered using Hyperion and ported to PBRT v3 for the public release. This data set gives a sense of the typical scene complexity and rendering challenges that Hyperion handles every day in production.</p>
  </li>
  <li>
    <p><strong>Denoising Deep Monte Carlo Renderings</strong></p>

    <p><a href="https://rgl.epfl.ch/people/dvicini">Delio Vicini</a>, <a href="https://www.linkedin.com/in/david-adler-5ab7b21/">David Adler</a>, <a href="http://drz.disneyresearch.com/~jnovak/">Jan Novák</a>, <a href="https://research.nvidia.com/person/fabrice-rousselle">Fabrice Rousselle</a>, and <a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a>. Denoising Deep Monte Carlo Renderings. <em>Computer Graphics Forum</em>, 38(1), February 2019.</p>

    <ul>
      <li><a href="https://drive.google.com/file/d/1n904HlzXQx_ahiRruyCh9KTQjCLZ9lDM/view?usp=sharing">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1111/cgf.13533">Official Publisher’s Version</a></li>
      <li><a href="http://drz.disneyresearch.com/~jnovak/publications/DeepZDenoising/index.html">Project Page</a></li>
    </ul>

    <p>Joint project between Disney Research Studios and Disney Animation. This paper presents a technique for denoising deep (meaning images with multiple depth bins per pixel) renders, for use with deep-compositing workflows. This technique was developed as part of general denoising research from Disney Research Studios and the Hyperion team.</p>
  </li>
  <li>
    <p><strong>The Challenges of Releasing the <em>Moana</em> Island Scene</strong></p>

    <p><a href="https://www.linkedin.com/in/rasmus-tamstorf-22835a1/">Rasmus Tamstorf</a> and <a href="https://www.linkedin.com/in/heather-pritchett-8067592/">Heather Pritchett</a>. The Challenges of Releasing the <em>Moana</em> Island Scene. In <em>Proceedings of EGSR 2019, Industry Track</em>, July 2019.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=18jLb3XNqXCvi2R7Yyb2E2aCdJ26zBBF7">Preprint Version</a></li>
      <li><a href="https://doi.org/10.2312/sr.20191223">Official Publisher’s Version</a></li>
    </ul>

    <p>Short paper from Disney Animation’s research department, discussing some of the challenges involved in preparing a production Hyperion scene for public release. The Hyperion team provided various support and advice to the larger studio effort to release the <em>Moana</em> Island Scene.</p>
  </li>
  <li>
    <p><strong>Practical Path Guiding in Production</strong></p>

    <p><a href="https://tom94.net/">Thomas Müller</a>. Practical Path Guiding in Production. In <em>ACM SIGGRAPH 2019 Course Notes: Path Guiding in Production</em>, July 2019.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1Dxa2Wm4j2Hv40KIUK3K_yg_v-acOU9rt">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/3305366.3328091">Official Publisher’s Version</a></li>
      <li><a href="https://jo.dreggn.org/path-tracing-in-production/2019/index.html">Path Guiding in Production SIGGRAPH 2019 Course</a></li>
    </ul>

    <p>Joint project between Disney Research Studios and Disney Animation. This paper presents a number of improvements and extensions made to <em>Practical Path Guiding</em> developed by in Hyperion by <a href="https://tom94.net/">Thomas Müller</a> and the Hyperion team. In use in production on <em>Frozen 2</em>.</p>
  </li>
  <li>
    <p><strong>Machine-Learning Denoising in Feature Film Production</strong></p>

    <p><a href="https://henrikdahlberg.github.io/">Henrik Dahlberg</a>, <a href="https://www.linkedin.com/in/david-adler-5ab7b21/">David Adler</a>, and <a href="https://www.linkedin.com/in/jeremy-newlin-07a87946/">Jeremy Newlin</a>. Machine-Learning Denoising in Feature Film Production. In <em>ACM SIGGRAPH 2019 Talks</em>, July 2019.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1CdUC9caWNSShHNvIj4kge7BWQczXWr79">Preprint Version</a></li>
      <li><a href="https://doi.org/10.1145/3306307.3328150">Official Publisher’s Version</a></li>
    </ul>

    <p>Joint publication from Pixar, Industrial Light &amp; Magic, and Disney Animation. Describes how the modern Disney-Research-developed second generation deep-learning denoiser was deployed into production at Pixar, ILM, and Disney Animation.</p>
  </li>
  <li>
    <p><strong>Taming the Shadow Terminator</strong></p>

    <p><a href="https://dl.acm.org/author_page.cfm?id=99658729701&amp;coll=DL&amp;dl=ACM&amp;trk=0">Matt Jen-Yuan Chiang</a>, <a href="https://www.yiningkarlli.com/">Yining Karl Li</a>, and <a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a>. Taming the Shadow Terminator. In <em>ACM SIGGRAPH 2019 Talks</em>, August 2019.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1Yb6GUP3pIuNiH9Xgq2P0L99V3JAQ7emM">Preprint Version</a> (Updated compared to official version)</li>
      <li><a href="https://doi.org/10.1145/3306307.3328172">Official Publisher’s Version</a></li>
      <li><a href="https://www.yiningkarlli.com/projects/shadowterminator.html">Project Page</a></li>
    </ul>

    <p>Internal project from Disney Animation. This short paper describes a solution to the long-standing “shadow terminator” problem associated with using shading normals. The technique in this paper is implemented in Hyperion and has been in use in production starting on <em>Frozen 2</em> through present.</p>
  </li>
  <li>
    <p><strong>On Histogram-Preserving Blending for Randomized Texture Tiling</strong></p>

    <p><a href="https://www.linkedin.com/in/brent-burley-56972557/">Brent Burley</a>. On Histogram-Preserving Blending for Randomized Texture Tiling. <em>Journal of Computer Graphics Techniques</em>, 8(4), November 2019.</p>

    <ul>
      <li><a href="https://drive.google.com/open?id=1kiMQUCcX_tEyQXWtsAPWZLVZTQt6OL_i">Preprint Version</a></li>
      <li><a href="http://www.jcgt.org/published/0008/04/02/">Official Publisher’s Version</a></li>
    </ul>

    <p>Internal project from Disney Animation. This paper describes some modiciations to the histogram-preserving hex-tiling algorithm of Heitz and Neyret; these modifications make implementing the Heitz and Neyret technique easier and more efficient. This paper describes Hyperion’s implementation of the technique, in use in production starting on <em>Frozen 2</em> through present.</p>
  </li>
</ol>

<p><a href="https://blog.yiningkarlli.com/content/images/2019/Jul/hyperion_logo.png"><div><p><img src="https://blog.yiningkarlli.com/content/images/2019/Jul/hyperion_logo.png" alt="Figure 2: Hyperion logo, modeled by Disney Animation artist Chuck Tappan and rendered in Disney's Hyperion Renderer."></p><p>Figure 2: Hyperion logo, modeled by Disney Animation artist Chuck Tappan and rendered in Disney's Hyperion Renderer.</p></div></a></p>

<p>Again, this post is meant to be a living document; any new publications with involvement from the Hyperion team will be added here.
Of course, the Hyperion team is not the only team at Disney Animation that regularly publishes; for a full list of publications from Disney Animation, see the <a href="https://www.disneyanimation.com/technology/publications">official Disney Animation publications page</a>.
The <a href="https://www.technology.disneyanimation.com/">Disney Animation Technology website</a> is also worth keeping an eye on if you want to keep up on what our engineers and TDs are working on!</p>

<p>If you’re just getting started and want to learn more about rendering in general, the must-read text that every rendering engineer has on their desk or bookshelf is <a href="http://www.pbr-book.org/">Physically Based Rendering 3rd Edition</a> by Matt Pharr, Wenzel Jakob, and Greg Humphreys (now available online completely for free!).
Also, the de-facto standard beginner’s text today is the <a href="https://www.amazon.com/gp/product/B01B5AODD8">Ray Tracing in One Weekend</a> series by Peter Shirley, which provides a great, gentle, practical introduction to ray tracing, and is also available completely for free. 
Also take a look at <a href="http://www.realtimerendering.com/book.html">Real-Time Rendering 4th Edition</a>, <a href="http://www.realtimerendering.com/raytracinggems/">Ray Tracing Gems</a> (also available online for free), <a href="http://graphicscodex.com/">The Graphics Codex</a> by Morgan McGuire, and Eric Haines’s <a href="http://www.realtimerendering.com/raytracing.html">Ray Tracing Resources page</a>.</p>

<p>Many other amazing rendering teams at both large studios and commercial vendors also publish regularly, and I highly recommend keeping up with all of their work too!
For a good starting point into exploring the wider world of production rendering, check out the <a href="https://dl.acm.org/citation.cfm?id=3243123">ACM Transactions on Graphics Special Issue on Production Rendering</a>, which is edited by Matt Pharr and contains extensive, detailed systems papers on <a href="https://dl.acm.org/citation.cfm?id=3182162">Pixar’s RenderMan</a>, <a href="https://dl.acm.org/citation.cfm?id=3182161">Weta Digital’s Manuka</a>, <a href="https://dl.acm.org/citation.cfm?id=3182160">Solid Angle (Autodesk)’s Arnold</a>, <a href="https://dl.acm.org/citation.cfm?id=3180495">Sony Picture Imageworks’ Arnold</a>, and of course <a href="https://dl.acm.org/citation.cfm?id=3182159">Disney Animation’s Hyperion</a>.
A sixth paper that I would group with five above is the High Performance Graphics 2017 paper detailing the architecture of <a href="https://doi.org/10.1145/3105762.3105768">DreamWorks Animation’s MoonRay</a>.</p>

<p>For even further exploration, extensive course notes are available from SIGGRAPH courses every year. Particularly good recurring courses to look at from past years are the Path Tracing in Production course (<a href="https://jo.dreggn.org/path-tracing-in-production/2017/index.html">2017</a>, <a href="https://jo.dreggn.org/path-tracing-in-production/2018/index.html">2018</a>, <a href="https://jo.dreggn.org/path-tracing-in-production/2019/index.html">2019</a>), the absolutely legendary Physically Based Shading course (<a href="http://renderwonk.com/publications/s2010-shading-course/">2010</a>, <a href="https://blog.selfshadow.com/publications/s2012-shading-course">2012</a>, <a href="https://blog.selfshadow.com/publications/s2013-shading-course">2013</a>, <a href="https://blog.selfshadow.com/publications/s2014-shading-course">2014</a>, <a href="https://blog.selfshadow.com/publications/s2015-shading-course">2015</a>, <a href="https://blog.selfshadow.com/publications/s2016-shading-course">2016</a>, <a href="https://blog.selfshadow.com/publications/s2017-shading-course/">2017</a>), the various incarnations of a volume rendering course (<a href="https://magnuswrenninge.com/productionvolumerendering">2011</a>, <a href="https://graphics.pixar.com/library/ProductionVolumeRendering/">2017</a>, <a href="https://cs.dartmouth.edu/~wjarosz/publications/novak18monte-sig.html">2018</a>), and now due to the dawn of ray tracing in games, <a href="http://advances.realtimerendering.com/">Advances in Real-Time Rendering</a> and <a href="https://openproblems.realtimerendering.com/">Open Problems in Real-Time Rendering</a>.
Also, Stephen Hill typically collects links to all publicly available course notes, slides, source code, and more for SIGGRAPH each year after the conference on <a href="https://blog.selfshadow.com/">his blog</a>; both his blog and the blogs listed on the sidebar of his website are essentially mandatory reading in the rendering world.
Also, interesting rendering papers are always being published in journals and at conferences.
The major journals to check are <a href="https://tog.acm.org/">ACM Transactions on Graphics (TOG)</a>, <a href="https://www.eg.org/wp/eurographics-publications/cgf/">Computer Graphics Forum (CGF)</a>, and the <a href="http://www.jcgt.org/">Journal of Computer Graphics Techniques (JCGT)</a>; the major academic conferences where rendering stuff appears are SIGGRAPH, SIGGRAPH Asia, EGSR (Eurographics Symposium on Rendering), HPG (High Performance Graphics), MAM (Workshop on Material Appearance Modeling), EUROGRAPHICS, and i3D (ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games); another three industry conferences where interesting stuff often appears are DigiPro, GDC (Game Developers Conference) and GTC (Graphics Technology Conference).
A complete listing of the contents for all of these conferences every year, along with links to preprints, is <a href="http://kesen.realtimerendering.com/">compiled by Ke-Sen Huang</a>.</p>

<p>A large number of people have contributed directly to Hyperion’s development since the beginning of the project, in a variety of capacities ranging from core developers to support staff and all the way to notable interns. In no particular order, including both present and past: Brent Burley, Daniel Teece, David Adler, Matt Jen-Yuan Chen, Yining Karl Li, Mark Lee, Wei-Feng Wayne Huang, Joe Schutte, Andrew Gartner, Jennifer Yu, Peter Kutz, Ralf Habel, Patrick Kelly, Gregory Nichols, Andrew Selle, Christian Eisenacher, Jan Novák, Ben Spencer, Doug Lesan, Lisa Young, Tami Valdez, Andrew Fisher, Noah Kagan, Benedikt Bitterli, Thomas Müller, Tizian Zeltner, Mathijs Molenaar, Laura Lediav, Guillaume Loubet, David Koerner, Simon Kallweit, Gabor Liktor, Ulrich Muller, and Serge Sretschinsky. Our closest research partners at Disney Research Studios and elsewhere include (in no particular order): Marios Papas, Per Christensen, Julian Fong, Christophe Hery, Wojciech Jarosz, Fabrice Rouselle, Rasmus Tamstorf, Ryusuke Villemin, and Magnus Wrenninge. Invaluable support from studio leadership over the years has been provided by (again, in no particular order): Nick Cannon, Golriz Fanai, Rajesh Sharma, Chuck Tappan, Sean Jenkins, Darren Robinson, Hank Driskill, Kyle Odermatt, Ernie Petti, Bettina Martin, Laura Franek, Collin Larkins, Andy Hendrickson, and Dan Candela. Of course, beyond this enormous list, there is an even more enormous list of countless artists, technical directors, production supervisors, and other technology development teams at Disney Animation who motivated Hyperion, participated in its development, and contributed to its success.</p>

<p>Finally, here is a list of all publicly released and announced projects to date made using Disney’s Hyperion Renderer:</p>

<p><strong>Feature Films</strong>: <a href="https://www.disneyanimation.com/projects/bighero6">Big Hero 6</a> (2014), <a href="https://www.disneyanimation.com/projects/zootopia">Zootopia</a> (2016), <a href="https://www.disneyanimation.com/projects/moana">Moana</a> (2016), <a href="https://www.disneyanimation.com/projects/ralphbreakstheinternet2">Ralph Breaks the Internet</a> (2018), <a href="https://www.disneyanimation.com/projects/frozen2">Frozen 2</a> (2019), <a href="https://www.disneyanimation.com/">Raya and the Last Dragon</a> (2020)</p>

<p><strong>Shorts and Featurettes</strong>: <a href="https://www.disneyanimation.com/projects/feast">Feast</a> (2014), <a href="https://www.imdb.com/title/tt4007502/?ref_=fn_al_tt_1">Frozen Fever</a> (2015), <a href="https://www.disneyanimation.com/projects/innerworkings">Inner Workings</a> (2016), <a href="https://www.imdb.com/title/tt6467284/">Gone Fishing</a> (2017), <a href="https://www.disneyanimation.com/projects/olafsfrozenadventure">Olaf’s Frozen Adventure</a> (2017), <a href="https://twitter.com/DisneyAnimation/status/1192517131188834304">Myth: A Frozen Tale</a><sup>1</sup> (2019)</p>

<p><strong>Short Circuit Shorts</strong>: <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">Exchange Student</a> (2020), <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">Just a Thought</a> (2020), <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">Jing Hua</a> (2020), <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">Elephant in the Room</a> (2020), <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">Puddles</a> (2020), <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">Lightning in a Bottle</a> (2020), <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">Zenith</a> (2020), <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">Drop</a> (2020), <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">Fetch</a> (2020), <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">Downtown</a> (2020), <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">Hair-Jitsu</a> (2020), <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">The Race</a> (2020), <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">Lucky Toupée</a> (2020), <a href="https://www.disneyplus.com/series/walt-disney-animation-studios-short-circuit-experimental-films/3S2DLVtMPA7V">Cycles</a><sup>2</sup> (2020), <a href="https://twitter.com/disneyanimation/status/1149743115130920960?lang=en">A Kite’s Tale</a><sup>2</sup> (2020)</p>

<p><strong>Intern Shorts</strong>: <a href="https://ohmy.disney.com/insider/2017/10/19/you-must-watch-this-beautiful-short-created-by-walt-disney-animation-interns/">Ventana</a> (2017), <a href="https://ohmy.disney.com/news/2018/12/05/voila-walt-disney-animation-studios-interns/">Voilà</a> (2018), <a href="https://ohmy.disney.com/movies/2019/09/19/watch-maestro-a-beautiful-short-from-this-years-walt-disney-animation-studios-interns/">Maestro</a> (2019)</p>

<p><strong>Filmmaker Co-op Shorts</strong>: <a href="https://www.imdb.com/title/tt7592274/">Weeds</a> (2017)</p>

<p><sup>1</sup> VR project running on Unreal Engine, with shading and textures baked out of Disney’s Hyperion Renderer.</p>

<p><sup>2</sup> VR project running on Unity, with shading and textures baked out of Disney’s Hyperion Renderer.</p>

            </section>

            
    </article>
</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>