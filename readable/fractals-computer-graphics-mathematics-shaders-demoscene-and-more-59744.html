<!DOCTYPE html>
<html lang="en">
<head>
    <title>
fractals, computer graphics, mathematics, shaders, demoscene and more - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="fractals, computer graphics, mathematics, shaders, demoscene and more - linksfor.dev(s)"/>
    <meta property="article:author" content="Inigo Quilez"/>
    <meta property="og:description" content="Tutorials and articles of Inigo Quilez on computer graphics, fractals, demoscene, shaders and more."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://www.iquilezles.org/www/articles/raymarchingdf/raymarchingdf.htm"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
	<div class="devring" style="background: #222">
		<div class="grid">
			<div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
				<span class="devring-title">devring.club</span>
				<a href="https://devring.club/site/1/previous" class="devring-previous">Previous</a>
				<a href="https://devring.club/random" class="devring-random">Random</a>
				<a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
			</div>
		</div>
	</div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - fractals, computer graphics, mathematics, shaders, demoscene and more</title>
<div class="readable">
        <h1>fractals, computer graphics, mathematics, shaders, demoscene and more</h1>
            <div>by Inigo Quilez</div>
            <div>Reading time: 16-20 minutes</div>
        <div>Posted here: 17 Mar 2020</div>
        <p><a href="https://www.iquilezles.org/www/articles/raymarchingdf/raymarchingdf.htm">https://www.iquilezles.org/www/articles/raymarchingdf/raymarchingdf.htm</a></p>
        <hr/>
<div id="readability-page-1" class="page"><p>

In 2008 I made some experiments in raymarching again, inspired by distance field optimizatios for parallax mapping, <a href="http://amd-dev.wpengine.netdna-cdn.com/wordpress/media/2012/10/Evans-Fast_Approximations_for_Lighting_of_Dynamic_Scenes-print.pdf">Alex Evan's work</a> (2006) and also the classic quaternionic Julia set tracing algorithms such as <a href="https://www.cs.cmu.edu/~kmcrane/Projects/QuaternionJulia/paper.pdf">Keenan Crane's</a> (2005) and <a href="https://www.evl.uic.edu/hypercomplex/html/book/rtqjs.pdf">the original paper by Sandin, Hart and Kauffman</a><a> (1989) and </a><a href="https://www.iquilezles.org/www/articles/juliasets3d/juliasets3d.htm">my own experiments improvement to the previous</a> (2001). But this time, instead of baking the distance fields on textures or compute them through complex dynamics, I decided to push the technique a bit see how far it could go with simple mathematical distance fields. As a result I created half a dozen images using this technique alone without any other method involved, some of which made it into demoscene productions, like <a href="https://www.iquilezles.org/prods/index.htm#13kimages">this four</a>.</p><p>

Raymarching of distance field proved super powerful for creating rich images with complex shapes procedurally and interesting efficient lighting effects in a minimal amount of code. Not only the actual content creation code modeling was small, but the actual renderer itself, the whole technical setup to sinthetize images was ridiculously compact comparing to a mesh based rasterizer or raytracer. So, the exercise became really fruitful and I produced 5 images in 2008 alone that I presented to the "4 kilobyte Procedural Image" category of different demo partys across Europe. Those images where created in the many cores of the CPU in a tile based manner. Later that same year, 2008, I gave a presentation about the technique, which you can find <a href="https://www.iquilezles.org/www/material/nvscene2008/nvscene2008.htm">here</a>, which became relativelly influencial to some of the youngest demosceners who didn't know about the technique and wanted to jump into the art of procedural modeling.</p><p>

As soon as the GPUs became more advanced and they finally gor to support conditional branching in their shader architectures, all these techniques became implementable in the GPU directly with equally minimal amount of rendering code and setup. As other demosceners started creating amazing 4 kilobytes demos as real-time raymarched distance fields, the expectations for the quality of the images grew and so did my interest in keeping pushing my own skills. This page is a collection of some of those (real-time) images that I created over the last decade, sorted from newest to oldest. Most of them come with a link to the source code and a realtime version that runs on your web browser. Beware that this same shaders copy-and-pasted to a native C++ GL executable run usually about 2 times faster (the browser GLSL to HLSL translator imposes some penalties, but I'm okey paying those for the sake of maximing reach for the art work).</p><p>
This website contains quite a few other relevant articles, I only listed the main ones here, so go, browse and explore them to learn more.
</p><div>

    <div>
        <p><b>sphere gears, 2019</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx33.jpg"></p><p>
        This was a improv session, based on some other Shadertoy user's idea, which I started as an optimization exercise. In particular, thanks to the symmetry of the object you can envaluate only 4 gear pieces instead of the 18 that make the whole object. Simiarly, withing each gear, only a single teeth/dent is evaluated instead of 12, making the whole SDF pretty cheap to evaluate. The source code in here: <a href="https://www.shadertoy.com/view/tt2XzG">https://www.shadertoy.com/view/tt2XzG</a> and the Youtube video is here: <a href="https://www.youtube.com/watch?v=ydTVmDBSGYQ">https://www.youtube.com/watch?v=ydTVmDBSGYQ</a>.
    </p></div>
	
    <div>
        <p><b>happy jumping, 2019</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx32.jpg"></p><p>
        Happy Jumping was a one-day effort to animate a character, which I had never done before really. I designed a super simple character for it and the animation was rought - in fact, it gets out of model very often. But it was a fine first attempt. The lighting is my usual 3 light rig (key, fill, bounce) and some fake subsurface. The source code in here: <a href="https://www.shadertoy.com/view/3lsSzf">https://www.shadertoy.com/view/3lsSzf</a> and the Youtube video is here: <a href="https://www.youtube.com/watch?v=s_UOFo2IULQ">https://www.youtube.com/watch?v=s_UOFo2IULQ</a>.
    </p></div>

    <div>
        <p><b>planet fall, 2018</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx30.jpg"></p><p>
        Planet Fall was an improv/jam session, although it turnied out pretty well. It's a level recursion of voronoi distributed cylinders on a sphere. The lighting is cheated as usual and the occlusion mostly painted by hand. But the color palette makes it look so pretty. The source code in here: <a href="https://www.shadertoy.com/view/lltBWB">https://www.shadertoy.com/view/lltBWB</a> and the Youtube video is here: <a href="https://www.youtube.com/watch?v=q1OBrqtl7Yo">https://www.youtube.com/watch?v=q1OBrqtl7Yo</a>.
    </p></div>

    <div>
        <p><b>surfer boy, 2018</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx31.jpg"></p><p>
        This was my first attempt to creating a human face completelly procedurally/mathematically. It's made mostly of ellipsoids, cones and quadratic bezier curves. It was mostly modeled to camera - it doesn't look that good from other angles. In order to keep it realtime I did a pretty simple lighting setup (no ambient occlusion, no GI, just painted colors here and there). The source code in here: <a href="https://www.shadertoy.com/view/ldd3DX">https://www.shadertoy.com/view/ldd3DX</a>, and its video capture in Youtube here: <a href="https://www.youtube.com/watch?v=ya3FRzuozQ0">https://www.youtube.com/watch?v=ya3FRzuozQ0</a>.
    </p></div>

    <div>
        <p><b>greek temple, 2017</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx28.jpg"></p><p>
        This image was born as a live coding improv session for the students of UPenn, although I spend a couple of days working after the live coding was done. The temple is made of basic domain repetition of 6 or 7 boxes and cylinders. The most intersting bit is probably the lack of global illumination - instead, the rich bounce lighting in the temple is achieved by colorzing the relevant areas by hand positioned colors. Also, for the sake of an interesting composition, the light direction and that lits the ocean and terrain is different than the direction of the light that lits the temple. The source code in here: <a href="https://www.shadertoy.com/view/ldScDh">https://www.shadertoy.com/view/ldScDh</a> and the Youtube video is here: <a href="https://www.youtube.com/watch?v=j5cctu1XGF0">https://www.youtube.com/watch?v=j5cctu1XGF0</a>.
    </p></div>

    <div>
        <p><b>ladybug, 2017</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx29.jpg"></p><p>
        I made this one after another live coding session for the students of the University of Washington. I made a mushroom for them, and then the two weeks that followed, in small chunkcs of night time, I slowly completed the drawings until I got here. The modeling is weak and I only pushed it enough to sell the image at medium resolution. It could get a lot more love, but I had to stop somewhere before I'd take too many nights. Lighting is mostly faked (no ambient occlusion, no GI) and very much painted by hand to look good (especially everything that has to do with bounce lighting and subsirface looking materials). The source code in here: <a href="https://www.shadertoy.com/view/4tByz3">https://www.shadertoy.com/view/4tByz3</a> and the Youtube video is here: <a href="https://www.youtube.com/watch?v=z_xM_jD08OM">https://www.youtube.com/watch?v=z_xM_jD08OM</a>.
    </p></div>
        
    

    <div>
        <p><b>rainforest - 2016</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx27.jpg"></p><p>
        This was an attempt to raymarch a signed distance field of a tree-populated terrain. Trees are mere spheres with some basic noise displacement distributed on a voronoi pattern. The most interesting part is the heavy use of analytical derivatives of noise to compute fast normals and slopes, which helped a lot speed up the raymarching process of both terrain (the bigger the slope, the smaller the step size - you can read on the Lipschitz constant). The source code is here: <a href="https://www.shadertoy.com/view/4ttSWf">https://www.shadertoy.com/view/4ttSWf</a> and the Youtube version of it here: <a href="https://www.youtube.com/watch?v=VqYROPZrDeU">https://www.youtube.com/watch?VqYROPZrDeU</a>.
    </p></div>
        
    <div>
        <p><b>snail, 2015</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx24.jpg"></p><p>
        The Snail was one of my all time favoirute images, because it looks good and tells a little story. It was mostly a modeling exerise, by using simple <a href="https://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm">distance functions</a> blended together <a href="https://www.iquilezles.org/www/articles/smin/smin.htm">smoothly</a>. The shell was interesting to make, and the translucent feeling of the snail itself took me a while to get right. The source code in here: <a href="https://www.shadertoy.com/view/ld3Gz2">https://www.shadertoy.com/view/ld3Gz2</a> and the Youtube video is here: <a href="https://www.youtube.com/watch?v=__G43hELHL0">https://www.youtube.com/watch?v=__G43hELHL0</a>. You canalso see the creation process of the image in the video at the begining of this article.
    </p></div>

    <div>
        <p><b>elephants - 2016</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx25.jpg"></p><p>
        Since the Snail worked so well, I tried to make elephants too, with the same exact techniques. This proved to be more difficult, and the results are only mediocre. In particular, the modeling was difficult to make for me by just typing formulas, so I left it unfinished and only added detail that would be seen from this camera angle. The trees are sllipsoids with some domain distortion, and the terrain a distance field to a plane with displacement. The source code is here: <a href="https://www.shadertoy.com/view/4dKGWm">https://www.shadertoy.com/view/4dKGWm</a> and the Youtube version of it here: <a href="https://www.youtube.com/watch?v=vga8FZzv5GE">https://www.youtube.com/watch?vga8FZzv5GE</a>.
    </p></div>
        
    

    

        
    

    
        
    <div>
        <p><b>antialias, sort of - 2014</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx18.jpg"></p><p>
        This was an attempt to antialiasing the screen-space edges of the raymarched distanece fields. By using ray differentials, one can estimate how much of the pixel footpring (pixel frustum) does approximatelly intersect the geometry, given that at each marching step we heave the distance to the closest surface. That was used in this image to compute partial coverage per near-intersection, and them they were all composited fron to back to give the correct smooth image without edge pixelixation. The source code in here: <a href="https://www.shadertoy.com/view/llXGR4">https://www.shadertoy.com/view/llXGR4</a>.
    </p></div>

    
        
    <div>
        <p><b>canyon - 2014</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx16.jpg"></p><p>
        A simple terrain in this case. Some bits are floating in the air since it was defined as a true 3D field, not as a height-map based distance field. Adding white snow on a red/yellow terrain alwats works and it's a cheap way to get good results without doing much effort on actual shading/texturing/surfacing. The source code in here: <a href="https://www.shadertoy.com/view/MdBGzG">https://www.shadertoy.com/view/MdBGzG</a> and the Youtube video of it here: <a href="https://www.youtube.com/watch?v=Jf9MlYtkJM0">https://www.youtube.com/watch?v=Jf9MlYtkJM0</a>.
    </p></div>

    
        
    <div>
        <p><b>fish swimming - 2014</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx14.jpg"></p><p>
        The interesting asped of this signed distance field image is the way the texturing was done. Since there are no meshes or vertices for the modeling of the fish, there is no place to store UV coordinates that can deform with the model itself. Hence, the texturing needs to be done differently. In this case I was able to make the animation of the fish invertible such that each point on the surface would be able to know where it came from in the res pose of the fish and do the noise and pattern lookups there. That way the textures didn't swim on the surface of the fish as they did in the Insect drawing below. The fish did swim actually, with some simple sine waves and noise. The source code in here: <a href="https://www.shadertoy.com/view/ldj3Dm">https://www.shadertoy.com/view/ldj3Dm</a> and the Youtube video of it here: <a href="https://www.youtube.com/watch?v=9EMTquFBr8Q">https://www.youtube.com/watch?v=9EMTquFBr8Q</a>.
    </p></div>

    <div>
        <p><b>dolphin - 2014</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx15.jpg"></p><p>
        This was  my attempt at doing water splashes. That was done by doing some displacement of the water plane with an exponential shape based on the proximity of the dolphin to the water. Indeed, the signed distance field representation can be used beyond finding marching and shadow or occlusion computation - in this case helps the water know about the dolphin. The dolphin itself was made with a few cylinders and some other smoothly blended primitives. The source code is here: <a href="https://www.shadertoy.com/view/4sS3zG">https://www.shadertoy.com/view/4sS3zG</a> and the Youtube version of it here: <a href="https://www.youtube.com/watch?v=Hx0LjmxFp78">https://www.youtube.com/watch?v=Hx0LjmxFp78</a>.
    </p></div>
        
    <div>
        <p><b>woods - 2013</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx12.jpg"></p><p>
        In this case a simple camera rotation was enough to hide the domain repetition of the trees. The interesting part is that I had to fake the lighting to the point of bending the light itself along the depth of the drawing: the direction of the sun light is different in the foreground and in the background (interpolated between those two poses). Tha allowed me to get the patch of light in the red mushroom by the camera and the nice side lighting in the tree in the background. Modeling wise, the trees are cylinders with an exponentially decaying radious along its axis, all smoothly blended together with the <a href="https://www.iquilezles.org/www/articles/smin/smin.htm">smooth minimun formula</a>, and some noise on top as a displacement. The source code in here: <a href="https://www.shadertoy.com/view/XsfGD4">https://www.shadertoy.com/view/XsfGD4</a>.
    </p></div>

    <div>
        <p><b>rounded voxels - 2013</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx13.jpg"></p><p>
        This was an exercise to integrate together fast ray-casting though a regular grid and raymarching inside the grid cells. Basically, the ray marches quickly though a volumetric regular grid, which can be done efficiently with a few additions and integer mask operations, and when found a grid cell to be not empty, a raymarcher takes over to find the intersection of the signed distance field degining the rounded boxes. If no intersection happens, the control is returned to the grid marcher. The source code is here: <a href="https://www.shadertoy.com/view/4djGWR">https://www.shadertoy.com/view/4djGWR</a> and the Youtube version of it here: <a href="https://www.youtube.com/watch?v=FkT8nIwol5U">https://www.youtube.com/watch?v=FkT8nIwol5U</a>. You can also see this 360 video of the same shader with a slightly different cube distrivution: <a href="https://www.youtube.com/watch?v=3EXNrPHG6Lg">https://www.youtube.com/watch?v=3EXNrPHG6Lg</a>.
    </p></div>
        
    

    
        
    <div>
        <p><b>angels - 2013</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx08.jpg"></p><p>
        Angels used some basic domain repetition to create many flying creatures despite I only had one. The differences in the animations between the different creatures was made by taking the cell id to offset the animation formula (which was based on cosine waves). The creatures themselves were made with some simple fractal recursion of ellipsoids. The code is here <a href="https://www.shadertoy.com/view/lssGRM">https://www.shadertoy.com/view/lssGRM</a>.
    </p></div>

    
        
    <div>
        <p><b>piano - 2013</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx06.jpg"></p><p>
        This was an exercise in combining true lighting with painted lighting. By "painted" I mean that it wasn't computed though shadow casting or pathtracing, but that it color was injected artificially in specifig areas and objects in the scene to convey ("fake") expensive lighting effects. For example, some of the light in the bottom part of the wall was added artificially, and the window from which the light comes in doesn't exist, but was shaped by hand with the formula of a square. On the other hand, this drawing performed true reflections. The code is here <a href="https://www.shadertoy.com/view/ldl3zN">https://www.shadertoy.com/view/ldl3zN</a>.
    </p></div>

    <div>
        <p><b>rocks - 2013</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx07.jpg"></p><p>
        This drawing was based on a voronoi pattern again, like Leizex (see below), and was mostly an exercise on shading simple rocks. However it's interesting to see how now this could be done in realt-time in the GPU while Leizex (2008) wasn't real time at all!Source code here: <a href="https://www.shadertoy.com/view/MsXGzM">https://www.shadertoy.com/view/MsXGzM</a>.
    </p></div>
        
    <div>
        <p><b>fruxis - 2012</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx04.jpg"></p><p>
        I made this one for the Trsac Demo party. It was my raymarched procedural distance field that was implemented in the GPU (GLSL). It was also my first to use a pathtracer (using <a href="https://www.iquilezles.org/www/articles/simplepathtracing/simplepathtracing.htm">this algorithm</a>). You can find a modified version of it that does <b>not</b> use pathtracing here: <a href="https://www.shadertoy.com/view/ldl3zl">https://www.shadertoy.com/view/ldl3zl</a>.
    </p></div>            

    <div>
        <p><b>cell - 2013</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx05.jpg"></p><p>
        This was my first procedural signed distance field exercise in Shadertoy (WebGL) (you can find the source code here: <a href="https://www.shadertoy.com/view/Xdl3R4">https://www.shadertoy.com/view/Xdl3R4</a>).</p><p>
        
        The interesting bit was my attempt to fake the subsurface scattering of light by raymarching inside the volume of the geometry to measure thickness.
    </p></div>
        
    <div>
        <p><b>leizex - 2008</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx02.jpg"></p><p>
        This was a one day production. I wanted to check how it is to directly raymarch a three dimensional voronoi pattern. It did work, although it was very slow. It is realtime this days of course, you can see it (and its code) here: <a href="https://www.shadertoy.com/view/XtycD1">https://www.shadertoy.com/view/XtycD1</a></p><p>
        
        Again shading is fake, there is no light source, neither there is ambient occlusion or anything. Colors are procedurally asigned to points in space.
    </p></div>
            
    <div>
        <p><b>bridge - 2009</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx03.jpg"></p><p>
        This is a sketch really, but it never got completed, due to the lack of artistic inspiration at the time. The intereseting part is probably the technique used for creating the grass, which is a voronoi based bombing approach.</p></div>
        
    <div>
        <p><b>slisesix - 2008</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx00.jpg"></p><p>
        This image was the first image I generated by signed distance field raymarching technique.</p><p>
        
        It contained smooth blending of geometric primitives, domain repetition and soft shadows. It won the 1st prize of 4 Kilobytes Procedural Graphics of Euskal Party 2008 in Spain. I also made a small video of the scene that you can grab <a href="http://iquilezles.untergrund.net/media/rgba_slisesix.avi">here</a> or watch directly <a href="http://www.youtube.com/watch?v=i1KWhPKlvY4">here</a> in youtube.</p></div>

    <div>
        <p><b>organix - 2008</b></p><p>
        <img src="https://www.iquilezles.org/www/articles/raymarchingdf/gfx01.jpg"></p><p>
        Organix won the 1st position at the Function Demoparty in Hungary. It was CPU computed and it took about 40 seconds to render in a standard machine back then at 1280x720 resolution. Needles to say this is raltime these days in the GPU, you can check it and its code here: <a href="https://www.shadertoy.com/view/ldByDh">https://www.shadertoy.com/view/ldByDh</a>.</p><p>
        
        The interesting part is taht the lighting is fake, in the sense that shadows and ambient occlusion are procedurally painted on the geometry, not computed by raycasting or anything similar.
    </p></div>
        
</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
		<div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>