<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Peephole optimizations in C&#x2B;&#x2B; and C# | Egor Bogatov &#x2014; Developer at Microsoft  - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Peephole optimizations in C&#x2B;&#x2B; and C# | Egor Bogatov &#x2014; Developer at Microsoft  - linksfor.dev(s)"/>
    <meta property="article:author" content="Egor Bogatov"/>
    <meta property="og:description" content="C#, C&#x2B;&#x2B;, Performance"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://egorbo.com/peephole-optimizations.html"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">üéâ</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Peephole optimizations in C&#x2B;&#x2B; and C# | Egor Bogatov &#x2014; Developer at Microsoft </title>
<div class="readable">
        <h1>Peephole optimizations in C&#x2B;&#x2B; and C# | Egor Bogatov &#x2014; Developer at Microsoft </h1>
            <div>by Egor Bogatov</div>
            <div>Watching time: 10-13 minutes</div>
        <div>Posted here: 01 Jul 2019</div>
        <p><a href="https://egorbo.com/peephole-optimizations.html">https://egorbo.com/peephole-optimizations.html</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div role="main">
                
                <article role="article" itemscope="" itemtype="http://schema.org/BlogPosting">
    

    <div>
        <blockquote>
  <p>‚ÄúPerformance gains due to improvements in compiler optimizations will double <br>
the speed of a program every 18 years‚Äù ¬© <a href="http://proebsting.cs.arizona.edu/law.html">Proebsting‚Äôs Law</a></p>
</blockquote>

<p>When we solve equations, we try to simplify them first, e.g. <code>Y = -(5 - X)</code> can be simplified to just  <code>Y = X - 5</code>. In modern compilers it‚Äôs called ‚ÄúPeephole Optimizations‚Äù. Roughly speaking, compilers search for certain patterns and replace them with corresponding simplified expressions. In this blog post I‚Äôll list some of them which I found in LLVM, GCC and .NET Core (CoreCLR) sources.</p>

<p>Let‚Äôs start with simple cases:</p>

<figure><pre><code data-lang="csharp"><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre>  <span>X</span> <span>*</span> <span>1</span>          <span>=&gt;</span>  <span>X</span>
 <span>-</span><span>X</span> <span>*</span> <span>-</span><span>Y</span>         <span>=&gt;</span>  <span>X</span> <span>*</span> <span>Y</span>
<span>-(</span><span>X</span> <span>-</span> <span>Y</span><span>)</span>         <span>=&gt;</span>  <span>Y</span> <span>-</span> <span>X</span>
  <span>X</span> <span>*</span> <span>Z</span> <span>-</span> <span>Y</span> <span>*</span> <span>Z</span>  <span>=&gt;</span>  <span>Z</span> <span>*</span> <span>(</span><span>X</span> <span>-</span> <span>Y</span><span>)</span></pre></td></tr></tbody></table></code></pre></figure>

<p>and check the 4th one in C++ and C# compilers:</p>

<figure><pre><code data-lang="csharp"><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>int</span> <span>Test</span><span>(</span><span>int</span> <span>x</span><span>,</span> <span>int</span> <span>y</span><span>,</span> <span>int</span> <span>z</span><span>)</span> <span>{</span>
    <span>return</span> <span>x</span> <span>*</span> <span>z</span> <span>-</span> <span>y</span> <span>*</span> <span>z</span><span>;</span>       <span>//  =&gt;  z * (x - y)</span>
<span>}</span></pre></td></tr></tbody></table></code></pre></figure>

<p>Now let‚Äôs take a look at what the compilers output:</p>
<figure>

<figure><pre><code data-lang="nasm"><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>Test</span><span>(</span><span>int</span><span>,</span> <span>int</span><span>,</span> <span>int</span><span>)</span><span>:</span>
  <span>mov</span> <span>eax</span><span>,</span> <span>edi</span>
  <span>sub</span> <span>eax</span><span>,</span> <span>esi</span>   <span>; -         </span>
  <span>imul</span> <span>eax</span><span>,</span> <span>edx</span>  <span>; *         </span>
  <span>ret</span></pre></td></tr></tbody></table></code></pre></figure>

	<figcaption>C++ (Clang, GCC, MSVC)</figcaption>
</figure>

<figure>

<figure><pre><code data-lang="nasm"><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre><span>C</span><span>.</span><span>Test</span><span>(</span><span>Int32</span><span>,</span> <span>Int32</span><span>,</span> <span>Int32</span><span>)</span>  
  <span>mov</span> <span>eax</span><span>,</span> <span>edx</span>
  <span>imul</span> <span>eax</span><span>,</span> <span>r9d</span>  <span>; *</span>
  <span>imul</span> <span>r8d</span><span>,</span> <span>r9d</span>  <span>; *</span>
  <span>sub</span> <span>eax</span><span>,</span> <span>r8d</span>   <span>; -</span>
  <span>ret</span></pre></td></tr></tbody></table></code></pre></figure>

	<figcaption>C# (RyuJIT)</figcaption>
</figure>
<figure>
</figure>
<!--more-->
<p>All three C++ compilers have just one <code>imul</code> instruction. C# (.NET Core) has two because it has a very limited set of available peephole optimizations and I‚Äôll list some of them later. Be sure to note, the entire InstCombine transformation implementation, where peephole optimizations live, in LLVM takes more than 30K lines of code (+20k LOC in DAGCombiner.cpp). By the way, <a href="https://github.com/llvm-mirror/llvm/blob/45adfa50b3fddb97d7fc512cec80e48c551f3280/lib/Transforms/InstCombine/InstCombineAddSub.cpp#L1329-L1332">here is the piece of code in LLVM</a> responsible for the pattern we are inspecting now. GCC has a special DSL which describes all peephole optimizations, and <a href="https://github.com/gcc-mirror/gcc/blob/5882c51592109e2e228d3c675792f891a09b43d6/gcc/match.pd#L2185-L2220">here is the piece of that DSL</a> for our case.</p>

<p>I decided, just for this blog post, to try to implement this optimization for C# in JIT (hold my beer üòõ):</p>
<figure>
	<img src="https://egorbo.com/images/instcombine/jit-1.png">
</figure>
<div><p>
Let‚Äôs now test my JIT improvement (see <a href="https://github.com/EgorBo/coreclr/commit/3d0abaa2c9919a48110a66b3fe19c7abed2bf041">EgorBo/coreclr</a> commit for more details) in VS2019 with Disasmo:
</p></div>
<figure>
	<img src="https://egorbo.com/images/instcombine/jit-2.png">
	<figcaption>lea + imul instead of imul + imul + add</figcaption>
</figure>



<p>Let‚Äôs go back to C++ and trace the optimization in Clang. We need to ask clang to emit LLVM IR for our C++ code via <code>-emit-llvm -g0</code> flags (see <a href="https://godbolt.org/z/RZQTDV">godbolt.org</a>) and then give it to the LLVM optimizer <strong>opt</strong> via <code>-O2 -print-before-all -print-after-all</code> flags in order to find out what transformation actually removes that extra multiplication from the <code>-O2</code> set. (see <a href="https://godbolt.org/z/3f0TyT">godbolt.org</a>):</p>

<figure>

<figure><pre><code data-lang="llvm"><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td><pre><span>; *** IR Dump Before Combine redundant instructions ***</span>
<span>define</span> <span>dso_lo</span><span>c</span><span>al</span> <span>i32</span> <span>@_Z5Case1iii</span><span>(</span><span>i32</span><span>,</span> <span>i32</span><span>,</span> <span>i32</span><span>)</span> <span>{</span>
  <span>%4</span> <span>=</span> <span>mul</span> <span>nsw</span> <span>i32</span> <span>%0</span><span>,</span> <span>%2</span>
  <span>%5</span> <span>=</span> <span>mul</span> <span>nsw</span> <span>i32</span> <span>%1</span><span>,</span> <span>%2</span>
  <span>%6</span> <span>=</span> <span>sub</span> <span>nsw</span> <span>i32</span> <span>%4</span><span>,</span> <span>%5</span>
  <span>ret</span> <span>i32</span> <span>%6</span>
<span>}</span>

<span>; *** IR Dump After Combine redundant instructions ***</span>
<span>define</span> <span>dso_lo</span><span>c</span><span>al</span> <span>i32</span> <span>@_Z5Case1iii</span><span>(</span><span>i32</span><span>,</span> <span>i32</span><span>,</span> <span>i32</span><span>)</span> <span>{</span>
  <span>%4</span> <span>=</span> <span>sub</span> <span>i32</span> <span>%0</span><span>,</span> <span>%1</span>
  <span>%5</span> <span>=</span> <span>mul</span> <span>i32</span> <span>%4</span><span>,</span> <span>%2</span>
  <span>ret</span> <span>i32</span> <span>%5</span>
<span>}</span></pre></td></tr></tbody></table></code></pre></figure>


	<figcaption>It's InstCombine!</figcaption>
</figure>

<p>So it‚Äôs InstCombine indeed, we can even use it as the only optimization for our code for tests via <code>-instcombine</code> flag passed to <code>opt</code>:</p>
<figure>
	<img src="https://egorbo.com/images/instcombine/p2.png">
</figure>



<p>Let‚Äôs go back to the examples. Look what a cute optimization I found in GCC sources:</p>

<figure><pre><code data-lang="cpp"><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>X</span> <span>==</span> <span>C</span> <span>-</span> <span>X</span>  <span>=&gt;</span>  <span>false</span> <span>if</span> <span>C</span> <span>is</span> <span>odd</span></pre></td></tr></tbody></table></code></pre></figure>

<p>And that‚Äôs true, e.g.: <code>4 == 8 - 4</code>. Any odd number for C (C usually means a constant/literal) will always be false for the expression:</p>
<figure>
	<img src="https://egorbo.com/images/instcombine/p3.png">
	<figcaption>Foo2(int x) always returns false. LLVM doesn't have this optimization.</figcaption>
</figure>

<h3 id="optimizations-vs-ieee754">Optimizations vs IEEE754</h3>

<p>Lots of this type of optimizations work for different data types, e.g. <code>byte</code>, <code>int</code>, <code>unsigned</code>, <code>float</code>. The latter is a bit tricky e.g. you can‚Äôt simplify <code>A - B - A</code> to <code>-B</code> for floats/doubles, even <code>(A * B) * C</code> is not equal to <code>A * (B * C)</code> due to the <a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE754 specification</a>. However, C++ compilers have a special flag to let the optimizers be less strict around IEEE754, NaN and other FP corner cases and just apply all of the optimizations - it‚Äôs usually called ‚ÄúFast Math‚Äù (<code>-ffast-math</code> for clang and gcc, <code>/fp:fast</code> for MSVC). Btw, here you can find my feature request for .NET Core to introduce the ‚ÄúFast Math‚Äù mode there: <a href="https://github.com/dotnet/coreclr/issues/24784">dotnet/coreclr#24784</a>).</p>

<p>As you can see, two <code>vsubss</code> were eliminated in the <code>-ffast-math</code> mode:</p>
<figure>
	<img src="https://egorbo.com/images/instcombine/p5.png">
	<figcaption></figcaption>
</figure>

<p>The C++ optimizers also support <code>math.h</code> functions, e.g.:</p>

<figure><pre><code data-lang="cpp"><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>abs</span><span>(</span><span>X</span><span>)</span> <span>*</span> <span>abs</span><span>(</span><span>X</span><span>)</span>  <span>=&gt;</span>  <span>X</span> <span>*</span> <span>X</span></pre></td></tr></tbody></table></code></pre></figure>

<p>The square root is always positive:</p>

<figure><pre><code data-lang="cpp"><table><tbody><tr><td><pre>1
2
</pre></td><td><pre><span>sqrt</span><span>(</span><span>X</span><span>)</span> <span>&lt;</span> <span>Y</span>  <span>=&gt;</span> <span>false</span><span>,</span> <span>if</span> <span>Y</span> <span>is</span> <span>negative</span><span>.</span>
<span>sqrt</span><span>(</span><span>X</span><span>)</span> <span>&lt;</span> <span>0</span>  <span>=&gt;</span> <span>false</span></pre></td></tr></tbody></table></code></pre></figure>

<p>Why should we calculate sqrt(X) if we can just calculate C^2 in compile time instead?:</p>

<figure><pre><code data-lang="cpp"><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>sqrt</span><span>(</span><span>X</span><span>)</span> <span>&gt;</span> <span>C</span>  <span>=&gt;</span> <span>X</span> <span>&gt;</span> <span>C</span> <span>*</span> <span>C</span></pre></td></tr></tbody></table></code></pre></figure>

<figure>
	<img src="https://egorbo.com/images/instcombine/sqrt.png">
</figure>
<p>More sqrt optimizations:</p>

<figure><pre><code data-lang="c"><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>sqrt</span><span>(</span><span>X</span><span>)</span> <span>==</span> <span>sqrt</span><span>(</span><span>Y</span><span>)</span>  <span>=&gt;</span> <span>X</span> <span>==</span> <span>Y</span>
<span>sqrt</span><span>(</span><span>X</span><span>)</span> <span>*</span> <span>sqrt</span><span>(</span><span>X</span><span>)</span>   <span>=&gt;</span> <span>X</span>
<span>sqrt</span><span>(</span><span>X</span><span>)</span> <span>*</span> <span>sqrt</span><span>(</span><span>Y</span><span>)</span>   <span>=&gt;</span> <span>sqrt</span><span>(</span><span>X</span> <span>*</span> <span>Y</span><span>)</span>
<span>logN</span><span>(</span><span>sqrt</span><span>(</span><span>X</span><span>))</span>       <span>=&gt;</span> <span>0</span><span>.</span><span>5</span> <span>*</span> <span>logN</span><span>(</span><span>X</span><span>)</span></pre></td></tr></tbody></table></code></pre></figure>

<p>or <code>exp</code>:</p>

<figure><pre><code data-lang="c"><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>exp</span><span>(</span><span>X</span><span>)</span> <span>*</span> <span>exp</span><span>(</span><span>Y</span><span>)</span>  <span>=&gt;</span> <span>exp</span><span>(</span><span>X</span> <span>+</span> <span>Y</span><span>)</span></pre></td></tr></tbody></table></code></pre></figure>

<p>And my favorite one:</p>

<figure><pre><code data-lang="c"><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>sin</span><span>(</span><span>X</span><span>)</span> <span>/</span> <span>cos</span><span>(</span><span>X</span><span>)</span>  <span>=&gt;</span> <span>tan</span><span>(</span><span>X</span><span>)</span></pre></td></tr></tbody></table></code></pre></figure>

<figure>
	<img src="https://egorbo.com/images/instcombine/p6.png">
	<figcaption></figcaption>
</figure>

<p>There are lots of boring bit/bool patterns:</p>

<figure><pre><code data-lang="c"><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
</pre></td><td><pre><span>((</span><span>a</span> <span>^</span> <span>b</span><span>)</span> <span>|</span> <span>a</span><span>)</span> <span>-&gt;</span> <span>(</span><span>a</span> <span>|</span> <span>b</span><span>)</span>
<span>(</span><span>a</span> <span>&amp;</span> <span>~</span><span>b</span><span>)</span> <span>|</span> <span>(</span><span>a</span> <span>^</span> <span>b</span><span>)</span>  <span>--&gt;</span>  <span>a</span> <span>^</span> <span>b</span>
<span>((</span><span>a</span> <span>^</span> <span>b</span><span>)</span> <span>|</span> <span>a</span><span>)</span> <span>-&gt;</span> <span>(</span><span>a</span> <span>|</span> <span>b</span><span>)</span>
<span>(</span><span>X</span> <span>&amp;</span> <span>~</span><span>Y</span><span>)</span> <span>|^+</span> <span>(</span><span>~</span><span>X</span> <span>&amp;</span> <span>Y</span><span>)</span> <span>-&gt;</span> <span>X</span> <span>^</span> <span>Y</span>
<span>A</span> <span>-</span> <span>(</span><span>A</span> <span>&amp;</span> <span>B</span><span>)</span> <span>into</span> <span>~</span><span>B</span> <span>&amp;</span> <span>A</span>
<span>X</span> <span>&lt;=</span> <span>Y</span> <span>-</span> <span>1</span> <span>equals</span> <span>to</span> <span>X</span> <span>&lt;</span> <span>Y</span>
<span>A</span> <span>&lt;</span> <span>B</span> <span>||</span> <span>A</span> <span>&gt;=</span> <span>B</span> <span>-&gt;</span> <span>true</span>
<span>...</span> <span>hundreds</span> <span>of</span> <span>them</span> <span>...</span></pre></td></tr></tbody></table></code></pre></figure>

<h3 id="machine-dependent-optimizations">Machine-dependent optimizations</h3>

<p>Some operations may be faster or slower on different CPUs, e.g.:</p>

<figure><pre><code data-lang="c"><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>X</span> <span>/</span> <span>2</span>  <span>=&gt;</span>  <span>X</span> <span>*</span> <span>0</span><span>.</span><span>5</span></pre></td></tr></tbody></table></code></pre></figure>

<figure>
	<img src="https://egorbo.com/images/instcombine/p8.png">
	<figcaption></figcaption>
</figure>

<p><code>mulss</code>/<code>mulsd</code> usually have better both latency and throughput than <code>divss</code>/<code>divsd</code> for example, here is the spec for my Intel Haswell CPU:</p>
<figure>
	<img src="https://egorbo.com/images/instcombine/p7.png">
	<figcaption></figcaption>
</figure>

<p>We can replace <code>/ C</code> with <code>* 1/C</code> even in the non-‚ÄúFast Math‚Äù mode if <code>C</code> is a power of two. Btw, here is my PR for .NET Core for this optimization: <a href="https://github.com/dotnet/coreclr/pull/24584">dotnet/coreclr#24584</a>.</p>

<p>The same rationale for:</p>

<figure><pre><code data-lang="cpp"><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>X</span> <span>*</span> <span>2</span>  <span>=&gt;</span>  <span>X</span> <span>+</span> <span>X</span></pre></td></tr></tbody></table></code></pre></figure>

<p><code>test</code> is better than <code>cmp</code> (see my PR <a href="https://github.com/dotnet/coreclr/pull/25458">dotnet/coreclr#25458</a> for more details):</p>

<figure><pre><code data-lang="c"><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>X</span> <span>&gt;=</span> <span>1</span>  <span>=&gt;</span>  <span>X</span> <span>&gt;</span> <span>0</span>
<span>X</span> <span>&lt;</span> <span>1</span>   <span>=&gt;</span>  <span>X</span> <span>&lt;=</span> <span>0</span>
<span>X</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>=&gt;</span>  <span>X</span> <span>&gt;=</span> <span>0</span>
<span>X</span> <span>&gt;</span> <span>-</span><span>1</span>  <span>=&gt;</span>  <span>X</span> <span>&gt;=</span> <span>0</span></pre></td></tr></tbody></table></code></pre></figure>

<p>And what do you think about these ones?:</p>

<figure><pre><code data-lang="cpp"><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>pow</span><span>(</span><span>X</span><span>,</span> <span>0.5</span><span>)</span>   <span>=&gt;</span>  <span>sqrt</span><span>(</span><span>x</span><span>)</span>
<span>pow</span><span>(</span><span>X</span><span>,</span> <span>0.25</span><span>)</span>  <span>=&gt;</span>  <span>sqrt</span><span>(</span><span>sqrt</span><span>(</span><span>X</span><span>))</span>
<span>pow</span><span>(</span><span>X</span><span>,</span> <span>2</span><span>)</span>     <span>=&gt;</span>  <span>X</span> <span>*</span> <span>X</span>     <span>;</span> <span>1</span> <span>mul</span>
<span>pow</span><span>(</span><span>X</span><span>,</span> <span>3</span><span>)</span>     <span>=&gt;</span>  <span>X</span> <span>*</span> <span>X</span> <span>*</span> <span>X</span> <span>;</span> <span>2</span> <span>mul</span></pre></td></tr></tbody></table></code></pre></figure>

<figure>
	<img src="https://egorbo.com/images/instcombine/p9.png">
</figure>

<p><br>
How many <code>mul</code> are needed to perform <code>pow(X, 4)</code> or <code>X * X * X * X</code>?</p>
<figure>
	<img src="https://egorbo.com/images/instcombine/pow4.png">
</figure>
<p>Just 2! Just like for <code>pow(X, 3)</code> and unlike <code>pow(X, 3)</code> we don‚Äôt even use the <code>xmm1</code> register.</p>

<p><br>
Modern CPUs support a special FMA instruction to perform <code>mul</code> and <code>add</code> in just one step without an intermediate rounding operation for <code>mul</code>:</p>

<figure><pre><code data-lang="cpp"><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>X</span> <span>*</span> <span>Y</span> <span>+</span> <span>Z</span>  <span>=&gt;</span>  <span>fmadd</span><span>(</span><span>X</span><span>,</span> <span>Y</span><span>,</span> <span>Z</span><span>)</span></pre></td></tr></tbody></table></code></pre></figure>

<figure>
	<img src="https://egorbo.com/images/instcombine/p11.png">
</figure>

<p><br>
Sometimes compilers are able to replace entire algorithms with just one CPU instruction, e.g.:</p>
<figure>
	<img src="https://egorbo.com/images/instcombine/p12.png">
</figure>

<h3 id="traps-for-optimizations">Traps for optimizations</h3>
<p>We can‚Äôt just find patterns &amp; optimize them:</p>
<ul>
  <li>There is a risk to break some code: there are always corner-cases, hidden side-effects. LLVM‚Äôs bugzilla contains lots of InstCombine bugs.</li>
  <li>An expression or its parts we want to simplify might be used somewhere else.</li>
</ul>

<p>I borrowed a nice example for the second issue from <a href="https://arxiv.org/pdf/1809.02161.pdf">‚ÄúFuture Directions for Optimizing Compilers‚Äù</a> article.<br>
Imagine we have a function:</p>

<figure><pre><code data-lang="c"><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>int</span> <span>Foo1</span><span>(</span><span>int</span> <span>a</span><span>,</span> <span>int</span> <span>b</span><span>)</span> <span>{</span>
   <span>int</span> <span>na</span> <span>=</span> <span>-</span><span>a</span><span>;</span>
   <span>int</span> <span>nb</span> <span>=</span> <span>-</span><span>b</span><span>;</span>
   <span>return</span> <span>na</span> <span>+</span> <span>nb</span><span>;</span>
<span>}</span></pre></td></tr></tbody></table></code></pre></figure>

<p>We need to perform 3 operations here: <code>0 - a</code>, <code>0 - b</code>, –∏ <code>na + nb</code>. LLVM simplifies it to just two operations: <code>return -(a + b)</code> - what a smart move, here is the IR:</p>

<figure><pre><code data-lang="llvm"><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>define</span> <span>dso_lo</span><span>c</span><span>al</span> <span>i32</span> <span>@_Z4Foo1ii</span><span>(</span><span>i32</span><span>,</span> <span>i32</span><span>)</span> <span>{</span>
  <span>%3</span> <span>=</span> <span>add</span> <span>i32</span> <span>%0</span><span>,</span> <span>%1</span> <span>; a + b</span>
  <span>%4</span> <span>=</span> <span>sub</span> <span>i32</span> <span>0</span><span>,</span> <span>%3</span>  <span>; 0 - %3</span>
  <span>ret</span> <span>i32</span> <span>%4</span>
<span>}</span></pre></td></tr></tbody></table></code></pre></figure>

<p>Now imagine that we need to store values of <code>na</code> and <code>nb</code> in some global variables, e.g. <code>x</code> and <code>y</code>:</p>

<figure><pre><code data-lang="c"><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>int</span> <span>x</span><span>,</span> <span>y</span><span>;</span>

<span>int</span> <span>Foo2</span><span>(</span><span>int</span> <span>a</span><span>,</span> <span>int</span> <span>b</span><span>)</span> <span>{</span>
   <span>int</span> <span>na</span> <span>=</span> <span>-</span><span>a</span><span>;</span>
   <span>int</span> <span>nb</span> <span>=</span> <span>-</span><span>b</span><span>;</span>
   <span>x</span> <span>=</span> <span>na</span><span>;</span>
   <span>y</span> <span>=</span> <span>nb</span><span>;</span>
   <span>return</span> <span>na</span> <span>+</span> <span>nb</span><span>;</span>
<span>}</span></pre></td></tr></tbody></table></code></pre></figure>

<p>The optimizer still recognizes the pattern and simplifies it by removing redundant (from its point of view) <code>0 - a</code> and <code>0 - b</code> operations. But we do need them! We save them to the global variables! Thus, it leads to this:</p>

<figure><pre><code data-lang="llvm"><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>define</span> <span>dso_lo</span><span>c</span><span>al</span> <span>i32</span> <span>@_Z4Foo2ii</span><span>(</span><span>i32</span><span>,</span> <span>i32</span><span>)</span> <span>{</span>
  <span>%3</span> <span>=</span> <span>sub</span> <span>nsw</span> <span>i32</span> <span>0</span><span>,</span> <span>%0</span>                    <span>; 0 - a </span>
  <span>%4</span> <span>=</span> <span>sub</span> <span>nsw</span> <span>i32</span> <span>0</span><span>,</span> <span>%1</span>                    <span>; 0 - b</span>
  <span>store</span> <span>i32</span> <span>%3</span><span>,</span> <span>i32</span><span>*</span> <span>@x</span><span>,</span> <span>align</span> <span>4</span><span>,</span> <span>!tbaa</span> <span>!2</span>  
  <span>store</span> <span>i32</span> <span>%4</span><span>,</span> <span>i32</span><span>*</span> <span>@y</span><span>,</span> <span>align</span> <span>4</span><span>,</span> <span>!tbaa</span> <span>!2</span>
  <span>%5</span> <span>=</span> <span>add</span> <span>i32</span> <span>%0</span><span>,</span> <span>%1</span>                       <span>; a + b</span>
  <span>%6</span> <span>=</span> <span>sub</span> <span>i32</span> <span>0</span><span>,</span> <span>%5</span>                        <span>; 0 - %5</span>
  <span>ret</span> <span>i32</span> <span>%6</span>
<span>}</span></pre></td></tr></tbody></table></code></pre></figure>

<p>4 math operations instead of 3! The optimizer has just made our code a bit slower.
Now let‚Äôs see what C# RuyJIT generates for this case:</p>

<figure>
	<img src="https://egorbo.com/images/instcombine/p10.png">
</figure>

<p>RuyJIT doesn‚Äôt have this optimization so the code contains only 3 operations :-) C# is faster than C++! :p</p>

<h3 id="do-we-really-need-these-optimizations">Do we really need these optimizations?</h3>
<p>Well, you never know what the final code will look like after inlining, constant folding, copy propagation, CSE, etc.<br>
Also, both LLVM IR and .NET IL are not tied to a specific programming language and can‚Äôt rely on quality of the IR it generates. And you can just run your app/lib with <code>InstCombine</code> pass on and off to measure the performance impact.</p>

<h3 id="what-about-c">What about C#?</h3>
<p>As I said earlier, peephole optimizations are very limited in C# at the moment. However, when I say ‚ÄúC#‚Äù I mean the most popular C# runtime - CoreCLR with RuyJIT. But there are more, including those, using LLVM as a backend: Mono (see my <a href="https://twitter.com/EgorBo/status/1063468884257316865">tweet</a>), Unity Burst and LILLC - these runtimes basically use exactly the same optimizations as clang does. Unity guys are even considering <a href="https://lucasmeijer.com/posts/cpp_unity/">replacing C++ with C#</a> in their internal parts. By the way, since .NET 5 will include Mono as an optional built-in runtime - you will be able to use LLVM power for such cases.</p>

<p>Back to CoreCLR - here are the peephole optimizations I managed to find in the <code>morph.cpp</code> comments (I am sure there are more):</p>

<figure><pre><code data-lang="cpp"><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>*</span><span>(</span><span>&amp;</span><span>X</span><span>)</span>  <span>=&gt;</span>  <span>X</span>
<span>X</span> <span>%</span> <span>1</span>  <span>=&gt;</span> <span>0</span>
<span>X</span> <span>/</span> <span>1</span>  <span>=&gt;</span>  <span>X</span>
<span>X</span> <span>%</span> <span>Y</span>  <span>=&gt;</span> <span>X</span> <span>-</span> <span>(</span><span>X</span> <span>/</span> <span>Y</span><span>)</span> <span>*</span> <span>Y</span>  <span>// arm
</span><span>X</span> <span>^</span> <span>-</span><span>1</span>  <span>=&gt;</span>  <span>~</span><span>x</span>
<span>X</span> <span>&gt;=</span> <span>1</span>  <span>=&gt;</span>  <span>X</span> <span>&gt;</span> <span>0</span> 
<span>X</span> <span>&lt;</span>  <span>1</span>  <span>=&gt;</span>  <span>X</span> <span>&lt;=</span> <span>0</span>
<span>X</span> <span>+</span> <span>–°</span><span>1</span> <span>==</span> <span>C2</span>  <span>=&gt;</span>  <span>X</span> <span>==</span> <span>C2</span> <span>-</span> <span>C1</span>
<span>((</span><span>X</span> <span>+</span> <span>C1</span><span>)</span> <span>+</span> <span>C2</span><span>)</span>  <span>=&gt;</span>  <span>(</span><span>X</span> <span>+</span> <span>(</span><span>C1</span> <span>+</span> <span>C2</span><span>))</span>
<span>((</span><span>X</span> <span>+</span> <span>C1</span><span>)</span> <span>+</span> <span>(</span><span>Y</span> <span>+</span> <span>C2</span><span>))</span>  <span>=&gt;</span>  <span>((</span><span>X</span> <span>+</span> <span>Y</span><span>)</span> <span>+</span> <span>(</span><span>C1</span> <span>+</span> <span>C2</span><span>))</span></pre></td></tr></tbody></table></code></pre></figure>

<p>There are also some in <code>lowering.cpp</code> (machine-dependent ones) but in general RyuJIT obviously loses to –°++ compilers here. RyuJIT just focuses more on different things and has a lot of requirements. The main one is - it should compile fast! it‚Äôs called JIT after all. And it does it very well (unlike the C++ compilers - see <a href="https://aras-p.info/blog/2018/12/28/Modern-C-Lamentations/">‚ÄúModern‚Äù C++ Lamentations</a>). It‚Äôs also more important to de-virtualize calls, optimize out boxings, heap allocations (e.g. <a href="https://github.com/dotnet/coreclr/issues/20253">Object Stack Allocation</a>). However, since RyuJIT is now supporting tiers, who knows maybe there will be a place for peephole optimizations in future in the tier1 or even a separate tier2 ;-). Maybe with some sort of DSL to declare them, just read <a href="https://medium.com/@prathamesh1615/adding-peephole-optimization-to-gcc-89c329dd27b3">this</a> article where Prathamesh Kulkarni managed to declare an optimization for GCC in just a few lines of DSL:</p>

<figure><pre><code data-lang="cpp"><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>(</span><span>simplify</span>
 <span>(</span><span>plus</span> <span>(</span><span>mult</span> <span>(</span><span>SIN</span> <span>@</span><span>0</span><span>)</span> <span>(</span><span>SIN</span> <span>@</span><span>0</span><span>))</span>
       <span>(</span><span>mult</span> <span>(</span><span>COS</span> <span>@</span><span>0</span><span>)</span> <span>(</span><span>COS</span> <span>@</span><span>0</span><span>)))</span>
 <span>(</span><span>if</span> <span>(</span><span>flag_unsafe_math_optimizations</span><span>)</span>
  <span>{</span> <span>build_one_cst</span> <span>(</span><span>TREE_TYPE</span> <span>(</span><span>@</span><span>0</span><span>));</span> <span>}))</span></pre></td></tr></tbody></table></code></pre></figure>

<p>for the following pattern:</p>

<figure><pre><code data-lang="cpp"><table><tbody><tr><td><pre>1
</pre></td><td><pre><span>cos</span><span>^</span><span>2</span><span>(</span><span>X</span><span>)</span> <span>+</span> <span>sin</span><span>^</span><span>2</span><span>(</span><span>X</span><span>)</span> <span>equals</span> <span>to</span> <span>1</span> </pre></td></tr></tbody></table></code></pre></figure>

<h3 id="links">Links</h3>
<ul>
  <li><a href="https://arxiv.org/pdf/1809.02161.pdf">‚ÄúFuture Directions for Optimizing Compilers‚Äù</a> by Nuno P. Lopes and John Regehr</li>
  <li><a href="https://blog.regehr.org/archives/1603">‚ÄúHow LLVM Optimizes a Function‚Äù</a> by John Regehr</li>
  <li><a href="https://lemire.me/blog/2016/05/23/the-surprising-cleverness-of-modern-compilers/">‚ÄúThe surprising cleverness of modern compilers‚Äù</a> by Daniel Lemire</li>
  <li><a href="https://medium.com/@prathamesh1615/adding-peephole-optimization-to-gcc-89c329dd27b3">‚ÄúAdding peephole optimization to GCC‚Äù</a> by Prathamesh Kulkarni</li>
  <li><a href="https://lucasmeijer.com/posts/cpp_unity/">‚ÄúC++, C# and Unity‚Äù</a> by Lucas Meijer</li>
  <li><a href="https://aras-p.info/blog/2018/12/28/Modern-C-Lamentations/">‚ÄúModern‚Äù C++ Lamentations‚Äù</a> by Aras Pranckeviƒçius</li>
  <li><a href="http://www.cs.utah.edu/~regehr/papers/pldi15.pdf">‚ÄúProvably Correct Peephole Optimizations with Alive‚Äù</a> by Nuno P. Lopes, David Menendez, Santosh Nagarakatte and John Regehr</li>
</ul>

    </div>

    
</article>


            </div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>