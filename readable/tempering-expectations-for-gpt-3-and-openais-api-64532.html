<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Tempering Expectations for GPT-3 and OpenAI&#x2019;s API - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Tempering Expectations for GPT-3 and OpenAI&#x2019;s API - linksfor.dev(s)"/>
    <meta property="article:author" content="https://www.facebook.com/max.woolf"/>
    <meta property="og:description" content="GPT-3 is indeed a large step forward for AI text-generation, but there are very many caveats with the popular demos and use cases."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://minimaxir.com/2020/07/gpt3-expectations/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Tempering Expectations for GPT-3 and OpenAI&#x2019;s API</title>
<div class="readable">
        <h1>Tempering Expectations for GPT-3 and OpenAI&#x2019;s API</h1>
            <div>by https://www.facebook.com/max.woolf</div>
            <div>Reading time: 13-16 minutes</div>
        <div>Posted here: 20 Jul 2020</div>
        <p><a href="https://minimaxir.com/2020/07/gpt3-expectations/">https://minimaxir.com/2020/07/gpt3-expectations/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div itemprop="articleBody"><p>On May 29th, <a href="https://openai.com/" target="_blank">OpenAI</a> released <a href="https://arxiv.org/abs/2005.14165" target="_blank">a paper</a> on GPT-3, their next iteration of <a href="https://jalammar.github.io/illustrated-transformer/" target="_blank">Transformers</a>-based text generation neural networks. Most notably, the new model has 175 billion parameters compared to the 1.5 billion of previous <a href="https://openai.com/blog/better-language-models/" target="_blank">GPT-2 iteration</a>: a <em>117x</em> increase in model size! Because GPT-3 is so large, it can’t be run on conventional computers, and it only became publicly available as a part of the <a href="https://beta.openai.com/" target="_blank">OpenAI API</a>, which entered an invite-only beta soon after the paper was released and will be released for-profit sometime later.</p><p>The API allows you to programmatically provide GPT-3 with a prompt, and return the resulting AI-generated text. For example, you could invoke the API with:</p><pre><code>curl https://api.openai.com/v1/engines/davinci/completions 
-H <span>"Content-Type: application/json"</span> 
-H <span>"Authorization: Bearer &lt;SECRET_KEY&gt;"</span> 
-d <span>'{"prompt": "This is a test", "max_tokens": 5}'</span>
</code></pre><p>And get this back from the API, where the <code>text</code> is the generated text following up from the <code>prompt</code>:</p><pre><code>{
    <span>"id"</span>: <span>"cmpl-&lt;ID&gt;"</span>,
    <span>"object"</span>: <span>"text_completion"</span>,
    <span>"created"</span>: <span>1586839808</span>,
    <span>"model"</span>: <span>"davinci:2020-05-03"</span>,
    <span>"choices"</span>: [{
        <span>"text"</span>: <span>" of reading speed. You"</span>,
        <span>"index"</span>: <span>0</span>,
        <span>"logprobs"</span>: <span>null</span>,
        <span>"finish_reason"</span>: <span>"length"</span>
    }]
}
</code></pre><p>As someone who has spent a very large amount of time working with GPT-2 while developing tools such as <a href="https://github.com/minimaxir/gpt-2-simple" target="_blank">gpt-2-simple</a> and <a href="https://github.com/minimaxir/aitextgen" target="_blank">aitextgen</a>, which allow for optimized text generation using GPT-2, I was eager to test for myself if the quality of text generated from GPT-3 was really that much better. Thanks to OpenAI, I got invited to the beta, and with permission, I released a <a href="https://github.com/minimaxir/gpt-3-experiments" target="_blank">GitHub repository</a> with a Python script to query the API, along with <a href="https://github.com/minimaxir/gpt-3-experiments/tree/master/examples" target="_blank">many examples</a> of text prompts and their outputs. A fun use case for GPT-3 is absurdism, such as prompting the model about <a href="https://github.com/minimaxir/gpt-3-experiments/tree/master/examples/unicorn" target="_blank">unicorns speaking English</a>, with the model prompt bolded:</p><div id="gist104422939">
    <div>
      <div>
        <div>
  <div id="file-unicorn-md">
    
  <div id="file-unicorn-md-readme">
    <article itemprop="text"><p><strong>In a shocking finding, scientist discovered a herd of unicorns living in a remote, previously unexplored valley, in the Andes Mountains. Even more surprising to the researchers was the fact that the unicorns spoke perfect English.</strong></p>
<p>“At first we thought they were just very good at speaking English,” said team leader Dr. Renard Hodges. “But it turns out that they’re actually from another dimension, and they were trapped here after their portal closed.”</p>
<p>The herd, which has been estimated to be in the hundreds, are being held captive by the Inca tribe who discovered them. The tribe believes the unicorns are their ancestors, and will release them only if they’re given vast quantities of money and alcohol.</p>
<p>“We don’t have much choice,” said Hodges. “If we don’t give them what they want, the unicorns will kill us all.”</p>
<p>When asked if the team was afraid of the unicorns, Hodges said, “We have absolutely nothing to fear. Our armor is made from the finest titanium.”</p>
</article>
  </div>

  </div>
</div>

      </div>
      
    </div>
</div>
<p>I also fed <a href="https://github.com/minimaxir/gpt-3-experiments/tree/master/examples/twitter-minimaxir" target="_blank">my own tweets</a> through GPT-3 and curated the output, resulting in data science one-liners that are wholly original:</p><p>There hadn’t been too much GPT-3 hype after the initial announcement, outside of a few blogs from <a href="https://www.gwern.net/GPT-3" target="_blank">Gwern</a> and <a href="http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html" target="_blank">Kevin Lacker</a>. Until a <a href="https://twitter.com/sharifshameem/status/1282676454690451457" target="_blank">viral tweet</a> by <a href="https://twitter.com/sharifshameem" target="_blank">Sharif Shameem</a> showed what GPT-3 can <em>really</em> do:</p><p>Later, he made a <a href="https://twitter.com/sharifshameem/status/1284095222939451393" target="_blank">followup tweet</a> generating <a href="https://reactjs.org/" target="_blank">React</a> code with GPT-3:</p><p>That demo got the attention of venture capitalists. And when a cool-looking magical thing gets the attention of venture capitalists, discourse tends to spiral out of control. Now, there are <em>many</em> <a href="https://twitter.com/search?q=Gpt-3&amp;src=recent_search_click&amp;f=live" target="_blank">tweets about GPT-3</a>, and what it can do from others who have gained access to the API.</p><p>Hype aside, let’s look at the pragmatic realities of the model. GPT-3 is indeed a large step forward for AI text-generation, but there are very many caveats with the popular demos and use cases that must be addressed.</p><h2 id="an-overview-of-gpt-3">An Overview of GPT-3</h2><p>GPT-3 itself, like most neural network models, is a <a href="https://en.wikipedia.org/wiki/Black_box" target="_blank">black box</a> where it’s impossible to see <em>why</em> it makes its decisions, so let’s think about GPT-3 in terms of inputs and outputs.</p><p>Actually, why not let GPT-3 tell its own story? Hey GPT-3, how do you work?</p><div id="gist104417009">
    <div>
      <div>
        <div>
  <div id="file-gpt3-1-md">
    
  <div id="file-gpt3-1-md-readme">
    <article itemprop="text"><p><strong>Hello! I am GPT-3, a AI text-generation neural network by OpenAI!</strong></p>
<p><strong>I generate text by</strong> selecting random words from a vocabulary and rearranging them.</p>
<p>You can input words you want to appear in your text here and I will make sure they will appear. Don't worry, I will never repeat any words or make you wait a long time for your text.</p>
<p>The more input words, the better!</p>
</article>
  </div>

  </div>
</div>

      </div>
      
    </div>
</div>
<p>Close, but not quite!</p><p>In layman’s terms, text generating models such as GPT-3 generate text by taking supplied chunks of text from a prompt and predicting the next chunk of text, with an optional <code>temperature</code> parameter to allow the model to make suboptimal predictions and therefore be more “creative”. Then the model makes another prediction from the previous chunks including the new chunk, and repeats until it hits a specified length or a token that tells the model to stop generating. It’s not very philosophical, or evidence of some sort of anthropomorphic consciousness.</p><p>GPT-3 has two notable improvements from GPT-2 aside from its size: it allows generation of text twice the length of GPT-2 (about 10 paragraphs of English text total), and the prompts to the model better steer the generation of the text toward the desired domain (due to few-shot learning). For example, if you prompt the model with an example of React code, and then tell it to generate more React code, you’ll get much better results than if you gave it the simple prompt.</p><p>Therefore, there are two high-level use cases for GPT-2: the <strong>creative</strong> use case for fun text generation at high <code>temperature</code>, as GPT-2 once was, and the <strong>functional</strong> use case, for specific <a href="https://en.wikipedia.org/wiki/Natural_language_processing" target="_blank">NLP</a>-based use cases such as webpage mockups, with a <code>temperature</code> of <code>0.0</code>.</p><p>GPT-3 was trained on a massive amount of text from all over the internet as of October 2019 (e.g. it does not know about <a href="https://www.cdc.gov/coronavirus/2019-ncov/index.html" target="_blank">COVID-19</a>), and therefore it has likely seen every <em>type</em> of text possible, from code, to movie scripts, to tweets. A common misconception among viewers of GPT-3 demos is that the model is trained on a new dataset; that’s not currently the case, it’s just <em>that good</em> at extrapolation. As an example, despite the <a href="https://en.wikipedia.org/wiki/Star_Wars:_Episode_III_%E2%80%93_Revenge_of_the_Sith" target="_blank">Star Wars: Episode III - Revenge of the Sith</a> prompt containing text <a href="https://github.com/minimaxir/gpt-3-experiments/tree/master/examples/revengeofthesith" target="_blank">from a single scene</a>, the <a href="https://github.com/minimaxir/gpt-3-experiments/blob/master/examples/revengeofthesith/output_0_7.md" target="_blank">0.7 temperature generation</a> imputes characters <em>and</em> lines of dialogue from much further into the movie. (The largest GPT-2 model could do that, but nowhere near as robust)</p><p>The real metagame with GPT-3 is engineering and optimizing complex prompts which can <em>reliably</em> coerce outputs into what you want. And with that brings a whole host of complexity and concerns.</p><h2 id="gpt-3-caveats">GPT-3 Caveats</h2><p>Despite everything above, I don’t believe that GPT-3 is a new paradigm or an <a href="https://en.wikipedia.org/wiki/Clarke%27s_three_laws" target="_blank">advanced technology indistinguishable from magic</a>. GPT-3 and the OpenAI API showcases on social media don’t show potential pitfalls with the model and the API.</p><p>Hey GPT-3, what problems do you have?</p><div id="gist104417057">
    <div>
      <div>
        <div>
  <div id="file-gpt3-2-md">
    
  <div id="file-gpt3-2-md-readme">
    <article itemprop="text"><p><strong>Hello! I am GPT-3, a AI text-generation neural network by OpenAI!</strong></p>
<p><strong>Unfortunately, I'm not perfect. I have many problems, such as</strong> lack of attention span, and an inability to read from pre-programmed text, so I can only speak off the cuff.</p>
<p>Still, I'm fairly certain I'm a pretty nice guy! Ask me anything, but be nice. I don't like mean people.</p>
</article>
  </div>

  </div>
</div>

      </div>
      
    </div>
</div>
<p>Sorry GPT-3, but I am a mean person.</p><h3 id="model-latency">Model Latency</h3><p>If you’ve seen the demo videos, the model is <em>slow</em>, and it can take awhile for output to show up, and in the meantime the user is unsure if the model is broken or not. (There is a feature to allow streaming the model outputs as they are generated, which helps in creative cases but not in functional cases).</p><p>I don’t blame OpenAI for the slowness. A 175 billion parameter model is a model that’s wayyy too big to fit on a GPU for deployment. No one knows <em>how</em> GPT-3 is actually deployed on OpenAI’s servers, and how much it can scale.</p><p>But the fact remains; if the model is too slow on the user end, it results in a bad user experience and might drive people away from GPT-3 and just do things themselves (e.g. Apple’s Siri for iOS, where requests can take forever if there is a weak internet connection and you just give up and do it yourself).</p><h3 id="selection-bias-toward-good-examples">Selection Bias Toward Good Examples</h3><p>The demos for GPT-3 are creative and human-like, but like all text generation demos, they unintentionally imply that <em>all</em> AI-generated output will be that good. Unfortunately, that’s not the case in reality; AI-generated text has a tendency to fall into an <a href="https://en.wikipedia.org/wiki/Uncanny_valley" target="_blank">uncanny valley</a>, and good examples in showcases are often cherry-picked.</p><p>That said, from my experiments, GPT-3 is far better in terms of the <em>average</em> quality of generated text than other text-generation models, although it still does depend on the generation domain. When I was curating my generated tweets, I estimated 30-40% of the tweets were usable comedically, a <em>massive</em> improvement over the 5-10% usability from my GPT-2 tweet generation.</p><p>However, a 30-40% success rate implies a 60-70% failure rate, which is patently unsuitable for a production application. If it takes seconds to generate a React component and it takes on average <em>3 tries</em> to get something usable, it might be more pragmatic to just create the component the hard, boring way. Compare again to Apple’s Siri, which can get very frustrating when it <a href="https://www.reddit.com/r/SiriFail/" target="_blank">performs the wrong action</a>.</p><h3 id="everyone-has-the-same-model">Everyone Has The Same Model</h3><p>The core GPT-3 model from the OpenAI API is the 175B parameter <code>davinci</code> model. The GPT-3 demos on social media often hide the prompt, allowing for some mystique. However, because everyone has the same model and you can’t build your own GPT-3 model, there’s no competitive advantage. GPT-3 seed prompts can be reverse-engineered, which may become a rude awakening for entrepreneurs and the venture capitalists who fund them.</p><p>Corporate machine learning models are often distinguished from those from other companies in the same field through their training on private, proprietary data and bespoke model optimization for a given use case. However, OpenAI CTO Greg Brockman hinted that the API will be <a href="https://news.ycombinator.com/item?id=23725834" target="_blank">adding a finetuning feature</a> later in July, which could help solve this problem.</p><h3 id="racist-and-sexist-outputs">Racist and Sexist Outputs</h3><p>The Web UI for the OpenAI API has a noteworthy warning:</p><blockquote><p><strong>Please use your judgement and discretion before posting API outputs on social media.</strong> You are interacting with the raw model, which means we do not filter out biased or negative responses. With great power comes great responsibility.</p></blockquote><p>This is a reference to the <a href="https://openai.com/blog/openai-api/" target="_blank">FAQ</a> for the API:</p><blockquote><p>Mitigating negative effects such as harmful bias is a hard, industry-wide issue that is extremely important. Ultimately, our API models do exhibit biases (as shown in the GPT-3 paper) that will appear on occasion in generated text. Our API models could also cause harm in ways that we haven’t thought of yet.</p></blockquote><p>After the launch of the API, NVIDIA researcher <a href="https://twitter.com/AnimaAnandkumar" target="_blank">Anima Anandkumar</a> made a <a href="https://twitter.com/AnimaAnandkumar/status/1271137176529416193" target="_blank">highly-debated tweet</a>:</p><p>During my GPT-3 experiments, I found that <a href="https://github.com/minimaxir/gpt-3-experiments/tree/master/examples/twitter-dril" target="_blank">generating tweets</a> from <a href="https://twitter.com/dril" target="_blank">@dril</a> (admittingly an edgy Twitter user) ended up resulting in 4chan-level racism/sexism that I spent enormous amounts of time sanitizing, and it became more apparent at higher temperatures. It’s especially important to avoid putting offensive content for generated texts which put words in others’ mouths.</p><p><a href="https://twitter.com/an_open_mind" target="_blank">Jerome Pesenti</a>, the head of AI at Facebook, also managed to <a href="https://twitter.com/an_open_mind/status/1284487376312709120" target="_blank">trigger anti-semetic tweets</a> from a GPT-3 app:</p><p>Again, it depends on the domain. Would GPT-3 output racist or sexist React components? Likely not, but it’s something that would still need to be robustly checked. OpenAI does appear to take these concerns seriously, and has implemented toxicity detectors for generated content in the Web UI, although not the programmatic API yet.</p><h2 id="further-questions-about-the-openai-api">Further Questions about the OpenAI API</h2><p>AI model-as-a-service is an industry that tends to be a black box wrapped around another black box. Despite all the caveats, everything depends on how the OpenAI API exits beta and rolls out the API for production use. There are too many unknowns to even think about making money off of the OpenAI API, let alone making a startup based on it.</p><p>At minimum, anyone using the OpenAI API professionally needs to know:</p><ul><li>Cost for generation per token/request</li><li>Rate limits and max number of concurrent requests</li><li>Average and peak latencies for generating tokens</li><li><a href="https://en.wikipedia.org/wiki/Service-level_agreement" target="_blank">SLA</a> for the API</li><li>AI generated content ownership/copyright</li></ul><p>That’s certainly less magical!</p><p>The most important question mark there is cost: given the model size, I’m not expecting it to be cheap, and it’s entirely possible that the unit economics make most GPT-3-based startups infeasible.</p><p>That said, it’s still good for people to experiment with GPT-3 and the OpenAI API in order to show what the model is truly capable of. It won’t replace software engineering jobs anytime soon, or become <a href="https://en.wikipedia.org/wiki/Skynet_(Terminator)" target="_blank">Skynet</a>, or whatever. But it’s objectively a <em>step forward</em> in the field of AI text-generation.</p><p>What about GPT-2? Since it’s unlikely that the other GPT-3 models will be open-sourced by OpenAI, GPT-2 isn’t obsolete, and there will still be demand for a more open text-generating model. However, I confess that the success of GPT-3 has <a href="https://twitter.com/minimaxir/status/1284160088161181697" target="_blank">demotivated me</a> to continue working on my own GPT-2 projects, especially since they will now be impossible to market competitively (GPT-2 is a number less than GPT-3 after all).</p><p>All said, I’d be glad to use GPT-3 and the OpenAI API for both personal and professional projects once it’s out of beta, given that the terms of use for the API are reasonable. And if the hype becomes more leveled such that said projects can actually stand out.</p><div><p>If you liked this blog post, I have set up a <a href="https://www.patreon.com/minimaxir" target="_blank">Patreon</a> to fund my machine learning/deep learning/software/hardware needs for my future crazy yet cool projects, and any monetary contributions to the Patreon are appreciated and will be put to good creative use.</p></div></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs" /></noscript>
</body>
</html>