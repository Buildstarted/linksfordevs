<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Hybridizer: High-Performance C# on GPUs | NVIDIA Developer Blog - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Hybridizer: High-Performance C# on GPUs | NVIDIA Developer Blog - linksfor.dev(s)"/>
    <meta property="article:author" content="View all posts by Florent Duguet"/>
    <meta property="og:description" content="Learn how to use the Hybridizer&#xA0;compiler from Altimesh&#xA0;to program GPUs and other accelerators using C# code or .NET Assembly."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://devblogs.nvidia.com/hybridizer-csharp/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Hybridizer: High-Performance C# on GPUs | NVIDIA Developer Blog</title>
<div class="readable">
        <h1>Hybridizer: High-Performance C# on GPUs | NVIDIA Developer Blog</h1>
            <div>by View all posts by Florent Duguet</div>
            <div>Reading time: 10-13 minutes</div>
        <div>Posted here: 09 Apr 2020</div>
        <p><a href="https://devblogs.nvidia.com/hybridizer-csharp/">https://devblogs.nvidia.com/hybridizer-csharp/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="pf-post-view">
    <div>

                  <article id="post-8788">
                

                <div>
                  <figure id="attachment_8784" aria-labelledby="figcaption_attachment_8784"><img src="https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2017/12/hybridizer-pipeline-300x167.png" alt="Figure 1. The Hybridizer Pipeline." width="400" height="222" srcset="https://devblogs.nvidia.com/wp-content/uploads/2017/12/hybridizer-pipeline-300x167.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/hybridizer-pipeline-768x427.png 768w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/hybridizer-pipeline-625x347.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/hybridizer-pipeline-500x278.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/hybridizer-pipeline-160x90.png 160w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/hybridizer-pipeline-362x201.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/hybridizer-pipeline-198x110.png 198w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/hybridizer-pipeline-1024x569.png 1024w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/hybridizer-pipeline.png 1179w" sizes="(max-width: 400px) 100vw, 400px"><figcaption id="figcaption_attachment_8784">Figure 1. The Hybridizer Pipeline.</figcaption></figure>
<p>Hybridizer&nbsp;is a compiler from <a href="http://www.altimesh.com/hybridizer-essentials/" target="_blank" rel="noopener">Altimesh</a>&nbsp;that lets you program GPUs and other accelerators from C# code or .NET Assembly. Using decorated symbols to express parallelism, Hybridizer generates source code or binaries optimized for multicore CPUs and GPUs. In this blog post we&nbsp;illustrate the CUDA target.</p>
<p>Figure 1 shows the Hybridizer compilation pipeline. Using parallelization patterns such as <code>Parallel.For</code>,&nbsp;or by distributing parallel work&nbsp;explicitly as you would in CUDA, you&nbsp;can benefit from the compute horsepower of accelerators without learning all the details of their internal architecture.&nbsp;Here is a simple example using <code>Parallel.For</code> with a lambda.</p>
<pre><span>[</span><span>EntryPoint</span><span>]</span><span>
</span><span>public</span><span> </span><span>static</span><span> </span><span>void</span><span> </span><span>Run</span><span>(</span><span>double</span><span>[]</span><span> a</span><span>,</span><span> </span><span>double</span><span>[]</span><span> b</span><span>,</span><span> </span><span>int</span><span> N</span><span>)</span><span>
</span><span>{</span><span>
 &nbsp; &nbsp;</span><span>Parallel</span><span>.</span><span>For</span><span>(</span><span>0</span><span>,</span><span> N</span><span>,</span><span> i </span><span>=&gt;</span><span> </span><span>{</span><span> a</span><span>[</span><span>i</span><span>]</span><span> </span><span>+=</span><span> b</span><span>[</span><span>i</span><span>];</span><span> </span><span>});</span><span>
</span><span>}</span></pre>
<p>You can debug and profile this code on the GPU using NVIDIA <a href="https://developer.nvidia.com/nvidia-nsight-visual-studio-edition">Nsight&nbsp;Visual Studio Edition</a>.&nbsp;Hybridizer implements&nbsp;advanced C# features including virtual functions&nbsp;and&nbsp;generics.<span id="more-8788"></span></p>
<h2>Where to Get Hybridizer</h2>
<p>Hybridizer comes&nbsp;in <a href="http://www.altimesh.com/hybridizer-products/" target="_blank" rel="noopener">two versions</a>:</p>
<ul>
<li>Hybridizer Software Suite: enables CUDA, AVX, AVX2, AVX512 targets and outputs source code. This source code can be reviewed, which is mandatory in some businesses such as investment banks. Hybridizer Software Suite is licensed per customer <a href="http://www.altimesh.com/contact/" target="_blank" rel="noopener">upon request</a>.</li>
<li><a href="http://www.altimesh.com/hybridizer-essentials/" target="_blank" rel="noopener">Hybridizer Essentials</a>: enables only the CUDA target and outputs only binaries. Hybridizer Essentials is a free <a href="https://marketplace.visualstudio.com/items?itemName=altimesh.AltimeshHybridizerExtensionEssentials" target="_blank" rel="noopener">Visual Studio extension</a>&nbsp;with no hardware restrictions. <a href="https://github.com/altimesh/hybridizer-basic-samples" target="_blank" rel="noopener">You can find a set of basic code samples and educational material on GitHub</a>. These samples also serve as a way to reproduce our performance results.</li>
</ul>
<p>While providing automated default behavior, Hybridizer gives full developer control at each phase, allowing you to&nbsp;reuse existing device-specific code, existing external libraries or custom handmade code snippets.</p>
<h2>Debugging And Profiling</h2>
<p>When compiled with debug information, you can debug Hybridizer C# / .NET&nbsp;code &nbsp;within Microsoft Visual Studio&nbsp;while running the optimized code on the target hardware.&nbsp;For example, a program written in C#&nbsp;can hit&nbsp;a breakpoint in the C# file within Visual Studio and you can explore local variables and object data that reside on the&nbsp;GPU.</p>
<figure id="attachment_8785" aria-labelledby="figcaption_attachment_8785"><img src="https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2017/12/debugging-with-nsight.png" alt="Figure 2: Debugging C# code running on the GPU with Hybridizer and NVIDIA Nsight Visual Studio Edition." width="1003" height="665" srcset="https://devblogs.nvidia.com/wp-content/uploads/2017/12/debugging-with-nsight.png 1003w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/debugging-with-nsight-300x199.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/debugging-with-nsight-768x509.png 768w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/debugging-with-nsight-625x414.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/debugging-with-nsight-452x300.png 452w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/debugging-with-nsight-136x90.png 136w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/debugging-with-nsight-362x240.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/debugging-with-nsight-166x110.png 166w" sizes="(max-width: 1003px) 100vw, 1003px"><figcaption id="figcaption_attachment_8785">Figure 2: Debugging C# code running on the GPU with Hybridizer and NVIDIA Nsight Visual Studio Edition.</figcaption></figure>
<p>You can integrate Hybridizer within complex projects, even in libraries for which code is not available or is obfuscated,&nbsp;because Hybridizer operates on MSIL bytecode. We demonstrated this ability in<a href="http://www.altimesh.com/image-processing-on-a-gpu-with-aforge/" target="_blank" rel="noopener">&nbsp;</a><a href="http://www.altimesh.com/image-processing-on-a-gpu-with-aforge/" target="_blank" rel="noopener">our blog post</a>&nbsp;about accelerating the AForge&nbsp;image processing library with Hybridizer without modifying the library. Operating on MSIL bytecode&nbsp;also enables&nbsp;support for a variety of languages built on top of the .Net virtual machine, such as VB.Net and F#.</p>
<p>All this flexibility does not come at the expense of performance loss. As our<a href="http://www.altimesh.com/expm1-benchmark/" target="_blank" rel="noopener">&nbsp;</a><a href="http://www.altimesh.com/expm1-benchmark/" target="_blank" rel="noopener">benchmark</a>&nbsp;illustrates, code generated by the Hybridizer can perform as well as hand-written code. You can use performance profilers such as NVIDIA Nsight and the NVIDIA Visual Profiler to measure performance of generated binaries, with&nbsp;performance indicators referring to the original source code (C#,&nbsp;for instance).</p>
<h2>A Simple Example: Mandelbrot</h2>
<p>As a first example, we demonstrate the rendering of the Mandelbrot fractal&nbsp;running on an NVIDIA&nbsp;GeForce GTX 1080 Ti GPU (Pascal architecture; Compute Capability 6.1).</p>
<h3>Mandelbrot C# Code</h3>
<p>The following code snippet shows plain C#. It runs smoothly on the CPU without any performance penalty, since most code modifications are attributes (such as the <code>EntryPoint</code> attribute&nbsp;on the <code>Run</code>&nbsp;method) which have no effect at run&nbsp;time.</p>
<pre><span>[</span><span>EntryPoint</span><span>]</span><span>
</span><span>public</span><span> </span><span>static</span><span> </span><span>void</span><span> </span><span>Run</span><span>(</span><span>float</span><span>[,]</span><span> result</span><span>)</span><span>
</span><span>{</span><span>
    </span><span>int</span><span> size </span><span>=</span><span> result</span><span>.</span><span>GetLength</span><span>(</span><span>0</span><span>);</span><span>
    </span><span>Parallel2D</span><span>.</span><span>For</span><span>(</span><span>0</span><span>,</span><span> size</span><span>,</span><span> </span><span>0</span><span>,</span><span> size</span><span>,</span><span> </span><span>(</span><span>i</span><span>,</span><span> j</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>
        </span><span>float</span><span> x </span><span>=</span><span> fromX </span><span>+</span><span> i </span><span>*</span><span> h</span><span>;</span><span>
        </span><span>float</span><span> y </span><span>=</span><span> fromY </span><span>+</span><span> j </span><span>*</span><span> h</span><span>;</span><span>
        result</span><span>[</span><span>i</span><span>,</span><span> j</span><span>]</span><span> </span><span>=</span><span> </span><span>IterCount</span><span>(</span><span>x</span><span>,</span><span> y</span><span>);</span><span>
    </span><span>});</span><span>
</span><span>}</span><span>

</span><span>public</span><span> </span><span>static</span><span> </span><span>float</span><span> </span><span>IterCount</span><span>(</span><span>float</span><span> cx</span><span>,</span><span> </span><span>float</span><span> cy</span><span>)</span><span>
</span><span>{</span><span>
    </span><span>float</span><span> result </span><span>=</span><span> </span><span>0.0F</span><span>;</span><span>
    </span><span>float</span><span> x </span><span>=</span><span> </span><span>0.0f</span><span>,</span><span> y </span><span>=</span><span> </span><span>0.0f</span><span>,</span><span> xx </span><span>=</span><span> </span><span>0.0f</span><span>,</span><span> yy </span><span>=</span><span> </span><span>0.0f</span><span>;</span><span>
    </span><span>while</span><span> </span><span>(</span><span>xx </span><span>+</span><span> yy </span><span>&lt;=</span><span> </span><span>4.0f</span><span> </span><span>&amp;&amp;</span><span> result </span><span>&lt;</span><span> maxiter</span><span>)</span><span> </span><span>{</span><span>
        xx </span><span>=</span><span> x </span><span>*</span><span> x</span><span>;</span><span>
        yy </span><span>=</span><span> y </span><span>*</span><span> y</span><span>;</span><span>
        </span><span>float</span><span> xtmp </span><span>=</span><span> xx </span><span>-</span><span> yy </span><span>+</span><span> cx</span><span>;</span><span>
        y </span><span>=</span><span> </span><span>2.0f</span><span> </span><span>*</span><span> x </span><span>*</span><span> y </span><span>+</span><span> cy</span><span>;</span><span>
        x </span><span>=</span><span> xtmp</span><span>;</span><span>
        result</span><span>++;</span><span>
    </span><span>}</span><span>
    </span><span>return</span><span> result</span><span>;</span><span>
</span><span>}</span></pre>
<p>The <code>EntryPoint</code>&nbsp;attribute tells the Hybridizer to generate a CUDA kernel. Multi-dimensional arrays are mapped to an internal type, while <code>Parallel2D.For</code> maps to a 2D execution&nbsp;grid. Given a few lines of boilerplate code, we run this code on the GPU transparently.</p>
<pre><span>float</span><span>[,]</span><span> result </span><span>=</span><span> </span><span>new</span><span> </span><span>float</span><span>[</span><span>N</span><span>,</span><span>N</span><span>];</span><span>
</span><span>HybRunner</span><span> runner </span><span>=</span><span> </span><span>HybRunner</span><span>.</span><span>Cuda</span><span>(</span><span>"Mandelbrot_CUDA.dll"</span><span>).</span><span>SetDistrib</span><span>(</span><span>32</span><span>,</span><span> </span><span>32</span><span>,</span><span> </span><span>16</span><span>,</span><span> </span><span>16</span><span>,</span><span> </span><span>1</span><span>,</span><span> </span><span>0</span><span>);</span><span>
</span><span>dynamic</span><span> wrapper </span><span>=</span><span> runner</span><span>.</span><span>Wrap</span><span>(</span><span>new</span><span> </span><span>Program</span><span>());</span><span>
wrapper</span><span>.</span><span>Run</span><span>(</span><span>result</span><span>);</span></pre>
<h3>Profiling</h3>
<p>We profiled this code with the Nvidia Nsight Visual Studio Edition&nbsp;profiler. C# code is linked to the PTX&nbsp;in the CUDA source view, as Figure 3 shows.</p>
<figure id="attachment_8781" aria-labelledby="figcaption_attachment_8781"><img src="https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2017/12/mandelbrot-profiling-source-view.png" alt="Figure 3. Profiling Mandelbrot C# code in the CUDA source view." width="1224" height="343" srcset="https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-profiling-source-view.png 1224w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-profiling-source-view-300x84.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-profiling-source-view-768x215.png 768w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-profiling-source-view-625x175.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-profiling-source-view-500x140.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-profiling-source-view-160x45.png 160w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-profiling-source-view-362x101.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-profiling-source-view-393x110.png 393w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-profiling-source-view-1024x287.png 1024w" sizes="(max-width: 1224px) 100vw, 1224px"><figcaption id="figcaption_attachment_8781">Figure 3. Profiling Mandelbrot C# code in the CUDA source view.</figcaption></figure>
<p>The profiler allows the same level of investigation as with CUDA C++ code.</p>
<p>As for performance, this example&nbsp;reaches&nbsp;72.5% of peak compute FLOP/s. This is 83% of the same code, handwritten in CUDA&nbsp;C++.</p>
<figure id="attachment_8776" aria-labelledby="figcaption_attachment_8776"><img src="https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2017/12/mandelbrot-parallel2d-pipe-utilization.png" alt="Figure 4: Profiler output showing the GPU utilization and execution efficiency of the Mandelbrot code on the GPU. It achieves nearly as good efficiency as handwritten CUDA C++ code." width="1600" height="600" srcset="https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallel2d-pipe-utilization.png 1600w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallel2d-pipe-utilization-300x113.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallel2d-pipe-utilization-768x288.png 768w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallel2d-pipe-utilization-625x234.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallel2d-pipe-utilization-500x188.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallel2d-pipe-utilization-160x60.png 160w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallel2d-pipe-utilization-362x136.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallel2d-pipe-utilization-293x110.png 293w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallel2d-pipe-utilization-1024x384.png 1024w" sizes="(max-width: 1600px) 100vw, 1600px"><figcaption id="figcaption_attachment_8776">Figure 4: Profiler output showing the GPU utilization and execution efficiency of the Mandelbrot code on the GPU. It achieves nearly as good efficiency as handwritten CUDA C++ code.</figcaption></figure>
<p>Obtaining better performance from C# code is possible using the extended control that Hybridizer provides. As the following code shows, the syntax is very similar to CUDA C++.</p>
<pre><span>[</span><span>EntryPoint</span><span>]</span><span>
</span><span>public</span><span> </span><span>static</span><span> </span><span>void</span><span> </span><span>Run</span><span>(</span><span>float</span><span>[]</span><span> result</span><span>)</span><span>
</span><span>{</span><span>
    </span><span>for</span><span> </span><span>(</span><span>int</span><span> i </span><span>=</span><span> threadIdx</span><span>.</span><span>y </span><span>+</span><span> blockIdx</span><span>.</span><span>y </span><span>*</span><span> blockDim</span><span>.</span><span>y</span><span>;</span><span> i </span><span>&lt;</span><span> N</span><span>;</span><span> i </span><span>+=</span><span> blockDim</span><span>.</span><span>y </span><span>*</span><span> gridDim</span><span>.</span><span>y</span><span>)</span><span>
    </span><span>{</span><span>
        </span><span>for</span><span> </span><span>(</span><span>int</span><span> j </span><span>=</span><span> threadIdx</span><span>.</span><span>x </span><span>+</span><span> blockIdx</span><span>.</span><span>x </span><span>*</span><span> blockDim</span><span>.</span><span>x</span><span>;</span><span> j </span><span>&lt;</span><span> N</span><span>;</span><span> j </span><span>+=</span><span> blockDim</span><span>.</span><span>x </span><span>*</span><span> gridDim</span><span>.</span><span>x</span><span>)</span><span>
        </span><span>{</span><span>
            </span><span>float</span><span> x </span><span>=</span><span> fromX </span><span>+</span><span> i </span><span>*</span><span> h</span><span>;</span><span>
            </span><span>float</span><span> y </span><span>=</span><span> fromY </span><span>+</span><span> j </span><span>*</span><span> h</span><span>;</span><span>
            result</span><span>[</span><span>i </span><span>*</span><span> N </span><span>+</span><span> j</span><span>]</span><span> </span><span>=</span><span> </span><span>IterCount</span><span>(</span><span>x</span><span>,</span><span> y</span><span>);</span><span>
        </span><span>}</span><span>
    </span><span>}</span><span>
</span><span>}</span></pre>
<p>In this case, generated code and handwritten CUDA C++ code perform identically and reach 87% of peak FLOP/s, as Figure 5 shows.</p>
<figure id="attachment_8783" aria-labelledby="figcaption_attachment_8783"><img src="https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2017/12/mandelbrot-parallelhand-pipe-utilization.png" alt="Figure 5: Profiling the hand-optimized Mandelbrot C# code." width="1600" height="633" srcset="https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallelhand-pipe-utilization.png 1600w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallelhand-pipe-utilization-300x119.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallelhand-pipe-utilization-768x304.png 768w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallelhand-pipe-utilization-625x247.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallelhand-pipe-utilization-500x198.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallelhand-pipe-utilization-160x63.png 160w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallelhand-pipe-utilization-362x143.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallelhand-pipe-utilization-278x110.png 278w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/mandelbrot-parallelhand-pipe-utilization-1024x405.png 1024w" sizes="(max-width: 1600px) 100vw, 1600px"><figcaption id="figcaption_attachment_8783">Figure 5: Profiling the hand-optimized Mandelbrot C# code.</figcaption></figure>
<h2>Generics And Virtual Functions</h2>
<p>Hybridizer supports&nbsp;<a href="http://www.altimesh.com/generics-and-inheritance/" target="_blank" rel="noopener">generics and virtual function calls</a>&nbsp;in device functions. These fundamental concepts of modern programming languages facilitate code modularity&nbsp;and increase expressivity. However, type resolution in C# is done at run&nbsp;time, which introduces some performance penalty.&nbsp;.NET&nbsp;generics can achieve higher&nbsp;performance while maintaining flexibility: Hybridizer maps generics to C++ templates, which are resolved at compile time, allowing function inlining and interprocedural optimizations. On the other hand, virtual function calls are mapped to a virtual function table in which instance methods are registered.</p>
<p>Template instantiation hints are given to the Hybridizer by two attributes, <code>HybridTemplateConcept</code> and <code>HybridRegisterTemplate</code> (which triggers the actual template instantiation in device code).&nbsp;As an example, let’s look at a simple stream benchmark in two versions, one using&nbsp;virtual function calls, and another with template mapping.&nbsp;The benchmark relies on a common interface <code>IMyArray</code> exposing subscript operators:</p>
<pre><span>[</span><span>HybridTemplateConcept</span><span>]</span><span>
</span><span>public</span><span> </span><span>interface</span><span> </span><span>IMyArray</span><span> </span><span>{</span><span>

    </span><span>double</span><span> </span><span>this</span><span>[</span><span>int</span><span> index</span><span>]</span><span> </span><span>{</span><span> </span><span>get</span><span>;</span><span> </span><span>set</span><span>;</span><span> </span><span>}</span><span>
</span><span>}</span></pre>
<p>These operators must be “Hybridized” to device functions. To do that, we put the <code>Kernel</code> attribute in the implementation class.</p>
<pre><span>public</span><span> </span><span>class</span><span> </span><span>MyArray</span><span> </span><span>:</span><span> </span><span>IMyArray</span><span> </span><span>{</span><span>
    </span><span>double</span><span>[]</span><span> _data</span><span>;</span><span>

    </span><span>public</span><span> </span><span>MyArray</span><span>(</span><span>double</span><span>[]</span><span> data</span><span>)</span><span> </span><span>{</span><span>
        _data </span><span>=</span><span> data</span><span>;</span><span>
    </span><span>}</span><span>

    </span><span>[</span><span>Kernel</span><span>]</span><span>
    </span><span>public</span><span> </span><span>double</span><span> </span><span>this</span><span>[</span><span>int</span><span> index</span><span>]</span><span> </span><span>{</span><span>
        </span><span>get</span><span> </span><span>{</span><span> </span><span>return</span><span> _data</span><span>[</span><span>index</span><span>];</span><span> </span><span>}</span><span>
        </span><span>set</span><span> </span><span>{</span><span> _data</span><span>[</span><span>index</span><span>]</span><span> </span><span>=</span><span> value</span><span>;</span><span> </span><span>}</span><span>
    </span><span>}</span><span>
</span><span>}</span></pre>
<h3>Virtual Function Calls</h3>
<p>In a first version, we write a stream algorithm using the interface with no further hint to the compiler.</p>
<pre><span>public</span><span> </span><span>class</span><span> </span><span>MyAlgorithmDispatch</span><span> </span><span>{</span><span>
    </span><span>IMyArray</span><span> a</span><span>,</span><span> b</span><span>;</span><span>

    </span><span>public</span><span> </span><span>MyAlgorithmDispatch</span><span>(</span><span>IMyArray</span><span> a</span><span>,</span><span> </span><span>IMyArray</span><span> b</span><span>)</span><span>  </span><span>{</span><span>
        </span><span>this</span><span>.</span><span>a </span><span>=</span><span> a</span><span>;</span><span>
        </span><span>this</span><span>.</span><span>b </span><span>=</span><span> b</span><span>;</span><span>
    </span><span>}</span><span>

    </span><span>[</span><span>Kernel</span><span>]</span><span>
    </span><span>public</span><span> </span><span>void</span><span> </span><span>Add</span><span>(</span><span>int</span><span> n</span><span>)</span><span> </span><span>{</span><span>
        </span><span>IMyArray</span><span> a </span><span>=</span><span> </span><span>this</span><span>.</span><span>a</span><span>;</span><span>
        </span><span>IMyArray</span><span> b </span><span>=</span><span> </span><span>this</span><span>.</span><span>b</span><span>;</span><span>
        </span><span>for</span><span> </span><span>(</span><span>int</span><span> k </span><span>=</span><span> threadIdx</span><span>.</span><span>x </span><span>+</span><span> blockDim</span><span>.</span><span>x </span><span>*</span><span> blockIdx</span><span>.</span><span>x</span><span>;</span><span> 
             k </span><span>&lt;</span><span> n</span><span>;</span><span> 
             k </span><span>+=</span><span> blockDim</span><span>.</span><span>x </span><span>*</span><span> gridDim</span><span>.</span><span>x</span><span>)</span><span> </span><span>{</span><span>
            a</span><span>[</span><span>k</span><span>]</span><span> </span><span>+=</span><span> b</span><span>[</span><span>k</span><span>];</span><span>
        </span><span>}</span><span>
    </span><span>}</span><span>
</span><span>}</span></pre>
<p>Since we call subscript operators on <code>a</code> and <code>b</code> viewed as interfaces, we have a <code>callvirt</code> in the MSIL.</p>
<pre><span>IL_002a</span><span>:</span><span> ldloc</span><span>.</span><span>3</span><span>
IL_002b</span><span>:</span><span> ldloc</span><span>.</span><span>s </span><span>4</span><span>
IL_002d</span><span>:</span><span> callvirt instance float64 </span><span>Mandelbrot</span><span>.</span><span>IMyArray</span><span>::</span><span>get_Item</span><span>(</span><span>int32</span><span>)</span><span>
IL_0032</span><span>:</span><span> ldloc</span><span>.</span><span>1</span><span>
IL_0033</span><span>:</span><span> ldloc</span><span>.</span><span>2</span><span>
IL_0034</span><span>:</span><span> callvirt instance float64 </span><span>Mandelbrot</span><span>.</span><span>IMyArray</span><span>::</span><span>get_Item</span><span>(</span><span>int32</span><span>)</span><span>
IL_0039</span><span>:</span><span> add
IL_003a</span><span>:</span><span> callvirt instance </span><span>void</span><span> </span><span>Mandelbrot</span><span>.</span><span>IMyArray</span><span>::</span><span>set_Item</span><span>(</span><span>int32</span><span>,</span><span> float64</span><span>)</span></pre>
<p>Inspecting&nbsp;the generated binary shows that&nbsp;Hybridizer generated a lookup in a virtual function table, as Figure 6 shows.</p>
<figure id="attachment_8782" aria-labelledby="figcaption_attachment_8782"><img src="https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2017/12/stream-dispatch-profiling.png" alt="Figure 6. A virtual function call in PTX." width="1375" height="373" srcset="https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-profiling.png 1375w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-profiling-300x81.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-profiling-768x208.png 768w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-profiling-625x170.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-profiling-500x136.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-profiling-160x43.png 160w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-profiling-362x98.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-profiling-405x110.png 405w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-profiling-1024x278.png 1024w" sizes="(max-width: 1375px) 100vw, 1375px"><figcaption id="figcaption_attachment_8782">Figure 6. A virtual function call in PTX.</figcaption></figure>
<p>This version of the algorithm consumes 32 registers and achieves a bandwidth of&nbsp;271&nbsp;GB/s, as Figure 7 shows. On the same hardware, the <code>bandwidthTest</code> sample in the CUDA Toolkit achieves 352 GB/s.</p>
<figure id="attachment_8787" aria-labelledby="figcaption_attachment_8787"><img src="https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2017/12/stream-dispatch-bandwidth.png" alt="Figure 7. Low achieved bandwidth due to virtual function calls." width="1063" height="642" srcset="https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-bandwidth.png 1063w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-bandwidth-300x181.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-bandwidth-768x464.png 768w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-bandwidth-625x377.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-bandwidth-497x300.png 497w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-bandwidth-149x90.png 149w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-bandwidth-362x219.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-bandwidth-182x110.png 182w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-dispatch-bandwidth-1024x618.png 1024w" sizes="(max-width: 1063px) 100vw, 1063px"><figcaption id="figcaption_attachment_8787">Figure 7. Low achieved bandwidth due to virtual function calls.</figcaption></figure>
<p>Virtual function tables lead to more register pressure, and prevent inlining.</p>
<h3>Generic Calls</h3>
<p>We wrote a second version with generics, asking Hybridizer to generate template code.</p>
<pre><span>[</span><span>HybridRegisterTemplate</span><span>(</span><span>Specialize</span><span> </span><span>=</span><span> </span><span>typeof</span><span>(</span><span>MyAlgorithm</span><span>))]</span><span>
</span><span>public</span><span> </span><span>class</span><span> </span><span>MyAlgorithm</span><span> </span><span>where</span><span> T </span><span>:</span><span> </span><span>IMyArray</span><span>
</span><span>{</span><span>
    T a</span><span>,</span><span> b</span><span>;</span><span>

    </span><span>[</span><span>Kernel</span><span>]</span><span>
    </span><span>public</span><span> </span><span>void</span><span> </span><span>Add</span><span>(</span><span>int</span><span> n</span><span>)</span><span>
    </span><span>{</span><span>
            T a </span><span>=</span><span> </span><span>this</span><span>.</span><span>a</span><span>;</span><span>
            T b </span><span>=</span><span> </span><span>this</span><span>.</span><span>b</span><span>;</span><span>
            </span><span>for</span><span> </span><span>(</span><span>int</span><span> k </span><span>=</span><span> threadIdx</span><span>.</span><span>x </span><span>+</span><span> blockDim</span><span>.</span><span>x </span><span>*</span><span> blockIdx</span><span>.</span><span>x</span><span>;</span><span> 
                 k </span><span>&lt;</span><span> n</span><span>;</span><span> 
                 k </span><span>+=</span><span> blockDim</span><span>.</span><span>x </span><span>*</span><span> gridDim</span><span>.</span><span>x</span><span>)</span><span>
               a</span><span>[</span><span>k</span><span>]</span><span> </span><span>+=</span><span> b</span><span>[</span><span>k</span><span>];</span><span>
            </span><span>}</span><span>
    </span><span>}</span><span>

    </span><span>public</span><span> </span><span>MyAlgorithm</span><span>(</span><span>T a</span><span>,</span><span> T b</span><span>)</span><span>
    </span><span>{</span><span>
            </span><span>this</span><span>.</span><span>a </span><span>=</span><span> a</span><span>;</span><span>
            </span><span>this</span><span>.</span><span>b </span><span>=</span><span> b</span><span>;</span><span>
    </span><span>}</span><span>
</span><span>}</span></pre>
<p>With the <code>RegisterTemplate</code> attribute, Hybridizer generates the appropriate template instance. Optimizer then inlines function calls as Figure 8 shows.</p>
<figure id="attachment_8779" aria-labelledby="figcaption_attachment_8779"><img src="https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2017/12/stream-generics-profiling.png" alt="Figure 8. Using generic parameters generates inline function calls rather than virtual function table lookups." width="1490" height="445" srcset="https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-profiling.png 1490w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-profiling-300x90.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-profiling-768x229.png 768w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-profiling-625x187.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-profiling-500x149.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-profiling-160x48.png 160w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-profiling-362x108.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-profiling-368x110.png 368w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-profiling-1024x306.png 1024w" sizes="(max-width: 1490px) 100vw, 1490px"><figcaption id="figcaption_attachment_8779">Figure 8. Using generic parameters generates inline function calls rather than virtual function table lookups.</figcaption></figure>
<p>Performance of generic parameters is much better, achieving 339&nbsp;GB/s, which is a 25% performance improvement&nbsp;(Figure 9), and 96% of <code>bandwidthTest</code>.</p>
<figure id="attachment_8786" aria-labelledby="figcaption_attachment_8786"><img src="https://devblogs.nvidia.com/parallelforall/wp-content/uploads/2017/12/stream-generics-bandwidth.png" alt="Figure 9. Generics achieve higher bandwidth due to function inlining." width="1057" height="615" srcset="https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-bandwidth.png 1057w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-bandwidth-300x175.png 300w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-bandwidth-768x447.png 768w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-bandwidth-625x364.png 625w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-bandwidth-500x291.png 500w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-bandwidth-155x90.png 155w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-bandwidth-362x211.png 362w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-bandwidth-189x110.png 189w, https://devblogs.nvidia.com/wp-content/uploads/2017/12/stream-generics-bandwidth-1024x596.png 1024w" sizes="(max-width: 1057px) 100vw, 1057px"><figcaption id="figcaption_attachment_8786">Figure 9. Generics achieve higher bandwidth due to function inlining.</figcaption></figure>
<h2>Get Started with Hybridizer</h2>
<p>Hybridizer supports a wide variety of C# features, allowing for code factorization and expressivity. Integration within Visual Studio and<a href="http://www.nvidia.com/object/nsight.html" target="_blank" rel="noopener">&nbsp;</a><a href="http://www.nvidia.com/object/nsight.html" target="_blank" rel="noopener">Nsight</a>&nbsp;(debugger and profiler) gives you&nbsp;a safe and productive development environment. Hybridizer achieves excellent GPU performance even on very complex,&nbsp;highly customized code.</p>
<p>You can download <a href="http://www.altimesh.com/hybridizer-essentials/" target="_blank" rel="noopener">Hybridizer Essentials</a>&nbsp;from <a href="https://marketplace.visualstudio.com/items?itemName=altimesh.AltimeshHybridizerExtensionEssentials" target="_blank" rel="noopener">Visual Studio Marketplace</a>. Have a look at <a href="https://github.com/altimesh/hybridizer-basic-samples" target="_blank" rel="noopener">our SDK</a>&nbsp;on github.</p>

                    

                    
                </div>
            </article>
        
    </div>
</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>