<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Deep Learning with Darwin: Evolutionary Synthesis of Deep Neural Networks - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Deep Learning with Darwin: Evolutionary Synthesis of Deep Neural Networks - linksfor.dev(s)"/>
    <meta property="article:author" content="Authors:Mohammad Javad Shafiee, Akshaya Mishra, Alexander Wong"/>
    <meta property="og:description" content="Taking inspiration from biological evolution, we explore the idea of &quot;Can&#xA;deep neural networks evolve naturally over successive generations into highly&#xA;efficient deep neural networks?&quot; by introducing the notion of synthesizing new&#xA;highly efficient, yet powerful deep neural networks over successive generations&#xA;via an evolutionary process from ancestor deep neural networks. The&#xA;architectural traits of ancestor deep neural networks are encoded using&#xA;synaptic probability models, which can be viewed as the `DNA&#x27; of these&#xA;networks. New descendant networks with differing network architectures are&#xA;synthesized based on these synaptic probability models from the ancestor&#xA;networks and computational environmental factor models, in a random manner to&#xA;mimic heredity, natural selection, and random mutation. These offspring&#xA;networks are then trained into fully functional networks, like one would train&#xA;a newborn, and have more efficient, more diverse network architectures than&#xA;their ancestor networks, while achieving powerful modeling capabilities.&#xA;Experimental results for the task of visual saliency demonstrated that the&#xA;synthesized `evolved&#x27; offspring networks can achieve state-of-the-art&#xA;performance while having network architectures that are significantly more&#xA;efficient (with a staggering $\sim$48-fold decrease in synapses by the fourth&#xA;generation) compared to the original ancestor network."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://arxiv.org/abs/1606.04393"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Deep Learning with Darwin: Evolutionary Synthesis of Deep Neural Networks</title>
<div class="readable">
        <h1>Deep Learning with Darwin: Evolutionary Synthesis of Deep Neural Networks</h1>
            <div>by Authors:Mohammad Javad Shafiee, Akshaya Mishra, Alexander Wong</div>
            <div>Reading time: 2-3 minutes</div>
        <div>Posted here: 27 Feb 2019</div>
        <p><a href="https://arxiv.org/abs/1606.04393">https://arxiv.org/abs/1606.04393</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">

    
    
    <p>
  
  
  
    
  
  
    
    
  

  (Submitted on 14 Jun 2016 (<a href="https://arxiv.org/abs/1606.04393v1">v1</a>), last revised 6 Feb 2017 (this version, v3))</p>
    <blockquote><span>Abstract:</span>  Taking inspiration from biological evolution, we explore the idea of "Can
deep neural networks evolve naturally over successive generations into highly
efficient deep neural networks?" by introducing the notion of synthesizing new
highly efficient, yet powerful deep neural networks over successive generations
via an evolutionary process from ancestor deep neural networks. The
architectural traits of ancestor deep neural networks are encoded using
synaptic probability models, which can be viewed as the `DNA' of these
networks. New descendant networks with differing network architectures are
synthesized based on these synaptic probability models from the ancestor
networks and computational environmental factor models, in a random manner to
mimic heredity, natural selection, and random mutation. These offspring
networks are then trained into fully functional networks, like one would train
a newborn, and have more efficient, more diverse network architectures than
their ancestor networks, while achieving powerful modeling capabilities.
Experimental results for the task of visual saliency demonstrated that the
synthesized `evolved' offspring networks can achieve state-of-the-art
performance while having network architectures that are significantly more
efficient (with a staggering <span>\sim</span>48-fold decrease in synapses by the fourth
generation) compared to the original ancestor network.
</blockquote>
    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Alexander Wong [<a href="https://arxiv.org/show-email/4011cde0/1606.04393">view email</a>]
      <br>
  <strong><a href="https://arxiv.org/abs/1606.04393v1">[v1]</a></strong>
  Tue, 14 Jun 2016 14:36:55 UTC (2,608 KB)<br>
  <strong><a href="https://arxiv.org/abs/1606.04393v2">[v2]</a></strong>
  Tue, 12 Jul 2016 16:15:40 UTC (6,651 KB)<br><strong>[v3]</strong>
Mon, 6 Feb 2017 22:51:33 UTC (6,713 KB)<br></p></div></div></div>
    </div>
    <footer>
        <div>created by <a href="https://buildstarted.com">buildstarted</a> &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>