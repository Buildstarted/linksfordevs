<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Experimenting with Memory Management for Basil - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Experimenting with Memory Management for Basil - linksfor.dev(s)"/>
    <meta property="article:author" content="Elucent"/>
    <meta property="og:description" content="A first pass at how Basil should handle dynamically-sized objects."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://degaz.io/blog/632020/post.html"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Experimenting with Memory Management for Basil</title>
<div class="readable">
        <h1>Experimenting with Memory Management for Basil</h1>
            <div>by Elucent</div>
            <div>Reading time: 22-28 minutes</div>
        <div>Posted here: 04 Jun 2020</div>
        <p><a href="https://degaz.io/blog/632020/post.html">https://degaz.io/blog/632020/post.html</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
            
            <br>
            <h3>Hey folks!</h3>
            <p>
            First time writing one of these! I'd normally just put a development update
            on Twitter (<a href="https://twitter.com/elucentdev">@elucentdev</a>), but this topic felt 
            like it was worthy of some greater discussion. 
            </p><p>
            Ever since I began work on the implementation of my programming 
            language, Basil, the problem of dynamic memory has lurked in the background. It's
            crucial for the implementation of a number of language features, but there's no one answer
            that achieves everything I want. This post will discuss what my goals were for a memory system,
            some of the options I considered, details about the option I've currently chosen, and a few
            extremely-preliminary performance numbers and conclusions.
            </p><p>
            I'll be talking primarily about <i>memory management</i> today, so this post will assume
            a basic knowledge of memory structure (stack, heap, etc), virtual memory, and common
            functions to allocate and manipulate memory (malloc, free, memcpy, etc).
            </p><p>
            With that said, let's jump into it!
            </p><h3>Background</h3>
            <p>
            Unless you've been following my development updates (or, quite likely, even if you have),
            chances are you're not super familiar with the Basil programming language. I've been working
            on the current iteration for close to six months now, but it's still quite far from being
            usable. So, here's a quick primer with a few examples:
            </p><p>
            Basil is <i>stack-based</i>. Expressions are evaluated as terms are pushed onto a stack.
            </p><pre><code>
    
    <span>1</span> <span>2</span> +   
            </code></pre><p>
            Most stack-based languages support the above expression, where the <code>+</code> function
            applies to the elements beneath it when pushed. Basil <i>additionally</i> allows a function
            to apply to an element <i>pushed onto it</i>. In conjunction with partial function application,
            this means Basil supports lots of different argument orders.
            </p><pre><code>
    
    + <span>1</span> <span>2</span>
    <span>1</span> + <span>2</span>
    <span>2</span> <span>1</span> +
            </code></pre><p>
            To help structure Basil programs, there are also a number of operators in Basil built into
            the syntax to aid readability. These are processed into a stack-based equivalent using built-in
            functions by the compiler.
            </p><pre><code>
    
    even? x -&gt;
        x % <span>2</span> == <span>0</span>
    
    (<span>lambda</span> (odd? x) ((<span>2</span> x %) <span>1</span> ==))

    
    <span>if</span> <span>10</span> even?: <span>print</span> <span>"cool!"</span>
            </code></pre><p>
            I won't go into too much more of the syntax for now (you'll see some more code later). But you
            should also know that Basil is <i>strongly, statically typed</i>. Type inference allows for
            the elision of explicit types in many places.
            </p><p>
            Additionally, Basil exhibits <i>value semantics</i> for all of its types.
            </p><h3>Motivations</h3>
            <p>
            So, Basil has a very flexible syntax. But due to its static typing, I don't think that should
            have any real impact on its speed. There aren't too many sticking points in the language's
            core that would make Basil fundamentally less optimizable than other languages.
            </p><p>
            ...but there are a few. Basil natively supports strings, which can vary in size. Basil
            also supports function closures, which are <i>extremely</i> important to the language
            since taking multiple arguments off the stack requires currying. These two types are massively
            more problematic than any type whose size is known at compile time. Canonically, both would
            require heap allocation.
            </p><p>
            Among my goals for Basil is to keep the language <i>lightweight</i>, both the compiler and the
            executables it generates. At the same time, I also think Basil should be expressive. An
            idiomatic Basil program should be close to the minimum amount of code necessary to express
            the problem. A complex runtime compromises the first goal; things like alternate types of
            functions or strings to avoid allocation compromise the second.
            </p><p>
            So ultimately, here's what I was looking for, with regards to memory management:
            </p><ul>
                <li>Low executable size - a complex runtime for the language would hinder its prospects
                    on embedded systems and make the language hard to understand.</li>
                <li>Speed - using objects like strings and closures shouldn't incur a huge 
                    performance overhead.</li>
                <li>Avoid unnecessary overhead - for example, a string constant that's never modified
                    doesn't need to be allocated independently.</li>
            </ul>
            <br>
            <h3>Candidate: Automatic Reference Counting</h3>
            <p>
            Reference counting was the first thing I tried, because it's fairly straightforward. I wrote
            a small general-purpose allocator (about 6kB of x86_64 on my system) in C and 
            included it in a core Basil library. After generating Basil's low-level IR, the compiler
            would insert reference-count increments and decrements at various points in the program.
            </p><p>
            There were a few problems with this, though.
            </p><p>
            First, it's costly! Attaching a reference count to every GC'd object,
            adding branching operations to increment and decrement counts...it ended up being quite a lot.
            </p><p>
            Second, it's hard to support refcounted and non-refcounted values with the same type. I tried
            including a unique refcount value for values like string constants, to signal that they didn't
            need to be freed - which mostly worked, but only made the aforementioned increment and 
            decrement more costly.
            </p><p>
            Overall, this was enough for me to put a pin in reference counting, and explore alternatives.
            </p><h3>Candidate: Tracing Garbage Collection</h3>
            <p>
            Tracing GC is perhaps the canonical best answer to dynamic memory management within a programming
            language. So I don't mean to knock GC when I say I didn't really consider this that strongly.
            </p><p>
            There's one simple reason: complexity. Currently Basil binaries require fairly little beyond
            their actual assembled code. The small core library I mentioned earlier is the only add-on.
            I won't claim to be an expert on tracing GC, but I'd expect a decent GC implementation
            to take tens of kilobytes at least, if not substantially more.
            </p><p>
            But there's another aspect of GC that I'm not a huge fan of, namely that it makes it much more
            complicated to reason about your memory use. It's harder to predict when objects will be freed,
            how large individual objects are, without in-depth knowledge of the language's runtime.
            </p><p>
            I'd like the average programmer to be able to try Basil and understand what it's doing under
            the hood reasonably well. So I decided not to explore GC, even if there are plenty of
            potential advantages.
            </p><h3>A Different Approach</h3>
            <p>
            So far I've discussed two different strategies for creating and destroying objects on the
            heap. In general, I think a lot of the trade-offs involved with memory management have to do
            with the nature of the heap itself.
            </p><p>
            In particular, requesting more memory from the heap is <i>costly</i>, requiring the help of
            the operating system. Allocators do their best to avoid requesting this memory, so they
            employ carefully-managed data structures. Managing these data structures requires more code
            and more processing power, but the overhead is well worth it compared to requesting memory
            more frequently.
            </p><p>
            What if we were to avoid the heap entirely?
            </p><p>
            Well, what other memory do we have available? Our program's data and code sections are
            usually full of important information, so we can't tamper with them. But our program <i>does</i>
            get a fairly large stack.
            </p><p>
            While most programs interact with the stack in a pretty consistent manner, the bounds of the
            stack <i>are</i> just registers! As long as we don't go beyond the stack limit of our
            operating system, we can move them wherever we want.
            </p><p>
            Of course, the stack is generally used for function activation records. Basil has functions,
            so it would be nice to continue to use the stack for them. What we're looking for is a way to
            incorporate dynamically-sized objects into the language's ABI, and to do that, I came up with
            four things we generally need to be able to do:
            </p><h4>Passing Arguments</h4>
            <p>
            We want to pass an argument to a function. But, we don't know how much memory that object is
            going to take up. We want a way to represent that object that isn't going to change depending
            on how large it is.
            </p><p>
            A pointer would do the trick! We can pass a pointer to the object, no matter how large it is,
            and access any of its data by reading from the pointer at different offsets. This is pretty
            straightforward, but remember: Basil exhibits <i>value semantics</i> for all its types. I'll
            talk about how we preserve those later.
            </p><p>
            <img src="https://degaz.io/blog/632020/img1.png"></p><h4>Reading Values</h4>
            <p>
            If we pass objects by pointer, reading their values can be done by reading through the pointer.
            But, how do we know if a read will be safe? What if we read out of bounds of the object?
            </p><p>
            How about we also keep track of how large the object is? This is important for the remaining 
            two operations as well, but it's important for most read-only operations too - for example,
            printing a string. Every dynamically-sized object gets a "size tag" in front of its data,
            which must always be equal to the size of its data in bytes.
            </p><p>
            <img src="https://degaz.io/blog/632020/img2.png">
            <br>
            This admittedly introduces overhead, but I think it's reasonable. I think it's a simple enough
            layout that the average programmer could work with it, and an extra <code>size_t</code> of 
            memory per object isn't too bad considering these objects can be arbitrarily large.
            </p><h4>Writing to Values</h4>
            <p>
            We have a pointer to some object, and we want to modify the object. This is where value
            semantics need to be preserved: if we modify a value through the pointer naively, we might
            modify a different value as well. Additionally, it's been legal thus far to use this
            methodology even for constants! But we can't write to a constant string.
            </p><p>
            This is where we need the stack. We implement <i>copy-on-write</i>. Whenever we modify an
            object, we copy it first and rereference our pointer to the new copy. We put this copy
            on the stack.
            </p><p>
            The procedure is actually quite simple. We know how large the object is from its size tag, so
            we increase the size of the stack frame to accommodate a copy of that object. 
            </p><p>
            <img src="https://degaz.io/blog/632020/img3.png">
            <br>
            
            Then, a hand-optimized <code>memcpy</code> implementation the compiler emits is run to copy 
            over the data. 
            </p><p>
            <img src="https://degaz.io/blog/632020/img4.png">
            <br>
            
            Now we have a local copy of the object that we can modify independently of 
            its source! Finally, we perform our modification.
            </p><p>
            <img src="https://degaz.io/blog/632020/img5.png"></p><h4>Returning a Value</h4>
            <p>
            We have a pointer to some object. It may or may not have been copied to a local slot on the
            stack, and we don't know the size of the object ahead of time. This is where <code>alloca</code>
            would fail in C: how do we take our object and keep it alive as we leave the stack frame?
            </p><p>
            This procedure is fairly complex. Instead of returning, we take the return address and
            previous base pointer and save them to registers.
            </p><p>
            <img src="https://degaz.io/blog/632020/img6.png">
            <br>

            Next, we copy the object from its previous position to the edge of the previous 
            stack frame. Its memory is now adjacent to the previous function's.
            </p><p>
            <img src="https://degaz.io/blog/632020/img7.png">
            <br>

            Next, we set the stack pointer to the address of our copied object. This shrinks the current
            stack frame so that it only contains the copied object.
            </p><p>
            <img src="https://degaz.io/blog/632020/img8.png">
            <br>

            Finally, we use the registers we wrote to earlier to restore the return address and base
            pointer. We've returned to the previous stack frame, but expanded it to accommodate our new
            object!
            </p><p>
            <img src="https://degaz.io/blog/632020/img9.png">
            <br>
            This might seem complicated - and relatively, it is - but it can be done fairly quickly.
            Because it happens at the end of the function, we're free to use any caller-saved register.
            There are more than enough registers to implement this whole procedure without any extraneous
            memory use or function calls.
            </p>
            <p>
            So, ultimately, this is what I went with. By using the stack we're provided when our program
            starts, we avoid ever having to ask the operating system to map more memory for us. The
            concept of the call stack is common to most microarchitectures, so it should be fairly
            portable. And far and away the most expensive operation involved is the copy, something that
            would be necessary anyway to preserve value semantics when writing to an object.
            </p><h3>Improvements</h3>
            <p>
            Of course, there are still some trade-offs, and the naive implementation I described above
            has a number of issues. Let's talk about some of them!
            </p><h4>Avoiding Unnecessary Copies</h4>
            <p>
            As described, <i>whenever we write to a reference</i>, we make a copy. This is completely
            overkill. We can avoid loads of unnecessary copies with some simple analysis.
            </p><p>
            When do we <i>actually</i> run the risk of violating value semantics? Well, we don't want to
            modify something that has multiple references. This could be a constant or a different variable. 
            Specifically, we don't want to modify its <i>data</i>, because then another reference could read that data
            and see that it's been changed somewhere else.
            </p><pre><code>
    x = <span>"hello"</span>
    x[<span>0</span>] = <span>'y'</span>
    y = x

    
    x[<span>0</span>] = <span>'m'</span>
            </code></pre><p>
            Only when there's a potential conflict like this is a copy truly necessary.
            </p><h4>Reducing Memory Usage</h4>
            <p>
            Probably the biggest present issue with this stack-based allocation system is its high
            memory usage. While any form of garbage collection would be able to clean up values, the 
            stack is linear. Within a stack frame, temporary values pile up more and more, until either
            the function returns or the stack overflows.
            </p><p>
            The high memory usage isn't a huge problem in itself, as the stack never gets particularly
            fragmented, and the operating system doesn't have to map more heap memory for our program
            on the fly. But in recursive functions, larger stack frames can be serious limiters on the
            possible depth of the function.
            </p><p>
            Even if we ignore recursive functions, there's still some particularly egregious examples
            of stack overflows occurring right now where they really shouldn't:
            </p><pre><code>
    
    

    s = <span>"a"</span>
    i = <span>0</span>
    <span>while</span> i &lt; <span>1000000</span>:
        s = s + <span>"a"</span>
        i = i + <span>1</span>
            </code></pre><p>
            It's apparent that the previous value of <code>s</code> can be discarded at the end of each
            iteration. But there's no easy way for the stack to deallocate it while keeping the new value
            intact.
            </p><p>
            I don't actually have a great answer to this at the moment. It's mitigated somewhat by lower
            overall memory usage, so the previous improvement helps here. But there are still cases that
            easily overflow. I have a few ideas but none detailed enough to write here at the moment.
            </p><h4>Containers of Pointers</h4>
            <p>
            Basil supports arrays. What happens if we return an array of strings? As described, the
            array would be returned, copying over the pointers...which might point into the closed stack 
            frame. Not good.
            </p><p>
            There's a clear solution here, but it's a headache, Essentially, Basil needs to support deep
            copy functionality for every composite type that contains dynamically-sized objects. If I have
            the aforementioned array of strings, Basil needs to traverse through it and copy each string,
            then coalesce them together to be added to the previous stack frame. I'm not sure I can think
            of a shortcut, so this is not something I'm looking forward to implementing...
            </p><h3>Performance</h3>
            <p>
            On a more positive note, I <i>did</i> implement all of this behavior in the current Basil
            compiler. And while it's a bit too early to make serious assertions about it's behavior, I 
            couldn't help seeing how stack-based allocation performed compared to other languages.
            </p><p>
            So, I implemented the following microbenchmark in Basil:
            </p><pre><code>
    f() -&gt;
        a = <span>"hello world"</span>
        b = <span>"lovely weather we're having"</span>
        i = <span>0</span>
        <span>while</span> i &lt; <span>100000</span>:
            t = a
            a = b
            b = t
            i = i + <span>1</span>
        a
    
    j = <span>0</span>
    <span>while</span> j &lt; <span>1000</span>:
        f() <span>print</span>
        j = j + <span>1</span>
            </code></pre>
            <p><code>f()</code> swaps two strings 100,000 times, then returns the first. The program
            calls <code>f()</code> 1,000 times and prints its result. I turned off all ownership analysis
            in Basil, so every assignment copies a string to a temporary and points the variable at that
            temporary. I basically just wanted to compare copying and creating strings, so this program
            is admittedly a bit contrived.
            </p><p>
            Anyway, I implemented the same program in C++:
            </p><pre><code>
    <span>#<span>include</span> <span>&lt;string&gt;</span></span>
    <span>#<span>include</span> <span>&lt;cstdio&gt;</span></span>
    
    <span>using</span> <span>std</span>::<span>string</span>;
    
    <span><span>string</span> <span>f</span><span>()</span> </span>{
        <span>string</span> a = <span>"hello world"</span>;
        <span>string</span> b = <span>"lovely weather we're having"</span>;
        <span>int</span> i = <span>0</span>;
        <span>while</span> (i &lt; <span>100000</span>) {
            <span>string</span> t = a;
            a = b;
            b = t;
            i = i + <span>1</span>;
        }
        <span>return</span> a;
    }
    
    <span><span>int</span> <span>main</span><span>(<span>int</span> argc, <span>char</span>** argv)</span> </span>{
        <span>for</span> (<span>int</span> i = <span>0</span>; i &lt; <span>1000</span>; i ++) {
            <span>printf</span>(f().c_str());
        }
    }
            </code></pre><p>
            ...and in OCaml:
            </p><pre><code>
    <span>open String

    let <span>f</span> <span>()</span> </span>=
            let a = ref <span>"hello world"</span> in
            let b = ref <span>"lovely weather we're having"</span> in
            let i = ref <span>1</span> in
            <span>while</span> !i &lt; <span>100000</span> <span>do</span>
                    let t = String.copy !a in
                    a := String.copy !b;
                    b := String.copy t;
                    i := !i + <span>1</span>
            done;
            !<span>a
    
    <span>let</span> <span>()</span> </span>=
            let j = ref <span>1</span> in
            <span>while</span> !j &lt; <span>1000</span> <span>do</span>
                    print_string (f ());
                    j := !j + <span>1</span>
            </code></pre><p>
            Again, these are contrived programs, and I know this isn't the best way to implement this in
            either language. But I wanted to specifically test allocation and copying here. C++ uses RAII
            and a built-in allocator to manage string memory, while OCaml has a tracing garbage collector.
            So I figure they're reasonably good examples of two alternative memory management schemes.
            </p><p>
            I compiled the C++ program with -O3, and the OCaml program with <code>ocamlopt</code>. Then,
            I timed all three executables on my laptop:
            </p><p>
            <img src="https://degaz.io/blog/632020/results.png">
            <br>
            Pretty good!...if I do say so myself. As much as I'd love to brag about Basil being four times
            faster than -O3 C++, none of these languages are really being used correctly.
            But, this does demonstrate to me that there is a large potential performance boost in using the
            stack over an allocator. 
            </p><p>
            Just for kicks, I popped both the Basil and C++ binaries in perf.
            Here's the C++ results:
            </p><p>
            <img src="https://degaz.io/blog/632020/c++perf.png">
            <br>
            At a glance, it looks like about 14% of the execution time was spent copying memory. Whereas 
            malloc and free appear to have taken up about 35%! In comparison, Basil's results were just
            about what you'd expect:
            </p><p>
            <img src="https://degaz.io/blog/632020/perf.png">
            <br>
            70% of runtime spent copying memory, 30% in the inner function (which includes actually
            allocating the stack memory), and nothing in the main loop. Copying the strings dominates by
            far. Interestingly, the absolute time spent copying strings in both programs was about the
            same - roughly a half second. Which also isn't surprising - memcpy is pretty simple to
            implement effectively - but it's nice to see it reflected in some numbers.
            </p><h3>Conclusion</h3>
            <p>
            Jeez. I wrote a lot more than I initially intended. If you made it to the end, thanks so much!
            I hope it was at least kind of interesting.
            </p><p>
            So, what does this all mean? What's the point of me writing this post? Well, I'm still in the
            very early stages of implementing this whole procedure, and there's still a bunch of holes.
            But I'm not familiar with any other language using this method for memory management.
            And despite some limitations, there are some clear cases where it results in a very large
            speedup compared to a traditional allocator.
            </p><p>
            I think the main point I'd like to demonstrate here is that first-class dynamically-sized
            objects can be <i>entirely managed</i> using stack memory. Whether or not it's better than
            using the heap for X or Y is a difficult question to answer. But I think there's potential
            in this technique. It could be used alongside a traditional allocator, perhaps as a
            "fast path" for small, single-allocation objects. Or it could be used in lieu of an allocator
            on an embedded system, potentially saving kilobytes of program memory.
            </p><p>
            For Basil, I'm just glad I have a system that works at the moment. Being able to easily handle
            dynamic objects is the first step towards implementing things like closures. So I'm going to
            be sticking with just stack-based allocation at the moment as I work on implementing those
            essential features. The language isn't at the stage of being "polished" or "practical" yet, so
            for now I'm just trying to get things working.
            </p><p>
            If you enjoyed this post, awesome! Let me know if you'd like to see more in the future, I could
            go in-depth on a number of PL-related topics that have come up while working on Basil.
            </p><p>
            If you're interested in the project, feel free to gawk at the horrible coding practices on the
            <a href="https://github.com/elucent/basil">Basil GitHub page</a>. Or 
            <a href="https://twitter.com/elucentdev">follow me on Twitter</a>! I post a lot of smaller
            development updates there.
            </p><p>
            Have a nice day!
        </p></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>