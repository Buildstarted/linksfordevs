<!DOCTYPE html>
<html lang="en">
<head>
    <title>
(Almost-)Zero-Additional-Latency UDP-over-TCP - IT Hare on Soft.ware -
linksfor.dev(s)
    </title>
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta charset="utf-8">
    <meta name="Description" content="A curated source of links that devs might find interesting. Updated around the clock." />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        
<div class="readable">
    <div id="readOverlay" class="style-ebook"><div id="readInner" class="margin-medium size-medium"><h1>(Almost-)Zero-Additional-Latency UDP-over-TCP - IT Hare on Soft.ware</h1><div><div class="entry-content" itemprop="text"><p>[rabbit_ddmog vol=”4″ chap=”Chapter 13(j) from “beta” Volume IV”]</p><p>It is rather well-known that TCP latency kinda suxx – and we have discussed in details why it is the case, above (in particular, head-of-line blocking is a Big Enemy of the latency).</p><p>However, it is really important to understand what <em>exactly </em>is meant under “TCP latency is bad”. Actually, on closer examination we will see that at least two different things can be understood under this umbrella statement. The first one is that</p><div class="rabbit-centerpiece-outer"><div class="rabbit-centerpiece-inner">We cannot use convenient TCP-like reliable-streaming API without incurring a latency penalty.</div></div><p>Let’s note, however, that this effect can be at least partially mitigated&nbsp;by using Reliable UDP (RUDP). For the time being, I won’t concentrate on RUDP (and on whatever-we-could-get-from-it) – and will just say that if we use reliable-and-ordered RUDP, it will still suffer from Head-of-Line blocking (that’s by definition) – and as a result, any gains from using reliable-and-ordered RUDP will be rather mild compared to TCP<a href="#rabbitfootnote-1"><sup>1</sup></a> (and if it is some different flavor of RUDP – we’re not really using TCP-like reliable-streaming APIs anymore).</p><p>The second potential – and quite wrong at that – statement says that</p><div class="rabbit-centerpiece-outer"><div class="rabbit-centerpiece-inner">&lt;wrong&gt;Whenever we don’t have UDP (for whatever reason) and are forced to use TCP – we’ll inevitably get a latency penalty.&lt;/wrong&gt;</div></div><p>While the statement above can look obvious and what-I-am-about-to-say&nbsp;may sound as an obvious heresy – I am about to demonstrate</p><div class="rabbit-centerpiece-outer"><div class="rabbit-centerpiece-inner">How to carry UDP-style packets over TCP without incurring (much of) additional latencies.</div></div><hr class="rabbit-footnote-separator"><h3>Why would we want it?</h3><p>Why we would want such a thing – it is simple. Let’s consider the following scenario:</p><p>Whether it is worth the trouble – depends on your needs, but IMO it is still nice to know that whenever you need it – such an option of tunneling UDP-like requests over TCP (and without incurring latency penalty) does exist.</p><h3>The Algorithm</h3><p>Actually, the idea is dead simple:</p><ul><li>We have N TCP connections between Client and Server
<ul><li>For each of these TCP connections – there is a “packet en route” flag. This flag is set to <em>false</em> after TCP connection is established.</li></ul></li><li>On the sending side, whenever an UDP packet comes in – we’re sending it over one of the TCP connections which does <em>not </em>have the <em>packet-en-route </em>flag<em>.&nbsp;</em>Also, we set the&nbsp;<em>packet-en-route </em>flag for the TCP connection where we sent the packet.
<ul><li>Of course, we still need to wrap the packet to send it over TCP (to denote the packet size and/or boundary)</li></ul></li><li>On the receiving side – whenever we get an incoming UDP-over-TCP packet – we send an app-level acknowledgement (as small as 1 byte) back to the sender, over the same TCP connection where we got the incoming message.</li><li>On the sending side, when we get this app-level acknowledgement – we reset the <em>packet-en-route&nbsp;</em>flag</li></ul><p>The description above is sufficient to understand how the algorithm works – though of course, to become practical, it will need other stuff (such as detecting connection being “hung” – for example, using app-level keep-alives or just having to wait for the app-level ack too long, creating new connections instead of “hung” ones, using the same N TCP connections for bidirectional connection, auto-detecting number N, and so on). Still, all the other stuff <em>seems </em>to be perfectly viable.</p><p>Now, let’s see <em>why </em>this thing will work (almost) about incurring additional latencies for TCP. The answer is simple –</p><div class="rabbit-centerpiece-outer"><div class="rabbit-centerpiece-inner">That’s because we always send a packet only to those connections of which we’re sure that there are no outstanding packets.</div></div><p>It means that whenever we’re sending the packet, several properties are guaranteed to stand:</p><p>Bingo! We’ve <span>ate our cake</span> got our UDP-over-TCP – and <span>have it</span> got no additional latencies too.</p><hr class="rabbit-footnote-separator"><h3>Calculating N</h3><p>However, before we can claim it as a win, there is still a very important consideration here. In particular: <em>this algorithm is realistically usable only if the number N is small enough</em> (in other words, if we’d need 100 TCP connections per user – it will probably&nbsp;start causing problems).</p><p>Let’s make some back-of-the-envelope calculations. For example, for a game with 20 “network ticks” per second (which is quite typical), and for a Client with 100ms RTT (it is more than enough for intra-continent stuff) – then under ideal circumstances we’ll need only 0.1/(1/20)=2 TCP connections for the algorithm above to work. In fact – we’ll certainly need to add at least other 2 connections to account for packet loss (which will result in some connections having <em>packet-en-route</em> flag longer than usual). Still, 4 or 5 TCP connections <em>seem </em>as a reasonably good starting point for such 20 network-ticks/second, and 100 ms RTT.</p><p>Other scenarios and likely-to-be-reasonable values of N:</p><ul><li>20 network ticks/second, 200ms RTT (this is enough to have global RTT). Reasonable starting N for this case is probably around 6-7 (4 in ideal case, 2-3 reserve).</li><li>60 network ticks/second, 100ms RTT. Reasonable starting N: 9-10 (6 for ideal case, 3-4 reserve).</li></ul><p><span class="rabbit-pullquote-right-outer rabbit-pullquote-top-p"><img class="rabbit-pullquote-img rabbit-pullquote-left-right " width="170" height="170" src="/wp-content/uploads/BB_emotion_0008b.png" alt="Hare pointing out:"><span class="rabbit-pullquote-right-inner"><span class="rabbit-pullquote-quote">“</span>As we can see, even in more stressful scenarios N is expected to be relatively small</span></span>As we can see, even in more stressful scenarios N is expected to be relatively small. Now, let’s see where having multiple connections will hurt us:</p><ul><li>more memory used on the Server-Side per player. This one can be partially mitigated by reducing the size of the TCP buffers. With the schema above – we’re not likely to need more than 4K / TCP connection, so to run 1’000 players/2S-2Userver (which is a kind of “industry standard” number for 2017), we’d need around 4K/TCP*10TCP/player*10000players/server = 40MBytes of RAM, which is pretty much nothing by today’s standards. Even if speaking about a “really communications-heavy” server with 10K players – it is still mere 400MBytes.</li><li>More TCP ports used.&nbsp;However – on the Server-Side we won’t see these additional ports (they will be still terminated by the same Server-Side TCP port), so I don’t expect it to be a real problem.</li></ul><p>As we can see, analysis and the numbers above <em>seem&nbsp;</em>to indicate that UDP-over-TCP using the schema above,&nbsp;is<em>&nbsp;</em>usable (no warranties of any kind, batteries not included).&nbsp;Moreover, as discussed above – we do NOT intend to use this thing for <em>all </em>the players – but just for those platforms (and/or firewalled users) which don’t have UDP at the moment. As a result – the overall impact of using additional resources for multiple connections will be most likely scaled down even further.</p><h3>Disclaimer and Conclusion</h3><div class="rabbit-epigraph"><p>Beware of bugs in the above code; I have only proved it correct, not tried it.</p></div><p>Now, a necessary disclaimer:</p><div class="rabbit-centerpiece-outer"><div class="rabbit-centerpiece-inner">Beware of problems with the algorithm above. I have only kinda-demonstrated its correctness, not tried it.</div></div><p>However, <em>assuming </em>that the analysis above stands – it opens the door to the following approach for writing games:</p><ul><li>Write all your time-critical protocols using UDP; it includes both different flavours of RUDP and state sync algorithm</li><li>However, for those players who cannot use UDP for whatever reason – your code can use UDP-over-TCP as an (almost-)no-added-latencies backup.
<ul><li>An additional disclaimer: at least in case of firewalls, <em>some </em>of them will do weird things with your TCP stream (in particular, re-assembling it and forwarding the stream further only after re-assembling) – and the algorithm above will <em>not </em>be able to deal with them. Still, from my experience I <em>feel </em>that such firewalls are not <em>that </em>frequent (though as always, YMMV, and batteries are not included).</li></ul></li></ul><p>Phew, I think it is enough for today. And BTW, if you see any mistakes in the reasoning above (or have tried it in reality and got either positive or negative results) – please LMK.</p><p><span class="rabbit-pullquote-left-outer rabbit-pullquote-top-p"><img class="rabbit-pullquote-img rabbit-pullquote-left-left " width="170" height="170" src="/wp-content/uploads/BB_emotionM_0001b.png" alt="Tired hare:"><span class="rabbit-pullquote-left-inner"></span></span>This concludes beta Chapter 13(j) from the upcoming book “Development and Deployment of Multiplayer Online Games (from social games to MMOFPS, with social games in between)”.</p><p>Stay tuned for beta Chapter 22, where&nbsp;we’ll start discussing all the boring stuff about debugging, tracing, logging – and not-so-boring post-factum beta/production debugging]]</p><h3>Acknowledgement</h3><p>Cartoons by Sergey Gordeev<sup><a href="/real-people-behind-the-hare#sergey-gordeev"><img width="16" height="16" src="/wp-content/uploads/irl-link.png" alt="IRL"></a></sup> from <a href="http://gagltd.eu/">Gordeev Animation Graphics</a>, Prague.</p></div></div></div></div>
</div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script>
        (function () {
            var COLLECT_URL = "https://dna.buildstarted.com/t";
            var SITE_ID = "linksfor.devs";
            var GLOBAL_VAR_NAME = "__DNA__";

            window[GLOBAL_VAR_NAME] = {};

            window[GLOBAL_VAR_NAME].sendPageView = function () {
                var path = location.pathname;
                var referrer = document.referrer;

                var url = COLLECT_URL + "?siteid=" + SITE_ID + "&p=" + encodeURIComponent(path) + "&r=" + encodeURIComponent(referrer);

                try { fetch(url, { method: "GET" }); } catch (e) { }
            };

            window[GLOBAL_VAR_NAME].sendPageView();
        })();
    </script>
</body>
</html>