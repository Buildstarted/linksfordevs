<!DOCTYPE html>
<html lang="en">
<head>
    <title>
The Deep Learning Revolution and Its Implications for Computer Architecture and Chip Design - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="The Deep Learning Revolution and Its Implications for Computer Architecture and Chip Design - linksfor.dev(s)"/>
    <meta property="article:author" content="Authors:Jeffrey Dean"/>
    <meta property="og:description" content="The past decade has seen a remarkable series of advances in machine learning,&#xA;and in particular deep learning approaches based on artificial neural networks,&#xA;to improve our abilities to build more accurate systems across a broad range of&#xA;areas, including computer vision, speech recognition, language translation, and&#xA;natural language understanding tasks. This paper is a companion paper to a&#xA;keynote talk at the 2020 International Solid-State Circuits Conference (ISSCC)&#xA;discussing some of the advances in machine learning, and their implications on&#xA;the kinds of computational devices we need to build, especially in the&#xA;post-Moore&#x27;s Law-era. It also discusses some of the ways that machine learning&#xA;may also be able to help with some aspects of the circuit design process.&#xA;Finally, it provides a sketch of at least one interesting direction towards&#xA;much larger-scale multi-task models that are sparsely activated and employ much&#xA;more dynamic, example- and task-based routing than the machine learning models&#xA;of today."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://arxiv.org/abs/1911.05289v1"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - The Deep Learning Revolution and Its Implications for Computer Architecture and Chip Design</title>
<div class="readable">
        <h1>The Deep Learning Revolution and Its Implications for Computer Architecture and Chip Design</h1>
            <div>by Authors:Jeffrey Dean</div>
            <div>Reading time: 2 minutes</div>
        <div>Posted here: 22 Nov 2019</div>
        <p><a href="https://arxiv.org/abs/1911.05289v1">https://arxiv.org/abs/1911.05289v1</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">

    
    
    <p>
  
  
  
    
  
  
    
    
  

  (Submitted on 13 Nov 2019)</p>
    <blockquote><span>Abstract:</span>  The past decade has seen a remarkable series of advances in machine learning,
and in particular deep learning approaches based on artificial neural networks,
to improve our abilities to build more accurate systems across a broad range of
areas, including computer vision, speech recognition, language translation, and
natural language understanding tasks. This paper is a companion paper to a
keynote talk at the 2020 International Solid-State Circuits Conference (ISSCC)
discussing some of the advances in machine learning, and their implications on
the kinds of computational devices we need to build, especially in the
post-Moore's Law-era. It also discusses some of the ways that machine learning
may also be able to help with some aspects of the circuit design process.
Finally, it provides a sketch of at least one interesting direction towards
much larger-scale multi-task models that are sparsely activated and employ much
more dynamic, example- and task-based routing than the machine learning models
of today.
</blockquote>
    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Jeffrey Dean [<a href="https://arxiv.org/show-email/8afb75fe/1911.05289">view email</a>]
      <br><strong>[v1]</strong>
Wed, 13 Nov 2019 04:41:31 UTC (1,049 KB)<br></p></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs" /></noscript>
</body>
</html>