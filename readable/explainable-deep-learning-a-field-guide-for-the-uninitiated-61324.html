<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Explainable Deep Learning: A Field Guide for the Uninitiated - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Explainable Deep Learning: A Field Guide for the Uninitiated - linksfor.dev(s)"/>
    <meta property="article:author" content="[Submitted on 30 Apr 2020]"/>
    <meta property="og:description" content="Deep neural network (DNN) is an indispensable machine learning tool for&#xA;achieving human-level performance on many learning tasks. Yet, due to its&#xA;black-box nature, it is inherently difficult to understand which aspects of the&#xA;input data drive the decisions of the network. There are various real-world&#xA;scenarios in which humans need to make actionable decisions based on the output&#xA;DNNs. Such decision support systems can be found in critical domains, such as&#xA;legislation, law enforcement, etc. It is important that the humans making&#xA;high-level decisions can be sure that the DNN decisions are driven by&#xA;combinations of data features that are appropriate in the context of the&#xA;deployment of the decision support system and that the decisions made are&#xA;legally or ethically defensible. Due to the incredible pace at which DNN&#xA;technology is being developed, the development of new methods and studies on&#xA;explaining the decision-making process of DNNs has blossomed into an active&#xA;research field. A practitioner beginning to study explainable deep learning may&#xA;be intimidated by the plethora of orthogonal directions the field is taking.&#xA;This complexity is further exacerbated by the general confusion that exists in&#xA;defining what it means to be able to explain the actions of a deep learning&#xA;system and to evaluate a system&#x27;s &quot;ability to explain&quot;. To alleviate this&#xA;problem, this article offers a &quot;field guide&quot; to deep learning explainability&#xA;for those uninitiated in the field. The field guide: i) Discusses the traits of&#xA;a deep learning system that researchers enhance in explainability research, ii)&#xA;places explainability in the context of other related deep learning research&#xA;areas, and iii) introduces three simple dimensions defining the space of&#xA;foundational methods that contribute to explainable deep learning. The guide is&#xA;designed as an easy-to-digest starting point for those just embarking in the&#xA;field."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://arxiv.org/abs/2004.14545"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Explainable Deep Learning: A Field Guide for the Uninitiated</title>
<div class="readable">
        <h1>Explainable Deep Learning: A Field Guide for the Uninitiated</h1>
            <div>by [Submitted on 30 Apr 2020]</div>
            <div>Reading time: 2-3 minutes</div>
        <div>Posted here: 04 May 2020</div>
        <p><a href="https://arxiv.org/abs/2004.14545">https://arxiv.org/abs/2004.14545</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    
      
    
  
    <p><a href="https://arxiv.org/pdf/2004.14545">Download PDF</a></p><blockquote>
      <span>Abstract:</span>  Deep neural network (DNN) is an indispensable machine learning tool for
achieving human-level performance on many learning tasks. Yet, due to its
black-box nature, it is inherently difficult to understand which aspects of the
input data drive the decisions of the network. There are various real-world
scenarios in which humans need to make actionable decisions based on the output
DNNs. Such decision support systems can be found in critical domains, such as
legislation, law enforcement, etc. It is important that the humans making
high-level decisions can be sure that the DNN decisions are driven by
combinations of data features that are appropriate in the context of the
deployment of the decision support system and that the decisions made are
legally or ethically defensible. Due to the incredible pace at which DNN
technology is being developed, the development of new methods and studies on
explaining the decision-making process of DNNs has blossomed into an active
research field. A practitioner beginning to study explainable deep learning may
be intimidated by the plethora of orthogonal directions the field is taking.
This complexity is further exacerbated by the general confusion that exists in
defining what it means to be able to explain the actions of a deep learning
system and to evaluate a system's "ability to explain". To alleviate this
problem, this article offers a "field guide" to deep learning explainability
for those uninitiated in the field. The field guide: i) Discusses the traits of
a deep learning system that researchers enhance in explainability research, ii)
places explainability in the context of other related deep learning research
areas, and iii) introduces three simple dimensions defining the space of
foundational methods that contribute to explainable deep learning. The guide is
designed as an easy-to-digest starting point for those just embarking in the
field.

    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Ning Xie [<a href="https://arxiv.org/show-email/24b064ce/2004.14545">view email</a>]
      <br><strong>[v1]</strong>
Thu, 30 Apr 2020 02:09:02 UTC (486 KB)<br></p></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs" /></noscript>
</body>
</html>