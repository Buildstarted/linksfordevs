<!DOCTYPE html>
<html lang="en">
<head>
    <title>
MessagePack for C# v2, new era of .NET Core(Unity) I/O Pipelines -
linksfor.dev(s)
    </title>
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta charset="utf-8">
    <meta name="Description" content="A curated source of links that devs might find interesting. Updated around the clock." />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        
<div class="readable">
    <div id="readOverlay" class="style-ebook"><div id="readInner" class="margin-medium size-medium"><h1>MessagePack for C# v2, new era of .NET Core(Unity) I/O Pipelines</h1><div><div class="ac ae af ag ah do aj ak"><p id="f583" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">MessagePack for C# Version 2 was released in 2019–12–16. The main implementation was done by <a href="https://github.com/AArnott" class="bi cv gk gl gm gn" target="_blank" rel="noopener nofollow">Andrew Arnott</a> who is a software engineer at Microsoft, Visual Studio Team. I checked the API design and performance and took care of the Unity compatibility. This collaboration took almost a year, and I think we did a great job.</p><p id="82a1" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj"><a href="https://github.com/neuecc/MessagePack-CSharp" class="bi cv gk gl gm gn" target="_blank" rel="noopener nofollow">https://github.com/neuecc/MessagePack-CSharp</a></p><p id="7958" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">Version 1 that implemented by me greatly boosted the old serializer’s performance standards and set a new standard. Version 2 made it work with new APIs (<em class="go">Span</em>, <em class="go">System.Buffers</em>) and also the overall I/O pipeline was optimized upon deciding how the serializer should be. For the C# application architecture henceforth, it will be an important thing.</p><p id="7474" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">There are many breaking changes, but the guide for migrating from Version 1 to Version 2 is in <a href="https://github.com/neuecc/MessagePack-CSharp/blob/master/doc/migration.md" class="bi cv gk gl gm gn" target="_blank" rel="noopener nofollow">migration.md</a>.</p><p id="0561" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">MessagePack for C# is used in ASP.NET Core(<a href="https://github.com/aspnet/AspNetCore/tree/master/src/submodules" class="bi cv gk gl gm gn" target="_blank" rel="noopener nofollow">existing in the submodule in the repository</a>!) and Visual Studio 2019.</p><h1 id="62d9" class="gp gq ar bz by gr ds gs du gt gu gv gw gx gy gz ha">Zero copy with pipeline</h1><p id="5941" class="fw fx ar bz fy b fz hb gb hc gd hd gf he gh hf gj dj">When thinking of the internal structure of MessagePack for C#, there are the following two method signatures to be looked at:</p><p id="1359" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj"><strong class="fy hg">void Serialize&lt;T&gt;(IBufferWriter&lt;byte&gt; writer, T value)<br>T Deserialize&lt;T&gt;(in ReadOnlySequence&lt;byte&gt; byteSequence)</strong></p><p id="49a8" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">The changes made after Version 1 are that for the serialization, <em class="go">IBufferWriter&lt;byte&gt;</em> is to be used for the I/O, and for deserialization, <em class="go">ReadOnlySequence&lt;byte&gt;</em> is to be used for the I/O. Both are .NET Standard 2.1 generation interfaces defined in <em class="go">System.Buffers</em>. Whereas in Version 1, both were <em class="go">byte[]</em> based.</p><figure class="hi hj hk hl hm hn da db paragraph-image"><p id="cc4f" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">The I/O pipeline handles the process from the input to the application processing and from the application processing to the output. At the end, when it goes to the native layer, most of it becomes <em class="go">byte[]</em>. For C#, the most primitive type (<em class="go">SocketAsyncEventArgs</em>, <em class="go">ConslePal+Stream</em>, <em class="go">FileStream</em>, etc.) bridging the native layer is handled by the framework layer, and the serializer result is output. It is important to look at this process flow.</p><p id="7e07" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">The serializer is always at the core(<em class="go">Object -&gt; byte[]</em> conversion, <em class="go">byte[] -&gt; Object</em> conversion). The image above is a normal case for example the <em class="go">RedisValue</em> (<em class="go">StackExchange.Redis</em>) takes <em class="go">byte[]</em> and <em class="go">ByteArrayContent</em> (<em class="go">HttpClient</em>) takes byte[]. In many cases, they take raw <em class="go">byte[]</em>. In such cases, the serializer will return a new <em class="go">byte[]</em> result, which will be processed by the framework and again copied to the I/O source.</p><p id="8457" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">The overhead occurring here is the allocation as well as the copying of <em class="go">byte[]</em>.</p><figure class="hi hj hk hl hm hn da db paragraph-image"><p id="dba8" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">Therefore, as a way to avoid the allocation of <em class="go">byte[]</em>, the serializer uses an external buffer pool (with .NET Core 3.0, the <em class="go">ArrayPool&lt;byte&gt;</em> defined by <em class="go">System.Buffers</em> is used a lot even in the class library) as the operation area, and it writes to the Stream provided by the framework.</p><p id="ee64" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">By doing so, the required cost will only be for copying. Note that although it is theoretically possible to write directly to the Stream so the buffer will not be used, the large Write overhead will degrade the performance. Also, the Stream may have a buffer internally in either case. The design idea behind Version 1 was based on <em class="go">byte[]</em> to avoid this large overhead and deem a single serialization result as the buffer area, so that without any overhead, the serialization would be executed and the writing to Stream could be done all at once. That was our idea. The respective architecture policy was correct, and we eliminated the performance of various serializers existing at the time.</p><figure class="hi hj hk hl hm hn da db paragraph-image"><p id="703e" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">When <em class="go">IBufferWriter&lt;byte&gt;</em> is used, the buffer required for the operation can be directly requested to the original source. This enables the buffer to be completely managed by the original source. And so this eliminates the copy cost from the operating buffer in the serializer. For example, <a href="https://docs.microsoft.com/en-us/dotnet/api/system.net.sockets.socketasynceventargs" class="bi cv gk gl gm gn" target="_blank" rel="noopener nofollow">SocketAsyncEventArgs</a> used for socket communications is normally used, but it is possible to directly write to its own (<em class="go">byte[]</em> Buffer).</p><p id="2fd9" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">For the Stream, <a href="https://docs.microsoft.com/en-us/dotnet/api/system.io.pipelines.pipewriter?view=dotnet-plat-ext-3.1" class="bi cv gk gl gm gn" target="_blank" rel="noopener nofollow">PipeWriter</a> provided by <em class="go">System.IO.Pipelines</em> implements <em class="go">IBufferWriter&lt;byte&gt;</em> and optimally manages the buffer as a substitute.</p><p id="053b" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">From ASP.NET Core 3.0, in addition to the traditional (<em class="go">Stream HttpResponse.Body</em>), <a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/middleware/request-response?view=aspnetcore-3.1" class="bi cv gk gl gm gn" target="_blank" rel="noopener nofollow">(<em class="go">PipeWriter HttpResponse.BodyWriter</em>)</a> is also now provided. Officially provided by MessagePack for C# Version 2, <strong class="fy hg">MessagePack.AspNetCoreMvcFormatter</strong> provides a serialized implementation for BodyWriter in the case of .NETCoreApp 3.0.</p><p id="2023" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">The current .NET framework mostly either requests <em class="go">Stream </em>or <em class="go">byte[]</em>, or <em class="go">ArraySegment(ReadOnlyMemory)</em>. However, when <em class="go">IBufferWriter</em> is supported at the framework level, the true value of MessagePack for C# Version 2 will likely be apparent. Of course, even with API(<em class="go">byte[] Serialize&lt;T&gt;(T value)</em>) that returns <em class="go">byte[]</em>, optimum buffer management suppresses the allocation and copy cost.</p><h1 id="8687" class="gp gq ar bz by gr ds gs du gt gu gv gw gx gy gz ha">Theory and performance</h1><p id="70be" class="fw fx ar bz fy b fz hb gb hc gd hd gf he gh hf gj dj">It is often misunderstood that just using Span will increase the performance, using async/await will increase the performance.</p><p id="0cf9" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">The current performance with .NET Core is based on the idea of “<strong class="fy hg">The buffer should be managed well, the execution should be in synchronous, and await should be minimized</strong>.” The double while loop shown in <a href="https://devblogs.microsoft.com/dotnet/an-introduction-to-system-threading-channels/" class="bi cv gk gl gm gn" target="_blank" rel="noopener nofollow">Introduction to System.Threading.Channels</a> is an example of this.</p><pre class="hi hj hk hl hm ii ij ik"><span id="d68a" class="il gq ar bz im b eu in io r ip">while (await channelReader.WaitToReadAsync())<br>while (channelReader.TryRead(out T item))<br>Use(item);</span></pre><p id="e620" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">Even with the serializer, since many object operations and binary processing are executed, it is necessary for the processing to be completed in sync as much as possible.</p><p id="4fdd" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">In Version 1, we defined one unit of buffer as the serialization of one type and the processes were executed according to this rule. This implementation works “correctly” from the aspect of performance. The fact is, Version 1 had less processing overhead than Version 2. Therefore, if you look at the performance of just one operation, it may be faster than with Version 2.</p><p id="153e" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">In particular, if <em class="go">IBufferWriter&lt;byte&gt;</em> or <em class="go">ReadOnlySequence&lt;byte&gt;</em> is simply implemented, it will not be faster. Logically, even if the copy is reduced, it may become slower. If the request (<em class="go">GetSpan/Memory + Advance</em>) for the <em class="go">IBufferWriter</em> writing area or the <em class="go">ReadOnlySequence&lt;byte&gt;</em>’s Slice is simply used, it can slow down the performance.</p><p id="e6af" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">To avoid this slowdown in performance, it will be necessary to carefully create an intermediate layer that suitably manages the buffer obtained with <em class="go">IBufferWriter&lt;byte&gt;</em> and to create an intermediate layer that suitably manages the Segment buffer obtained with <em class="go">ReadOnlySequence&lt;byte&gt;</em>.</p><p id="dbed" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">Version 2 implements these adequately and successfully minimize degraded performance by using Version 1’s standard as the benchmark to detect the performance being degraded by the presence of the intermediate layers, where Version 1 is fine-tuned to the limit in terms of writing to a simple buffer.</p><p id="f589" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">If you compare Version 1 and Version 2, Version 2 comes out on top as the actual application. By integrating the pipeline mentioned above and implementing various measures for smarter buffer management, Version 2 is better when we think about it overall.</p><h1 id="35de" class="gp gq ar bz by gr ds gs du gt gu gv gw gx gy gz ha">LZ4 compression for the array</h1><p id="b6b0" class="fw fx ar bz fy b fz hb gb hc gd hd gf he gh hf gj dj">One factor in Version 2’s performance improvement over Version 1 was the new allocation where Version 1 did not use a pool for 64K or higher serialization. For the internal buffer, Version 2 uses the 32K chunk’s linked list obtained from the <em class="go">ArrayPool</em> (in the case where <em class="go">IBufferWriter</em> is not given externally and Version 2’s internal buffer pool is used).</p><figure class="hi hj hk hl hm hn da db paragraph-image"><p id="787b" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">When creating <em class="go">byte[]</em>, it is connected in the end in one clump. When writing to Stream, there is WriteAsync for every 32K. If this floods the buffer, instead of securing a buffer twice the size as with <em class="go">List&lt;T&gt;</em> and writing to it, the size of the buffer used will always be less than 85K, so we can also avoid consuming the Large Object Heap (LOH).</p><p id="ac4e" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">As for <em class="go">MessagePackCompression.Lz4BlockArray</em>, which is a new compression mode newly provided by Version 2, this internal format is used to apply LZ4 compression to every 32K.</p><figure class="hi hj hk hl hm hn da db paragraph-image"><p id="e481" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">Since it is compressed, it avoids having in advance a large array that has become a clump of everything. During serialization also, memory efficiency is effective. However, for deserialization, since decompression can be done in blocks, it is advantageous because even the large data need not have a huge array.</p><p id="50e6" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">The compression mode used in Version 1 is still available as <em class="go">MessagePackCompression.Lz4Block</em>. However, with Version 2, using <em class="go">MessagePackCompression.Lz4BlockArray</em> is recommended. As for the binary data already compressed, Lz4Block can be deserialized even with Lz4BlockArray (same for vice versa).</p><h1 id="fd42" class="gp gq ar bz by gr ds gs du gt gu gv gw gx gy gz ha">AOT (Unity IL2CPP, Xamarin, UWP, CoreRT)</h1><p id="89fd" class="fw fx ar bz fy b fz hb gb hc gd hd gf he gh hf gj dj">Since MessagePack for C# is geared for performance, it has no fallback to an easy reflection in the AOT environment and we have no desire to implement one. Instead, by generating the code in advance, the fastest serialization is achieved whenever possible in the AOT environment. From Version 2, .NET Core Tools, MSBuild Task, and Unity Editor Window have been provided for easier handling. It is now easier to use than ever before.</p><p id="ce30" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">Since I founded <a href="https://cysharp.co.jp/en/" class="bi cv gk gl gm gn" target="_blank" rel="noopener nofollow">Cysharp</a>, a company that builds games with Unity + .NET Core (a subsidiary of <a href="https://www.cygames.co.jp/en/" class="bi cv gk gl gm gn" target="_blank" rel="noopener nofollow">Cygames</a>, I definitely had to enable compatibility with Unity.</p><h1 id="c104" class="gp gq ar bz by gr ds gs du gt gu gv gw gx gy gz ha">Conclusion</h1><p id="90ed" class="fw fx ar bz fy b fz hb gb hc gd hd gf he gh hf gj dj">Much of the wonderful work was done by Andrew Arnott. I thank him again.</p><p id="eff0" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">We will make MessagePack for C# Version 2 the heart of the .NET application henceforth. (Since it is always at the core of pipeline!) But as mentioned above, on the framework level, we still largely have not finished making it compatible with IBufferWriter, etc.</p><p id="134c" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">I am also creating an RPC framework called <a href="https://github.com/Cysharp/MagicOnion" class="bi cv gk gl gm gn" target="_blank" rel="noopener nofollow">MagicOnion</a> based on HTTP/2 and gRPC(Without requiring .proto, this RPC can be completed with only C#. It is better replaceable from WCF.). Due to the situation of the dependent library, there are many stages that resort to byte[] and this becomes a problem for performance as well. This is a serious problem especially since we are developing games with realtime communication in mind with Unity. I’ll replace the network layer in MagicOnion in the next update to solve it.</p><p id="6db0" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">Also, MessagePack for C# Version 1, <a href="https://github.com/neuecc/ZeroFormatter" class="bi cv gk gl gm gn" target="_blank" rel="noopener nofollow">ZeroFormatter</a> which I had developed earlier and <a href="https://github.com/neuecc/Utf8Json" class="bi cv gk gl gm gn" target="_blank" rel="noopener nofollow">Utf8Json</a>, I am proud that I revamped the standards for high-speed serializers.</p><p id="ca66" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">This Version 2 will also likely establish new standards. I would be very happy if it becomes a library that sparks debate over what the .NET Core 3 serializers should be.</p><p id="2766" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">With regard to Utf8Json, we want to improve it as we did for Version 2. Unfortunately, the <em class="go">JsonSerializer</em> performance is extremely poor with <em class="go">System.Text.Json</em> implemented officially by Microsoft and first appearing in .NET Core 3.</p><p id="16bd" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">So Utf8Json is still necessary. Too bad that Microsoft does not know at all how to create a flexible and good performing serializer. I understand this so I should be able to create one without a problem.</p><p id="b919" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">The entire .NET is also complete with Core 3 fundamental tools for performance. However, revisions of libraries and frameworks are still ahead. Many remain close to <em class="go">byte[]</em> bases. And especially since ADO.NET is a very old and thick layer, which requires a faster and thinner new abstraction layer.</p><p id="2c36" class="fw fx ar bz fy b fz ga gb gc gd ge gf gg gh gi gj dj">When everything is in place, C# will be the fastest and best environment for truly realistic applications. I also want to contribute to that.</p></figure></figure></figure></figure></figure></div></div></div></div>
</div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script>
        (function () {
            var COLLECT_URL = "https://dna.buildstarted.com/t";
            var SITE_ID = "linksfor.devs";
            var GLOBAL_VAR_NAME = "__DNA__";

            window[GLOBAL_VAR_NAME] = {};

            window[GLOBAL_VAR_NAME].sendPageView = function () {
                var path = location.pathname;
                var referrer = document.referrer;

                var url = COLLECT_URL + "?siteid=" + SITE_ID + "&p=" + encodeURIComponent(path) + "&r=" + encodeURIComponent(referrer);

                try { fetch(url, { method: "GET" }); } catch (e) { }
            };

            window[GLOBAL_VAR_NAME].sendPageView();
        })();
    </script>
</body>
</html>