<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Making rust as fast as go - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Making rust as fast as go - linksfor.dev(s)"/>
    <meta property="og:description" content="Update: as some keen HN commenters have pointed out, it looks like the rust program is not actually equivalent to the go program. The go program parses the string once, while the rust program parses it repeatedly inside every loop. It&#x2019;s quite late in Sydney as I write this so I&#x2019;m not up for a fix right now, but this post is probably Fake News. The perf gains from jemalloc are real, but it&#x2019;s likely not the allocators fault."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://www.christianfscott.com/making-rust-as-fast-as-go/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
	<div class="devring" style="background: #222">
		<div class="grid">
			<div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
				<span class="devring-title">devring.club</span>
				<a href="https://devring.club/site/1/previous" class="devring-previous">Previous</a>
				<a href="https://devring.club/random" class="devring-random">Random</a>
				<a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
			</div>
		</div>
	</div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Making rust as fast as go</title>
<div class="readable">
        <h1>Making rust as fast as go</h1>
            <div>Reading time: 6-8 minutes</div>
        <div>Posted here: 03 May 2020</div>
        <p><a href="https://www.christianfscott.com/making-rust-as-fast-as-go/">https://www.christianfscott.com/making-rust-as-fast-as-go/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><article><h2><time datetime="2020-05-03">May 3, 2020</time></h2><p><em><strong>Update:</strong> as some keen HN commenters have pointed out, it looks like the rust program is not actually equivalent to the go program. The go program parses the string once, while the rust program parses it repeatedly inside every loop. It’s quite late in Sydney as I write this so I’m not up for a fix right now, but this post is probably Fake News. The perf gains from jemalloc are real, but it’s likely not the allocators fault.</em></p><p><em>The one-two combo of 1) better performance on linux &amp; 2) jemalloc seeming to fix the issue lured me into believing that the allocator was to blame. I’m not sure what the lesson here is – <a href="https://en.wikipedia.org/wiki/Ward_Cunningham#Cunningham's_Law">perhaps more proof of Cunningham’s law?</a></em></p><p>Go is garbage collected, rust is not. That means rust is faster than go, right? No! Not always.</p><p>Let’s take an example that I stumbled across while playing around with an algorithm that calculates Levenshtein edit distances. I wanted to compare the performance of the same algorithm in a bunch of different languages. Two of these languages were rust and go.</p><p>To my surprise, the go version was faster than the rust version. A lot faster. My initial reaction was that I must have implemented the rust version incorrectly. Maybe I was doing some unsafe (but fast) things in go that rust wouldn’t let me do. To account for this, I laid out some ground rules:</p><ol><li>The more idiomatic the better. Rust, for example, promises zero cost abstractions so we should lean on this &amp; write safe code</li><li>No static global variables. This means that containers need to be heap allocated &amp; dynamically sized. We don’t know how big the inputs will be!</li><li>Memory access should be safe. Don’t eliminate bounds checks</li><li>Assume that text is utf8 encoded</li></ol><p>In short, this should be code that you’d happily ship to prod. Here’s what I ended up with:</p><details><summary><code>edit_distance.go</code></summary><div><pre><code data-lang=".go"><span>func</span> EditDistance(source, target <span>string</span>) <span>int</span> {
	<span>if</span> len(source) == <span>0</span> {
		<span>return</span> len(target)
	}

	<span>if</span> len(target) == <span>0</span> {
		<span>return</span> len(source)
	}

	sourceChars := []rune(source)
	targetChars := []rune(target)

	cache := make([]<span>int</span>, len(target)+<span>1</span>)
	<span>for</span> i := <span>0</span>; i &lt; len(target)+<span>1</span>; i++ {
		cache[i] = i
	}

	<span>for</span> i, sourceChar := <span>range</span> sourceChars {
		nextDist := i + <span>1</span>
		<span>for</span> j, targetChar := <span>range</span> targetChars {
			currentDist := nextDist

			distIfSubstitute := cache[j]
			<span>if</span> sourceChar != targetChar {
				distIfSubstitute++
			}

			distIfInsert := currentDist + <span>1</span>
			distIfDelete := cache[j+<span>1</span>] + <span>1</span>

			nextDist = min(distIfDelete, min(distIfInsert, distIfSubstitute))

			cache[j] = currentDist
		}

		cache[len(target)] = nextDist
	}

	<span>return</span> cache[len(target)]
}
</code></pre></div></details><details><summary><code>edit_distance.rs</code></summary><div><pre><code data-lang=".rs"><span>pub</span><span> </span><span>fn</span> levenshtein_distance(source: <span>&amp;</span><span>str</span>,<span> </span>target: <span>&amp;</span><span>str</span>)<span> </span>-&gt; <span>usize</span> {<span>
</span><span>    </span><span>if</span><span> </span>source.is_empty()<span> </span>{<span>
</span><span>        </span><span>return</span><span> </span>target.len();<span>
</span><span>    </span>}<span>
</span><span>
</span><span>    </span><span>if</span><span> </span>target.is_empty()<span> </span>{<span>
</span><span>        </span><span>return</span><span> </span>source.len();<span>
</span><span>    </span>}<span>
</span><span>
</span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span>cache: Vec&lt;<span>usize</span>&gt;<span> </span>=<span> </span>(<span>0</span>..=target.chars().count()).collect();<span>
</span><span>
</span><span>    </span><span>for</span><span> </span>(i,<span> </span>source_char)<span> </span><span>in</span><span> </span>source.chars().enumerate()<span> </span>{<span>
</span><span>        </span><span>let</span><span> </span><span>mut</span><span> </span>next_dist<span> </span>=<span> </span>i<span> </span>+<span> </span><span>1</span>;<span>
</span><span>
</span><span>        </span><span>for</span><span> </span>(j,<span> </span>target_char)<span> </span><span>in</span><span> </span>target.chars().enumerate()<span> </span>{<span>
</span><span>            </span><span>let</span><span> </span>current_dist<span> </span>=<span> </span>next_dist;<span>
</span><span>
</span><span>            </span><span>let</span><span> </span><span>mut</span><span> </span>dist_if_substitute<span> </span>=<span> </span>cache[j];<span>
</span><span>            </span><span>if</span><span> </span>source_char<span> </span>!=<span> </span>target_char<span> </span>{<span>
</span><span>                </span>dist_if_substitute<span> </span>+=<span> </span><span>1</span>;<span>
</span><span>            </span>}<span>
</span><span>
</span><span>            </span><span>let</span><span> </span>dist_if_insert<span> </span>=<span> </span>current_dist<span> </span>+<span> </span><span>1</span>;<span>
</span><span>            </span><span>let</span><span> </span>dist_if_delete<span> </span>=<span> </span>cache[j<span> </span>+<span> </span><span>1</span>]<span> </span>+<span> </span><span>1</span>;<span>
</span><span>
</span><span>            </span>next_dist<span> </span>=<span> </span>std::cmp::min(<span>
</span><span>                </span>dist_if_substitute,<span>
</span><span>                </span>std::cmp::min(dist_if_insert,<span> </span>dist_if_delete),<span>
</span><span>            </span>);<span>
</span><span>
</span><span>            </span>cache[j]<span> </span>=<span> </span>current_dist;<span>
</span><span>        </span>}<span>
</span><span>
</span><span>        </span>cache[target.len()]<span> </span>=<span> </span>next_dist;<span>
</span><span>    </span>}<span>
</span><span>
</span><span>    </span>cache[target.len()]<span>
</span><span></span>}<span>
</span></code></pre></div></details><p>Even with the playing field levelled, go still outperformed rust by 50%. For the dataset I was using to benchmark the programs, the go version to 1.5 seconds and rust 3 seconds.</p><p>This was bizarre. As far as I could tell, these programs were identical besides the fact that the go runtime needs to spend precious cycles collecting garbage. That means it should be slower, right?</p><p>I took the question to my coworkers, who had some good suggestions. Theories included <a href="https://en.wikipedia.org/wiki/Escape_analysis">escape analysis</a>, string allocation, and the rust implementation being wrong. The last one was true but the performance gap remained once I fixed it (I have tests now!).</p><p>The winning suggestion ended up being to switch the allocator in the rust program to <code>jemalloc</code>. This was the default allocator used by rust binaries in the past, but it was <a href="https://github.com/rust-lang/rust/pull/55238">removed in favour of using the system allocator instead in late 2018</a>. Read <a href="https://github.com/rust-lang/rust/issues/36963">#36963</a> to get the full rationale for this change.</p><p>To change the allocator, you simply add the following to the start of your program:</p><div><pre><code data-lang="rs"><span>extern</span><span> </span><span>crate</span><span> </span>jemallocator;<span>
</span><span>
</span><span></span><span>#[global_allocator]</span><span>
</span><span></span><span>static</span><span> </span>ALLOC: jemallocator::Jemalloc<span> </span>=<span> </span>jemallocator::Jemalloc;<span>
</span></code></pre></div><p>This made a huge difference. On my machine, this dropped the execution time from 3 seconds to about 1.8 seconds. Let’s take a look at the flamegraphs (generated with <a href="https://github.com/flamegraph-rs/flamegraph">flamegraph-rs/flamegraph</a>) to see the change:</p><p><img src="https://paper-attachments.dropbox.com/s_37D0C8C70724613891307BCE6762349294204ED734B7440F48079DCC0DD663E4_1588496091226_Screenshot+2020-05-03+18.48.43.png" alt="Flamegraph before, with system allocator. Roughly 40% of execution time spent allocating"></p><p><img src="https://paper-attachments.dropbox.com/s_37D0C8C70724613891307BCE6762349294204ED734B7440F48079DCC0DD663E4_1588496091216_Screenshot+2020-05-03+18.45.57.png" alt="Flamegraph after allocator was changed to jemalloc. Time spent allocating dropped to 20%"></p><p>This means that the time spend allocating has dropped from about 40% to 20%. Keep in mind this is for the full benchmark, including all the setup code, but it gives us a good sense of what changed.</p><p>I’m not sure why the change was so severe. I tried searching for things like “macos allocator slow” but didn’t find anything. If you have some information here, please let me know!</p><p>Why doesn’t go suffer from the slow system allocator on macos? Two things come to mind. The first is that <a href="https://golang.org/src/runtime/malloc.go">go uses a custom allocator</a>. I assume that this is also faster than the macos system allocator. The second is that while this program does spend a lot of time allocating and freeing memory, there are barely any objects in the heap at any given moment. <code>EditDistance</code> only allocates one object on the heap (<code>cache</code>), meaning that the time spent garbage collecting is probably negligible.</p><p>So the answer is:</p><ol><li>The macos allocator is slow</li><li>Go uses a custom allocator, which is faster than the one that ships with macos</li></ol><p>What’s the lesson here? If you’re writing a rust program that does a lot of allocation, consider using a non-system allocator if you need some more performance. Don’t make the mistake of extrapolating beyond that simple point, though. This is a “microbenchmark”, and the results are tightly coupled to the very contrived scenario I’ve concocted.</p><p><a href="https://github.com/christianscott/levenshtein-distance-benchmarks">Check out the whole github repo.</a> It has implementations in several languages, as well as scripts to benchmark + test them.
<a href="https://github.com/christianscott/levenshtein-distance-benchmarks"></a></p></article></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
		<div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>