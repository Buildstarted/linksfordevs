<!DOCTYPE html>
<html lang="en">
<head>
    <title>
A detailed look at Ubuntu&#x2019;s new experimental ZFS installer -
linksfor.dev(s)
    </title>
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta charset="utf-8">
    <meta name="Description" content="A curated source of links that devs might find interesting. Updated around the clock." />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        
<div class="readable">
    <div class="article-content post-page"> <aside id="social-left" class="social-left"> <a class="comment-count icon-comment-bubble-down" href="https://arstechnica.com/information-technology/2019/10/a-detailed-look-at-ubuntus-new-experimental-zfs-installer/?comments=1"> </a> </aside> <p>Yesterday brought exciting news on the ZFS and Ubuntu fronts&#x2014;experimental ZFS root support in the installer for Ubuntu&apos;s upcoming interim release, Eoan Ermine. The feature <a href="https://twitter.com/popey/status/1181547646378500096">appeared</a> in the 2019-10-09 daily build of Eoan&#x2014;it&apos;s not in the regular beta release and, in fact, wasn&apos;t even in the &quot;current daily&quot; when we first went to download it. It&apos;s that new! (Readers wanting to play with the new functionality can find it in&#xA0;<em>today&apos;s</em> daily build, available <a href="http://cdimage.ubuntu.com/daily-live/current/">here</a>.)</p> <div class="gallery shortcode-gallery gallery-wide"> <ul> <li> <figure> <figcaption id="caption-1582493"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> Time to install the 2019-10-09 daily build of Eoan Ermine on a fresh new VM! </div> </figcaption> </figure> </li> <li> <figure> <figcaption id="caption-1582495"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> Our first choice during the Eoan install is a basic one. Yeah yeah yeah, let&apos;s get to the ZFS please... </div> </figcaption> </figure> </li> <li> <figure> <figcaption id="caption-1582499"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> WHEEEE! Now that we&apos;ve got the correct daily build .iso, we have the experimental ZFS install option available. </div> </figcaption> </figure> </li> <li> <figure> <figcaption id="caption-1582503"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> Minor bug: even though we chose a ZFS root, Eoan&apos;s installer is still telling us it will use ext4. Welcome to alpha software! </div> </figcaption> </figure> </li> <li> <figure> <figcaption id="caption-1582505"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> Now that we&apos;ve selected our ZFS root, Eoan Ermine is on its merry way to installation. </div> </figcaption> </figure> </li> </ul> </div> <h2>For the ZFS newbies</h2>
<p>If you&apos;re new to the <a href="https://arstechnica.com/information-technology/2014/02/ars-walkthrough-using-the-zfs-next-gen-filesystem-on-linux/">ZFS</a> hype train, you might wonder why a new filesystem option in an OS installer is a big deal. So here&apos;s a quick explanation: ZFS is a copy-on-write filesystem, which can take <a href="https://arstechnica.com/information-technology/2014/01/bitrot-and-atomic-cows-inside-next-gen-filesystems/">atomic snapshots</a>&#xA0;of entire filesystems. This looks like sheer magic if you&apos;re not used to it&#x2014;a snapshot of a 10TB filesystem can be taken instantly without interrupting any system process in the slightest. Once the snapshot is taken, it&apos;s an immutable record of the exact, block-for-block condition of the filesystem at the moment in time the snapshot was taken.</p>
<p>When a snapshot is first taken, it consumes no additional disk space. As time goes by and changes are made to the filesystem, the space required to keep the snapshot grows by the amount of data that has been deleted or altered. So let&apos;s say you snapshot a 10TB filesystem: the snapshot completes instantly, requiring no additional room. Then you delete a 5MB JPEG file&#x2014;now the snapshot consumes 5MB of disk space, because it still has the JPEG&#xA0;you deleted. Then you change 5MB of data in a database, and the snapshot takes 10MB&#x2014;5MB for the JPEG&#xA0;you deleted and another 5MB for the data that you altered in the database.</p>
<p>That&apos;s just one awesome ZFS feature. There&apos;s also the ability to manage multiple disks in a native RAID-like system, inline compression with selectable algorithms, rapid asynchronous incremental <a href="https://arstechnica.com/information-technology/2015/12/rsync-net-zfs-replication-to-the-cloud-is-finally-here-and-its-fast/">replication</a>, and more. But we&apos;re going to focus mostly on the snapshots here, because one&#xA0;<em>other</em> thing you can do with a snapshot is roll it back.</p> <div class="gallery shortcode-gallery gallery-wide"> <ul> <li> <figure> <figcaption id="caption-1582509"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> A simple test of undoing an operation: first, take a snapshot. Then, do something you regret (in this case, uninstalling Firefox). </div> </figcaption> </figure> </li> <li> <figure> <figcaption id="caption-1582523"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> The rollback is instantaneous, and Firefox is back&#x2014;but things still look a little wonky due to orphaned filehandles. We need to reboot now. </div> </figcaption> </figure> </li> <li> <figure> <figcaption id="caption-1582487"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> We rolled back, we rebooted, and everything&apos;s golden. Hello again, Firefox old friend! </div> </figcaption> </figure> </li> </ul> </div> <p>Although there isn&apos;t any support built into Eoan&apos;s apt package manager for automatically taking snapshots yet, we can demonstrate a snapshot&#x2014;oops&#x2014;rollback moment manually. In the above gallery, first we take a ZFS snapshot. Eoan has split our root filesystem into tons of little datasets (more on that later), so we use the <code>-r</code> option for <code>zfs snapshot</code> to recursively take snapshots throughout the entire tree.</p>
<p>Now that we&apos;ve insured ourselves against mistakes, we do something we&apos;re going to regret. For the purposes of this demo, we&apos;re just removing Firefox&#x2014;but we could really recover from anything up to and including an <code>rm -rf --no-preserve-root /</code> this way with a little extra legwork. After removing Firefox, we need to roll back our snapshots to restore the system to its original condition.</p>
<p>Since the root filesystem is scattered through a&#xA0;<em>bunch</em> of individual datasets, we need to roll them all back individually. Although this is a pain for the casual user without additional tooling, it does make it possible to do more granular restore operations if we&apos;re feeling picky&#x2014;like rolling back the root filesystem without rolling back <code>/home</code>. Ubuntu will undoubtedly eventually have tooling to make this easier, but for the moment, we do a bit of sysadmin-fu and pipe <code>zfs list</code> to <code>grep</code> to <code>awk</code> to <code>xargs</code>, oh my.</p>
<p>The command line acrobatics might have been obnoxious, but the rollback itself was instantaneous, and Firefox has returned. It still doesn&apos;t work quite right, though, due to <a href="https://unix.stackexchange.com/questions/290116/what-is-an-orphaned-inode/290119#290119">orphaned filehandles</a>&#x2014;we rolled back a live mounted root filesystem, which is kind of a cowboy thing to do. To make things entirely right, a reboot is necessary&#x2014;but after the reboot, everything&apos;s the way it once was, and without the need to wait through any lengthy Windows Restore Point-style <a href="http://catb.org/jargon/html/G/grovel.html">groveling</a> over the filesystem.</p>
<h2>For the ZFS enthusiasts</h2>
<p>In this section, we&apos;re going to take a detailed look at just how Ubuntu is carving up the filesystems in Eoan&apos;s experimental installer. The version in our daily build is 0.8.1, so this is great news for the ZFS fans among us, even without the experimental root installer&#x2014;assuming the final version of Eoan follows this one, we&apos;ll get native encryption, TRIM, device removal, and zpool checkpoints. These <a href="https://arstechnica.com/gadgets/2019/06/zfs-features-bugfixes-0-8-1/">features</a> have been in the ZFS on Linux <a href="https://github.com/zfsonlinux/zfs">master</a> since 0.8, but this is the first time they&apos;ve shown up in Ubuntu&apos;s native ZFS.</p> <div class="gallery shortcode-gallery gallery-wide"> <ul> <li> <figure> <figcaption id="caption-1582485"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> A peek at /dev/vda&apos;s partition table shows us a small UEFI boot partition, a 2G partition for bpool, and the remainder of the disk as rpool. </div> </figcaption> </figure> </li> <li> <figure> <figcaption id="caption-1582517"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> Eoan&apos;s experimental ZFS installer creates two zpools, rpool and bpool. Bpool contains boot files only; all the interesting stuff is in rpool, shown here. </div> </figcaption> </figure> </li> <li> <figure> <figcaption id="caption-1582491"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> Taking a look at the ZFS dataset properties of my home directory, as set by the installer. </div> </figcaption> </figure> </li> </ul> </div> <p>So far&#x2014;remember, this is alpha software in a daily build&#x2014;the installer doesn&apos;t give you any control over how it carves up the disk when you select a ZFS install; it just does what it wants to do. The Eoan VM I created has a single 20GB virtual disk. Eoan&apos;s installer carved this into one primary partition and two logical&#x2014;a small UEFI boot partition and partitions for two separate ZFS storage pools, named <code>bpool</code> and <code>rpool</code>.</p>
<p>Bpool is pretty boring; it&apos;s just where the system&apos;s /boot directory gets mounted. Eoan made this pool 2GB, which is twice what a conservative <code>/boot</code> is normally provisioned to; this is probably to allow headroom to maintain a fairly deep archive of snapshots in the future. <code>rpool</code> gets all the remaining disk space after the UEFI and <code>bpool</code> partitions are created; it&apos;s where all the fun stuff goes, including your root filesystem, home directory, and so forth.</p>
<p>Beneath <code>rpool</code>, you&apos;ll find a pretty bewildering array of small datasets, all of which correspond to particular vital areas in what would normally be a single root filesystem. This appears to us to be an inherited BSD-ism&#x2014;most Linux distributions left the concept of heavily partitioned disks with multiple filesystems behind twenty years ago, but FreeBSD&#x2014;which has had root ZFS options in its installer for many years now&#x2014;was a lot more stubborn about it.</p>
<p>The good thing about carving up the root filesystem into so many separate datasets is that you can snapshot and roll them back individually. In some cases, this is great&#x2014;there&apos;s an obvious, clear, and useful distinction between rolling back the root filesystem as a whole and rolling back your own home directory, for example. Most users&#x2014;even pretty competent sysadmin types&#x2014;will be a lot more confused about how and why you might want to roll back <code>/usr</code> without rolling back, say, <code>/var/lib/AccountServices</code>, though. It&apos;s nice that you&#xA0;<em>can</em> if you really want to, but we&apos;re not so sure the capability outweighs the utility of a simpler approach.</p> <div class="gallery shortcode-gallery gallery-wide"> <ul> <li> <figure> <figcaption id="caption-1582483"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> Have I mentioned that this is a daily build, and therefore alpha software? It&apos;s a daily build, and therefore alpha software. Both bpool itself and the boot dataset beneath it have /boot as a mountpoint. Oops. =) </div> </figcaption> </figure> </li> <li> <figure> <figcaption id="caption-1582491"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> Taking a look at the ZFS dataset properties of my home directory, as set by the installer. </div> </figcaption> </figure> </li> <li> <figure> <figcaption id="caption-1582477"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> Eoan&apos;s ZFS support doesn&apos;t yet include automatically creating new ZFS datasets for new user accounts&apos; homedirs. </div> </figcaption> </figure> </li> <li> <figure> <figcaption id="caption-1582521"> <span class="icon caption-arrow icon-drop-indicator"></span> <div class="caption"> A peek into root&apos;s crontab and the jobs in /etc/cron.* show that no automatic snapshot creation is present in Eoan&apos;s ZFS support yet; only an automatic scrub once monthly. </div> </figcaption> </figure> </li> </ul> </div> <p>Peeking a little deeper, we can see that Eoan isn&apos;t setting any significant per-dataset properties on all these separate datasets. It is setting compression=lz4 on across the entire pool, though. This is a good thing&#x2014;many people worry that compressed filesystems are slow filesystems, but LZ4 stream compression is so lightweight that it&apos;s effectively &quot;free.&quot; We&apos;ve done extensive testing across years of ZFS experience and have never seen a situation where LZ4 wasn&apos;t a good idea. Even a $50 tinkertoy APU from several years ago can compress and decompress LZ4 faster than a pair of fast SSDs can keep up, with no significant CPU utilization.</p>
<p><del>We did spot a bug pretty quickly while looking over the pools and datasets. Both <code>bpool</code> itself and <code>bpool/BOOT/ubuntu_oalrlu</code> (we think the string of random-seeming characters is intended to be a unique system identifier) have <code>/boot</code> set as their mountpoint. This clearly isn&apos;t causing any significant problems right now, and we&apos;re sure it will get ironed out well before Eoan goes live.</del> (<strong>Edit:</strong>&#xA0;a Canonical core admin <a href="https://twitter.com/didrocks/status/1182329263913082880">clarified</a>&#xA0;that this is not a bug;&#xA0;<code>bpool</code> is set&#xA0;<code>canmount=no</code>. The reason for&#xA0;<code>bpool</code>&apos;s unmountable mountpoint is so that any new datasets created under&#xA0;<code>bpool</code>&#xA0;will automatically mount at&#xA0;<code>/boot/newdataset</code>, not at&#xA0;<code>/bpool/newdataset.)</code></p>
<p>Although Eoan created datasets automatically for both my real user account homedir and root&apos;s, the <code>adduser</code> command didn&apos;t create one for a new test user. This is something we also expect to get ironed out reasonably quickly&#x2014;even if <code>adduser</code> itself never takes those steps, the GUI for adding new users likely will, if it doesn&apos;t already. This is also pretty simple to do manually; in the above example, where new user test is&#xA0;<em>not</em> logged in, we could upgrade test to a zfs dataset homedir like this:</p>
<pre>root@eoan:~$ zfs create rpool/ROOT/ubuntu_oal4lu/test_twm547
root@eoan:~$ rsync -ha /home/test/ /rpool/ROOT/ubuntu_oal4lu/test_twm547/
root@eoan:~$ rm -r /home/test
root@eoan:~$ chown test.test /rpool/ROOT/ubuntu_oal4lu/test_twm547
root@eoan:~$ zfs set mountpoint=/home/test rpool/ROOT/ubuntu_oal4lu/test_twm547
root@eoan:~$ zfs mount rpool/ROOT/ubuntu_oal4lu/test_twm547</pre>
<p>... and that would be that.</p>
<p>The next big thing we looked for was a mechanism for automatically taking snapshots. You can&apos;t roll back to a snapshot you never took, so a safe ZFS system should automatically take snapshots pretty regularly. There&apos;s nothing in Eoan to take snapshots for you yet&#x2014;the only cron job is the standard one that scrubs the pool once per month&#x2014;but there are a few general purpose ZFS snapshot orchestration tools readily available; these include <a href="https://manpages.ubuntu.com/manpages/bionic/man8/zfs-auto-snapshot.8.html">zfs-auto-snapshot</a>&#xA0;and my own <a href="https://github.com/jimsalterjrs/sanoid">sanoid</a>.</p>
<h2>Alpha software is alpha!</h2>
<p>In conclusion, we want to remind readers that while ZFS itself is very stable, Ubuntu&apos;s ZFS-enabled installer and use of it as a root filesystem are still&#xA0;<em>alpha</em> quality. We do not recommend that you attempt to use the new ZFS installer on systems you care deeply about until the installer makes it past alpha, past beta, and all the way to full release quality. This also means you should be kind about any bugs you find playing with it in the meantime&#x2014;again, this is&#xA0;<em>alpha</em> software and bugs are not only possible, they&apos;re to be expected.</p>
<p>With all that said, we&apos;re extremely excited about ZFS on root making visible progress in Ubuntu&#x2014;and we hope these features and more will make it into Eoan Ermine&apos;s expected end-of-the-month release.</p> <p><em>Listing image by Jim Salter</em></p> </div>
</div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script>
        (function () {
            var COLLECT_URL = "https://dna.buildstarted.com/t";
            var SITE_ID = "linksfor.devs";
            var GLOBAL_VAR_NAME = "__DNA__";

            window[GLOBAL_VAR_NAME] = {};

            window[GLOBAL_VAR_NAME].sendPageView = function () {
                var path = location.pathname;
                var referrer = document.referrer;

                var url = COLLECT_URL + "?siteid=" + SITE_ID + "&p=" + encodeURIComponent(path) + "&r=" + encodeURIComponent(referrer);

                try { fetch(url, { method: "GET" }); } catch (e) { }
            };

            window[GLOBAL_VAR_NAME].sendPageView();
        })();
    </script>
</body>
</html>