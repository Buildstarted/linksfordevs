<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Y&#x16B;binkyoku &#x1F3E3; - Tristan Hume - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Y&#x16B;binkyoku &#x1F3E3; - Tristan Hume - linksfor.dev(s)"/>
    <meta property="og:description" content="Made as my final project for UWaterloo&#x27;s CS488 Graphics class, this is the demo page for my path tracing renderer made with the goal of maximum photorealism. I put about a full time month&#x27;s worth of work effort into this project, way more than required, since I was having a lot of fun and had a final scene in mind I wanted to reach."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="http://thume.ca/ray-tracer-site/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">ðŸŽ‰</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Y&#x16B;binkyoku &#x1F3E3; - Tristan Hume</title>
<div class="readable">
        <h1>Y&#x16B;binkyoku &#x1F3E3; - Tristan Hume</h1>
            <div>Reading time: 15-19 minutes</div>
        <div>Posted here: 21 Jul 2019</div>
        <p><a href="http://thume.ca/ray-tracer-site/">http://thume.ca/ray-tracer-site/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>

<div>
<div>
<p>
Made as my <a href="https://www.student.cs.uwaterloo.ca/~cs488/gallery-A5.html">final project for UWaterloo's CS488 Graphics class</a>, this is the demo page for my path tracing renderer made with the goal of maximum photorealism. I put about a full time month's worth of work effort into this project, way more than required, since I was having a lot of fun and had a final scene in mind I wanted to reach.
</p>
<p>
It's named after the Japanese word for "post office" because it made so little sense as the name for a ray tracer that it made me burst out laughing, and the fact that there's an emoji for it sealed the deal. Why the idea of naming it after the Japanese word for "post office" occurred to me in the first place is a long story.
</p>
<p>
It's not open source since it uses some code (e.g OBJ file loading) from the course, and there are better open source renderers out there. But if you want more technical details you can read the <a href="https://thume.ca/ray-tracer-site/report.pdf">project report</a>, although it's written with an intended audience of the course TAs.
</p>

</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/final_1097_mc6_preview.jpg" alt="My Final Scene">
</p>
<div>
<div>
<h3>Prologue</h3>
<div>
<p>First, for context for the rest of the renders, all my renders use an implementation of a subset of the Disney BRDF (Burley 2012). This is a high quality physically based microfacet BRDF including proper Fresnel and other effects for dielectrics and metals. My implementation has three parameters: base colour, metalness and roughness. I also implemented Phong Shading for my meshes.</p>
<p>After implementing the Disney BRDF, I rendered a simple scene with both Blenderâ€™s Cycles renderer and mine and they were a perfect match, which gave me confidence and allowed me to tune materials in Blender.</p>
</div>
<div>
<div id="render-desc-1-1" data-file="fancy_mesh_73_phong.png" data-sectionid="1" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_73_phong.png" id="render-thumb-1-1"></p><div>
<h5>Disney BRDF</h5>
<p>Suzanne monkey head model with dielectric 0.5 roughness Disney BRDF material.</p>
</div>
</div>
<div id="render-desc-1-2" data-file="fancy_mesh_73_nophong.png" data-sectionid="1" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_73_nophong.png" id="render-thumb-1-2"></p><div>
<h5>No Phong Shading</h5>
<p>Same scene rendered with Phong shading disabled.</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_73_phong.png" id="render-full-1-1">
<img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_73_nophong.png" id="render-full-1-2">
</p>
</div>
<div>
<div>
<h3>Texture Mapping</h3>
<div>
<p>I implemented texture mapping by making my material take all of its attributes from a texture, and then implented the ability to create constant and image texture files from Lua. I added UV coordinates for meshes, cubes and spheres. Textures are filtered with bilinear filtering of the 4 nearest texels.</p>
<p>This allows mapping base colour, metalness and roughness. I also added special support for emission textures and rendering inside spheres to support environment maps.</p>
</div>
<div>
<div id="render-desc-2-1" data-file="fancy_mesh_skybox.png" data-sectionid="2" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_skybox.png" id="render-thumb-2-1"></p><div>
<h5>Sky emission sphere</h5>
<p>Sky texture mapped onto the inside of a giant sphere.</p>
</div>
</div>
<div id="render-desc-2-2" data-file="fancy_mesh_paint.png" data-sectionid="2" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_paint.png" id="render-thumb-2-2"></p><div>
<h5>Painted mesh</h5>
<p>Texture painted in Blender, also looks glitchy there.</p>
</div>
</div>
<div id="render-desc-2-3" data-file="fancy_mesh_cube.png" data-sectionid="2" data-renderid="3">
<p><img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_cube.png" id="render-thumb-2-3"></p><div>
<h5>Varying material</h5>
<p>Colour, metallness and roughness textures on a cube.</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_skybox.png" id="render-full-2-1">
<img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_paint.png" id="render-full-2-2">
<img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_cube.png" id="render-full-2-3">
</p>
</div>
<div>
<div>
<h3>Normal Mapping</h3>
<div>
<p>I implemented normal mapping including the required tangents for meshes, cubes and spheres.</p>
<p>I verified with the test texture shown on the cube that the normals have the correct orientation.</p>
</div>
<div>
<div id="render-desc-3-1" data-file="studio_full_2.mp4" data-sectionid="3" data-renderid="1">
<video autoplay="" loop="" muted="" src="renders/studio_full_2.mp4" id="render-thumb-3-1">
No video :-(
</video>
<div>
<h5>Moving highlights</h5>
<p>Animation showing moving normal mapped highlights</p>
</div>
</div>
<div id="render-desc-3-2" data-file="fancy_mesh_cubenormal.png" data-sectionid="3" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_cubenormal.png" id="render-thumb-3-2"></p><div>
<h5>Test normal map</h5>
<p>Shiny plastic cube with normal map</p>
</div>
</div>
<div id="render-desc-3-3" data-file="studio_73_2.png" data-sectionid="3" data-renderid="3">
<p><img src="https://thume.ca/ray-tracer-site/renders/studio_73_2.png" id="render-thumb-3-3"></p><div>
<h5>Fancy normal map</h5>
<p>Textured and normal mapped surfaces</p>
</div>
</div>
</div>
</div>
<div>
<video autoplay="" loop="" muted="" src="renders/studio_full_2.mp4" id="render-full-3-1">
No video :-(
</video>
<p><img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_cubenormal.png" id="render-full-3-2">
<img src="https://thume.ca/ray-tracer-site/renders/studio_73_2.png" id="render-full-3-3">
</p></div>
</div>
<div>
<div>
<h3>Path Tracing</h3>
<div>
<p>I implemented global illumination using path tracing. I importance sample both the diffuse and specular lobes of the Disney BRDF.</p>
<p>My integrator is based on the path formulation of the rendering equation, where the integration is done in the outer loop so that path components can be re-used as they are extended and checked against direct lights at each bounce.</p>
</div>
<div>
<div id="render-desc-4-1" data-file="cornell_10313_plain.png" data-sectionid="4" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_10313_plain.png" id="render-thumb-4-1"></p><div>
<h5>Cornell box</h5>
<p>Cornell box with diffuse objects showing colour bleed</p>
</div>
</div>
<div id="render-desc-4-2" data-file="cornell_10313_refl.png" data-sectionid="4" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_10313_refl.png" id="render-thumb-4-2"></p><div>
<h5>Reflective sphere</h5>
<p>With a sphere material emulating polished copper</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_10313_plain.png" id="render-full-4-1">
<img src="https://thume.ca/ray-tracer-site/renders/cornell_10313_refl.png" id="render-full-4-2">
</p>
</div>
<div>
<div>
<h3>Soft Shadows</h3>
<div>
<p>I implemented soft shadows by overhauling my lighting model so that lights are just spheres with an emission texture on them, just like environment maps. I then changed the lights array normally passed into the render to just a list of <code>GeometryNode</code>s to sample explicitly.</p>
<p>The path tracing integrator then at each bounce samples the cone of directions subtended by the sphere that would fit in the bounding box of the objects. This means at the moment only spherical area lights work correctly. This is more efficient than sampling a point on the sphere since only visible positions on the light are sampled.</p>
<p>This also allows me to render the area light as a physical object that exists in the world, or I can put it in the list to be sampled but not in the scene for an invisible light.</p>
</div>
<div>
<div id="render-desc-5-1" data-file="cornell_10313_area.png" data-sectionid="5" data-renderid="1">

<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_10313_area.png" id="render-thumb-5-1"></p><div>
<h5>Soft shadows</h5>
<p>Cornell box with area light</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_10313_area.png" id="render-full-5-1">
</p>
</div>
<div>
<div>
<h3>Glossy Reflection</h3>
<div>
<p>Glossy reflection falls out directly from the path tracing integrator and the specular lobe of the Disney BRDF, which uses an empirically based GGX distribution for the microfacet normals. I importance sample the GGX distribution term of the specular lobe so glossy reflection converges quickly.</p>
<p>With path tracing the only difference between specular highlights and glossy reflection is whether the light was directly sampled!</p>
</div>
<div>
<div id="render-desc-6-1" data-file="cornell_12361_gloss_area.png" data-sectionid="6" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_12361_gloss_area.png" id="render-thumb-6-1"></p><div>
<h5>Glossy reflection</h5>
<p>Cornell box with rough copper sphere</p>
</div>
</div>
<div id="render-desc-6-2" data-file="cornell_10313_gloss_floor.png" data-sectionid="6" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_10313_gloss_floor.png" id="render-thumb-6-2"></p><div>
<h5>Glossy floor</h5>
<p>Cornell box with shiny dielectric floor</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_12361_gloss_area.png" id="render-full-6-1">
<img src="https://thume.ca/ray-tracer-site/renders/cornell_10313_gloss_floor.png" id="render-full-6-2">
</p>
</div>
<div>
<div>
<h3>Anti-aliasing</h3>
<div>
<p>Anti-aliasing is implemented as part of the same sampling framework that the path tracing uses. On each sample a random position in a square pixel region is picked to cast the ray for.</p>
<p>For textures I only do bilinear filtering with 4 texels so for high resolution textures anti-aliasing is also necessary for textured surfaces to look correct.</p>
</div>
<div>
<div id="render-desc-7-1" data-file="fancy_mesh_cube_noaa.png" data-sectionid="7" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_cube_noaa.png" id="render-thumb-7-1"></p><div>
<h5>Cube with no AA</h5>
<p>Textured cube without anti-aliasing</p>
</div>
</div>
 <div id="render-desc-7-2" data-file="fancy_mesh_cube.png" data-sectionid="7" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_cube.png" id="render-thumb-7-2"></p><div>
<h5>Cube with AA</h5>
<p>Textured cube with anti-aliasing</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_cube_noaa.png" id="render-full-7-1">
<img src="https://thume.ca/ray-tracer-site/renders/fancy_mesh_cube.png" id="render-full-7-2">
</p>
</div>
<div>
<div>
<h3>Depth of Field</h3>
<p>I implement the thin lens model of depth of field by finding where the original ray intersects the focal plane, then sampling a random point on a disk representing the aperture of the camera and casting a ray from that point to the point on the focal plane.</p>
<div>
<div id="render-desc-8-1" data-file="dof_6217_fancy.png" data-sectionid="8" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/dof_6217_fancy.png" id="render-thumb-8-1"></p><div>
<h5>Cubes with DOF</h5>
<p>Focal point is on the red cube</p>
</div>
</div>
<div id="render-desc-8-2" data-file="dof_6217_nodof.png" data-sectionid="8" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/dof_6217_nodof.png" id="render-thumb-8-2"></p><div>
<h5>No DOF</h5>
<p>Comparison rendered with zero aperture</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/dof_6217_fancy.png" id="render-full-8-1">
<img src="https://thume.ca/ray-tracer-site/renders/dof_6217_nodof.png" id="render-full-8-2">
</p>
</div>
<div>
<div>
<h3>Animation</h3>
<div>
<p>I implemented animation in Lua by constructing multiple scenes and rendering them to separate files, then using FFMPEG to stitch them together. The animation is done with math, logic and a cosine-based curve for smoothly easing in and out.</p>
<p>This scene shows a perfectly looping animation with rose gold and black plastic rounded hexagons on a metal surface. It was <em>heavily</em> inspired by <a href="https://gfycat.com/WideeyedAstonishingDonkey">this animation</a>.</p>
<p>This also shows off a bit of the distance field ray marching explained in the next section. In this case I use modulo to do a domain repetition of a rounded hexagonal bar primitive formula with the parameter being the rotation, which is driven from Lua.</p>
</div>
<div>
<div id="render-desc-9-1" data-file="anim_hq.mp4" data-sectionid="9" data-renderid="1">
<video autoplay="" loop="" muted="" src="renders/anim_hq.mp4" id="render-thumb-9-1">
No video :-(
</video>
<div>
<h5>Abstract animation</h5>
<p>Perfect loop!</p>
</div>
</div>
<div id="render-desc-9-2" data-file="anim_hq_f-0t.png" data-sectionid="9" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/anim_hq_f-0t.png" id="render-thumb-9-2"></p><div>
<h5>First frame</h5>
<p>Uncompressed render</p>
</div>
</div>
</div>
</div>
<div>
<video autoplay="" loop="" muted="" src="renders/anim_hq.mp4" id="render-full-9-1">
No video :-(
</video>
<p><img src="https://thume.ca/ray-tracer-site/renders/anim_hq_f-0t.png" id="render-full-9-2">
</p></div>
</div>
<div>
<div>
<h3>Constructive Solid Geometry</h3>
<div>
<p>I implemented Constructive Solid Geometry (CSG) in a different way than is standard for ray tracers. I implemented a primitive for ray marching a distance field. This is a method of rendering a 3D surface given a function from a point to the distance to a surface by taking steps along a ray based on the function.</p>
<p>Once that is implemented, CSG is simple to implement by taking the minimum (union) or maximum (intersection) of two distance functions, subtraction is taking the maximum with the negative of a signed distance function.</p>
</div>
<div>
<div id="render-desc-10-1" data-file="csg_329_mat5.png" data-sectionid="10" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/csg_329_mat5.png" id="render-thumb-10-1"></p><div>
<h5>CSG Shape</h5>
<p>Cube with spheres and ellipsoids subtracted and intersected</p>
</div>
</div>
<div id="render-desc-10-2" data-file="csg_copper_hq.mp4" data-sectionid="10" data-renderid="2">
<video autoplay="" loop="" muted="" src="renders/csg_copper_hq.mp4" id="render-thumb-10-2">
No video :-(
</video>
<div>
<h5>CSG Animation</h5>
<p>Showing parameterization and that itâ€™s not a mesh</p>
</div>
</div>
</div>
</div>
<div>
<p><img src="https://thume.ca/ray-tracer-site/renders/csg_329_mat5.png" id="render-full-10-1"></p><video autoplay="" loop="" muted="" src="renders/csg_copper_hq.mp4" id="render-full-10-2">
No video :-(
</video>
</div>
</div>
<div>
<div>
<h3>Mandelbox Primitive</h3>
<div>
<p>Using distance field ray marching it is possible to render Mandelbrot-style iteration fractals by using the running derivative of the iteration as a distance estimate. I implemented the distance function for one such fractal, the Mandelbox.</p>
<p>I then used CSG to subtract and intersect with some cubes to carve out an interesting region inside the fractal, since the outside isnâ€™t too impressive.</p>
</div>
<div>
<div id="render-desc-11-1" data-file="studio_585_smallmandel.png" data-sectionid="11" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/studio_585_smallmandel.png" id="render-thumb-11-1"></p><div>
<h5>Small Mandelbox</h5>
<p>Wooden floor and small copper Mandelbox</p>
</div>
</div>
<div id="render-desc-11-2" data-file="studio_585_bigredmandel.png" data-sectionid="11" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/studio_585_bigredmandel.png" id="render-thumb-11-2"></p><div>
<h5>Big red Mandelbox</h5>
<p>Wooden floor and big red Mandelbox</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/studio_585_smallmandel.png" id="render-full-11-1">
<img src="https://thume.ca/ray-tracer-site/renders/studio_585_bigredmandel.png" id="render-full-11-2">
</p>
</div>
<div>
<div>
<h3>PORTALS!</h3>
<div>
<p>In order to implement my final scene concept I needed portals, which for my case meant a way to have an object act as a portal where rays passing through it would end up in a different scene, bidirectionally.</p>
<p>I implemented this by giving all rays and surface hits a world number field. Then I modified my code so all scattering and light sampling would observe the world field and cast follow up and shadow rays with the same world.</p>
<p>Then I added a portal <code>SceneNode</code> subclass that checks the world ID of incoming rays and first tests it against that index of its children, as well as a special portal node pointer, and if it hits the portal before it hits the current world, it spawns a new ray in the next world number modulo its number of children, and does the required changing and remapping ray t values to spawn the new ray at the portal.</p>
</div>
<div>
<div id="render-desc-12-1" data-file="cornell_8265_portal.png" data-sectionid="12" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_8265_portal.png" id="render-thumb-12-1"></p><div>
<h5>Portal</h5>
<p>Portal from Cornell box to wooden floor scene</p>
</div>
</div>

</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_8265_portal.png" id="render-full-12-1">
</p>
</div>
<div>
<div>
<h3>Final Scene: "Realism"</h3>
<div>
<p>My goal was to render a scene that was as photorealistic as possible while having whimsical elements that clearly couldnâ€™t be real. The scene shows off high quality textures and models (not done by me) in a scene I arranged and tuned the materials for. I also tried to compose an artistically nice scene that tells a story. Uses a portal, a Mandelbox, global illumination, and various hand-tuned Disney BRDF materials.</p>
<p>While I didnâ€™t make most of the models and textures, I still spent over 15 hours arranging, tuning materials and light, composing the scene, and importing various model formats.</p>
<p><strong>Extras shown:</strong> Non-filtered textures</p>
</div>
<div>
<div id="render-desc-13-1" data-file="final_1097_mc6_4k.png" data-sectionid="13" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/final_1097_mc6_4k.png" id="render-thumb-13-1"></p><div>
<h5>Final Scene</h5>
<p>My best scene</p>
</div>
</div>
<div id="render-desc-13-2" data-file="final_1097_mc6_1080p_dof.png" data-sectionid="13" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/final_1097_mc6_1080p_dof.png" id="render-thumb-13-2"></p><div>
<h5>With depth of field</h5>
<p>With artistic DOF</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/final_1097_mc6_4k.png" id="render-full-13-1">
<img src="https://thume.ca/ray-tracer-site/renders/final_1097_mc6_1080p_dof.png" id="render-full-13-2">
</p>
</div>
<div>
<div>
<h3>Filmic Tone Mapping</h3>
<div>
<p>An important part of the photorealism of my renders is very high quality tone mapping. I implemented a parser for the 1D and 3D OpenColorIO lookup table (LUT) formats, and a function to apply them correctly with linear and trilinear interpolation respectively.</p>
<p>The good tone mapping allows for scenes with realistic high dynamic range lighting to render properly without getting blown out and with photo-like colour. As you can see from the render with no tone mapping where the colours are bad, the sun on the keyboard is totally blown out, and the shades of black on the display rim are lost.</p>
<p>I can also use different LUTs for different scenes. I rendered my final scene with a more camera-like LUT with lots of dynamic range, but the rest of my scenes with a higher contrast LUT that gives punchier colours but isnâ€™t as photorealistic.</p>
<p>I can also use a false colour LUT to see what the dynamic range of my scene is like.</p>
</div>
<div>
<div id="render-desc-14-1" data-file="final_585_notone.png" data-sectionid="14" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/final_585_notone.png" id="render-thumb-14-1"></p><div>
<h5>No mapping</h5>
<p>Final scene with no tone mapping</p>
</div>
</div>
<div id="render-desc-14-2" data-file="final_585_false.png" data-sectionid="14" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/final_585_false.png" id="render-thumb-14-2"></p><div>
<h5>False Colour</h5>
<p>Showing dynamic range</p>
</div>
</div>
<div id="render-desc-14-3" data-file="final_1097_mc6_4k.png" data-sectionid="14" data-renderid="3">
<p><img src="https://thume.ca/ray-tracer-site/renders/final_1097_mc6_4k.png" id="render-thumb-14-3"></p><div>
<h5>Normal Comparison</h5>
<p>The LUT used for the main render</p>
</div>
</div>
<div id="render-desc-14-4" data-file="final_585_highcontrast.png" data-sectionid="14" data-renderid="4">
<p><img src="https://thume.ca/ray-tracer-site/renders/final_585_highcontrast.png" id="render-thumb-14-4"></p><div>
<h5>Higher contrast LUT</h5>
<p>Final scene rendered with high-contrast LUT used for other renders</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/final_585_notone.png" id="render-full-14-1">
<img src="https://thume.ca/ray-tracer-site/renders/final_585_false.png" id="render-full-14-2">
<img src="https://thume.ca/ray-tracer-site/renders/final_1097_mc6_4k.png" id="render-full-14-3">
<img src="https://thume.ca/ray-tracer-site/renders/final_585_highcontrast.png" id="render-full-14-4">
</p>
</div>
<div>
<div>
<h3>Tone Desaturation</h3>
<div>
<p>Part of the tone mapping is a 3D LUT that desaturates very bright colours, simulating bleed between film layers, which can produce a pleasing effect with very bright colours getting desaturated. This effectively allows for more dynamic range to be shown.</p>
<p>This scene shows includes a ridiculously bright pure pink light to demonstrate.</p>
</div>
<div>
<div id="render-desc-15-1" data-file="outside_73_notone.png" data-sectionid="15" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/outside_73_notone.png" id="render-thumb-15-1"></p><div>
<h5>No mapping</h5>
<p>Blowout of a colour light</p>
</div>
</div>
<div id="render-desc-15-2" data-file="outside_73_nodesat.png" data-sectionid="15" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/outside_73_nodesat.png" id="render-thumb-15-2"></p><div>
<h5>1D LUT</h5>
<p>Tone mapping with just a 1D LUT</p>
</div>
</div>
<div id="render-desc-15-3" data-file="outside_73_tone.png" data-sectionid="15" data-renderid="3">
<p><img src="https://thume.ca/ray-tracer-site/renders/outside_73_tone.png" id="render-thumb-15-3"></p><div>
<h5>3D Desaturation LUT</h5>
<p>With desaturation LUT</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/outside_73_notone.png" id="render-full-15-1">
<img src="https://thume.ca/ray-tracer-site/renders/outside_73_nodesat.png" id="render-full-15-2">
<img src="https://thume.ca/ray-tracer-site/renders/outside_73_tone.png" id="render-full-15-3">
</p>
</div>
<div>
<div>
<h3>Low Discrepancy Sampling</h3>
<p>I implemented sampling using the Sobol (0,2) sequence with a fast gray code technique from the <a href="http://www.pbrt.org/">PBRT book</a>. These samples have better distribution in many dimensions and can be used progressively, leading to faster render convergence rates.</p>
<div>
<div id="render-desc-16-1" data-file="dof_9_plain_uniform.png" data-sectionid="16" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/dof_9_plain_uniform.png" id="render-thumb-16-1"></p><div>
<h5>Uniform random</h5>
<p>9 samples of DOF with uniform random sampling</p>
</div>
</div>
<div id="render-desc-16-2" data-file="dof_9_plain_02.png" data-sectionid="16" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/dof_9_plain_02.png" id="render-thumb-16-2"></p><div>
<h5>Low-discrepancy</h5>
<p>9 samples of DOF with (0,2) sequence sampling</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/dof_9_plain_uniform.png" id="render-full-16-1">
<img src="https://thume.ca/ray-tracer-site/renders/dof_9_plain_02.png" id="render-full-16-2">
</p>
</div>
 <div>
<div>
<h3>Blender Export</h3>
<div>
<p>I put my final scene together in Blender and it took over 15 hours to do, if I had to do it entirely with conversion scripts and lua files it would have been infeasible. So I wrote a script using Blenderâ€™s Python API that exports all objects in the scene into OBJ files and a lua file that references them all and sets them up with the right materials.</p>
<p>I can then reference the objects defined in this lua file in my final sceneâ€™s lua file, while adding arrangements like portals that Blender canâ€™t do. It also exports object transforms separately so I can do things like replace a cube with a Mandelbox.</p>
<p>I used the same set of film emulation LUTs included in Blender so that I could match Cycles almost exactly.</p>
</div>
<div>
<div id="render-desc-17-1" data-file="blender_1.png" data-sectionid="17" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/blender_1.png" id="render-thumb-17-1"></p><div>
<h5>Blender</h5>
<p>Final scene in Blender</p>
</div>
</div>
<div id="render-desc-17-2" data-file="blender_2.png" data-sectionid="17" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/blender_2.png" id="render-thumb-17-2"></p><div>
<h5>Previewing</h5>
<p>Using Cycles to preview parts of the scene</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/blender_1.png" id="render-full-17-1">
<img src="https://thume.ca/ray-tracer-site/renders/blender_2.png" id="render-full-17-2">
</p>
</div>
<div>
<div>
<h3>Progressive Rendering</h3>
<p>I made my renderer progressive by saving a matrix of Sobol sampler states and running my sampler in epochs of gradually increasing sample count, while keeping the samples for each pixel in each epoch in the innermost loop for cache/branch prediction efficiency. Every epoch it saves an image of its progress so far.</p>
<div>
<div id="render-desc-18-1" data-file="cornell_1.png" data-sectionid="18" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_1.png" id="render-thumb-18-1"></p><div>
<h5>1 sample</h5>
<p>1 sample image of a Cornell box</p>
</div>
</div>
<div id="render-desc-18-2" data-file="cornell_9.png" data-sectionid="18" data-renderid="2">
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_9.png" id="render-thumb-18-2"></p><div>
<h5>9 samples</h5>
<p>9 samples image from same run</p>
</div>
</div>
<div id="render-desc-18-3" data-file="cornell_73.png" data-sectionid="18" data-renderid="3">
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_73.png" id="render-thumb-18-3"></p><div>
<h5>73 samples</h5>
<p>73 samples image from same run</p>
</div>
</div>
<div id="render-desc-18-4" data-file="cornell_10313_area.png" data-sectionid="18" data-renderid="4">
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_10313_area.png" id="render-thumb-18-4"></p><div>
<h5>10313 samples</h5>
<p>10313 samples image from same run</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/cornell_1.png" id="render-full-18-1">
<img src="https://thume.ca/ray-tracer-site/renders/cornell_9.png" id="render-full-18-2">
<img src="https://thume.ca/ray-tracer-site/renders/cornell_73.png" id="render-full-18-3">
<img src="https://thume.ca/ray-tracer-site/renders/cornell_10313_area.png" id="render-full-18-4">
</p>
</div>
<div>
<div>
<h3>Multithreading &amp; Bar</h3>
<div>
<p>I made my renderer multithreaded using all available hyperthreads using the C++11 threading library. It distributes rows of image alternately to each thread for evenly distributed difficulty. I implemented a multi-threaded progress bar with proper locking to print nice console progress with ANSI escape codes.</p>
<p>It scales linearly with number of cores. I rendered most images on this page on a 64 core pre-emptible Google Cloud instance for only $0.50 an hour.</p>
</div>
<div>
<div id="render-desc-19-1" data-file="progress_crop.png" data-sectionid="19" data-renderid="1">
<p><img src="https://thume.ca/ray-tracer-site/renders/progress_crop.png" id="render-thumb-19-1"></p><div>
<h5>Progress bar</h5>
<p>Console output of a render</p>
</div>
</div>
</div>
</div>
<p><img src="https://thume.ca/ray-tracer-site/renders/progress_crop.png" id="render-full-19-1">
</p>
</div>
<div>
<div>
<h3>Misc. Acceleration</h3>
<div>
<p>I implemented a number of optimizations so that I could render large scenes with path tracing in a reasonable amount of time. I donâ€™t have graphs because these are mostly asymptotic or varying by scene so I could make the graphs show whatever I wanted.</p>
<ul>
<li>So that I could render large meshes, I integrated the <a href="https://github.com/brandonpelfrey/Fast-BVH">FastBVH</a> bounding box hierarchy library into my mesh primitive. This took about 2 hours.</li>
<li>I implemented my own bounding box hierachy checks at the scene node level, although that hierarchy is just the manually constructed hierarchy from Lua.</li>
<li>I baked the hierarchical transform down into each <code>GeometryNode</code> and only apply the transform if it is not the identity, to reduce the number of matrix multiplies per ray per object.</li>
<li>When implementing formulas, I follow best practices for floating point performance and avoid or precompute square roots, trig functions and divisions wherever possible using a number of standard tricks.</li>
<li>I use the Moller-Trumbore ray-triangle intersection method which is just an algebraic improvement on the one presented in class, but is much faster.</li>
</ul>
</div>
</div>
</div>
<div>
<div>
<h3>Other Credits</h3>
<div>
<ul>
<li>I learned a lot of what I know from sitting down and reading the <a href="https://www.pbrt.org/">PBRT book</a>, many parts of my ray tracer are based on reading the theory and rationale for doing something a certain way in my paper copy of the book while reading it start to finish, and then coding up my own version later. Things built following the methods from PBRT include my path tracing, importance sampling, area light sampling, depth of field and my low-discrepancy sequence generation.</li>
<li>The primitive signed distance function equations I use for modeling including the box, sphere, ellipsoid and hex bar all come from <a href="http://iquilezles.org/www/articles/distfunctions/distfunctions.htm">Inigo Quilezâ€™s SDF modeling page</a>.</li>
<li>My Mandelbox distance estimator is based on code from <a href="http://blog.hvidtfeldts.net/index.php/2011/11/distance-estimated-3d-fractals-vi-the-mandelbox/">a blog post</a> by Mikael Hvidtfeldt Christensen explaining the theory behind the distance estimator. It is nigh-impossible to implement a Mandelbox estimator without referencing code since the way it is designed is based on aesthetics and approximations that donâ€™t always have a perfect theoretical basis.</li>
<li>All the models and textures in all my scenes except the Mandelbox pedestal and desk were downloaded from the internet, although I re-did the materials myself using the Disney BRDF. The Minecraft hill was sculpted by me in Minecraft and then exported using the jmc2obj tool. Links: <a href="https://www.modelplusmodel.com/tech/electronics/apple-macbook-pro-15.html">Macbook model</a>, <a href="https://www.blendswap.com/blends/view/73501">stapler model</a>, <a href="https://pbrt.org/scenes-v3.html">book model</a>, <a href="https://www.cgbookcase.com/">CGBookCase</a>, <a href="https://cc0textures.com/">CC0Textures</a>, <a href="https://3dtextures.me/">3DTextures</a>, <a href="https://texturehaven.com/">TextureHaven</a>, <a href="https://hdrihaven.com/">HDRIHaven</a>.</li>
<li>The Lego in my final scene was based on <a href="https://www.mecabricks.com/en/models/nKZvmlQbjG6">a model</a> found on the <a href="https://www.mecabricks.com/">Mecabricks Lego CAD site</a>, simplified a bit by me, and then exported.</li>
<li>The Film emulation LUTs I load in for tone mapping come from <a href="https://github.com/sobotka/filmic-blender">Troy Sobotkaâ€™s Filmic Blender addon</a>, which was later incorporated directly into Blender. I also had an email conversation with Troy where he clarified some of my understanding of how the different colour spaces fit together.</li>
</ul>
</div>
</div>
</div>
<div>
<div>
<h5>Website Credits</h5>
<p>
CSS template thanks to <a href="http://getskeleton.com/">Skeleton</a>, magnifying glass thanks to <a href="https://github.com/paulkr/blowup.js">blowup.js</a>. The image and animation gallery, the rest of the page, and the renders on it I did myself.
</p>
</div>
</div>
</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>