<!DOCTYPE html>
<html lang="en">
<head>
    <title>
There Is No (Real World) Use Case for Face Super Resolution - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="There Is No (Real World) Use Case for Face Super Resolution - linksfor.dev(s)"/>
    <meta property="og:description" content="A blog post about the PULSE paper and the general problems of super resolution."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://zentralwerkstatt.org/post_PULSE.html?3="/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - There Is No (Real World) Use Case for Face Super Resolution</title>
<div class="readable">
        <h1>There Is No (Real World) Use Case for Face Super Resolution</h1>
            <div>Reading time: 6-7 minutes</div>
        <div>Posted here: 22 Jun 2020</div>
        <p><a href="https://zentralwerkstatt.org/post_PULSE.html?3=">https://zentralwerkstatt.org/post_PULSE.html?3=</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>
          <div>
<p>In the past few days, a disturbing image of a “white face” Obama has been making the rounds on Twitter. The image was created with the help of a new method for upscaling images<span data-cites="menon_2020"><a href="#fn1" id="fnref1"><sup>1</sup></a></span> called PULSE. The researchers behind the method describe PULSE as a new way to achieve super resolution on images of human faces, i.e.&nbsp;to produce high resolution images of human faces from low resolution images of human faces.</p>
<twitter-widget id="twitter-widget-0" data-tweet-id="1274314622447820801"></twitter-widget>

<p>Super resolution, in general, is one of the major problems in computer vision that have received increased attention over the past few years, as deep learning methods have slowly revolutionized the field.<span data-cites="wang_2019b"><a href="#fn2" id="fnref2"><sup>2</sup></a></span></p>
<p>Lately, researchers have increasingly started to employ generative adversarial networks<span data-cites="goodfellow_2014a"><a href="#fn3" id="fnref3"><sup>3</sup></a></span> to help with super resolution tasks. Importantly, using GANs, researchers have claimed to have gone beyond the “deconvolution limit,”<span data-cites="schawinski_2017"><a href="#fn4" id="fnref4"><sup>4</sup></a></span> i.e.&nbsp;beyond what is “naturally” reconstructable from a limited amount of information.<a href="#fn5" id="fnref5"><sup>5</sup></a></p>
<p>The deconvolution limit is a “hard” limit. Hence, transcending this limit has, for decades, been a topos in science fiction. The most prominent example is of course <em>Blade Runner</em>:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/hHwjceFcF2Q" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p>A more "recent" one is this <em>X-Files</em> scene:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/6LYmlWXuW_s" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
</iframe>
<p>From there on, transcending the deconvolution limit has <a href="https://knowyourmeme.com/memes/zoom-and-enhance">become an Internet meme</a> (what a time to be alive, that this is a valid sentence), with shows like Navy CIS intentionally exploiting the ridiculousness of infinite super resolution.</p>
<p>Thus, there must be a catch. In case of GANs, the catch is this: GANs are only able to take the super resolution process beyond the deconvolution limit because they introduce <em>additional information about the problem domain</em> in the form of a latent space filled to the brink with images. In other words: GANs cannot reconstruct what is un-reconstructable, but they can take best guesses <em>based exclusively on the additional information supplied</em>. In other words: super resolution, with GANs, is always, to a degree, hallucination.</p>
<p>The Doom Guy image below is a great example (and is, at this point, almost a <a href="https://www.doomworld.com/forum/topic/99021-doom-neural-upscale-2x-v-10/">nerdy inside joke</a>). Coming from an 8-bit video game, an“unpixelated” version of this face does simply not exist. Nevertheless, PULSE is able to produce something “realistic” by searching the latent space of a GAN (StyleGAN trained on FFHQ) for a closest match. And that, right there, is the problem: a latent space full of white faces will always return some variation of a white face.</p>
<twitter-widget id="twitter-widget-1" data-tweet-id="1274245778551328769"></twitter-widget>

<p>Interestingly, the dataset that the underlying StyleGAN was trained on is more diverse than the results would suggest. Alexia Jolicoeur-Martineau and Tom White (@dribnet) have pointed out that the problems are likely an artifact of mode collapse, a classic open problem in GAN applications.</p>
<twitter-widget id="twitter-widget-2" data-tweet-id="1274447446760927232"></twitter-widget>

<p>And indeed, Mario Klingenmann has shown that you can get marginally better results by starting the optimization form a different place in latent space.</p>
<twitter-widget id="twitter-widget-3" data-tweet-id="1274636495941500928"></twitter-widget>

<p>The problem with face super resolution, however, goes beyond the disturbing bias issues that this particular method has. <strong>There is simply no real world use case for face super resolution.</strong> The story might be different for video games, or the next <em>Avengers</em> movie, but the limitless upscaling of human faces from unrecognizably degraded images simply has no place in the real world.</p>
<p>The researchers behind PULSE are aware of this, of course, and were quick to emphasize that PULSE cannot be utilized to identify people. We all know, however, that law enforcement will use it at some point, no matter the disclaimers.<a href="#fn11" id="fnref6"><sup>6</sup></a> <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">COMPAS has shown this much</a>.</p>
<p>In other words, the problem is this (from the Duke press release):</p>
<blockquote>
<p>While the researchers focused on faces as a proof of concept, the same technique could in theory take low-res shots of almost anything and create sharp, realistic-looking pictures, with applications ranging from medicine and microscopy to astronomy and satellite imagery […].</p>
</blockquote>
<p>Why faces then? Nothing good ever comes from face datasets, as <a href="https://ahprojects.com/megapixels/">Adam Harvey’s <em>megapixels</em> project</a> reminds us. Deep learning has opened up a plethora of amazing possibilities in computer vision and beyond. None of them absolutely depend on (real world) face datasets. Yes, faces can be nicely aligned. Yes, faces are easy to come by. Yes, generating realistic faces is more impressive than generating realistic, I don’t know, vaccuums (to just pick a random ILSVRC-2012 class). The responsibility, however, that comes with face datasets, outweighs all of this. <strong>Malicious applications will always be, rightfully, presumed by default.</strong></p>
<section>
<hr>
<ol>
<li id="fn1"><p>Sachit Menon et al., “PULSE: Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models,” in <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2020, 2437–45.<a href="#fnref1">↩</a></p></li>
<li id="fn1"><p>Zhihao Wang, Jian Chen, and Steven CH Hoi, “Deep Learning for Image Super-Resolution: A Survey,” <em>arXiv Preprint arXiv:1902.06068</em>, 2019.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Ian Goodfellow et al., “Generative Adversarial Nets,” in <em>Advances in Neural Information Processing Systems</em>, 2014, 2672–80.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p>Kevin Schawinski et al., “Generative Adversarial Networks Recover Features in Astrophysical Images of Galaxies Beyond the Deconvolution Limit,” <em>Monthly Notices of the Royal Astronomical Society: Letters</em> 467, no. 1 (2017): L110–L114.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Technically, this is the <a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem">Shannon-Nyquist limit</a>.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>The original <a href="https://today.duke.edu/2020/06/artificial-intelligence-makes-blurry-faces-look-more-60-times-sharper?fbclid=IwAR3WAMI4pgsQ6uSyOoSR5NOFt7kG2uHPt3VO4eeks68I2GjYfu0bqqhDpt4">Duke press announcement</a> had this line (emphasis mine): “The system cannot be used to identify people, the researchers say: It won’t turn an out-of-focus, unrecognizable photo from a security camera into a crystal clear image of a real person. Rather, it is capable of generating new faces that don’t exist, but <em>look plausibly real</em>.” In the meantime (after it went viral, <a href="https://github.com/adamian98/pulse/commit/5a130c91862975234f1a77a982e4cefa58e6e0b9#diff-04c6e90faac2675aa89e2176d2eec7d8">as the commit history shows</a>), the researchers behind PULSE have added a more extensive disclaimer to the project’s GitHub README.<a href="#fnref6">↩</a></p></li>
</ol>
</section>
</div>
        </div></div></div>
    </div>
    <footer>
        <div>created by <a href="https://buildstarted.com">buildstarted</a> &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>