<!DOCTYPE html>
<html lang="en">
<head>
    <title>
What&#x2019;s up with my branch on GPU? -
linksfor.dev(s)
    </title>
    <meta charset="utf-8">
    <meta name="Description" content="A curated source of links that devs might find interesting. Updated around the clock." />
    <meta name="google" value="notranslate">
    <style type="text/css">
        html {
            font-family: sans-serif;
            line-height: 1.15;
            -webkit-text-size-adjust: 100%;
            -webkit-tap-highlight-color: transparent;
            height: 100%;
        }

        *, ::after, ::before {
            box-sizing: border-box;
        }

        body {
            margin: 0;
            font-family: -apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";
            font-size: 1rem;
            font-weight: 400;
            line-height: 1.5;
            color: #60656a;
            text-align: left;
            background-color: #323b44;
        }

        h1 {
            font-size: 6rem;
            font-weight: 300;
            line-height: 1.2;
            margin-top: 0;
            margin-bottom: 0.5rem;
            margin-bottom: 0.5rem
        }

        a {
            color: #007bff;
            color: #ccc;
            text-decoration: none;
            background-color: transparent;
            word-break: break-all;
        }

        .unseen a {
            font-weight: bold;
        }

        h3 {
            margin-top: 0;
            padding-top: 0;
            font-weight: normal;
        }

        .grid {
            -ms-flex-direction: column;
            flex-direction: column;
            width: 1024px;
            margin: 0 auto;
            flex: 1 0 auto;
        }

        .row {
            -ms-flex-direction: row;
            flex-direction: row;
            width: 100%;
            -ms-flex-wrap: wrap;
            flex-wrap: wrap;
            display: -ms-flexbox;
            display: flex;
        }

        .col {
            margin: 0 10px 0 10px;
            box-sizing: border-box;
            vertical-align: top;
        }

        .col-3-of-4, .col-6-of-8, .col-9-of-12 {
            width: calc(75% - 20px);
        }

        .col-1-of-4, .col-2-of-8, .col-3-of-12 {
            width: calc(25% - 20px);
        }

        @media (max-width:1023px) {
            /* big landscape tablets, laptops, and desktops */
            body {
                overflow-x: hidden;
            }

            main {
                width: 99%;
            }

            h1 {
                font-size: 50px;
            }
        }

        .text-right {
            text-align: right;
        }

        footer {
            left: 0;
            width: 100%;
            margin-top: 2em;
            padding: 50px 0;
            text-align: center;
            -moz-box-sizing: border-box;
            -webkit-box-sizing: border-box;
            box-sizing: border-box;
        }

        .readable {
            color: #949ba2;
        }

        svg:not(:root).svg-inline--fa {
            color: #60656a;
            overflow: visible;
        }

        .svg-inline--fa.fa-w-12 {
            width: 0.75em;
        }

        svg:not(:root) {
            overflow: hidden;
        }

        .svg-inline--fa {
            display: inline-block;
            font-size: inherit;
            height: 1em;
            overflow: visible;
            vertical-align: -0.125em;
        }

        img {
            max-width: 100%;
        }

        .text-center {
            text-align: center;
        }

        .readable h1 {
            font-size: 2em;
        }
    </style>
</head>
<body>
    <div class="grid">
        
<div class="readable">
    <h1>What&#x2019;s up with my branch on GPU?</h1>
    <main class="page-content"> <p class="wrapper"> <article class="post h-entry"> <div class="post-content e-content"> <p>This post is a small writeup addressed to programmers who are interested to learn more about how GPU handles branching and targeted as an introduction to the topic. I recommend skimming through [<a href="https://fgiesen.wordpress.com/2011/07/09/a-trip-through-the-graphics-pipeline-2011-index/">1</a>], [<a href="http://cs149.stanford.edu/winter19/">2</a>] and [<a href="https://t.co/QG28evt7QR">8</a>] to get an idea of what GPU execution model looks like in general because here we&#x2019;re gonna take a closer look at one particular detail. A curious reader shall find all references at the end of the post. If you find any mistakes please reach out.</p> <h2 id="table-of-content">Table of content</h2> <h2 id="vocabulary">Vocabulary</h2>
<ul> <li>GPU - Graphics processing unit</li> <li>Flynn&#x2019;s taxonomy <ul> <li>SIMD - Single instruction multiple data</li> <li>SIMT - Single instruction multiple threads</li> </ul> </li> <li>SIMD wave - Thread executing in SIMD mode</li> <li>Lane - designated data stream in SIMD model</li> <li>SMT - Simultaneous multi-threading (Intel Hyper-threading)[<a href="http://cs149.stanford.edu/winter19/">2</a>] <ul> <li>Multiple threads share computational resources of a core</li> </ul> </li> <li>IMT - Interleaved multi-threading[<a href="http://cs149.stanford.edu/winter19/">2</a>] <ul> <li>Multiple threads share computational resources of a core but only one executes per clock</li> </ul> </li> <li>BB - Basic Block - linear sequence of instructions with only one jump at the end</li> <li>ILP - Instruction Level Parallelism[<a href="https://www.elsevier.com/books/computer-architecture/hennessy/978-0-12-811905-1">3</a>]</li> <li>ISA - Instruction Set Architecture</li>
</ul> <p>Throughout this post I&#x2019;m referring to this fictional taxonomy. It approximates how a modern GPU is organized.</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Hardware:
GPU  -+
      |- core 0 -+
      |          |- wave 0 +
      |          |         |- lane 0
      |          |         |- lane 1
      |          |         |- ...
      |          |         +- lane Q-1
      |          |
      |          |- ...
      |          +- wave M-1
      |            
      |- ...
      +- core N-1

* ALU - SIMD ALU unit for short

Software:
group +
      |- thread 0
      |- ...
      +- thread N-1
</code></pre></div></div>
<p>Other names:</p>
<ul> <li>core could be CU, SM, EU</li> <li>wave could be wavefront, HW thread, warp, context</li> <li>lane could be SW thread</li>
</ul> <h2 id="what-is-so-special-about-gpu-core-compared-to-cpu-core">What is so special about GPU core compared to CPU core?</h2>
<p>Any current generation single GPU core is less beefy compared to what you may encounter in CPU world: simple ILP/multi-issue[<a href="https://arxiv.org/pdf/1804.06826.pdf">6</a>] and prefetch[<a href="https://arxiv.org/pdf/1509.02308&amp;ved=0ahUKEwifl_P9rt7LAhXBVxoKHRsxDIYQFgg_MAk&amp;usg=AFQjCNGchkZRzkueGqHEz78QnmcIVCSXvg&amp;sig2=IdzxfrzQgNv8yq7e1mkeVg">5</a>], no speculation or branch/return prediction. All of this coupled with tiny caches frees up quite a lot of the die area which gets filled with more cores. Memory load/store machinery is able to handle bandwidths of an order of magnitude larger(not true for integrated/mobile GPUs) than that of a typical CPU at a cost of more latency. GPU employs SMT[<a href="http://cs149.stanford.edu/winter19/">2</a>] to hide this latency - while one wave is stalled, another utilizes free computation resources of a core. Typically the number of waves handled by one core depends on registers used and determined dynamically by allocating on a fixed register file[<a href="https://t.co/QG28evt7QR">8</a>]. The instruction scheduling is hybrid dynamic and static[<a href="https://arxiv.org/pdf/1804.06826.pdf">6</a>] [<a href="https://developer.amd.com/wp-content/resources/Vega_Shader_ISA_28July2017.pdf">11</a> 4.4]. SMT cores execute in SIMD mode yielding high number of FLOPS.
<img src="/assets/legend.png" alt="Figure 1"></p>
<h6 id="diagram-legend">Diagram legend</h6>
<p><img src="/assets/interleaving.png" alt="Figure 1"></p>
<h6 id="figure-1-execution-history-42">Figure 1. Execution history 4:2</h6>
<p>The image shows history of execution mask where the x axis is time from left to right and the y axis is lane id from top to bottom. If it does not make sense to you, please return to it after reading the next sections.
This is an illustration of how a GPU core execution history might look like for a fictional configuration: four waves share one sampler and two ALU units. Wave scheduler dispatches two instructions from two waves each cycle. When a wave stalls on memory access or long ALU operation, scheduler switches to another pair of waves making ALU units almost 100% busy all the time.</p><p>
<img src="/assets/interleaving_2.png" alt="Figure 2"></p></div></article></p>
<h6 id="figure-2-execution-history-41">Figure 2. Execution history 4:1</h6>
<p>This is the same workload but this time only one wave issues instructions each cycle. Note how the second ALU is starving.<br>
<img src="/assets/interleaving_3.png" alt="Figure 3"></p>
<h6 id="figure-3-execution-history-44">Figure 3. Execution history 4:4</h6>
<p>This time four instructions are issued each cycle. Note that ALUs are oversubscribed in this case so two waves idle almost all the time(actually it&#x2019;s a pitfall of the scheduling algorithm).<br>
<strong><em>Update</em></strong> Read more about scheduling challenges[<a href="http://www.joshbarczak.com/blog/?p=823#">12</a>].</p> <p>Real world GPUs have different configurations per core: some may have up to 40 waves per core and 4 ALUs, some have fixed 7 waves and 2 ALUs. It all depends on a variety of factors and is determined through thorough architecture simulation process.
Also real SIMD ALUs may have narrower width than those of waves they serve, it then takes multiple cycles to process one issued instruction, the multiplier is called &#x2018;chime&#x2019; length[<a href="https://www.elsevier.com/books/computer-architecture/hennessy/978-0-12-811905-1">3</a>].</p> <h2 id="what-is-coherencedivergence">What is coherence/divergence?</h2>
<p>Lets look at the following kernel:</p>
<h6 id="example-1">Example 1</h6>
<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">uint</span> <span class="n">lane_id</span> <span class="o">=</span> <span class="n">get_lane_id</span><span class="p">();</span>
<span class="k">if</span> <span class="p">(</span><span class="n">lane_id</span> <span class="o">&amp;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// Do smth
</span><span class="p">}</span>
<span class="c1">// Do some more
</span></code></pre></div></div>
<p>Here we see instruction stream where execution path depends on the id of the lane being executed. Apparently different lanes have different values. So what should happen? There are different approaches to tackle this problem [<a href="https://hal.archives-ouvertes.fr/hal-00622654/document">4</a>] but eventually they do approximately the same thing. One of such approaches is execution mask which I will focus on. This approach is employed by pre-Volta Nvidia and AMD GCN GPUs. The core of execution mask is that we keep a bit for each lane within wave. If a lane has 0 set to its corresponding execution bit no registers will be touched for that lane by the next issued instruction. Effectively the lane shouldn&#x2019;t feel the impact of all the executed instruction as long as it&#x2019;s execution bit is 0. The way it works is that a wave traverses control flow graph in depth first order keeping a history of branches taken. I think it&#x2019;s better to follow an example.<br>
So lets say we have waves of width 8. This is how execution mask will look like for the kernel:</p>
<h6 id="example-1-execution-mask-history">Example 1. Execution mask history</h6>
<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c1">// execution mask
</span><span class="n">uint</span> <span class="n">lane_id</span> <span class="o">=</span> <span class="n">get_lane_id</span><span class="p">();</span> <span class="c1">// 11111111
</span><span class="k">if</span> <span class="p">(</span><span class="n">lane_id</span> <span class="o">&amp;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// 11111111
</span> <span class="c1">// Do smth // 01010101
</span><span class="p">}</span>
<span class="c1">// Do some more // 11111111
</span></code></pre></div></div>
<p>Now, take a look at more complicated examples:</p>
<h6 id="example-2">Example 2</h6>
<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">uint</span> <span class="n">lane_id</span> <span class="o">=</span> <span class="n">get_lane_id</span><span class="p">();</span>
<span class="k">for</span> <span class="p">(</span><span class="n">uint</span> <span class="n">i</span> <span class="o">=</span> <span class="n">lane_id</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">16</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// Do smth
</span><span class="p">}</span>
</code></pre></div></div>
<h6 id="example-3">Example 3</h6>
<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">uint</span> <span class="n">lane_id</span> <span class="o">=</span> <span class="n">get_lane_id</span><span class="p">();</span>
<span class="k">if</span> <span class="p">(</span><span class="n">lane_id</span> <span class="o">&lt;</span> <span class="mi">16</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// Do smth
</span><span class="p">}</span> <span class="k">else</span> <span class="p">{</span> <span class="c1">// Do smth else
</span><span class="p">}</span>
</code></pre></div></div>
<p>You&#x2019;ll notice that history is needed. With execution mask approach usually some kind of stack is employed by the HW. A naive approach is to keep a stack of tuples (exec_mask, address) and add reconvergence instructions that pop a mask from the stack and change the instruction pointer for the wave. In that way a wave will have enough information to traverse the whole CFG for each lane.
From performance point of view, it takes a couple of cycles just to process a control flow instruction because of all the bookkeeping. And don&#x2019;t forget that the stack has limited depth.</p><p>
<strong><em>Update</em></strong> By courtesy of <a href="https://twitter.com/craigkolb">@craigkolb</a> I&#x2019;ve read [<a href="https://tangentvector.wordpress.com/2013/04/12/a-digression-on-divergence/">13</a>] in which it is noted that AMD GCN selects the path with the fewer number of threads first [<a href="https://developer.amd.com/wp-content/resources/Vega_Shader_ISA_28July2017.pdf">11</a>4.6] which guarantees that log2 depth of the mask stack is enough.</p>
<h3 id="hw-support-for-execution-mask">HW support for execution mask</h3>
<p>Now take a look at these control flow graphs(image from Wikipedia):<br>
<img src="/assets/Some_types_of_control_flow_graphs.png" alt="Figure 4"></p>
<h6 id="figure-4-some-types-of-control-flow-graphs">Figure 4. Some types of control flow graphs</h6>
<p>So what is the minimal set of mask control instructions we need to handle all cases? Here is how it looks in my toy ISA with implicit parallelization, explicit mask control and fully dynamic data hazard synchronization:</p>
<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">push_mask</span> <span class="n">BRANCH_END</span> <span class="c">; Push current mask and reconvergence pointer</span>
<span class="n">pop_mask</span> <span class="c">; Pop mask and jump to reconvergence instruction</span>
<span class="n">mask_nz</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="c">; Set execution bit, pop mask if all bits are zero</span> <span class="c">; Branch instruction is more complicated</span>
<span class="c">; Push current mask for reconvergence</span>
<span class="c">; Push mask for (r0.x == 0) for else block, if any lane takes the path</span>
<span class="c">; Set mask with (r0.x != 0), fallback to else in case no bit is 1</span>
<span class="n">br_push</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">ELSE</span><span class="p">,</span> <span class="n">CONVERGE</span> 
</code></pre></div></div>
<p>Lets take a look at how d) case might look like.</p> <div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">A</span><span class="o">:</span> <span class="n">br_push</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">D</span>
<span class="n">B</span><span class="o">:</span>
<span class="n">C</span><span class="o">:</span> <span class="n">mask_nz</span> <span class="n">r0</span><span class="p">.</span><span class="n">y</span> <span class="k">jmp</span> <span class="n">B</span>
<span class="n">D</span><span class="o">:</span> <span class="k">ret</span>
</code></pre></div></div>
<p>I&#x2019;m not an expert in control flow analysis or ISA design so I&#x2019;m sure there is a case that could not be tamed with my toy ISA, although it does not matter as structured CFG should be enough for everyone.</p> <p>Bottom line:</p>
<ul> <li>Divergence - emerging difference in execution paths taken by different lanes of the same wave</li> <li>Coherence - lack of divergence :)</li>
</ul> <h2 id="execution-mask-handling-examples">Execution mask handling examples</h2>
<h3 id="fictional-isa">Fictional ISA</h3>
<p>I compiled the previous code snippets into my toy ISA and run it with my simulator which produces cool pictures. Take a look at how it handles execution mask.<br>
<strong><em>Update</em></strong> Note that the toy simulator always selects true path first which is not the best method.</p>
<h6 id="example-1-1">Example 1</h6>
<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">; uint lane_id = get_lane_id();</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">lane_id</span>
<span class="c">; if (lane_id &amp; 1) {</span> <span class="n">push_mask</span> <span class="n">BRANCH_END</span> <span class="k">and</span> <span class="n">r0</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">u</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="n">mask_nz</span> <span class="n">r0</span><span class="p">.</span><span class="n">y</span>
<span class="n">LOOP_BEGIN</span><span class="o">:</span> <span class="c">; // Do smth</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="n">pop_mask</span> <span class="c">; pop mask and reconverge</span>
<span class="n">BRANCH_END</span><span class="o">:</span> <span class="c">; // Do some more</span> <span class="k">ret</span>
</code></pre></div></div>
<p><img src="/assets/branch_1.png" alt="Figure 5"></p>
<h6 id="figure-5-example-1-execution-history">Figure 5. Example 1 execution history</h6>
<p>Did you Notice the black area? It is wasted time. Some lanes are waiting for others to finish iterating.</p>
<h6 id="example-2-1">Example 2</h6>
<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">; uint lane_id = get_lane_id();</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">lane_id</span>
<span class="c">; for (uint i = lane_id; i &lt; 16; i++) {</span> <span class="n">push_mask</span> <span class="n">LOOP_END</span> <span class="c">; Push the current mask and the pointer to reconvergence instruction</span>
<span class="n">LOOP_PROLOG</span><span class="o">:</span> <span class="n">lt</span><span class="p">.</span><span class="n">u32</span> <span class="n">r0</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">u</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span> <span class="c">; r0.y &lt;- r0.x &lt; 16</span> <span class="k">add</span><span class="p">.</span><span class="n">u32</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">u</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c">; r0.x &lt;- r0.x + 1</span> <span class="n">mask_nz</span> <span class="n">r0</span><span class="p">.</span><span class="n">y</span> <span class="c">; exec bit &lt;- r0.y != 0 - when all bits are zero next mask is popped</span>
<span class="n">LOOP_BEGIN</span><span class="o">:</span> <span class="c">; // Do smth</span> <span class="k">jmp</span> <span class="n">LOOP_PROLOG</span>
<span class="n">LOOP_END</span><span class="o">:</span> <span class="c">; // }</span> <span class="k">ret</span>
</code></pre></div></div>
<p><img src="/assets/branch_2.png" alt="Figure 6"></p>
<h6 id="figure-6-example-2-execution-history">Figure 6. Example 2 execution history</h6>
<h6 id="example-3-1">Example 3</h6>
<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">lane_id</span> <span class="n">lt</span><span class="p">.</span><span class="n">u32</span> <span class="n">r0</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">u</span><span class="p">(</span><span class="mi">16</span><span class="p">)</span> <span class="c">; if (lane_id &lt; 16) {</span> <span class="c">; Push (current mask, CONVERGE) and (else mask, ELSE)</span> <span class="c">; Also set current execution bit to r0.y != 0</span> <span class="n">br_push</span> <span class="n">r0</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="n">ELSE</span><span class="p">,</span> <span class="n">CONVERGE</span>
<span class="n">THEN</span><span class="o">:</span> <span class="c">; // Do smth</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="n">pop_mask</span> <span class="c">; } else {</span>
<span class="n">ELSE</span><span class="o">:</span> <span class="c">; // Do smth else</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="k">mov</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">r0</span><span class="p">.</span><span class="n">x</span> <span class="n">pop_mask</span> <span class="c">; }</span>
<span class="n">CONVERGE</span><span class="o">:</span> <span class="k">ret</span>
</code></pre></div></div>
<p><img src="/assets/branch_3.png" alt="Figure 7"></p>
<h6 id="figure-7-example-3-execution-history">Figure 7. Example 3 execution history</h6> <h3 id="amd-gcn-isa">AMD GCN ISA</h3>
<p><strong><em>Update</em></strong> GCN also uses an explicit mask handling, you can read more about it here[<a href="https://developer.amd.com/wp-content/resources/Vega_Shader_ISA_28July2017.pdf">11</a> 4.x]. I decided it&#x2019;s worth putting some examples with their ISA, thanks to <a href="http://shader-playground.timjones.io">shader-playground</a> it is easy. Maybe some day I&#x2019;ll come across a simulator and pull out some cool diagrams.
Note that the compiler is smart, you may get a different result. I tried to fool the compiler into not optimizing my branches by putting pointer chase loops in there then cleaned up the assembly, I&#x2019;m not a GCN expert so some necessary nops might&#x2019;ve been omitted.</p><p>
Also note that S_CBRANCH_I/G_FORK and S_CBRANCH_JOIN instructions are not used in these snippets because of the simplicity, so the mask stack is not covered.</p>
<h6 id="example-1-2">Example 1</h6>
<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">; uint lane_id = get_lane_id();</span>
<span class="c">; GCN uses 64 wave width, so lane_id = thread_id &amp; 63</span> <span class="n">v_mov_b32</span> <span class="n">v1</span><span class="p">,</span> <span class="mh">0x00000400</span> <span class="c">; 1024 - group size</span> <span class="n">v_mad_u32_u24</span> <span class="n">v0</span><span class="p">,</span> <span class="n">s12</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v0</span> <span class="c">; thread_id calculation</span> <span class="n">v_and_b32</span> <span class="n">v1</span><span class="p">,</span> <span class="mi">63</span><span class="p">,</span> <span class="n">v0</span>
<span class="c">; if (lane_id &amp; 1) {</span> <span class="n">v_and_b32</span> <span class="n">v2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">v0</span> <span class="n">s_mov_b64</span> <span class="n">s</span><span class="err">[</span><span class="mi">0</span><span class="o">:</span><span class="mi">1</span><span class="err">]</span><span class="p">,</span> <span class="n">exec</span> <span class="c">; Save the execution mask</span> <span class="n">v_cmpx_ne_u32</span> <span class="n">exec</span><span class="p">,</span> <span class="n">v2</span><span class="p">,</span> <span class="mi">0</span> <span class="n">s_cbranch_execz</span> <span class="n">ELSE</span>
<span class="c">; // Do smth</span>
<span class="n">ELSE</span><span class="o">:</span>
<span class="c">; }</span>
<span class="c">; // Do some more</span> <span class="n">s_mov_b64</span> <span class="n">exec</span><span class="p">,</span> <span class="n">s</span><span class="err">[</span><span class="mi">0</span><span class="o">:</span><span class="mi">1</span><span class="err">]</span> <span class="c">; Restore the execution mask</span> <span class="n">s_endpgm</span>
</code></pre></div></div>
<h6 id="example-2-2">Example 2</h6>
<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">; uint lane_id = get_lane_id();</span> <span class="n">v_mov_b32</span> <span class="n">v1</span><span class="p">,</span> <span class="mh">0x00000400</span> <span class="n">v_mad_u32_u24</span> <span class="n">v0</span><span class="p">,</span> <span class="n">s8</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v0</span> <span class="c">; Not sure why s8 this time and not s12</span> <span class="n">v_and_b32</span> <span class="n">v1</span><span class="p">,</span> <span class="mi">63</span><span class="p">,</span> <span class="n">v0</span>
<span class="c">; LOOP PROLOG</span> <span class="n">s_mov_b64</span> <span class="n">s</span><span class="err">[</span><span class="mi">0</span><span class="o">:</span><span class="mi">1</span><span class="err">]</span><span class="p">,</span> <span class="n">exec</span> <span class="c">; Save the execution mask</span> <span class="n">v_mov_b32</span> <span class="n">v2</span><span class="p">,</span> <span class="n">v1</span> <span class="n">v_cmp_le_u32</span> <span class="n">vcc</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">v1</span> <span class="n">s_andn2_b64</span> <span class="n">exec</span><span class="p">,</span> <span class="n">exec</span><span class="p">,</span> <span class="n">vcc</span> <span class="n">s_cbranch_execz</span> <span class="n">LOOP_END</span>
<span class="c">; for (uint i = lane_id; i &lt; 16; i++) {</span>
<span class="n">LOOP_BEGIN</span><span class="o">:</span> <span class="c">; // Do smth</span> <span class="n">v_add_u32</span> <span class="n">v2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">v2</span> <span class="n">v_cmp_le_u32</span> <span class="n">vcc</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="n">v2</span> <span class="n">s_andn2_b64</span> <span class="n">exec</span><span class="p">,</span> <span class="n">exec</span><span class="p">,</span> <span class="n">vcc</span> <span class="c">; Mask out lanes which are beyond loop limit</span> <span class="n">s_cbranch_execnz</span> <span class="n">LOOP_BEGIN</span>
<span class="n">LOOP_END</span><span class="o">:</span> <span class="c">; // }</span> <span class="n">s_mov_b64</span> <span class="n">exec</span><span class="p">,</span> <span class="n">s</span><span class="err">[</span><span class="mi">0</span><span class="o">:</span><span class="mi">1</span><span class="err">]</span> <span class="c">; Restore the execution mask</span> <span class="n">s_endpgm</span>
</code></pre></div></div>
<h6 id="example-3-2">Example 3</h6>
<div class="language-nasm highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">; uint lane_id = get_lane_id();</span> <span class="n">v_mov_b32</span> <span class="n">v1</span><span class="p">,</span> <span class="mh">0x00000400</span> <span class="n">v_mad_u32_u24</span> <span class="n">v0</span><span class="p">,</span> <span class="n">s12</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v0</span> <span class="n">v_and_b32</span> <span class="n">v1</span><span class="p">,</span> <span class="mi">63</span><span class="p">,</span> <span class="n">v0</span> <span class="n">v_and_b32</span> <span class="n">v2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">v0</span> <span class="n">s_mov_b64</span> <span class="n">s</span><span class="err">[</span><span class="mi">0</span><span class="o">:</span><span class="mi">1</span><span class="err">]</span><span class="p">,</span> <span class="n">exec</span> <span class="c">; Save the execution mask</span>
<span class="c">; if (lane_id &lt; 16) {</span> <span class="n">v_cmpx_lt_u32</span> <span class="n">exec</span><span class="p">,</span> <span class="n">v1</span><span class="p">,</span> <span class="mi">16</span> <span class="n">s_cbranch_execz</span> <span class="n">ELSE</span> <span class="c">; Skip if all bits are zero</span>
<span class="c">; // Do smth</span>
<span class="c">; } else {</span>
<span class="n">ELSE</span><span class="o">:</span> <span class="n">s_andn2_b64</span> <span class="n">exec</span><span class="p">,</span> <span class="n">s</span><span class="err">[</span><span class="mi">0</span><span class="o">:</span><span class="mi">1</span><span class="err">]</span><span class="p">,</span> <span class="n">exec</span> <span class="c">; Inverse the mask and &amp; with previous</span> <span class="n">s_cbranch_execz</span> <span class="n">CONVERGE</span> <span class="c">; Skip if all bits are zero</span>
<span class="c">; // Do smth else</span>
<span class="c">; }</span>
<span class="n">CONVERGE</span><span class="o">:</span> <span class="n">s_mov_b64</span> <span class="n">exec</span><span class="p">,</span> <span class="n">s</span><span class="err">[</span><span class="mi">0</span><span class="o">:</span><span class="mi">1</span><span class="err">]</span> <span class="c">; Restore the execution mask</span>
<span class="c">; // Do some more</span> <span class="n">s_endpgm</span>
</code></pre></div></div>
<h2 id="how-to-fight-divergence">How to fight divergence?</h2>
<p>I tried to come up with a simple yet complete illustration for the inefficiency introduced by combining divergent lanes.<br>
Imagine a simple kernel like this:</p>
<div class="language-c++ highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">uint</span> <span class="n">thread_id</span> <span class="o">=</span> <span class="n">get_thread_id</span><span class="p">();</span>
<span class="n">uint</span> <span class="n">iter_count</span> <span class="o">=</span> <span class="n">memory</span><span class="p">[</span><span class="n">thread_id</span><span class="p">];</span>
<span class="k">for</span> <span class="p">(</span><span class="n">uint</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">iter_count</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span> <span class="c1">// Do smth
</span><span class="p">}</span>
</code></pre></div></div>
<p>Let&#x2019;s spawn 256 threads and measure the duration:<br>
<img src="/assets/rand.png" alt="Figure 8"></p>
<h6 id="figure-8-divergent-threads-execution-time">Figure 8. Divergent threads execution time</h6>
<p>The x axis is SW thread id, the y axis is clock cycles; the different bars show how much time is wasted by grouping threads with different wave widths compared to single threaded execution.
The execution time of a wave is equal to the maximum execution time among confined lanes. You can see that the performance is already ruined at SIMD8, further widening just makes it slightly worse.</p><p>
<img src="/assets/sorted.png" alt="Figure 9"></p>
<h6 id="figure-9-coherent-threads-execution-time">Figure 9. Coherent threads execution time</h6>
<p>This figure shows the same bars but this time iteration counts are sorted over thread ids, so that threads with similar iteration counts get dispatched to the same wave.<br>
For this example the potential speedup is around 2x.</p> <p>Of course the example is too simple but I hope you get the idea: execution divergence stems from data divergence, so keep your CFG simple and data coherent.<br>
For example, if you are writing a ray tracer, grouping rays with similar direction and position could be beneficial because they are likely to be traversing the same nodes in BVH. For more details please follow [<a href="https://www.eecis.udel.edu/~cavazos/cisc879-spring2012/papers/a3-han.pdf">10</a>] and related articles.</p> <p>It&#x2019;s worth mentioning that there are some techniques to grapple with divergence on HW level, some of them are Dynamic Warp Formation[<a href="http://www.cs.cmu.edu/afs/cs/academic/class/15869-f11/www/readings/fung07_dynamicwarp.pdf">7</a>] and predicated execution for small branches.</p> <p>[1]<a href="https://fgiesen.wordpress.com/2011/07/09/a-trip-through-the-graphics-pipeline-2011-index/">A trip through the Graphics Pipeline</a></p> <p>[2]<a href="http://cs149.stanford.edu/winter19/">Kayvon Fatahalian: PARALLEL COMPUTING</a></p> <p>[3]<a href="https://www.elsevier.com/books/computer-architecture/hennessy/978-0-12-811905-1">Computer Architecture A Quantitative Approach</a></p> <p>[4]<a href="https://hal.archives-ouvertes.fr/hal-00622654/document">Stack-less SIMT reconvergence at low cost</a></p> <p>[5]<a href="https://arxiv.org/pdf/1509.02308&amp;ved=0ahUKEwifl_P9rt7LAhXBVxoKHRsxDIYQFgg_MAk&amp;usg=AFQjCNGchkZRzkueGqHEz78QnmcIVCSXvg&amp;sig2=IdzxfrzQgNv8yq7e1mkeVg">Dissecting GPU memory hierarchy through microbenchmarking</a></p> <p>[6]<a href="https://arxiv.org/pdf/1804.06826.pdf">Dissecting the NVIDIA Volta GPU Architecture via Microbenchmarking</a></p> <p>[7]<a href="http://www.cs.cmu.edu/afs/cs/academic/class/15869-f11/www/readings/fung07_dynamicwarp.pdf">Dynamic Warp Formation and Scheduling for Efficient GPU Control Flow</a></p> <p>[8]<a href="https://t.co/QG28evt7QR">Maurizio Cerrato: GPU Architectures</a></p> <p>[9]<a href="https://aschrein.github.io/guppy/">Toy GPU simulator</a></p> <p>[10]<a href="https://www.eecis.udel.edu/~cavazos/cisc879-spring2012/papers/a3-han.pdf">Reducing Branch Divergence in GPU Programs</a></p> <p>[11]<a href="https://developer.amd.com/wp-content/resources/Vega_Shader_ISA_28July2017.pdf">&#x201C;Vega&#x201D; Instruction Set Architecture</a></p> <p>[12]<a href="http://www.joshbarczak.com/blog/?p=823#">Joshua Barczak:Simulating Shader Execution for GCN</a></p> <p>[13]<a href="https://tangentvector.wordpress.com/2013/04/12/a-digression-on-divergence/">Tangent Vector: A Digression on Divergence</a></p> <a class="u-url" href="/jekyll/update/2019/06/13/whatsup-with-my-branches-on-gpu.html"></a> </main>
</div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2019 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
    </footer>
    
</body>
</html>