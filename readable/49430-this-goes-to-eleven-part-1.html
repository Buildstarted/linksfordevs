<!DOCTYPE html>
<html lang="en">
<head>
    <title>
This Goes to Eleven (Part 1/&#x221E;) -
linksfor.dev(s)
    </title>
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta charset="utf-8">
    <meta name="Description" content="A curated source of links that devs might find interesting. Updated around the clock." />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        
<div class="readable">
    <div id="readOverlay" class="style-ebook"><div id="readInner" class="margin-medium size-medium"><h1>This Goes to Eleven (Part 1/∞)</h1><div><div id="" class="page__content"><p>Let’s get in the ring and show what AVX/AVX2 intrinsics can really do for a non-trivial problem, and even discuss potential improvements that future CoreCLR versions could bring to the table.</p><p>Everyone needs to sort arrays, once in a while, and many algorithms we take for granted rely on doing so. We think of it as a <em>solved</em> problem and that nothing can be <em>further</em> done about it in 2020, except for waiting for newer, marginally faster machines to pop-up<sup id="fnref:0"><a href="#fn:0" class="footnote">1</a></sup>. However, that is not the case, and while I’m not the first to have thoughts about it; or the best at implementing it, if you join me in this rather long journey, we’ll end up with a replacement function for <code class="highlighter-rouge">Array.Sort</code>, written in pure C# that outperforms CoreCLR’s C++<sup id="fnref:3"><a href="#fn:3" class="footnote">2</a></sup> code by a factor north of 10x on most modern Intel CPUs, and north of 11x on my laptop.<br>Sounds interesting? If so, down the rabbit hole we go…</p><table class="notice--warning"><tbody><tr><td><span class="uk-label">Note</span></td><td><p>In the final days before posting this series, Intel started seeding a CPU microcode update that is/was affecting the performance of the released version of CoreCLR 3.0/3.1 quite considerably. I managed to stir up a <a href="https://twitter.com/damageboy/status/1194751035136450560">small commotion</a> as this was unraveling in my benchmarks. As it happened, my code was (not coincidentally) less affected by this change, while CoreCLRs <code class="highlighter-rouge">Array.Sort()</code><a href="https://github.com/dotnet/coreclr/issues/27877">took a 20% nosedive</a>. Let it never be said I’m nothing less than chivalrous, for I rolled back the microcode update, and for this <strong>entire</strong> series, I’m going to run against a much faster version of <code class="highlighter-rouge">Array.Sort()</code> than what you, the reader, are probably using, Assuming you update your machine from time to time. For the technically inclined, here’s a whole footnote<sup id="fnref:4"><a href="#fn:4" class="footnote">3</a></sup> on how to double-check what your machine is actually running. I also opened two issues in the CoreCLR repo about attempting to mitigate this both in CoreCLRs C++ code and separately in the JIT. If/when there is movement on those fronts, the microcode you’re running will become less of an issue, to begin with, but for now, this just adds another level of unwarranted complexity to our lives.</p></td></tr></tbody></table><p>A while back now, I was reading the post by Stephen Toub about <a href="https://devblogs.microsoft.com/dotnet/performance-improvements-in-net-core-3-0/">Improvements in CoreCLR 3.0</a>, and it became apparent that hardware intrinsics were common to many of these, and that so many parts of CoreCLR could still be sped up with these techniques, that one thing led to another, and I decided an attempt to apply hardware intrinsics to a larger problem than I had previously done myself was in order. To see if I could rise to the challenge, I decided to take on array sorting and see how far I can go.</p><p>What I came up with eventually would become a re-write of <code class="highlighter-rouge">Array.Sort()</code> with AVX2 hardware intrinsics. Fortunately, choosing sorting and focusing on QuickSort makes for a great blog post series, since:</p><ul><li>Everyone should be familiar with the domain and even the original (sorting is the bread and butter of learning computer science, really, and QuickSort is the queen of all sorting algorithms).</li><li>It’s relatively easy to explain/refresh on the original.</li><li>If I can make it there, I can make it anywhere.</li><li>I had no idea how to do it.</li></ul><p>I started with searching various keywords and found an interesting paper titled: <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1009.7773&amp;rep=rep1&amp;type=pdf">Fast Quicksort Implementation Using AVX Instructions</a> by Shay Gueron and Vlad Krasnov. That title alone made me think this is about to be a walk in the park. While initially promising, it wasn’t good enough as a drop-in replacement for <code class="highlighter-rouge">Array.Sort</code> for reasons I’ll shortly go into. I ended up having a lot of fun expanding on their basic approach. I will submit a proper pull-request to start a discussion with CoreCLR devs about integrating this code into the main <a href="https://github.com/dotnet/runtime">dotnet/runtime</a> repository, but for now, let’s talk about sorting.</p><p>Since there’s a lot to go over here, I’ve split it up into no less than 6 parts:</p><ol><li>In this part, we start with a refresher on QuickSort and how it compares to <code class="highlighter-rouge">Array.Sort()</code>. If you don’t need a refresher, skip it and get right down to part 2 and onwards. I recommend skimming through, mostly because I’ve got excellent visualizations which should be in the back of everyone’s mind as we deal with vectorization &amp; optimization later.</li><li>In <a href="/2020-01-29/this-goes-to-eleven-pt2">part 2</a>, we go over the basics of vectorized hardware intrinsics, vector types, and go over a handful of vectorized instructions we’ll use in part 3. We still won’t be sorting anything.</li><li>In <a href="/2020-01-30/this-goes-to-eleven-pt3">part 3</a>, we go through the initial code for the vectorized sorting, and we’ll start seeing some payoff. We finish agonizing courtesy of the CPU’s Branch Predictor, throwing a wrench into our attempts.</li><li>In part 4, we go over a handful of optimization approaches that I attempted trying to get the vectorized partitioning to run faster. We’ll see what worked and what didn’t.</li><li>In part 5, we’ll see how we can almost get rid of all the remaining scalar code- by implementing small-constant size array sorting. We’ll use, drum roll…, yet more AVX2 vectorization.</li><li>Finally, in part 6, I’ll list the outstanding stuff/ideas I have for getting more juice and functionality out of my vectorized code.</li></ol><h2 id="quicksort-crash-course">QuickSort Crash Course</h2><p>QuickSort is deceivingly simple.<br>No, it really is.<br>In 20 lines of C# or whatever language you can sort numbers. Lots of them, and incredibly fast. However, try and change something about it; nudge it in the wrong way, and it will quickly turn around and teach you a lesson in humility. It is hard to improve on it without breaking any of the tenants it is built upon.</p><h3 id="in-words">In words</h3><p>Before we discuss any of that, let’s describe QuickSort in words, code, pictures, and statistics:</p><ul><li>It uses a <em>divide-and-conquer</em> approach.
    <ul><li>In other words, it’s recursive.</li><li>It performs  comparisons to sort <em>n</em> items.</li></ul></li><li>It performs an in-place sort.</li></ul><p>That last point, referring to in-place sorting, sounds simple and neat, and it sure is from the perspective of the user: no additional memory allocation needs to occur regardless of how much data they’re sorting. While that’s great, I’ve spent days trying to overcome the correctness and performance challenges that arise from it, specifically in the context of vectorization. It is also essential to remain in-place since I intend for this to become a <em>drop-in</em> replacement for <code class="highlighter-rouge">Array.Sort</code>.</p><p>More concretely, QuickSort works like this:</p><ol><li>Pick a pivot value.</li><li><strong>Partition</strong> the array around the pivot value.</li><li>Recurse on the left side of the pivot.</li><li>Recurse on the right side of the pivot.</li></ol><p>Picking a pivot could be a mini-post in itself, but again, in the context of competing with <code class="highlighter-rouge">Array.Sort</code> we don’t need to dive into it, we’ll copy whatever CoreCLR does, and get on with our lives.<br>CoreCLR uses a pretty standard scheme of median-of-three for pivot selection, which can be summed up as: “Let’s sort these 3 elements: In the first, middle and last positions, then pick the middle one of those three as the pivot”.</p><p><strong>Partitioning</strong> the array is where we spend most of the execution time: we take our selected pivot value and rearrange the array segment that was handed to us such that all numbers <em>smaller-than</em> the pivot are in the beginning or <strong>left</strong>, in no particular order amongst themselves. Then comes the <em>pivot</em>, in its <strong>final</strong> resting position, and following it are all elements <em>greater-than</em> the pivot, again in no particular order amongst themselves.</p><p>After partitioning is complete, we recurse to the left and right of the pivot, as previously described.</p><p>That’s all there is: this gets millions, billions of numbers sorted, in-place, efficiently as we know how to do 60+ years after its invention.</p><p class="notice--info">Bonus trivia points for those who are still here with me: <a href="https://en.wikipedia.org/wiki/Tony_Hoare">Tony Hoare</a>, who invented QuickSort back in the early 60s also took responsibility for inventing the <code class="highlighter-rouge">null</code> pointer concept. So I guess there really is no good without evil in this world.</p><h3 id="in-code">In code</h3><div class="language-csharp highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
</pre></td><td class="rouge-code"><pre><span class="k">void</span><span class="nf">QuickSort</span><span class="p">(</span><span class="kt">int</span><span class="p">[]</span><span class="n">items</span><span class="p">)</span><span class="p">=&gt;</span><span class="nf">QuickSort</span><span class="p">(</span><span class="n">items</span><span class="p">,</span><span class="m">0</span><span class="p">,</span><span class="n">items</span><span class="p">.</span><span class="n">Length</span><span class="p">-</span><span class="m">1</span><span class="p">);</span><span class="k">void</span><span class="nf">QuickSort</span><span class="p">(</span><span class="kt">int</span><span class="p">[]</span><span class="n">items</span><span class="p">,</span><span class="kt">int</span><span class="n">left</span><span class="p">,</span><span class="kt">int</span><span class="n">right</span><span class="p">)</span><span class="p">{</span><span class="k">if</span><span class="p">(</span><span class="n">left</span><span class="p">==</span><span class="n">right</span><span class="p">)</span><span class="k">return</span><span class="p">;</span><span class="kt">int</span><span class="n">pivot</span><span class="p">=</span><span class="nf">PickPivot</span><span class="p">(</span><span class="n">items</span><span class="p">,</span><span class="n">left</span><span class="p">,</span><span class="n">right</span><span class="p">);</span><span class="kt">int</span><span class="n">pivotPos</span><span class="p">=</span><span class="nf">Partition</span><span class="p">(</span><span class="n">items</span><span class="p">,</span><span class="n">pivot</span><span class="p">,</span><span class="n">left</span><span class="p">,</span><span class="n">right</span><span class="p">);</span><span class="nf">QuickSort</span><span class="p">(</span><span class="n">items</span><span class="p">,</span><span class="n">left</span><span class="p">,</span><span class="n">pivotPos</span><span class="p">);</span><span class="nf">QuickSort</span><span class="p">(</span><span class="n">items</span><span class="p">,</span><span class="n">pivotPos</span><span class="p">+</span><span class="m">1</span><span class="p">,</span><span class="n">right</span><span class="p">);</span><span class="p">}</span><span class="kt">int</span><span class="nf">PickPivot</span><span class="p">(</span><span class="kt">int</span><span class="p">[]</span><span class="n">items</span><span class="p">,</span><span class="kt">int</span><span class="n">left</span><span class="p">,</span><span class="kt">int</span><span class="n">right</span><span class="p">)</span><span class="p">{</span><span class="kt">var</span><span class="n">mid</span><span class="p">=</span><span class="n">left</span><span class="p">+</span><span class="p">((</span><span class="n">right</span><span class="p">-</span><span class="n">left</span><span class="p">)</span><span class="p">/</span><span class="m">2</span><span class="p">);</span><span class="nf">SwapIfGreater</span><span class="p">(</span><span class="k">ref</span><span class="n">items</span><span class="p">[</span><span class="n">left</span><span class="p">],</span><span class="k">ref</span><span class="n">items</span><span class="p">[</span><span class="n">mid</span><span class="p">]);</span><span class="nf">SwapIfGreater</span><span class="p">(</span><span class="k">ref</span><span class="n">items</span><span class="p">[</span><span class="n">left</span><span class="p">],</span><span class="k">ref</span><span class="n">items</span><span class="p">[</span><span class="n">right</span><span class="p">]);</span><span class="nf">SwapIfGreater</span><span class="p">(</span><span class="k">ref</span><span class="n">items</span><span class="p">[</span><span class="n">mid</span><span class="p">],</span><span class="k">ref</span><span class="n">items</span><span class="p">[</span><span class="n">right</span><span class="p">]);</span><span class="kt">var</span><span class="n">pivot</span><span class="p">=</span><span class="n">items</span><span class="p">[</span><span class="n">mid</span><span class="p">];</span><span class="p">}</span><span class="kt">int</span><span class="nf">Partition</span><span class="p">(</span><span class="kt">int</span><span class="p">[]</span><span class="n">array</span><span class="p">,</span><span class="kt">int</span><span class="n">pivot</span><span class="p">,</span><span class="kt">int</span><span class="n">left</span><span class="p">,</span><span class="kt">int</span><span class="n">right</span><span class="p">)</span><span class="p">{</span><span class="k">while</span><span class="p">(</span><span class="n">left</span><span class="p">&lt;=</span><span class="n">right</span><span class="p">)</span><span class="p">{</span><span class="k">while</span><span class="p">(</span><span class="n">array</span><span class="p">[</span><span class="n">left</span><span class="p">]</span><span class="p">&lt;</span><span class="n">pivot</span><span class="p">)</span><span class="n">left</span><span class="p">++;</span><span class="k">while</span><span class="p">(</span><span class="n">array</span><span class="p">[</span><span class="n">right</span><span class="p">]</span><span class="p">&gt;</span><span class="n">pivot</span><span class="p">)</span><span class="n">right</span><span class="p">--;</span><span class="k">if</span><span class="p">(</span><span class="n">left</span><span class="p">&lt;=</span><span class="n">right</span><span class="p">)</span><span class="p">{</span><span class="kt">var</span><span class="n">t</span><span class="p">=</span><span class="n">array</span><span class="p">[</span><span class="n">left</span><span class="p">];</span><span class="n">array</span><span class="p">[</span><span class="n">left</span><span class="p">++]</span><span class="p">=</span><span class="n">array</span><span class="p">[</span><span class="n">right</span><span class="p">];</span><span class="n">array</span><span class="p">[</span><span class="n">right</span><span class="p">--]</span><span class="p">=</span><span class="n">t</span><span class="p">;</span><span class="p">}</span><span class="p">}</span><span class="k">return</span><span class="n">left</span><span class="p">;</span><span class="p">}</span></pre></td></tr></tbody></table></code></pre></div></div><p>I did say it is deceptively simple, and grasping how QuickSort really works sometimes feels like trying to lift sand through your fingers; To that end I’ve included two more visualizations of QuickSort, which are derivatives of the amazing work done by <a href="https://observablehq.com/@mbostock">Michael Bostock (@mbostock)</a> with <a href="https://d3js.org/">d3.js</a>.</p><h3 id="visualizing-quicksorts-recursion">Visualizing QuickSort’s recursion</h3><p>One thing that we have to keep in mind is that the same data is partitioned over-and-over again, many times, with ever-shrinking partition sizes until we end up having a partition size of 2 or 3, in which case we can trivially sort the partition as-is and return.</p><p>To help see this better, we’ll use this way of visualizing arrays and their intermediate states in QuickSort:</p><div><p><img src="/talks/intrinsics-sorting-2019/quicksort-mbostock/quicksort-vis-legend.svg" alt="QuickSort Legend"></p><p>Here, we see an unsorted array of 200 elements (in the process of getting sorted).<br>The different sticks represent numbers in the  [-45°..+45°] range, and the angle of each individual stick represents its value, as I hope it is easy to discern.<br>We represent the pivots with <strong>two</strong> colors:</p><ul><li><span><strong>Red</strong></span> for the currently selected pivot at a given recursion level.</li><li><span><strong>Green</strong></span> for previous pivots that have already been partitioned around in previous rounds/levels of the recursion.</li></ul><p>Our ultimate goal is to go from the messy image above to the visually appeasing one below:</p></div><p><img src="/talks/intrinsics-sorting-2019/quicksort-mbostock/quicksort-vis-sorted.svg" alt="QuickSort Sorted"></p><p>What follows is a static (e.g., non-animated) visualization that shows how pivots are randomly selected at each level of recursion and how, by the next step, the unsorted segments around them become partitioned until we finally have a completely sorted array. Here is how the whole thing looks:</p><p class="notice--info">These visuals are auto-generated in Javascript + d3.js, so feel free to hit that “Reload” button and/or change the number of elements in the array  if you feel you want to see a new set of random sticks sorted.</p><p>I encourage you to look at this and try to explain to yourself what QuickSort “does” here, at every level. What you can witness here is the interaction between pivot selection, where it “lands” in the next recursion level (or row), and future pivots to its left and right and in the next levels of recursion. We also see how, with every level of recursion, the partition sizes decrease in until finally, every element is a pivot, which means sorting is complete.</p><h3 id="visualizing-quicksorts-comparisonsswaps">Visualizing QuickSort’s Comparisons/Swaps</h3><p>While the above visualization really does a lot to help understand <strong>how</strong> QuickSort works, I also wanted to leave you with an impression of the total amount of work done by QuickSort:</p><div><p>Above is an <strong>animation</strong> of the whole process as it goes over the same array, slowly and recursively going from an unsorted mess to a completely sorted array.</p><p>We can witness just how many comparisons and swap operations need to happen for a 200 element QuickSort to complete successfully. There’s genuinely a lot of work that needs to happen per element (when considering how we re-partition virtually all elements again and again) for the whole thing to finish.</p></div><h3 id="arraysort-vs-quicksort">Array.Sort vs. QuickSort</h3><p>It’s important to note that <code class="highlighter-rouge">Array.Sort</code> uses a couple of more tricks to get better performance and avoid certain dark-spots the come with QuickSort. I would be irresponsible if I didn’t mention those since in the later posts, I borrow at least one idea from its play-book, and improve upon it with intrinsics.</p><p><code class="highlighter-rouge">Array.Sort</code> isn’t strictly QuickSort; it is a variation on it called <a href="https://en.wikipedia.org/wiki/Introsort">Introspective Sort</a> invented by <a href="https://en.wikipedia.org/wiki/David_Musser">David Musser</a> in 1997. What it roughly does is combine Quick-Sort, Heap-Sort, and Insertion-Sort by dynamically switching between them: more specifically it starts with quick-sort and <em>may</em> switch to heap-sort if the recursion depth goes beyond a specific threshold while also switching into insertion-sort if the size of the partition goes below a different threshold. This hybrid approach is a clever way of mitigating the two biggest shortcomings in quick-sort alone:</p><ul><li>QuickSort is notorious for degenerating into  for various edge-cases input sequences. I won’t go very deeply into this, but think about an array that is made up of a single repeated number. In such an extreme case, partitioning results in a bad separation around the pivot (e.g. one sub-partition will always have a size of <code class="highlighter-rouge">0</code>) for each partitioning attempt, and the whole thing goes south very quickly.
    <ul><li>Introspective-sort mitigates such bad cases by tracking the current recursion depth vs. an acceptable worst-case depth (usually ). Once the measured/actual depth crosses over that threshold, introspective-sort switches internally from partitioning/quick-sort to heap-sort which deals with such cases better, on average.</li></ul></li><li>Lastly, once the partition is small enough, introspective-sort switches to using insertion-sort. This is a critical improvement when we consider that recursive calls are never cheap (even more so for the code I’ll present later in this series). In CoreCLR/C#, where this threshold was selected to be 16 elements, this hybrid approach manages to replace up to 3 levels of recursive calls (or  partitioning calls on average) with a <strong>single</strong> call to insertion-sort, which is very effective for these small input sizes anyway. The impact of this optimization, where recursion is replaced with simpler loop-based code, cannot be overstated.</li></ul><p>As mentioned, I ended up borrowing this last idea for my code as the issues around smaller partition sizes are exacerbated by using vectorized intrinsics in the following posts.</p><p>For the unfriendly cases I mentioned before, I have no vectorized approach yet (OK, I kind of do, but I have no intention of making this a 9-post blog series :). However, I have no problem admitting to this while weaseling my way out of this pit of despair in the most direct way: use the same logic that introspective-sort uses for switching to heap-sort (where it triggers when the depth exceeds some dynamically computed threshold) and in-turn switch to… <code class="highlighter-rouge">Array.Sort</code>; We let <em>it</em> stumble a bit with the same input until it will give up and switch internally to heap-sort. It’s slightly nasty, but it works…</p><h2 id="comparing-scalar-variants">Comparing Scalar Variants</h2><p>With all this new information, this is a good time to measure how a couple of different scalar (e.g. non-vectorized) versions compare to <code class="highlighter-rouge">Array.Sort</code>. I’ll show some results generated using <a href="https://benchmarkdotnet.org/">BenchmarkDotNet</a> (BDN) with:</p><ul><li><code class="highlighter-rouge">Array.Sort()</code> as the baseline.</li><li><a href="(https://github.com/damageboy/VxSort/blob/master/VxSortResearch/Unstable/Scalar/Managed.cs)"><code class="highlighter-rouge">Managed</code></a> as the code I’ve just presented above.
    <ul><li>This version is just basic QuickSort using regular/safe C#. With this version, every time we access an array element, the JIT inserts bounds-checking machine code around our actual access that ensures the CPU does not read/write outside the memory region owned by the array.</li></ul></li><li><a href="https://github.com/damageboy/VxSort/blob/master/VxSortResearch/Unstable/Scalar/Unmanaged.cs"><code class="highlighter-rouge">Unmanaged</code></a> as an alternative/faster version to <code class="highlighter-rouge">Scalar</code> where:
    <ul><li>The code uses native pointers and unsafe semantics (using C#‘s new <code class="highlighter-rouge">unmanaged</code> constraint, neat!).</li><li>We switch to <code class="highlighter-rouge">InsertionSort</code> (again, copy-pasted from CoreCLR) when below 16 elements, just like <code class="highlighter-rouge">Array.Sort</code> does.</li></ul></li></ul><p>I’ve prepared this last version to show that with unsafe code + <code class="highlighter-rouge">InsertionSort</code>, we can remove most of the performance gap between C# and C++ for this type of code, which mainly stems from bounds-checking, that the JIT cannot elide for these sort of random-access patterns as well as the jump-to <code class="highlighter-rouge">InsertionSort</code> optimization.</p><table class="notice--info"><tbody><tr><td><span class="uk-label">Note</span></td><td><p>Throughout this series, I’ll benchmark each sorting method with various array sizes (BDN parameter: <code class="highlighter-rouge">N</code>): . I’ve added a custom column to the BDN column to the report: <code class="highlighter-rouge">Time / N</code>. This represents the time spent sorting <em>per element</em> in the array, and as such, very useful to compare the results on a more uniform scale.<br>In addition, I will only start with purely randon and unique sets of values, as that is a classical input type where I want to focus for this series.<br>When I actually get to submitting a PR, I will have to show more test cases and prove that the whole thing doesn’t crumble once the input is less than optimal, but that is <em>outside of the scope</em> for this series.</p></td></tr></tbody></table><p>Here are the results in the form of charts and tables. I’ve included a handy large button you can press to get a quick tour of what each tab contains, what we have here is:</p><ol><li>A chart scaling the performance of various implementations being compared to <code class="highlighter-rouge">Array.Sort</code> as a ratio.</li><li>A chart showing time spent sorting a single element in an array of N elements (Time / N).</li><li>BDN results in a friendly table form.</li><li>Statistics/Counters that teach us about what is actually going on under the hood.</li></ol><div><div class="stickemup"><ul id="91b4eb8c-ce50-421e-a9f9-b1590ab47f0e" class="uk-switcher uk-margin"><li><div><button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><div data-intro="Size of the sorting problem, 10..10,000,000 in powers of 10" data-position="bottom"><div data-intro="Performance scale: Array.Sort (solid gray) is always 100%, and the other methods are scaled relative to it" data-position="left"><p class="benchmark-chart-container"><canvas data-chart="line">
N,100,1K,10K,100K,1M,10M
ArraySort,1,1,1,1,1,1
Scalar,2.04,1.57,1.33,1.12,1.09,1.11
Unmanaged,1.75,1.01,0.99,0.97,0.93,0.95
</canvas></p></div></div></button></div></li><li><div><button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><div data-intro="Size of the sorting problem, 10..10,000,000 in powers of 10" data-position="bottom"><div data-intro="Time in nanoseconds spent sorting per element. Array.Sort (solid gray) is the baseline, again" data-position="left"><p class="benchmark-chart-container"><canvas data-chart="line">
N,100,1K,10K,100K,1M,10M
ArraySort,12.1123,30.5461,54.641,60.4874,70.7539,80.8431
Scalar,24.7385,47.8796,72.7528,67.7419,77.3906,89.7593
Unmanaged,21.0955,30.9692,54.3112,58.9577,65.7222,76.8631
</canvas></p></div></div></button></div></li><li><div><button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><table class="table datatable" data-json="../_posts/Bench.BlogPt1_Int32_-report.datatable.json" data-id-field="name" data-pagination="true" data-page-list="[9, 18]" data-intro="Each row in this table represents a benchmark result" data-position="left" data-show-pagination-switch="false"><thead data-intro="The header can be used to sort/filter by clicking" data-position="right"><tr><th data-field="TargetMethodColumn.Method" data-sortable="true" data-filter-control="select"><span data-intro="The name of the benchmarked method" data-position="top">
            Method<br>Name
          </span></th><th data-field="N" data-sortable="true" data-value-type="int" data-filter-control="select"><span data-intro="The size of the sorting problem being benchmarked (# of integers)" data-position="top">
            Problem<br>Size
            </span></th><th data-field="TimePerNDataTable" data-sortable="true" data-value-type="float2-interval-muted"><span data-intro="Time in nanoseconds spent sorting each element in the array (with confidence intervals in parenthesis)" data-position="top">
              Time /<br>Element (ns)
            </span></th><th data-field="RatioDataTable" data-sortable="true" data-value-type="inline-bar-horizontal-percentage"><span data-intro="Each result is scaled to its baseline (Array.Sort in this case)" data-position="top">
                  Scaling
            </span></th><th data-field="Measurements" data-sortable="true" data-value-type="inline-bar-vertical"><span data-intro="Raw benchmark results visualize how stable the result it. Longest/Shortest runs marked with <span style='color: red'>Red</span>/<span style='color: green'>Green</span>" data-position="top">Measurements</span></th></tr></thead></table></button></div></li><li><div><button class="helpbutton" data-toggle="chardinjs" onclick="$('body').chardinJs('start')"><table class="table datatable" data-json="../_posts/scalar-vs-unmanaged-stats.json" data-id-field="name" data-pagination="true" data-page-list="[9, 18]" data-intro="Each row in this table contains statistics collected &amp; averaged out of thousands of runs with random data" data-position="left" data-show-pagination-switch="false"><thead data-intro="The header can be used to sort/filter by clicking" data-position="right"><tr><th data-field="MethodName" data-sortable="true" data-filter-control="select"><span data-intro="The name of the benchmarked method" data-position="top">Method<br>Name</span></th><th data-field="ProblemSize" data-sortable="true" data-value-type="int" data-filter-control="select"><span data-intro="The size of the sorting problem being benchmarked (# of integers)" data-position="top">Problem<br>Size</span></th><th data-field="MaxDepthScaledDataTable" data-sortable="true" data-value-type="inline-bar-horizontal"><span data-intro="The maximal depth of recursion reached while sorting" data-position="top">Max<br>Depth</span></th><th data-field="NumPartitionOperationsScaledDataTable" data-sortable="true" data-value-type="inline-bar-horizontal"><span data-intro="# of partitioning operations for each sort" data-position="top">#<br>Part-<br>itions</span></th><th data-field="AverageSmallSortSizeScaledDataTable" data-sortable="true" data-value-type="inline-bar-horizontal"><span data-intro="For hybrid sorting, the average size that each small sort operation was called with (e.g. InsertionSort)" data-position="top">
            Avg.<br>Small<br>Sorts<br>Size
            </span></th><th data-field="NumScalarComparesScaledDataTable" data-sortable="true" data-value-type="inline-bar-horizontal"><span data-intro="How many branches were executed in each sort operation that were based on the unsorted array elements" data-position="top">
            # Data-<br>Based<br>Branches
            </span></th><th data-field="PercentSmallSortCompares" data-sortable="true" data-value-type="float2-percentage"><span data-intro="What percent of</br>⬅<br/>branches happenned as part of small-sorts" data-position="top">
            % Small<br>Sort<br>Data-<br>Based<br>Branches
            </span></th></tr></thead></table></button></div></li><li><div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre></td><td class="rouge-code"><pre><span class="nv">BenchmarkDotNet</span><span class="o">=</span>v0.12.0, <span class="nv">OS</span><span class="o">=</span>clear-linux-os 32120
Intel Core i7-7700HQ CPU 2.80GHz <span class="o">(</span>Kaby Lake<span class="o">)</span>, 1 CPU, 4 logical and 4 physical cores
.NET Core <span class="nv">SDK</span><span class="o">=</span>3.1.100
  <span class="o">[</span>Host]     : .NET Core 3.1.0 <span class="o">(</span>CoreCLR 4.700.19.56402, CoreFX 4.700.19.56404<span class="o">)</span>, X64 RyuJIT
  Job-DEARTS : .NET Core 3.1.0 <span class="o">(</span>CoreCLR 4.700.19.56402, CoreFX 4.700.19.56404<span class="o">)</span>, X64 RyuJIT

<span class="nv">InvocationCount</span><span class="o">=</span>3  <span class="nv">IterationCount</span><span class="o">=</span>15  <span class="nv">LaunchCount</span><span class="o">=</span>2
<span class="nv">UnrollFactor</span><span class="o">=</span>1  <span class="nv">WarmupCount</span><span class="o">=</span>10

<span class="nv">$ </span><span class="nb">grep</span><span class="s1">'stepping\|model\|microcode'</span> /proc/cpuinfo | <span class="nb">head</span><span class="nt">-4</span>
model           : 158
model name      : Intel<span class="o">(</span>R<span class="o">)</span> Core<span class="o">(</span>TM<span class="o">)</span> i7-7700HQ CPU @ 2.80GHz
stepping        : 9
microcode       : 0xb4
</pre></td></tr></tbody></table></code></pre></div></div></li></ul></div><p>Surprisingly<sup id="fnref:1"><a href="#fn:1" class="footnote">4</a></sup>, the unmanaged C# version is running slightly faster than <code class="highlighter-rouge">Array.Sort</code>, but with one caveat: it only outperforms the C++ version for large inputs. Otherwise, everything is as expected: The purely <code class="highlighter-rouge">Managed</code> variant is just slow, and the <code class="highlighter-rouge">Unamanged</code> one mostly is on par with <code class="highlighter-rouge">Array.Sort</code>.<br>These C# implementations were written to <strong>verify</strong> that we can get to <code class="highlighter-rouge">Array.Sort</code><em>like</em> performance in C#, and they do just that. Running 5% faster for <em>some</em> input sizes will not cut it for me; I want it <em>much</em> faster. An equally important reason for re-implementing these basic versions is that we can now sprinkle <em>statistics-collecting-code</em> magic fairy dust<sup id="fnref:2"><a href="#fn:2" class="footnote">5</a></sup> on them so that we have even more numbers to dig into in the “Statistics” tab: These counters will assist us in deciphering and comparing future results and implementations. In this post they serve us by establishing a baseline. We can see, per each <code class="highlighter-rouge">N</code> value (with some commentary):</p><ul><li>The maximal recursion depth. Note that:
      <ul><li>The unmanaged version, like CoreCLR’s <code class="highlighter-rouge">Array.Sort</code> switches to <code class="highlighter-rouge">InsertionSort</code> for the last couple of recursion levels, therefore, its maximal depth is smaller.</li></ul></li><li>The total number of partitioning operations performed.
      <ul><li>Same as above, less recursion ⮚ less partitioning calls.</li></ul></li><li>The average size of what I colloquially refer to as “small-sort” operations performed (e.g., <code class="highlighter-rouge">InsertionSort</code> for the <code class="highlighter-rouge">Unmanaged</code> variant).
      <ul><li>The <code class="highlighter-rouge">Managed</code> version doesn’t have any of this, so it’s just 0.</li><li>In the <code class="highlighter-rouge">Unmanaged</code> version, we see a consistent value of 9.x: Given that we special case 1,2,3 in the code and 16 is the upper limit, 9.x seems like a reasonable outcome here.</li></ul></li><li>The number of branch operations that were user-data dependent; This one may be hard to relate to at first, but it becomes apparent why this is a crucial number to track starting with the 3<sup>rd</sup> post onwards. For now, a definition: This statistic counts <em>how many</em> times our code did an <code class="highlighter-rouge">if</code> or a <code class="highlighter-rouge">while</code> or any other branch operation <em>whose condition depended on unsorted user supplied data</em>!
      <ul><li>The numbers boggle the mind, this is the first time we get to show how much work is involved.</li><li>What’s even more surprising that for the <code class="highlighter-rouge">Unmanged</code> variant, the number is even higher (well only surprising if you don’t know anything about how <code class="highlighter-rouge">InsertionSort</code> works…) and yet this version seems to run faster… I have an entire post dedicated just to this part of the problem in this series, so let’s just make note of this for now, but already we see peculiar things.</li></ul></li><li>Finally, I’ve also included a statistic here that shows what percent of those data-based branches came from small-sort operations. Again, this was 0% for the <code class="highlighter-rouge">Managed</code> variant, but we can see that a large part of those compares are now coming from those last few levels of recursion that were converted to <code class="highlighter-rouge">InsertionSort</code>…</li></ul><p>Some of these statistics will remain pretty much the same for the rest of this series, regardless of what we do next in future versions, while others radically change; We’ll observe and make use of these as key inputs in helping us to figure out how/why something worked, or not!</p></div><h2 id="all-warmed-up">All Warmed Up?</h2><p>We’ve spent quite some time polishing our foundations concerning QuickSort and <code class="highlighter-rouge">Array.Sort</code>. I know lengthy introductions are somewhat dull, but I think time spent on this post will pay off with dividend when we next encounter our actual implementation in the 3<sup>rd</sup> post and later on. This might be also a time to confess that just doing the leg-work to provide this refresher helped me come up with at least one, super non-trivial optimization, which I think I’ll keep the lid on all the way until the 6<sup>th</sup> and final post. So never underestimate the importance of “just” covering the basics.</p><p>Before we write vectorized code, we need to pick up some knowhow specific to vectorized intrinsics and introduce a few select intrinsics we’ll be using, so, this is an excellent time to break off this post, grab a fresh cup of coffee and head to the <a href="/2020-01-29/this-goes-to-eleven-pt2">next post</a>.</p><hr></div></div></div></div>
</div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script>
        (function () {
            var COLLECT_URL = "https://dna.buildstarted.com/t";
            var SITE_ID = "linksfor.devs";
            var GLOBAL_VAR_NAME = "__DNA__";

            window[GLOBAL_VAR_NAME] = {};

            window[GLOBAL_VAR_NAME].sendPageView = function () {
                var path = location.pathname;
                var referrer = document.referrer;

                var url = COLLECT_URL + "?siteid=" + SITE_ID + "&p=" + encodeURIComponent(path) + "&r=" + encodeURIComponent(referrer);

                try { fetch(url, { method: "GET" }); } catch (e) { }
            };

            window[GLOBAL_VAR_NAME].sendPageView();
        })();
    </script>
</body>
</html>