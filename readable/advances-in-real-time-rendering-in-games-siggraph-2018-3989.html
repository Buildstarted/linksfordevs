<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Advances in Real-Time Rendering in Games, SIGGRAPH 2018 - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Advances in Real-Time Rendering in Games, SIGGRAPH 2018 - linksfor.dev(s)"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="http://advances.realtimerendering.com/s2018/index.htm"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Advances in Real-Time Rendering in Games, SIGGRAPH 2018</title>
<div class="readable">
        <h1>Advances in Real-Time Rendering in Games, SIGGRAPH 2018</h1>
            <div>Reading time: 16-20 minutes</div>
        <div>Posted here: 27 Feb 2019</div>
        <p><a href="http://advances.realtimerendering.com/s2018/index.htm">http://advances.realtimerendering.com/s2018/index.htm</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div>

<p><span><!--[if gte vml 1]><v:shape
 id="Picture_x0020_9" o:spid="_x0000_i1045" type="#_x0000_t75" style='width:712.5pt;
 height:78.75pt;visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image003.jpg" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img width="950" height="105" src="http://advances.realtimerendering.com/s2018/index_files/image020.jpg" v:shapes="Picture_x0020_9"><!--[endif]--></span></p>


<p><span lang="EN">Modern
video games employ a variety of sophisticated algorithms to produce
groundbreaking 3D rendering pushing the visual boundaries and interactive experience
of rich environments. This course brings state-of-the-art and production-proven
rendering techniques for fast, interactive rendering of complex and engaging
virtual worlds of video games.<o:p></o:p></span></p>

<p><span lang="EN">This
year the course includes speakers from the makers of several innovative game
companies, such as Ubisoft, Sledgehammer Games, Activision, NVIDIA, Unity
Technologies, <span>Lucasfilm</span><span>,<span>&nbsp; </span>and</span> Epic Games. Topics range from
variations on the latest techniques for modern rendering pipelines,
high-quality depth-of-field post processing, advances in material
representation for deferred rendering pipelines, including improvements in
subsurface scattering and PBR material representations, improvements to diffuse
multi-scattering BRDFs, volumetric rendering techniques, using ray tracing
techniques for accurate soft shadows in real-time, and many more. <o:p></o:p></span></p>


<p><b><span lang="EN">This is <i>the</i> course to attend if you are in the game development industry or
want to learn the latest and greatest techniques in real-time rendering domain!<o:p></o:p></span></b></p>

<h2><a name="_mypq5h4qutnh"></a><b><i><u><span lang="EN"><a href="http://advances.realtimerendering.com/"><span>Previous years’ Advances course slides: go here</span></a></span></u></i></b><b><i><u><span lang="EN"><o:p></o:p></span></u></i></b></h2>
<h2><a name="_3qg1viqwx2o5"></a><span lang="EN">
<hr size="5">
</span></h2>
<h2><a name="_j1h6izlhj01t"></a><span lang="EN">Syllabus<o:p></o:p></span></h2>
<h4><a name="_zghyx8lb13ny"></a><b><i><u><span lang="EN"><a href="https://s2018.siggraph.org/presentation/?id=gensubcur_139&amp;sess=sess475"><span>Advances in Real-Time Rendering in Games: Part I</span></a></span></u></i></b><span><b><i><span lang="EN"><o:p></o:p></span></i></b></span></h4>
<h4><a name="_plbf0qt5s350"></a><i><span lang="EN">Monday, 13 August 2018 9am - 12:15pm</span></i><i><span lang="EN"> <span>|<span>&nbsp; </span><span>East</span></span></span></i><i><span lang="EN"> Building, Ballroom
BC, Vancouver Convention Centre</span></i><span lang="EN"><o:p></o:p></span></h4>
<h4><a name="_ejdatl1m7e0j"></a><b><i><u><span lang="EN"><a href="https://s2018.siggraph.org/presentation/?id=gensubcur_140&amp;sess=sess476"><span>Advances in Real-Time Rendering in Games: Part II</span></a></span></u></i></b><span><b><span lang="EN"><o:p></o:p></span></b></span></h4>

<p><i><span lang="EN">Monday, 13 August 2018 2pm - 5:15pm</span></i><i><span lang="EN"> <span>|<span>&nbsp; </span><span>East</span></span></span></i><i><span lang="EN"> Building, Ballroom
BC, Vancouver Convention Centre</span></i><b><span lang="EN"><o:p></o:p></span></b></p>
<h2><a name="_w5u5l1m9rws2"></a><span lang="EN">Prerequisites<o:p></o:p></span></h2>

<p><b><span lang="EN">Working
knowledge of modern real-time graphics APIs like DirectX or Vulkan or Metal and
a solid basis in commonly used graphics algorithms. Familiarity with the
concepts of programmable shading and shading languages. Familiarity with
shipping gaming consoles hardware and software capabilities is a plus but not
required.<o:p></o:p></span></b></p>
<h2><a name="_rnllt53yhtor"></a><span lang="EN">Intended Audience<o:p></o:p></span></h2>

<p><b><span lang="EN">Technical
practitioners and developers of graphics engines for visualization, games, or
effects rendering who are interested in interactive rendering.<o:p></o:p></span></b></p>
<h4><a name="_vab9532uj8jw"></a><b><i><u><span lang="EN"><a href="https://s2018.siggraph.org/presentation/?id=gensubcur_139&amp;sess=sess475"><span>Advances in Real-Time Rendering in Games: Part I</span></a></span></u></i></b><span><i><span lang="EN"><o:p></o:p></span></i></span></h4>

<p><b><span lang="EN">9:00 am<o:p></o:p></span></b></p>
<p><span lang="EN">Natalya
Tatarchuk<o:p></o:p></span></p>
<p><b><span lang="EN">Welcome and introduction<o:p></o:p></span></b></p>

<p><b><span lang="EN">9:10 am<o:p></o:p></span></b></p>
<p><span lang="EN">Steve <span>McAuley</span> (Ubisoft)<o:p></o:p></span></p>
<p><b><span lang="EN">The challenges of rendering an open world in <i>Far Cry 5<o:p></o:p></i></span></b></p>

<p><b><span lang="EN">10:10 am<o:p></o:p></span></b></p>
<p><span lang="EN">Danny
Chan (Sledgehammer)<o:p></o:p></span></p>
<p><b><span lang="EN">Material advances in <i>Call of Duty: WWII<o:p></o:p></i></span></b></p>

<p><b><span lang="EN">11:10 am<o:p></o:p></span></b></p>
<p><span lang="EN">Guillaume
<span>Abadie</span> (Epic Games)<o:p></o:p></span></p>
<p><b><span lang="EN">A life of a <span>bokeh</span><i><o:p></o:p></i></span></b></p>

<p><b><span lang="EN">12:10 pm<o:p></o:p></span></b></p>
<p><b><span lang="EN">Closing Q&amp;A<o:p></o:p></span></b></p>
<h4><a name="_dj5rvk9s5nt1"></a><b><i><u><span lang="EN"><a href="https://s2018.siggraph.org/presentation/?id=gensubcur_140&amp;sess=sess476"><span>Advances in Real-Time Rendering in Games: Part II</span></a></span></u></i></b><span><i><span lang="EN"><o:p></o:p></span></i></span></h4>

<p><b><span lang="EN">2:00 pm<o:p></o:p></span></b></p>
<p><span lang="EN">Natalya Tatarchuk<o:p></o:p></span></p>
<p><b><span lang="EN">Welcome (and welcome back!)<o:p></o:p></span></b></p>

<p><b><span lang="EN">2:05 pm<o:p></o:p></span></b></p>
<p><span lang="EN">Sebastien
<span>Lagarde</span> (Unity Technologies)<o:p></o:p></span></p>
<p><span><span lang="EN">Evgenii</span></span><span lang="EN"> <span>Golubev</span> (Unity Technologies)<o:p></o:p></span></p>
<p><b><span lang="EN">The road toward unified rendering with Unity’s high
definition rendering pipeline<o:p></o:p></span></b></p>

<p><b><span lang="EN">3:05 pm<o:p></o:p></span></b></p>
<p><span><span lang="EN">Evgenii</span></span><span lang="EN"> <span>Golubev</span> (Unity Technologies)<o:p></o:p></span></p>
<p><b><span lang="EN">Efficient screen-space subsurface scattering using
Burley’s normalized diffusion in real-time<o:p></o:p></span></b></p>

<p><b><span lang="EN">3:35 pm<o:p></o:p></span></b></p>
<p><span lang="EN">Matt
Pharr (NVIDIA)<o:p></o:p></span></p>
<p><b><span lang="EN">Real-time rendering’s next frontier: adopting
lessons from offline ray tracing to practical real-time ray tracing pipelines<o:p></o:p></span></b></p>

<p><b><span lang="EN">4:35pm<o:p></o:p></span></b></p>
<p><span lang="EN">Stephen
Hill (<span>Lucasfilm</span>) (presenter)<o:p></o:p></span></p>
<p><span lang="EN">Morgan
McGuire (NVIDIA) (presenter)<o:p></o:p></span></p>
<p><span lang="EN">Eric <span>Heitz</span> (Unity Technologies) (non-presenting contributor)<o:p></o:p></span></p>
<p><b><span lang="EN">Real-time ray tracing of correct* soft shadows (*
without a shadow of a doubt)<o:p></o:p></span></b></p>

<p><b><span lang="EN">5:15 pm<o:p></o:p></span></b></p>
<p><span lang="EN">Natalya Tatarchuk<o:p></o:p></span></p>
<p><b><span lang="EN">Closing Remarks<o:p></o:p></span></b></p>


<h2><a name="_xhfu1wy3el8j"></a><b><i><span lang="EN">Course Organizer<o:p></o:p></span></i></b></h2>
<p><i><span lang="EN">Natalya Tatarchuk (</span></i><i><u><span lang="EN"><a href="https://twitter.com/mirror2mask"><span>@mirror2mask</span></a></span></u></i><i><span lang="EN">) </span></i><span lang="EN">is a graphics engineer and a rendering enthusiast at heart. As the VP of
Graphics at Unity Technologies, she is focusing on driving the state-of-the-art
rendering technology and graphics performance for the Unity engine. Previously
she was the Graphics Lead and an Engineering Architect at Bungie, working on
innovative cross-platform rendering engine and game graphics for Bungie’s<i> Destiny </i>franchise, including leading
graphics on the upcoming<i> Destiny 2 </i>title.
Natalya also contributed graphics engineering to the<i> Halo </i>series, such as<i> Halo:
ODST </i>and<i> <span>Halo<span>:Reach</span></span>. </i>Before moving into game development
full-time, Natalya was a graphics software architect and a lead in the Game
Computing Application Group at AMD Graphics Products Group (Office of the CTO)
where she pushed parallel computing boundaries investigating advanced real-time
graphics techniques. Natalya has been encouraging sharing in the games graphics
community for several decades, largely by organizing a popular series of
courses such as </span><u><span lang="EN"><a href="http://advances.realtimerendering.com/"><span>Advances
in Real-time Rendering</span></a></span></u><span lang="EN">
and the </span><u><span lang="EN"><a href="http://openproblems.realtimerendering.com/"><span>Open
Problems in Real-Time</span></a></span></u><span lang="EN"> Rendering at
SIGGRAPH. She has also published papers and articles at various computer
graphics conferences and technical book series, and has presented her work at
graphics and game developer conferences worldwide. Natalya is a member of
multiple industry and hardware advisory boards. She holds an M.S. in Computer
Science from Harvard University with a focus in Computer Graphics and B.A.
degrees in Mathematics and Computer Science from Boston University.<o:p></o:p></span></p>



<p><b><span><!--[if gte vml 1]><v:shape id="image10.png" o:spid="_x0000_i1044"
 type="#_x0000_t75" style='width:468pt;height:264pt;visibility:visible;
 mso-wrap-style:square'>
 <v:imagedata src="index_files/image005.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img width="624" height="352" src="http://advances.realtimerendering.com/s2018/index_files/image021.gif" v:shapes="image10.png"><!--[endif]--></span></b><b><span lang="EN"><o:p></o:p></span></b></p>

<p><b><span lang="EN">Abstract:</span></b><span lang="EN"> Open worlds with dynamic
time of day cycles pose a significant challenge to graphics development. There
are fewer hiding places for the weaknesses and edge cases in our rendering
features, as care has to be taken to ensure features work in all scenarios.
This talk discusses some of the challenges faced on <i>Far Cry 5 </i>developing a water system, a physically-based time of day
cycle and closes by looking at some small techniques to improve the lives of
artists.<o:p></o:p></span></p>

<p><b><span lang="EN">Bio:</span></b><span lang="EN"> <i>Stephen <span>McAuley</span> </i>is a 3D Technical Lead at
Ubisoft Montreal on the <i>Far Cry</i>
Central Tech team, where he holds the vision for the future of the 3D engine. During
his time at Ubisoft, he has worked on many <i>Far
Cry</i> games, spearheading the switch to physically-based lighting and
shading, working towards a more data-driven rendering architecture, and
focusing on visual quality. Previously, he was a graphics programmer at Bizarre
Creations, shipping games such as Blur and Blood Stone.<span>&nbsp; </span><o:p></o:p></span></p>

<p><b><span lang="EN">Materials</span></b><span lang="EN"> (Updated:
September 4<sup>h</sup> 2018): <a href="http://advances.realtimerendering.com/s2018/The%20Challenges%20of%20Rendering%20an%20Open%20World%20in%20Far%20Cry%205.pptx">PPTX</a>
(382 MB), <a href="http://advances.realtimerendering.com/s2018/The%20Challenges%20of%20Rendering%20an%20Open%20World%20in%20Far%20Cry%205%20(With%20Notes).pdf">PDF</a>
(17 MB)<o:p></o:p></span></p>




<p><span><!--[if gte vml 1]><v:shape id="image8.png" o:spid="_x0000_i1043"
 type="#_x0000_t75" style='width:468pt;height:264pt;visibility:visible;
 mso-wrap-style:square'>
 <v:imagedata src="index_files/image007.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img width="624" height="352" src="http://advances.realtimerendering.com/s2018/index_files/image022.gif" v:shapes="image8.png"><!--[endif]--></span><span lang="EN"><o:p></o:p></span></p>

<p><b><span lang="EN">Abstract: </span></b><span lang="EN">This session will describe a number of improvements that were made to
the <i>Call of <span>Duty<span>:WWII</span></span> </i>shaders for lit opaque surfaces. The
authors extended the Diffuse BRDF to model <span>Lambertian</span>
<span>microfacets</span> with multi-scattering. They derived a
simple method to <span>mipmap</span> normal and gloss maps, by
directly correlating gloss to average normal length of a distribution,
bypassing an intermediate representation, like variance. Then cavity maps are </span><span lang="EN">auto-generated
<span>for every surface that has a normal map, and the
presentation will also show how the authors handled occlusion and indirect
lighting in cavities represented by these textures. The presenters will
demonstrate how the environment split integral <span>precalculation</span>
can be easily reused for energy conserving diffuse. Finally, they will show how
Rational Functions can be a useful tool to approximate many functions that
can't be represented analytically or efficiently.</span></span><span lang="EN"><o:p></o:p></span></p>

<p><b><span lang="EN">Bio:</span></b><span lang="EN"> <i><span>Danny Chan </span></i><span>is Principal Software Engineer at
Sledgehammer Games, leading the rendering effort on <i>Call of Duty: Modern Warfare 3</i>, <i>Call
of Duty: Advanced Warfare</i> and <i>Call of
Duty: WWII</i>. Previously, he’s worked at Crystal Dynamics, Naughty Dog (as
Lead Programmer on <i>Crash Team Racing</i>),
EA and Namco.<o:p></o:p></span></span></p>

<p><b><span lang="EN">Materials</span></b><span lang="EN"> (Updated: February
5, 2019): <a href="http://advances.realtimerendering.com/s2018/MaterialAdvancesInWWII.pptx">PPTX</a> (140MB), <a href="http://advances.realtimerendering.com/s2018/MaterialAdvancesInWWII.pdf">PDF</a> (4MB), <a href="http://advances.realtimerendering.com/s2018/MaterialAdvancesInWWII-course_notes.pdf">Course Notes PDF</a> (4MB)<o:p></o:p></span></p>



<p><b><span><!--[if gte vml 1]><v:shape
 id="image5.png" o:spid="_x0000_i1042" type="#_x0000_t75" style='width:468pt;
 height:264pt;visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image009.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img width="624" height="352" src="http://advances.realtimerendering.com/s2018/index_files/image023.gif" v:shapes="image5.png"><!--[endif]--></span></b><b><span lang="EN"><o:p></o:p></span></b></p>

<p><b><span lang="EN">Abstract: </span></b><span lang="EN">Lens of a physical camera have a depth of
field phenomena that has an importance in cinematography to bring focus on
desired subject of a frame. The challenge of real-time depth of field is to
output the highest <span>bokeh</span> quality while remaining
fast. This talk will journey through the step by step implementation of a depth
of field algorithm starting from existing state-of-the-art, and fixing
artifacts one after the other to converge to the final implementation released
in Unreal Engine 4.20. In order to achieve its opposing goals including
scalability across a large variety of hardware, high quality and performance,
the self-contained algorithm blends between:<o:p></o:p></span></p>
<p><!--[if !supportLists]--><span lang="EN"><span>-<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]--><span lang="EN">The fast performance of scatter-as-gather approach while efficiently
solving a physically plausible geometric occlusion with large variety of
blurring radii for background, and hole filling for the foreground;<o:p></o:p></span></p>
<p><!--[if !supportLists]--><span lang="EN"><span>-<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]--><span lang="EN">The quality of scattered sprites for highlights and deals with all the
complexity implication of combining them plausibly;<o:p></o:p></span></p>
<p><!--[if !supportLists]--><span lang="EN"><span>-<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]--><span lang="EN">The details of sub-pixel accuracy of slight out of focus convolution
with the challenges of running with a Temporal Anti-Aliasing from older but
sadly never published algorithm used in Unreal Engine 4.<o:p></o:p></span></p>


<p><b><span lang="EN">Bio: </span></b><i><span lang="EN">Guillaume <span>Abadie</span></span></i><span lang="EN"> is Graphic Programmer at Epic Games, working directly on Unreal Engine
4's renderer, more specifically on post processing. Notably, he implemented
temporal up-sampling &amp; dynamic resolution duo shipping on <i>Fortnite Battle Royal</i> running at 60Hz on
consoles. He also built the compositing of the SIGGRAPH real-time live 2017
awarded <i>The Human Race</i> demo. (<span>twitter</span>: @<span>GuillaumeAbadie</span>).<o:p></o:p></span></p>

<p><b><span lang="EN">Materials</span></b><span lang="EN"> (Updated:
August 24<sup>th</sup> 2018): <a href="http://advances.realtimerendering.com/s2018/2018-08-13-SIGGRAPH-A-Life-of-a-Bokeh.pptx">PPTX</a> (150MB)<o:p></o:p></span></p>



<p><span><!--[if gte vml 1]><v:shape id="image14.jpg" o:spid="_x0000_i1041"
 type="#_x0000_t75" style='width:468pt;height:263.25pt;visibility:visible;
 mso-wrap-style:square'>
 <v:imagedata src="index_files/image011.jpg" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img width="624" height="351" src="http://advances.realtimerendering.com/s2018/index_files/image024.jpg" v:shapes="image14.jpg"><!--[endif]--></span><span lang="EN"><o:p></o:p></span></p>

<p><b><span lang="EN">Abstract: </span></b><span lang="EN">When designing a rendering engine
architecture, one frequently must choose whether to implement a forward or a
deferred renderer, as each choice presents an important number of design
decisions for material and lighting pipelines. Each of the approaches
(forward-, forward-plus, or deferred) has a number of strengths and
deficiencies, widely covered in previous conference presentations from shipping
games’ engines. The features offered by each rendering architecture varies
widely, and often can be content-centric. <o:p></o:p></span></p>

<p><span lang="EN">When designing the high-definition rendering
pipeline (HDRP) for the Unity engine, the authors desired to leverage the
strengths of each rendering approach, as necessary for various application
contexts (a console game, VR application, etc.). Thus, an important design
constraint for the architecture of HDRP became a unified feature set between
the deferred and forward rendering paths. <o:p></o:p></span></p>

<p><span lang="EN">This presentation will explain how the team
tackled designing the lighting, material and rendering architecture for the
HDRP with the feature parity design constraint as one of the main pillars. It
will cover the details of the flexible G-buffer layout architecture, explain
the logic behind the taken design choices, and necessary optimizations for
efficient execution on modern console hardware. In addition, the authors will
present advanced developments made in the field of physically-based rendering,
material advances, focusing on the novel BRDF model used for the rendering
pipeline. The talk will also provide a framework for correctly mixing <span>normals</span> with complex material for evaluation at runtime.
Lastly, the architecture and technical details of the physically-based
volumetric lighting approach will be described, along with the necessary
optimizations for fast performance. <o:p></o:p></span></p>
<p><b><span lang="EN">Bios: </span></b><span><i><span lang="EN">Sébastien</span></i></span><i><span lang="EN"> <span>Lagarde</span> is a </span></i><span lang="EN">lead graphics programmer at Unity
Technologies where he's driving the architecture of Unity's high definition
rendering pipeline, amongst other projects. Prior to Unity, he has worked on
many game consoles for variety of titles, from small casual games to AAA (<i>Remember Me</i>, <i>Mirror's Edge 2</i>, <span><span><i>StarWars</i></span></span><i> Battlefront</i>, among some).<span>&nbsp; </span><span>Sébastien</span> has
previously worked for <span>Neko</span> Entertainment, <span>Darkworks</span>, <span>Trioviz</span>, <span>Dontnod</span> and Electronic Arts / Frostbite.<o:p></o:p></span></p>
<p><span><i><span lang="EN">Evgenii</span></i></span><i><span lang="EN"> <span>Golubev</span></span></i><span lang="EN">, Graphics Programmer in the Unity’s Paris
Graphics team, where he is contributing to Unity’s high definition rendering
pipeline architecture, focusing on physically-based materials and advanced
light transport, making them run efficiently on modern hardware. Previously
worked on the rendering technology at Havok and Microsoft.<o:p></o:p></span></p>

<p><b><span lang="EN">Materials</span></b><span lang="EN"> (Updated:
August 25<sup>th</sup> 2018): <a href="http://advances.realtimerendering.com/s2018/Siggraph%202018%20HDRP%20talk_with%20notes.pdf">PDF</a> (14 MB), <a href="https://www.youtube.com/watch?v=DDsRfbfnC_A">Book of the Dead HD RP Video</a>,
<a href="https://www.youtube.com/watch?v=ojPmPeNcFyU">Automotive HD RP Video</a>,
<a href="http://advances.realtimerendering.com/s2018/SIGGRAPH%202018%20HD%20RP%20volumetrics.mp4"><span>Volumetrics</span>
in HD RP Video</a> (Slide 134), <a href="http://advances.realtimerendering.com/s2018/SIGGRAPH%202018%20HD%20RP%20volumetrics%20participating%20media%20authoring.mp4">HD
RP Participating Media Authoring Video</a> (Slide 137), <a href="http://advances.realtimerendering.com/s2018/SIGGRAPH%202018%20HDRP%20talk%20-%20spotlight%20with%20forward%20scatter%20fog.gif">Spotlight
with highly forward-scattering fog GIF</a> (Slide 140)<o:p></o:p></span></p>



<p><span><!--[if gte vml 1]><v:shape id="image12.png" o:spid="_x0000_i1040"
 type="#_x0000_t75" style='width:165.75pt;height:211.5pt;visibility:visible;
 mso-wrap-style:square'>
 <v:imagedata src="index_files/image013.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img width="221" height="282" src="http://advances.realtimerendering.com/s2018/index_files/image025.jpg" v:shapes="image12.png"><!--[endif]--></span><span lang="EN"><o:p></o:p></span></p>

<p><b><span lang="EN">Abstract: </span></b><span lang="EN">Screen-space subsurface scattering
by Jimenez et al and the multitude of parameterization options developed for
it, such as Gaussian lobe, two Gaussian lobe, SVD, <span>etc.,have</span>
produced impressive results in rendering organic materials and characters.
However, these methods focused primarily on the multi-scattering contribution
rather than the single scattering contribution (aside from simple
approximations via an extra weight for the original diffuse texture.) These
previously introduced techniques rely on a separable Gaussian filter to achieve
fast performance on modern GPUs.<o:p></o:p></span></p>

<p><span lang="EN">In this talk, the authors build on
the recently introduced Burley normalized diffusion method, bringing this
technique developed for offline rendering pipelines into real-time with a novel
screen-space subsurface scattering method. This method accounts for both multi
and single scattering appearance models. Its parameterization model is simple
and is derived based on the values from real world measurements. The authors
will compare the quality of this approach to the more commonly used
screen-space subsurface scattering techniques and explain the necessary
optimizations required to evaluate its non-separable kernel efficiently in
real-time. This method is used in production and is highly performant on
commodity console hardware, such as <span>Playstation</span> 4 and
Xbox One at 1080p resolution.<o:p></o:p></span></p>
<p><b><span lang="EN">Bio: </span></b><span><i><span lang="EN">Evgenii</span></i></span><i><span lang="EN"> <span>Golubev</span></span></i><span lang="EN">, Graphics Programmer in the Unity’s Paris
Graphics team, where he is contributing to Unity’s high definition rendering
pipeline architecture, focusing on physically-based materials and advanced
light transport, making them run efficiently on modern hardware. Previously
worked on the rendering technology at Havok and Microsoft.<o:p></o:p></span></p>

<p><b><span lang="EN">Materials</span></b><span lang="EN"> (Updated:
August 25<sup>th</sup> 2018): <a href="http://advances.realtimerendering.com/s2018/Efficient%20screen%20space%20subsurface%20scattering%20Siggraph%202018.pdf">PDF</a>
(5MB)<o:p></o:p></span></p>


<p><span><!--[if gte vml 1]><v:shape
 id="image13.png" o:spid="_x0000_i1039" type="#_x0000_t75" style='width:482.25pt;
 height:271.5pt;visibility:visible;mso-wrap-style:square'>
 <v:imagedata src="index_files/image015.jpg" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img width="643" height="362" src="http://advances.realtimerendering.com/s2018/index_files/image026.jpg" v:shapes="image13.png"><!--[endif]--></span><span lang="EN"><o:p></o:p></span></p>
<h2><a name="_yaadki5cqmd5"></a><b><span lang="EN">Abstract: </span></b><span lang="EN">Ray-tracing has finally
arrived to the real-time graphics pipeline, tightly integrated with
rasterization, shading, and compute.<span>&nbsp; </span>The
ability to trace rays offers the promise of finally being able to accurately
simulate global light scattering in real time graphics.<span>&nbsp; </span>Just as physically-based materials have
revolutionized real-time graphics in recent years, physically-based global
lighting offers the chance to have a similar impact on both image quality and
developer and artist productivity.<o:p></o:p></span></h2>

<p><span lang="EN">Getting there won't be easy,
however: currently, only a handful of rays can be traced at each pixel, which
requires great care and creativity from the graphics programmer.<span>&nbsp; </span>There are lessons to be learned from offline
rendering, which broadly adopted ray tracing ten years ago.<span>&nbsp; </span>The author will discuss the experience of the
offline pipelines with the technology and highlight a variety of key
innovations that have been developed in that realm that are worth knowing about
for developers adopting real-time ray tracing.<o:p></o:p></span></p>

<p><b><span lang="EN">Bio:
</span></b><i><span lang="EN">Matt Pharr</span></i><span lang="EN"> is a Distinguished Research
Scientist at NVIDIA where he works on ray-tracing and real-time rendering.<span>&nbsp; </span>He is the author of the book Physically Based
Rendering for which he and the co-authors were awarded a Scientific and
Technical Academy Award in 2014 for the book's impact on the film industry.<o:p></o:p></span></p>

<p><b><span lang="EN">Materials</span></b><span lang="EN"> (Updated:
August 24<sup>th</sup> 2018): <a href="http://advances.realtimerendering.com/s2018/Pharr%20-%20Advances%20in%20RTR%20-%20Real-time%20Ray%20Tracing.pdf">PDF</a>
(74 MB)<o:p></o:p></span></p>



<p><span lang="EN">(* without a shadow of a
doubt)<o:p></o:p></span></p>

<p><b><span><!--[if gte vml 1]><v:shape id="image9.png" o:spid="_x0000_i1038"
 type="#_x0000_t75" style='width:238.5pt;height:238.5pt;visibility:visible;
 mso-wrap-style:square'>
 <v:imagedata src="index_files/image017.png" o:title=""/>
</v:shape><![endif]--><!--[if !vml]--><img width="318" height="318" src="http://advances.realtimerendering.com/s2018/index_files/image027.jpg" v:shapes="image9.png"><!--[endif]--></span></b><b><span lang="EN"><o:p></o:p></span></b></p>

<p><b><span lang="EN">Abstract</span></b><span lang="EN">: With recent advances in real-time shading techniques, we can now light
physically based materials with complex area light sources. Alas, one critical
challenge remains: accurate area-light shadowing. The arrival of DXR opens the
door to solving this problem via ray tracing, but the correct formulation isn't
obvious and there are several potential pitfalls. For instance, the most
popular strategy consists of tracing rays to points randomly distributed on the
light source and averaging the visibility, but we will show that this is
incorrect and produces visual artifacts. Instead, we propose a definition for
soft shadows that allows us to compute the correct result, along with an
efficient implementation that works with existing analytic area lighting
solutions.<o:p></o:p></span></p>
<p><span lang="EN">Note:
this talk is an extended presentation of the paper Combining Analytic Direct
Illumination and Stochastic Shadows (presented at I3D) that includes additional
practical details.</span><span lang="EN"><o:p></o:p></span></p>

<p><b><span lang="EN">Speakers</span></b><span lang="EN">: Stephen Hill (<span>Lucasfilm</span>) and Morgan McGuire (NVIDIA)<o:p></o:p></span></p>
<p><b><span lang="EN">Non-speaking
contributor: </span></b><span lang="EN">Eric <span>Heitz</span> (Unity Technologies)<o:p></o:p></span></p>

<p><b><span lang="EN">Bios</span></b><span lang="EN">: <i>Stephen Hill </i>is a Senior Rendering Engineer within <span>Lucasfilm’s</span> Advanced Development group, where he is engaged
in physically based rendering R&amp;D for real-time productions such as the <i>Carne y Arena</i> VR installation
experience.<o:p></o:p></span></p>

<p><i><span lang="EN">Morgan McGuire</span></i><span lang="EN"> is a scientist at NVIDIA, holds
faculty appointments at the University of Waterloo, Williams College, and
McGill University, and has co-authored several books, including <i>The Graphics Codex</i> and <i>Computer Graphics: Principles and Practice</i>.</span><span lang="EN"><o:p></o:p></span></p>

<p><i><span lang="EN">Eric <span>Heitz</span></span></i><span lang="EN"> is a Research Scientist at
Unity Technologies. His research focuses on physically based rendering
including materials, lighting, sampling, <span>LoDs</span>,
anti-aliasing, etc.<o:p></o:p></span></p>


<p><b><span lang="EN">Materials</span></b><span lang="EN"> (Updated:
August 27<sup>th</sup> 2018): <a href="http://advances.realtimerendering.com/s2018/s2018_real_time_correct_soft_shadows.pdf">PDF</a>
(78MB), <a href="https://www.youtube.com/watch?v=4ex2nrO7jgE">Video</a> <o:p></o:p></span></p>








</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>