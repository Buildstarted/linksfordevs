<!DOCTYPE html>
<html lang="en">
<head>
    <title>
A crash course in compilers &#x2013; Increment: Programming Languages - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="A crash course in compilers &#x2013; Increment: Programming Languages - linksfor.dev(s)"/>
    <meta property="article:author" content="Ramsey Nasser"/>
    <meta property="og:description" content="Diving deeper into program language theory is a great way to grow as a developer. Here, we go through the essentials of using compilers in language design."/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://increment.com/programming-languages/crash-course-in-compilers/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - A crash course in compilers &#x2013; Increment: Programming Languages</title>
<div class="readable">
        <h1>A crash course in compilers &#x2013; Increment: Programming Languages</h1>
            <div>by Ramsey Nasser</div>
            <div>Reading time: 17-22 minutes</div>
        <div>Posted here: 03 Apr 2020</div>
        <p><a href="https://increment.com/programming-languages/crash-course-in-compilers/">https://increment.com/programming-languages/crash-course-in-compilers/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div><p>Late one night on an uncrowded subway car in New York City, I had my laptop open, working on a game whose deadline was drawing near. A gentleman sat next to me and, seeing the walls of colored text on my screen, asked if I was writing C++. I told him I wasn’t, and he was curious to hear what language I was using. I was working on a web game in a programming language I had designed for myself, and I told him so<span>—</span>it was something that I made up, I said. After looking at me for a moment, he asked,<span></span><span> “</span>Why would anyone do that?” I started to answer, but alas, we had arrived at his stop, and he disappeared onto the platform before I could explain myself. In many ways, I’ve been trying to answer that man’s question for years&nbsp;now<span>.</span></p><p>The thing is, I absolutely love programming languages. I work as a graphics and video game developer, which is thrilling and challenging work, but secretly I would rather be hacking on compilers. I love languages because, of everything I’ve encountered in computing, languages are by far the weirdest. They combine the brain-bending rigor of abstract math, the crushing pressures of capitalistic industry, and the irrational anxiety of a high school prom. The decision to adopt or avoid a language is always a mix of their perceived formal power (“Does this language even have this particular feature?”), employability (“Will this language get me a job?”), and popularity (“Does anyone important use this language anymore?”). I can’t think of another engineering tool that demands similar quasi-religious devotion from its users. Programming languages ask us to reshape our minds, and that makes them deeply personal and&nbsp;subjective<span>.</span></p><p>The field of study of programming languages is called programming language theory, or <span>PLT.</span> Software engineers are confronted with programming languages just about every day, but few develop a deep relationship with <span>PLT.</span> Languages are tools, primarily, a means to an end, and most professionals will do fine just learning to use the popular ones well enough to get their jobs&nbsp;done<span>.</span></p><p>Diving deeper into <span>PLT,</span> though, is a great way to grow as a developer. Not only is language design a lot of fun, but a deeper understanding of the tools you use every day will give you a better handle on them, and can make learning new languages considerably easier, even if you don’t dream of becoming the next <a href="https://www.python.org/" null="" target="_blank"><strong>Guido van Rossum</strong></a> or <a href="https://clojure.org/" null="" target="_blank"><strong>Rich Hickey</strong></a>. And hey, you never know<span>—</span>your personal project could become the next major piece of software engineering infrastructure. <a href="https://secure.php.net/history.php" null="" target="_blank">It’s happened&nbsp;before</a><span>.</span></p></div><div><h2 id="what-is-a-programming-language"><a href="#what-is-a-programming-language">What is a programming language?</a></h2><p>So, what is a programming language? This might seem like an odd question to ask about tools this ubiquitous, but starting from a definition is often helpful to focus the conversation. A programming language is a formal language used to communicate instructions to a computer. It is formal in that it conforms to a rigid set of rules that determine what is and is not allowed. It is a means of communication in that the primary goal of the tool is to translate ideas in a programmer’s head into a form that a computer can act on. The fact that you are communicating with a computer is significant. Unlike other forms of language, or even instructional arts like musical composition or screenwriting, the final agent fulfilling the instructions is not human. The result is that qualities that other forms of communication tend to depend on<span>—</span>like intuition, common sense, and context<span>—</span>are not&nbsp;available<span>.</span></p><p>The decisive factor in what makes something a programming language (or not) is known as Turing completeness. Alan Turing’s seminal work in the 1940s included the definition of the Turing machine, a mathematical description of an abstract computer that became foundational for our understanding of how algorithms work. A Turing machine can, provably, implement any computable algorithm, and any system that can simulate the Turing machine can do so as well. Such a system is deemed Turing complete, and most programming languages have this status as a basic goal (though there are some interesting languages that do not). A deep dive into computability theory is beyond the scope of this article, but suffice it to say that a language with some notion of state (often variables or argument passing) and conditionals is most likely Turing complete. This leaves out markup languages like <span>HTML </span>and configuration languages like <span>YAML </span>or <span>JSON,</span> but includes a hilarious collection of systems that are <a href="http://beza1e1.tuxen.de/articles/accidentally_turing_complete.html" null="" target="_blank">accidentally Turing complete</a> (including an abuse of <span>HTML </span>and&nbsp;<span>CSS)</span><span>.</span></p><p>In practice, you interact with programming languages via computer programs or software libraries into which you feed code in order to produce an effect. They come in two broad manifestations: as compilers and as interpreters. Each approach has its advantages and disadvantages, and the line between the two can be quite blurry, with frameworks like Mono going so far as to <a href="http://www.mono-project.com/news/2017/11/13/mono-interpreter/" null="" target="_blank">offer both simultaneously</a><span>.</span></p><p>An interpreter’s job is to take source code and immediately implement its effects. An interpreter turns source code into an internal representation that it can use to carry out the computation the source code describes. This representation will include the functions, variables, expressions, statements, and all other semantics of the source language. You can think of source code as an extreme, Turing-complete configuration file that controls the interpreter’s behavior. My first foray into language design was based on <a href="http://norvig.com/lispy.html" null="" target="_blank">Peter Norvig’s excellent Lispy interpreter in Python</a>, and the more recent <strong><a href="https://github.com/kanaka/mal" null="" target="_blank"><span>MAL </span>project</a></strong> has amassed implementations in 72 languages. The advantages of interpreters include their simplicity, the fact that they can often start executing faster than compilers, and their ability to run in environments where compiling new code is prohibited (like on <a href="https://developer.apple.com/app-store/review/guidelines/#software-requirements" null="" target="_blank">iOS</a> or most video game&nbsp;consoles)<span>.</span></p><p>This piece, however, will focus on compilers. The job of a compiler is to take source code and translate it into a target code with the same meaning. Often that target code is in a lower-level language like machine code, but that isn’t always the case. The generated target code can then be evaluated in order to carry out the computation of the original source code. Compilers can be thought of as a pipeline of transformations, starting with the programmer’s source code and proceeding through a series of internal representations that end in the desired target code, after which it is handed off to another system for&nbsp;evaluation<span>.</span></p><p>The classic example is a compiler for the C programming language, where source code written in C is compiled into machine code that a computer’s hardware can execute directly. In this case, a higher-level language is compiled into a lower-level one. C# and Java are similar, but they compile into <strong>bytecodes</strong> that are executed by the <a href="https://en.wikipedia.org/wiki/Common_Language_Runtime" null="" target="_blank">Common Language Runtime</a> (<span>CLR)</span> and the <a href="https://en.wikipedia.org/wiki/Java_bytecode" null="" target="_blank">Java virtual machine</a> (<span>JVM)</span>, respectively, as opposed to physical hardware. Virtual machines like the <span>CLR </span>and the <span>JVM </span>provide cross-platform environments that handle a lot of low-level details for you while providing additional functionality like garbage collection and a type system. There are even cases where it is desirable to compile a lower-level language into a higher-level one. To run in the browser, the <a href="http://jsil.org/" null="" target="_blank"><span>JSIL</span></a> project compiles C# bytecode into JavaScript so it can run on the web, and <a href="https://github.com/kripken/emscripten" null="" target="_blank">Emscripten</a> does the same for C and C++. There are also situations where the same language is both the source and target language. The so-called transpilers <a href="https://babeljs.io/" null="" target="_blank">Babel</a> and <a href="https://developers.google.com/closure/" null="" target="_blank">Closure</a> compile JavaScript into JavaScript in order to access new features of the language and implement optimizations,&nbsp;respectively<span>.</span></p></div><div><h2 id="how-does-a-compiler-work"><a href="#how-does-a-compiler-work">How does a compiler work?</a></h2><p>Compilers tend to proceed in a linear sequence of phases, each phase providing the next with its input. Even wildly different languages will broadly have the same structure. Comparing the compilation steps of different languages is a useful way to get a handle on the general process, and to begin to grok how a compiler&nbsp;works<span>.</span></p><h3 id="parsing">Parsing</h3><p>The first question a compiler has to answer is,<span></span><span> “</span>What did the programmer say?” This step in the compiler pipeline is usually called parsing. The user prepares source code that is valid in the language they are programming in. Source code is often text, but it doesn’t have to be<span>—</span>take the visual languages <a href="https://scratch.mit.edu/" null="" target="_blank">Scratch</a>, <a href="https://puredata.info/" null="" target="_blank">Pure Data (Pd</a>), and <a href="https://cycling74.com/products/max/" null="" target="_blank">Max/<span>MSP</span></a>, for example. Once the programmer has prepared their source code, the compiler’s first task is to turn it into a data structure that is useful to later stages of the compiler. This is the stage where errors specific to the syntax are reported, like missing semicolons or unmatched braces. This is done differently from language to language, but in two broad categories: Lisp reading and scanning/parsing<span>.</span></p><p>Languages in the Lisp family are notorious for their simple syntaxes. The simplicity is a result of deliberate design, but also a side-effect of a property that Lisp programmers take very seriously: Lisp source code is a literal representation of Lisp data. Put another way, Lisp source code is <a href="https://en.wikipedia.org/wiki/Homoiconicity" null="" target="_blank">homoiconic</a> with Lisp data. To that end, the first step in a Lisp compiler is to turn source code text into data structures that the language understands. Historically this has included lists, numbers, and symbols, known collectively as<span></span><span> “</span>symbolic expressions” or<span></span><span> “</span>s-expressions,” but modern Lisps like Clojure include hashmaps, vectors, and sets in their syntax. Lisps traditionally call this step<span></span><span> “</span>reading” instead of parsing (which is where the R in <a href="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop" null="" target="_blank"><span>REPL</span></a> comes from, a Lisp idea). Lisp readers are simple enough that they tend to be written by hand. <a href="https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/LispReader.java" null="" target="_blank">Clojure’s reader</a> is handwritten in Java and contains a combination of regular expressions and <a href="https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/LispReader.java#L282" null="" target="_blank">string operations</a> to convert text into data structures, even matching against <a href="https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/LispReader.java#L383" null="" target="_blank">string literals</a> when it needs&nbsp;to<span>.</span></p><p>Languages with more complex syntax require more work. The majority of mainstream languages require a two-step process: scanning followed by parsing. A scanner (also known as a lexical analyzer) reads source text and produces a linear stream of tokens; the parser reads the stream of tokens and recognizes patterns to transform into nodes in an abstract syntax tree that the next step of the pipeline will deal with. The complexity of this step depends on the complexity of the syntax of the language. Some languages will use handwritten scanners and parsers, while others will depend on parser generators like Lex/Yacc or <a href="https://github.com/westes/flex" null="" target="_blank">Flex</a>/<a href="https://www.gnu.org/software/bison/" null="" target="_blank">Bison</a>, which take as input a specification of the desired grammar of the language, and produce as output a scanner and parser for that&nbsp;language<span>.</span></p><p>TypeScript’s <a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/scanner.ts" null="" target="_blank">scanner</a> is handwritten and features recognizable constructs like <a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/scanner.ts#L64" null="" target="_blank">mapping from keywords to token types</a> and a <a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/scanner.ts#L1413" null="" target="_blank">large statement switching on character codes</a> to determine what to scan next. The tokens allow the <a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/parser.ts" null="" target="_blank">parser</a> to reason with higher-level constructs like <code>SyntaxKind.​AsteriskToken</code> and <code>SyntaxKind.​OpenBraceToken</code> as in the <code><a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/parser.ts#L5906" null="" target="_blank">parse​Import​Declaration​Or​Import​Equals​Declaration</a></code> function. CoffeeScript relies on <a href="https://github.com/zaach/jison" null="" target="_blank">Jison</a>, a JavaScript port of Bison, for <a href="https://github.com/jashkenas/coffeescript/blob/master/src/grammar.coffee" null="" target="_blank">its parsing</a>. We can see the language described as <a href="https://github.com/jashkenas/coffeescript/blob/master/src/grammar.coffee#L71" null="" target="_blank">a grammar</a> with declarative rules, like the rules for <a href="https://github.com/jashkenas/coffeescript/blob/master/src/grammar.coffee#L779" null="" target="_blank">if expressions</a>. Ruby’s <a href="https://github.com/ruby/ruby/blob/trunk/parse.y" null="" target="_blank">Yacc grammar</a> is a favorite of mine: In order to implement Ruby’s famously appealing syntax, the grammar comes out to a colossal <a href="https://github.com/ruby/ruby/blob/trunk/parse.y#L11406" null="" target="_blank">11,400+ lines of Yacc&nbsp;code</a>!</p><h3 id="analysis">Analysis</h3><p>Once parsing is complete, the compiler must analyze the parsed code into an abstract syntax tree, or <span>AST.</span> Analysis answers the question,<span></span><span> “</span>What did the user mean?” Languages in the Lisp family will usually take an additional step to go from the s-expressions the reader produced to an initial <span>AST,</span> while the parsers of languages outside the Lisp family will usually produce an <span>AST </span>directly. This is where the semantic features of the language are implemented, like name resolution, control flow, and function invocation. Additionally, analysis is a phase where optimizations can begin to happen, by transforming the <span>AST </span>into semantically equivalent <span>ASTs</span> that perform better. This is likely the most varied phase between compilers, and each language will be radically different here. There aren’t really any libraries or <span>APIs</span> to lean on here, and it’s up to the language implementer to derive this meaning&nbsp;themselves<span>.</span></p><p>In languages with types, this is where type information is inferred, flowed, and validated. Even dynamically typed languages can flow type information in order to gain performance. For example, Clojure<span>CLR </span>uses <strong>reflection</strong> to determine the type of its <a href="https://github.com/clojure/clojure-clr/blob/master/Clojure/Clojure/CljCompiler/Ast/StaticMethodExpr.cs#L83" null="" target="_blank">static method invocations</a> and <a href="https://github.com/clojure/clojure-clr/blob/master/Clojure/Clojure/CljCompiler/Ast/StaticFieldExpr.cs#L106" null="" target="_blank">static field lookups</a>. This information is used to generate better bytecode and compiler errors. Languages like TypeScript provide a type system to a target that is dynamically typed by <a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/checker.ts" null="" target="_blank">thoroughly checking types in the analysis phase</a> and issuing a warning if types do not line up. Type-safe languages like Haskell will dedicate a <a href="https://github.com/ghc/ghc/tree/master/compiler/typecheck" null="" target="_blank">large portion of their analysis</a> phase to type&nbsp;checking<span>.</span></p><h3 id="emission">Emission</h3><p>Once an <span>AST </span>is produced and settled on, the final step is to emit the target code. When targeting machine code, modern languages will most often use the <a href="https://llvm.org/" null="" target="_blank"><span>LLVM </span>toolchain</a>. <span>LLVM </span>is an exciting project because it unifies various hardware platforms and optimizations under one target. It specifies its own <a href="https://llvm.org/docs/LangRef.html" null="" target="_blank">intermediate representation (<span>LLVM </span><span>IR)</span></a> that a compiler would emit. <span>IR </span>code then goes through the same parse-analyze-emit pipeline described in this article to turn into machine code. The benefit is that <span>LLVM </span>presents a more straightforward assembly language that is still very low level without concerning the language developer with platform-specific quirks. Targeting <span>IR </span>means your language can take advantage of optimizations written for C and C++ with no additional effort on your part. <span>LLVM </span>exposes both a <a href="https://llvm.org/docs/ProgrammersManual.html" null="" target="_blank">C++</a> and a <a href="https://llvm.org/doxygen/group__LLVMC.html" null="" target="_blank">C</a> <span>API </span>to generate <span>IR.</span> The C <span>API </span>means bindings to other languages are possible (I’ve successfully used them in <a href="https://github.com/kevinmehall/node-llvm" null="" target="_blank">Node</a> and <a href="https://github.com/Microsoft/LLVMSharp/" null="" target="_blank">C#</a>). <span>LLVM </span>can even be found in compilers for dynamic languages like&nbsp;<a href="https://github.com/JuliaLang/julia/blob/master/src/codegen.cpp#L3345" null="" target="_blank">Julia</a><span>.</span></p><p>Virtual machine targets like the <span>CLR </span>and the <span>JVM </span>are similar, but each exposes a bytecode language that is at an even higher level than <span>LLVM </span><span>IR.</span> C#’s standard library provides a very robust namespace <a href="https://msdn.microsoft.com/en-us/library/system.reflection.emit%28v=vs.110%29.aspx" null="" target="_blank">specifically for generating bytecode</a> that exposes an object-oriented interface to emit <a href="https://msdn.microsoft.com/en-us/library/system.reflection.emit.assemblybuilder%28v=vs.110%29.aspx" null="" target="_blank">assemblies</a>, <a href="https://msdn.microsoft.com/en-us/library/system.reflection.emit.typebuilder%28v=vs.110%29.aspx" null="" target="_blank">types</a>, <a href="https://msdn.microsoft.com/en-us/library/system.reflection.emit.methodbuilder%28v=vs.110%29.aspx" null="" target="_blank">methods</a>, and every other aspect of bytecode. Java does not have a comparable namespace in its own standard library, but third-party libraries like <a href="http://asm.ow2.org/" null="" target="_blank"><span>ASM</span></a> or <a href="https://commons.apache.org/proper/commons-bcel/" null="" target="_blank"><span>BCEL</span></a> can fill this gap. These <span>APIs</span> can be seen in somewhat wrapped form in Clojure’s <a href="https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/Compiler.java#L3795" null="" target="_blank"><span>JVM</span></a> and <a href="https://github.com/clojure/clojure-clr/blob/master/Clojure/Clojure/CljCompiler/Ast/InvokeExpr.cs#L382" null="" target="_blank"><span>CLR</span></a>&nbsp;compilers<span>.</span></p><p>If the target is source code in a high-level language, emission might actually involve concatenating strings together. There often isn’t an existing <span>API </span>to generate source code in a high-level programming language<span>—</span>the expectation is that a human programmer will manually type it all out. This is an issue for languages that compile to JavaScript, as is evident in the <a href="https://github.com/clojure/clojurescript/blob/master/src/main/clojure/cljs/compiler.cljc#L604" null="" target="_blank">ClojureScript</a> and <a href="https://github.com/Microsoft/TypeScript/blob/master/src/compiler/emitter.ts#L1877" null="" target="_blank">TypeScript</a> compilers. Some languages, like Carp, treat C as their compile target, resulting in <a href="https://github.com/carp-lang/Carp/blob/master/src/Emit.hs#L537" null="" target="_blank">similar-looking emission&nbsp;phases</a><span>.</span></p><h3 id="tooling-and-ecosystems">Tooling and ecosystems</h3><p>At this point, formally speaking, you’re done! The compiler has transformed code from the source language into the target language and achieved its basic goal. In practice, however, the job of a language designer is just beginning. Languages are more than their compilers, and the day-to-day experience of working with a language actually involves myriad developer tools acting in concert. Once a language’s compiler is working, the question then becomes one of editor integration, debugger support, documentation, a community, and a library ecosystem. Most of this takes considerable time to develop, and this is what gives existing languages inertia over new&nbsp;ones<span>.</span></p><p>Historically, languages had not directly addressed the task of managing third-party libraries, or packages. In the pre-web, pre-open source days, when languages like C++ arrived, the issue of integrating with a stranger’s code was nowhere near as complicated as it is now. Even languages that appeared in the 1990s tended to not include package managers, with Ruby’s <a href="https://rubygems.org/" null="" target="_blank">RubyGems</a> not landing until eight years after Ruby itself. Post-web languages are more likely to include a package manager as part of their standard tooling, as <a href="http://elm-lang.org/blog/announce/package-manager" null="" target="_blank">Elm</a> and <a href="https://github.com/rust-lang/cargo" null="" target="_blank">Rust</a> do. Most package managers are specific to their languages, custom built, and require server infrastructure, though generic solutions like <a href="https://github.com/whyrusleeping/gx" null="" target="_blank">Gx</a> and <a href="https://nixos.org/nix/" null="" target="_blank">Nix</a> are available as well. Gx is interesting because it operates over <a href="https://ipfs.io/" null="" target="_blank"><span>IPFS</span></a>, a peer-to-peer protocol that requires no central server coordination. Nix is the result of Eelco Dolstra’s PhD thesis,<span></span><span> “</span><a href="http://grosskurth.ca/bib/2006/dolstra-thesis.pdf" null="" target="_blank">The Purely Functional Software Deployment Model</a>,” and is primarily used in the Nix<span>OS </span>operating system. It’s purely functional and, as a result, provides very reproducible&nbsp;deployments<span>.</span></p><p>Integrating with editors has also been a pain, traditionally. Programmers expect good syntax highlighting, completion, and other features all in their favorite editor. It was usually up to the community to provide these bindings, leading to an uneven developer experience across editors. Recently, Microsoft has put out what they call the <a href="https://langserver.org/" null="" target="_blank">Language Server Protocol</a> to help address these issues and make it easier to integrate new programming languages with text editors. It’s essentially a network protocol for a text editor. Your language only needs to implement the protocol once, and then every editor that supports it (which is most major editors) can communicate with your language to get autocomplete and other&nbsp;features<span>.</span></p><h2 id="why-anyone-would-do-this"><a href="#why-anyone-would-do-this">Why anyone would do this</a></h2><p>If you’re reading this, gentleman from the subway, I hope it has begun to answer your question about why anyone would make up a programming language. It’s a wonderful puzzle to solve, and more approachable than it may seem at first. Languages represent different ideas of how to capture human creativity on a machine, and I’ve never been disappointed by pulling the curtain back on an implementation to see how it ticks. Seeing common patterns across different languages and getting a sense of their trade-offs also gives you a new perspective when picking up new languages, something every working programmer will have to do at some point in their&nbsp;career<span>.</span></p><p>Whether you’re building the next chapter in the history of software engineering or just peeking under the hood of a machine that you use every day, the world of programming languages is yours to explore. It will expand your mind and make you a better programmer<span>—</span>and you might not even be the strangest person on the&nbsp;train<span>.</span></p></div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>