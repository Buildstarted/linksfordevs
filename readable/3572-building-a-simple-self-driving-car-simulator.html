<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Building a Simple Self-Driving Car Simulator -
linksfor.dev(s)
    </title>
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta charset="utf-8">
    <meta name="Description" content="A curated source of links that devs might find interesting. Updated around the clock." />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        
<div class="readable">
    <div id="readOverlay" class="style-ebook" xmlns=""><div id="readInner" class="margin-medium size-medium"><h1>Building a Simple Self-Driving Car Simulator</h1><div><div class="entry clear" xmlns="http://www.w3.org/1999/xhtml"><p>As part of my new job, I’ve been working with Professor Liam Paull and his students on building a simulator for <a href="http://duckietown.org/">Duckietown</a>. This is a university course being taught at ETH Zurich, the University of Montreal, TTIC/UChicago and other institutions, where&nbsp;students learn about self-driving cars and robotics by building their own small-scale model which can drive around in the miniature Duckietown universe, complete with turns, intersections, traffic signs, and other moving vehicles.</p><p>The course has, so far, been focused on traditional robotics methods using computer vision and PID controllers to drive the robots. However, students and professors are becoming increasingly interested in using deep learning (and reinforcement learning in particular). Since reinforcement learning needs a lot of data, it’s much more practical to do it in simulation than with physical robots. This has been one of the main motivations for building a simulator.</p><p>The simulator I’m building works as an OpenAI Gym environment, which makes it easy to use for reinforcement learning. It’s written in pure Python and uses OpenGL (pyglet) to produce graphics. I chose Python because this is the language most used by the deep learning community, and I wanted for students to be able to modify the simulator easily. The simulator performs many forms of <a href="https://blog.openai.com/spam-detection-in-the-physical-world/">domain randomization</a>: it randomly varies colors, the camera angle and field of view, etc. This feature is meant to help neural networks learn to deal with variability, so that trained networks will hopefully work not just in simulation, but also in the real world as well.</p><span class="embed-youtube"><p>Because Duckietown is a toy universe that is essentially two-dimensional,&nbsp;I’ve designed a <a href="https://github.com/duckietown/gym-duckietown/blob/master/gym_duckietown/maps/udem1.yaml">YAML map format</a> which can be easily hand-edited to create custom new environments. It essentially describes a set of tiles, and where to place 3D models relative to those tiles. I’ve also made some simplifying assumptions with regard to physics (the agent essentially moves along a 2D plane).</p><p>While working on this simulator, I’m also experimenting with sim-to-real transfer, that is, getting policies trained in simulation to work with a real robot. This is a work in progress, but we are close to having this working reliably. The video below shows some promising results:</p><span class="embed-youtube"><p>If you’re interested in playing with this, the source code is <a href="https://github.com/duckietown/gym-duckietown">available on GitHub</a>. Feedback and contributions are welcome. If you run into any issues, please report them, as I’d like to make the simulator as easy to use as possible.</p><div id="jp-post-flair" class="sharedaddy sd-like-enabled sd-sharing-enabled"></div></span></span></div></div></div></div>
</div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script>
        (function () {
            var COLLECT_URL = "https://dna.buildstarted.com/t";
            var SITE_ID = "linksfor.devs";
            var GLOBAL_VAR_NAME = "__DNA__";

            window[GLOBAL_VAR_NAME] = {};

            window[GLOBAL_VAR_NAME].sendPageView = function () {
                var path = location.pathname;
                var referrer = document.referrer;

                var url = COLLECT_URL + "?siteid=" + SITE_ID + "&p=" + encodeURIComponent(path) + "&r=" + encodeURIComponent(referrer);

                try { fetch(url, { method: "GET" }); } catch (e) { }
            };

            window[GLOBAL_VAR_NAME].sendPageView();
        })();
    </script>
</body>
</html>