<!DOCTYPE html>
<html lang="en">
<head>
    <title>
first20hours/google-10000-english: This repo contains a list of the 10,000 most common English words in order of frequency, as determined by n-gram frequency analysis of the Google&#x27;s Trillion Word Corpus. -
linksfor.dev(s)
    </title>
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta charset="utf-8">
    <meta name="Description" content="A curated source of links that devs might find interesting. Updated around the clock." />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        
<div class="readable">
    <div id="readOverlay" class="style-ebook"><div id="readInner" class="margin-medium size-medium"><h1>first20hours/google-10000-english: This repo contains a list of the 10,000 most common English words in order of frequency, as determined by n-gram frequency analysis of the Google's Trillion Word Corpus.</h1><div><div id="" class="markdown-body entry-content p-5"><p>This repo contains a list of the 10,000 most common English words in order of frequency, as determined by <a href="https://en.wikipedia.org/wiki/N-gram" rel="nofollow">n-gram</a><a href="https://en.wikipedia.org/wiki/Frequency_analysis" rel="nofollow">frequency analysis</a> of the <a href="https://books.google.com/ngrams/info" rel="nofollow">Google's Trillion Word Corpus</a>.</p><p>According to the <a href="https://ai.googleblog.com/2006/08/all-our-n-gram-are-belong-to-you.html" rel="nofollow">Google Machine Translation Team</a>:</p><blockquote><p>Here at Google Research we have been using word n-gram models for a variety of R&amp;D projects, such as statistical machine translation, speech recognition, spelling correction, entity detection, information extraction, and others. While such models have usually been estimated from training corpora containing at most a few billion words, we have been harnessing the vast power of Google's datacenters and distributed processing infrastructure to process larger and larger training corpora. We found that there's no data like more data, and scaled up the size of our data by one order of magnitude, and then another, and then one more - resulting in a training corpus of one trillion words from public Web pages.</p><p>We believe that the entire research community can benefit from access to such massive amounts of data. It will advance the state of the art, it will focus research in the promising direction of large-scale, data-driven approaches, and it will allow all research groups, no matter how large or small their computing resources, to play together. That's why we decided to share this enormous dataset with everyone. We processed 1,024,908,267,229 words of running text and are publishing the counts for all 1,176,470,663 five-word sequences that appear at least 40 times. There are 13,588,391 unique words, after discarding words that appear less than 200 times.</p></blockquote><p>This repo is derived from <a href="https://norvig.com/ngrams/" rel="nofollow">Peter Norvig's</a> compilation of the <a href="https://norvig.com/ngrams/count_1w.txt" rel="nofollow">1/3 million most frequent English words</a>. I limited this file to the 10,000 most common words, then removed the appended frequency counts by running this sed command in my text editor:</p><pre><code>sed 's/[0-9]*//g'
</code></pre><p>Special thanks to <a href="https://github.com/koseki">koseki</a> for <a href="https://github.com/first20hours/google-10000-english/issues/6">de-duplicating the list</a>.</p><h2><a id="user-content-swear-free-lists" class="anchor" aria-hidden="true" href="#swear-free-lists"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Swear-free lists</h2><p>There are two additional lists which are identical to the original 10,000 word list, but with swear words removed. These are ideal for generating URLs, temporary passwords, or other uses where swear words may not be desired.</p><p>Swears were removed based on these lists:</p><h2><a id="user-content-word-length-lists" class="anchor" aria-hidden="true" href="#word-length-lists"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Word length lists</h2><p>Three of the lists (all based on the US english list) are based on word length:</p><ul><li><strong>Short</strong>: 1-4 characters</li><li><strong>Medium</strong>: 5-8 characters</li><li><strong>Long</strong>: 9+ characters</li></ul><p>Each list retains the original list sorting (by frequency, decending).</p><h2><a id="user-content-usage" class="anchor" aria-hidden="true" href="#usage"><svg class="octicon octicon-link" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Usage</h2><p>This repo is useful as a corpus for typing training programs. According to analysis of the <a href="https://en.oxforddictionaries.com/explore/what-can-corpus-tell-us-about-language/" rel="nofollow">Oxford English Corpus</a>, the 7,000 most common English lemmas account for approximately 90% of usage, so a 10,000 word training corpus is more than sufficient for practical training applications.</p><p>To use this list as a training corpus in <a href="https://code.google.com/archive/p/amphetype/" rel="nofollow">Amphetype</a>, paste the contents into the "Lesson Generator" tab with the following settings:</p><pre><code>Make **3** copies of the list

Divide into sublists of size **3**

Add to sources as **google-10000-english**
</code></pre><p>In the "Sources" tab, you should see <strong>google-10000-english</strong> available for training. Set WPM at 10 more than your current average, set accuracy to 98%, and you're set to train.</p><p>Enjoy!</p></div></div></div></div>
</div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script>
        (function () {
            var COLLECT_URL = "https://dna.buildstarted.com/t";
            var SITE_ID = "linksfor.devs";
            var GLOBAL_VAR_NAME = "__DNA__";

            window[GLOBAL_VAR_NAME] = {};

            window[GLOBAL_VAR_NAME].sendPageView = function () {
                var path = location.pathname;
                var referrer = document.referrer;

                var url = COLLECT_URL + "?siteid=" + SITE_ID + "&p=" + encodeURIComponent(path) + "&r=" + encodeURIComponent(referrer);

                try { fetch(url, { method: "GET" }); } catch (e) { }
            };

            window[GLOBAL_VAR_NAME].sendPageView();
        })();
    </script>
</body>
</html>