<!DOCTYPE html>
<html lang="en">
<head>
    <title>
JaidedAI/EasyOCR - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="JaidedAI/EasyOCR - linksfor.dev(s)"/>
    <meta property="og:description" content="Ready-to-use OCR with 40&#x2B; languages supported including Chinese, Japanese, Korean and Thai - JaidedAI/EasyOCR"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://github.com/JaidedAI/EasyOCR"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
	<div class="devring" style="background: #222">
		<div class="grid">
			<div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
				<span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
				<a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
				<a href="https://devring.club/random" class="devring-random">Random</a>
				<a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
			</div>
		</div>
	</div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - JaidedAI/EasyOCR</title>
<div class="readable">
        <h1>JaidedAI/EasyOCR</h1>
            <div>Reading time: 4-5 minutes</div>
        <div>Posted here: 08 Jul 2020</div>
        <p><a href="https://github.com/JaidedAI/EasyOCR">https://github.com/JaidedAI/EasyOCR</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div id="readme">
    
        

      <div>
        <article itemprop="text">
<p>Ready-to-use OCR with 40+ languages supported including Chinese, Japanese, Korean and Thai.</p>
<h2>Examples</h2>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/JaidedAI/EasyOCR/blob/master/examples/example.png"><img src="https://github.com/JaidedAI/EasyOCR/raw/master/examples/example.png" alt="example"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/JaidedAI/EasyOCR/blob/master/examples/example2.png"><img src="https://github.com/JaidedAI/EasyOCR/raw/master/examples/example2.png" alt="example2"></a></p>
<h2>Supported Languages</h2>
<p>We are currently supporting following 42 languages.</p>
<p>Afrikaans (af), Azerbaijani (az), Bosnian (bs), Simplified Chinese (ch_sim),
Traditional Chinese (ch_tra), Czech (cs), Welsh (cy),
Danish (da), German (de), English (en), Spanish (es), Estonian (et),
French (fr), Irish (ga), Croatian (hr), Hungarian (hu), Indonesian (id),
Icelandic (is), Italian (it), Japanese (ja), Korean (ko), Kurdish (ku),
Latin (la), Lithuanian (lt),
Latvian (lv), Maori (mi), Malay (ms), Maltese (mt), Dutch (nl), Norwegian (no),
Polish (pl), Portuguese (pt),Romanian (ro), Slovak (sk) (need revisit), Slovenian (sl),
Albanian (sq), Swedish (sv),Swahili (sw), Thai (th), Tagalog (tl),
Turkish (tr), Uzbek (uz), Vietnamese (vi)</p>
<p>List of characters is in folder easyocr/character. If you are native speaker
of any language and think we should add or remove any character,
please create an issue and/or pull request (like <a href="https://github.com/JaidedAI/EasyOCR/pull/15">this one</a>).</p>
<h2>Installation</h2>
<p>Install using <code>pip</code> for stable release,</p>

<p>For latest development release,</p>
<div><pre>pip install git+git://github.com/jaidedai/easyocr.git</pre></div>
<p>Note: for Windows, please install torch and torchvision first by following official instruction here <a href="https://pytorch.org/" rel="nofollow">https://pytorch.org</a></p>
<h2>Usage</h2>
<div><pre><span>import</span> <span>easyocr</span>
<span>reader</span> <span>=</span> <span>easyocr</span>.<span>Reader</span>([<span>'th'</span>,<span>'en'</span>])
<span>reader</span>.<span>readtext</span>(<span>'test.jpg'</span>)</pre></div>
<p>Note: Instead of filepath 'test.jpg', you can also pass OpenCV image object or image file as bytes.</p>
<p>Model weight for chosen language will be automatically downloaded or you can
download it manually from the following links and put it in '~/.EasyOCR/model' folder</p>
<p><a href="https://drive.google.com/file/d/1tdItXPoFFeKBtkxb9HBYdBGo-SyMg1m0/view?usp=sharing" rel="nofollow">text detection model</a></p>
<p><a href="https://drive.google.com/file/d/1M7Lj3OtUsaoppD4ZKudjepzCMsXKlxp3/view?usp=sharing" rel="nofollow">latin model</a></p>
<p><a href="https://drive.google.com/file/d/1xWyQC9NIZHNtgz57yofgj2N91rpwBrjh/view?usp=sharing" rel="nofollow">chinese (traditional) model</a></p>
<p><a href="https://drive.google.com/file/d/1-jN_R1M4tdlWunRnD5T_Yqb7Io5nNJoR/view?usp=sharing" rel="nofollow">chinese (simplified) model</a></p>
<p><a href="https://drive.google.com/file/d/1ftAeVI6W8HvpLL1EwrQdvuLss23vYqPu/view?usp=sharing" rel="nofollow">japanese model</a></p>
<p><a href="https://drive.google.com/file/d/1UBKX7dHybcwKK_i2fYx_CXaL1hrTzQ6y/view?usp=sharing" rel="nofollow">korean model</a></p>
<p><a href="https://drive.google.com/file/d/14BEuxcfmS0qWi3m9RsxwcUsjavM3rFMa/view?usp=sharing" rel="nofollow">thai model</a></p>
<p>Output will be in list format, each item represents bounding box, text and confident level, respectively.</p>
<div><pre>[([[1344, 439], [2168, 439], [2168, 580], [1344, 580]], <span><span>'</span>ใจเด็ด<span>'</span></span>, 0.4542357623577118),
 ([[1333, 562], [2169, 562], [2169, 709], [1333, 709]], <span><span>'</span>Project<span>'</span></span>, 0.9557611346244812)]</pre></div>
<p>In case you do not have GPU or your GPU has low memory, you can run it in CPU mode by adding gpu = False</p>
<div><pre><span>reader</span> <span>=</span> <span>easyocr</span>.<span>Reader</span>([<span>'th'</span>,<span>'en'</span>], <span>gpu</span> <span>=</span> <span>False</span>)</pre></div>
<p>There are optional arguments for readtext function, <code>decoder</code> can be 'greedy'(default), 'beamsearch', or 'wordbeamsearch'. For 'beamsearch' and 'wordbeamsearch', you can also set <code>beamWidth</code> (default=5). Bigger number will be slower but can be more accurate. For multiprocessing, you can set <code>workers</code> and <code>batch_size</code>. Current version converts image into grey scale for recognition model, so contrast can be an issue. You can try playing with <code>contrast_ths</code>, <code>adjust_contrast</code> and <code>filter_ths</code>.</p>
<h2>To be implemented</h2>
<ol>
<li>Language packs: Hindi, Arabic, Cyrillic alphabet, etc.</li>
<li>Language model for better decoding</li>
<li>Better documentation and api</li>
</ol>
<h2>Acknowledgement and References</h2>
<p>This project is based on researches/codes from several papers/open-source repositories.</p>
<p>Detection part is using CRAFT algorithm from this <a href="https://github.com/clovaai/CRAFT-pytorch">official repository</a> and their <a href="https://arxiv.org/abs/1904.01941" rel="nofollow">paper</a>.</p>
<p>Recognition model is CRNN (<a href="https://arxiv.org/abs/1507.05717" rel="nofollow">paper</a>). It is composed of 3 main components, feature extraction (we are currently using <a href="https://arxiv.org/abs/1512.03385" rel="nofollow">Resnet</a>), sequence labeling (<a href="https://www.bioinf.jku.at/publications/older/2604.pdf" rel="nofollow">LSTM</a>) and decoding (<a href="https://www.cs.toronto.edu/~graves/icml_2006.pdf" rel="nofollow">CTC</a>). Training pipeline for recognition part is a modified version from this <a href="https://github.com/clovaai/deep-text-recognition-benchmark">repository</a>.</p>
<p>Beam search code is based on this <a href="https://github.com/githubharald/CTCDecoder">repository</a> and his <a href="https://towardsdatascience.com/beam-search-decoding-in-ctc-trained-neural-networks-5a889a3d85a7" rel="nofollow">blog</a>.</p>
<p>And good read about CTC from distill.pub <a href="https://distill.pub/2017/ctc/" rel="nofollow">here</a>.</p>
<h2>Want To Contribute?</h2>
<p>Let's advance humanity together by making AI available to everyone!</p>
<p>Please create issue to report bug or suggest new feature. Pull requests are welcome. Or if you found this library useful, just tell your friend about it.</p>
</article>
      </div>
  </div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
		<div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>