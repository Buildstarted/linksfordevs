<!DOCTYPE html>
<html lang="en">
<head>
    <title>linksfor.dev(s)</title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        <h1>
                <span style="cursor: default" title="linksfor.dev(s) has been running for 1 year! :partypopper:">🎉</span>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <div class="readable">
        <h1>The Leaning Tower of Morality</h1>
        <p>
by Kevin Simler <br/>Reading time: 23-30 minutes        </p>
        <p><a href="https://www.ribbonfarm.com/2017/11/28/the-leaning-tower-of-morality/">https://www.ribbonfarm.com/2017/11/28/the-leaning-tower-of-morality/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><div><blockquote><p><em>Don’t hate the player, hate the game. — <a href="https://genius.com/Ice-t-dont-hate-the-playa-lyrics">Ice-T</a></em></p>
<p><em>Game theory is asleep, cooperate for no reason. — <a href="https://twitter.com/deityofreligion/status/651904944816168960">Deity of Religion</a></em></p></blockquote>
<p>There’s an image that’s taken root in my mind recently that I can’t seem to shake. I picture humanity living in a large, rickety tower, tilting at a precarious angle to the ground — like so:</p>
<p><a href="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower.png"><img src="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower.png" alt="" width="1775" height="669" srcset="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower.png 1775w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower-300x113.png 300w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower-768x289.png 768w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower-1024x386.png 1024w" sizes="(max-width: 1775px) 100vw, 1775px"></a></p>
<p>The tower represents our capacity for moral behavior. Lower levels are more base; higher levels, more virtuous. We don’t need an exact floorplan, but here’s the kind of thing I’m imagining:</p>
<ul>
<li><strong>Ground floor</strong>: Perfect zero-sum selfishness. Aggression and exploitation. The war of all against all.</li>
<li><strong>Middle floors</strong>: Various flavors of mutualism. “I’ll help you if you help me.” Reciprocity. Tit for tat.</li>
<li><strong>Higher floors</strong>: Empathy and compassion. Turning the other cheek. True virtue (not just signaling). A tendency to cooperate in one-shot prisoner’s dilemmas.</li>
<li><strong>Penthouse</strong>: Perfect self-sacrificing altruism. A willingness to give time, energy, money, or even one’s life to help a stranger for nothing in return.</li>
</ul>
<p>Now, some people inhabit higher floors than others, but with the exception of bona fide psychopaths, all of us live somewhere in the tower, happily above ground.</p>
<p>Here’s the question I want to explore today: How does this structure remain standing? On what ultimate explanatory principles do our moral instincts rest?</p>

<p>Let’s take a look at three possible answers.</p>
<p><strong>God</strong></p>
<p>One common answer is that our moral instincts are propped up by <strong>God</strong>, the great cosmic buttress:</p>
<p><a href="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_god.png"><img src="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_god.png" alt="" width="1775" height="668" srcset="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_god.png 1775w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_god-300x113.png 300w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_god-768x289.png 768w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_god-1024x385.png 1024w" sizes="(max-width: 1775px) 100vw, 1775px"></a></p>
<p>In the Christian worldview, it’s God’s love that induces us to climb higher. By promising eternal rewards (or threatening eternal punishment), God effectively subsidizes moral behavior, thereby stabilizing the higher floors. If He one day decided to forsake us, the tower would collapse and we’d fall to a much lower, more savage state.¹</p>
<p>Now, I don’t take this explanation particularly seriously. It strikes me, if you’ll pardon the expression, as a <em>deus ex machina</em> — a magical placeholder solution to what is otherwise a fascinating and important problem.² I just wanted to give a feel for the kind of thing that fits as an answer here.</p>
<p>Let’s now turn to the natural world, where two more interesting answers await.</p>
<p><strong>Individual selection</strong></p>
<p>A second answer to our question — <em>what supports the tower of morality?</em> — is natural selection. Specifically, <strong>individual selection</strong>. This is the Darwinian mechanism we all learned in high school: good old survival (and reproduction) of the fittest. The idea is that some individuals have more useful traits than others, and thereby live longer and pass more of their genes along to the next generation.</p>
<p>So if <em>morality</em> evolved via individual selection, it means that our ancestors who behaved morally outcompeted their rivals who didn’t; it was to their individual advantage to help others. This puts morality on the same foundation as our fear of heights, our taste for fatty foods, and our sex drive — namely, the logic of (genetic) self-interest.</p>
<p>As explanatory principles go, self-interest is solid. Certainly it’s capable of the kind of theoretical heavy-lifting needed to explain most features of the biological world. Metaphorically speaking, it means there’s nothing funky propping up the tower — just the ordinary forces of static friction and solids pushing back against solids:</p>
<p><a href="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower.png"><img src="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower.png" alt="" width="1775" height="669" srcset="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower.png 1775w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower-300x113.png 300w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower-768x289.png 768w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower-1024x386.png 1024w" sizes="(max-width: 1775px) 100vw, 1775px"></a></p>
<p>The problem with individual selection is that it has trouble explaining precisely the traits we’re investigating today: namely, those that involve true self-sacrifice. If someone behaves altruistically, he’s giving up some of his own resources — his own reproductive EV — in order to help others. In the game of individual selection, this is (by definition) a losing move. To take an extreme example, someone might martyr himself on a grenade to save the lives of innocent bystanders — in which case he’s <em>definitely</em> not passing any more of his altruistic genes along. In this way, when individuals compete against each other, altruism inevitably gets weeded out of the gene pool:</p>
<p><a href="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/individual_selection.png"><img src="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/individual_selection.png" alt="" width="1798" height="386" srcset="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/individual_selection.png 1798w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/individual_selection-300x64.png 300w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/individual_selection-768x165.png 768w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/individual_selection-1024x220.png 1024w" sizes="(max-width: 1798px) 100vw, 1798px"></a></p>
<p>I certainly don’t mean to suggest that individual selection is incapable of explaining morality. It’s just that any path from self-interest to moral behavior is going to be convoluted. Moreover, whatever explanation we come up with will necessarily entail two unpalatable conclusions — two “bitter pills” we would have to swallow if we want to ascribe our moral instincts to individual selection:</p>
<ul>
<li><strong>Bitter pill #1</strong>: Accepting that there’s no instinct for <em>true altruism</em>. Individual selection simply can’t evolve a creature that doesn’t optimize for its own bottom line; self-interest is non-negotiable. In the language of our tower metaphor, this means accepting that the penthouse doesn’t exist.</li>
<li><strong>Bitter pill #2</strong>: Accepting that even the highest floors, just below the missing penthouse, are manifestations of self-interest. In other words, every instinct for empathy, compassion, charity, and virtue, to the extent that it’s inborn, evolved because it benefitted our ancestors who expressed it.</li>
</ul>
<p>Thus, if we want to explain morality as a product of individual selection, we have to accept that the <em>entire tower</em> is based on self-interest:</p>
<p><a href="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_all_selfish.png"><img src="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_all_selfish.png" alt="" width="1775" height="668" srcset="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_all_selfish.png 1775w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_all_selfish-300x113.png 300w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_all_selfish-768x289.png 768w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_all_selfish-1024x385.png 1024w" sizes="(max-width: 1775px) 100vw, 1775px"></a></p>
<p><strong>Group selection</strong></p>
<p>The third answer to the question of what “props up” our moral instincts is <strong>group selection</strong>:</p>
<p><a href="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_group_selection.png"><img src="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_group_selection.png" alt="" width="1775" height="668" srcset="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_group_selection.png 1775w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_group_selection-300x113.png 300w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_group_selection-768x289.png 768w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_group_selection-1024x385.png 1024w" sizes="(max-width: 1775px) 100vw, 1775px"></a></p>
<p>Group selection — often discussed as <em>multilevel selection</em> — is another mechanism of Darwinian (genetic) evolution. The idea is that we have to look at competition among groups in addition to competition among individuals. This adds just enough of a twist to make things interesting.</p>
<p>Note that group selection, as biologists use the term, needs to be sharply distinguished from <em><a href="https://en.wikipedia.org/wiki/Cultural_selection_theory">cultural selection</a></em> — though the two are often conflated. Group selection is a <em>genetic</em> process whereby group competition causes some genes to become more or less frequent within a population. Cultural selection, in contrast, is a <em>memetic</em> process whereby group competition drives cultural change. (For example, one group might copy a practice from a more successful group.) There are many fascinating things to say about cultural selection, but in this post we are entirely concerned with group selection and its effects on human DNA.</p>
<p>To illustrate group selection, consider a simplified model with just two types of people: <em>saints</em> (indiscriminate altruists) and <em>sociopaths</em> (ruthless exploiters). Further, assume a person’s identity is fixed at birth and determined by a single gene. Now, within the context of a single group, saints will always lose out to sociopaths. An entire <em>group of saints</em>, however, will tend to outcompete a <em>group of sociopaths</em> — because the saints will cooperate while the sociopaths are cutting each other down. And thus nicer groups will grow, flourish, and make more babies, while nasty groups wither away. This is how we might, plausibly, evolve altruism out of “nature red in tooth and claw.”</p>
<p><a href="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_pure_matchup.png"><img src="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_pure_matchup.png" alt="" width="1578" height="708" srcset="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_pure_matchup.png 1578w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_pure_matchup-300x135.png 300w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_pure_matchup-768x345.png 768w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_pure_matchup-1024x459.png 1024w" sizes="(max-width: 1578px) 100vw, 1578px"></a></p>
<p>Sounds great, right? This seems to give us exactly what we want: instincts to help others (well, fellow group members at least), self-interest be damned. In practice, however, there’s almost never such a pure matchup: 100% Saints vs. 100% Sociopaths. <a href="https://twitter.com/kevinsimler/status/746495168996511744">Everything is always more mixed</a>, meaning that group selection and individual selection operate simultaneously. And, unfortunately, individual selection tends to work much faster and exert stronger evolutionary pressures than group selection, quickly eroding whatever altruism might otherwise be able to evolve.</p>
<p>Let’s play it out. A common group-vs.-group matchup might look like this:</p>
<p><a href="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_mixed_matchup.png"><img src="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_mixed_matchup.png" alt="" width="1578" height="707" srcset="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_mixed_matchup.png 1578w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_mixed_matchup-300x134.png 300w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_mixed_matchup-768x344.png 768w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_mixed_matchup-1024x459.png 1024w" sizes="(max-width: 1578px) 100vw, 1578px"></a></p>
<p>On a group level, we can reasonably expect the Nice Group to fare better, since it has a higher proportion of saints. But within each group, saints will lose to sociopaths. So the proportion of saints in the <em>overall</em> population will typically fall over time:</p>
<p><a href="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_mixed_matchup_results.png"><img src="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_mixed_matchup_results.png" alt="" width="2084" height="1014" srcset="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_mixed_matchup_results.png 2084w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_mixed_matchup_results-300x146.png 300w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_mixed_matchup_results-768x374.png 768w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/group_selection_mixed_matchup_results-1024x498.png 1024w" sizes="(max-width: 2084px) 100vw, 2084px"></a></p>
<p>The only way to get group selection to work out, mathematically, is under very specific conditions. (1) Groups have to be fairly isolated from each other, enough that sociopaths can’t jump freely from group to group. And (2) they need enough time in isolation to allow group-level advantages to produce demographic gains. However, (3) the groups also need to come together periodically to remix their members. This all hinges on <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson’s paradox</a>, and you can read more about it <a href="https://www.ncbi.nlm.nih.gov/pubmed/17087973">here</a> and <a href="https://arxiv.org/abs/1208.0520">here</a>. But suffice it to say that the fussiness of these models is a real drawback when trying to use group selection to explain altruism.</p>
<p><strong>A counterintuitive dilemma</strong></p>
<p>OK, let’s regroup.</p>
<p>So far we’ve discussed two materialist hypotheses for the origin of human morality. <em>Individual selection</em> is robust, but requires us to abandon the idea of altruism and reconceptualize morality as a form of self-interest. In contrast, <em>group selection</em> gives us perfect (group-oriented) altruism, but requires a very special kind of environment in which to operate.</p>
<p>Now, Q: <em>Which hypothesis should we root for?</em></p>
<p>I realize this is a strange question to ask. Emotional precommitments are a big scientific no-no, because Nature doesn’t care what we <em>want</em> to be true. (<a href="https://www.youtube.com/watch?v=cRmbwczTC6E">Channeling</a> <a href="https://www.youtube.com/watch?v=lmTmGLzPVyM">Feynman</a>, the only legitimate scientific emotion is curiosity.) But I’d like to apply for an exception in this case, because interrogating our (irrational) desires will, I think, shed light on the nature of these two explanations.</p>
<p>So, please, indulge me: Which hypothesis should we root for?</p>
<p>I suspect many of us intuitively root for group selection. When we witness an act of true altruism, true self-sacrifice, we celebrate it with every fiber of our beings — and rightly so. <em>We want true altruism to exist</em>. And we want it not to be a fluke. Group selection gives us that. Moreover, it’s depressing to think that morality might be an outgrowth of self-interest. It would mean that, behind every virtuous act and noble impulse, our brains are doing some kind of calculation which implies that the deed in question is likely to benefit us in some way. And that’s not the kind of morality we want. So isn’t it right and good and proper to hope our species is better than that?</p>
<p>In this case, no. Such hope is intuitively appealing, but dangerously misplaced.</p>
<p>The problem with group selection — and why it’s definitely <em>not</em> worth rooting for — comes back to how particular it is. As we discussed, group selection only works in a very specific type of environment, one in which groups are isolated from each other for generations. And yes, it’s possible that our ancestors actually lived in those conditions. But — here’s the important part — our modern environment <em>isn’t</em> conducive to group selection. Most people today live in big heterogenous populations of more or less freely mixing (and freely mating) individuals. So whatever group-level processes were selecting for good behavior in the past are no longer operating today.</p>
<p>When a trait was once adaptive, but no longer is, we call it <em>vestigial</em>. And if morality derives from group selection, it must be a vestigial instinct. A holdover from our evolutionary past — like a dinosaur after the asteroid impact, somehow still alive but soon to be extinct.</p>
<p>In our tower metaphor, it’s as if a load-bearing support structure had been used to <em>construct</em> the tower, but was recently pulled out from under us. And this, in turn, implies a grim future:</p>
<p><a href="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_tipping_over.png"><img src="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_tipping_over.png" alt="" width="2285" height="760" srcset="https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_tipping_over.png 2285w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_tipping_over-300x100.png 300w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_tipping_over-768x255.png 768w, https://206hwf3fj4w52u3br03fi242-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/leaning_tower_tipping_over-1024x341.png 1024w" sizes="(max-width: 2285px) 100vw, 2285px"></a></p>
<p>Let me put this in even stronger (and more discouraging) terms. If group selection is how we arrived at our moral instincts, it means we’re now living in a world where <em>bad people will outcompete good people</em>. Where virtue will be punished and evil rewarded. Where sociopaths are destined to win — or at least have the upper hand for the foreseeable future.</p>
<p>I don’t know about you, but I have a pretty clear (if unscientific) preference for <em>not</em> living in such a world.</p>
<p><strong>Quick scenic detour</strong></p>
<p>There’s at least one other place in science where well-meaning intuition misleads us into rooting for disaster.</p>
<p>Suppose tomorrow we found evidence of single-celled organisms on Mars. At first blush, this seems like something to celebrate. <em>We’re not alone! The universe isn’t as cold and dead as we feared!</em> Unfortunately, such a discovery would be among the worst pieces of news we could ever learn.</p>
<p>To understand why, consider <a href="https://en.wikipedia.org/wiki/Fermi_paradox">Enrico Fermi’s puzzle</a>: the strange fact that we seem to be the only intelligent (technological) species in our galaxy, despite billions of years and billions of planets on which another one could have evolved. In very broad terms, there are two ways to resolve the puzzle: Either (1) the universe rarely makes an intelligent species, or (2) the universe makes a lot of intelligent species, but bad things inevitably happen to them (e.g., they destroy themselves with their own technology). When we put our choices this way, it’s pretty clear we should root for resolution #1. (Especially given that we already exist!) Unfortunately, every scrap of evidence we find of life on other planets makes #2 more likely to be the case. Even the existence of primitive life raises the odds that the universe can produce intelligence. And if we happen to find life on the very planet next door, it would imply that the universe is <em>teeming</em> with the potential to make other species like ours, shifting a lot of probability mass to #2 — which doesn’t bode well for our future. (I’ve simplified this a bit. <a href="https://nickbostrom.com/extraterrestrial.pdf">Nick Bostrom has more</a>.)</p>
<p>Happily, as with individual selection and group selection, Nature doesn’t care if we root for the “wrong” hypothesis. The question is already settled, out there in objective reality, just waiting for us to find it.</p>
<p><strong>Back to morality</strong></p>
<p>OK, time to come clean.</p>
<p>I don’t believe in group selection. Specifically, I don’t think our ancestors actually lived under the conditions that would allow group selection to operate — or, if they did, I don’t think the selection pressures would have been nearly strong enough to evolve significant traits. This isn’t just my opinion; near as I can tell, it seems to be the scientific consensus.³ <a href="https://www.sciencedirect.com/science/article/pii/B9780124201903000235">This textbook chapter</a> provides a good (and readable) overview. Steven Pinker <a href="https://www.edge.org/conversation/steven_pinker-the-false-allure-of-group-selection">also weighs in</a> with characteristic clarity.</p>
<p>Earlier I described two “bitter pills” a person should be prepared to swallow in order to accept individual selection as the source of our moral instincts. Let me choke them down now:</p>
<blockquote><p>Bitter pill #1: There’s no instinct for true altruism.</p></blockquote>
<p>Sure, I’ll accept this.</p>
<p>Of course there are <em>instances</em> of perfect self-sacrificial altruism: people do occasionally fall on their grenades, undertake suicide missions, risk their own lives to save a stranger’s, etc. But there’s an important sense in which we should analyze these as <em>mistakes</em> or <em>accidents</em>, rather than deliberate (strategic) behavior — at least from the perspective of the genes that fashioned our brains.</p>
<p>More precisely, perhaps, we might say that self-sacrifice is an “unintended, low-probability side-effect” of instincts that otherwise serve us quite well. Previously I’ve described this as <a href="https://twitter.com/KevinSimler/status/665676087511355392">hill-climbing a volcano</a>. Our instincts tell us to climb “up” the fitness landscape, and most of the time, that’s where we go. Great! But occasionally, we try to go “up” and plummet to the bottom of a crater. ¯\_(ツ)_/¯. But what are you gonna do? You can’t just sit and play it safe at the bottom of the hill while your rivals have all the fun.</p>
<p>Note that this <em>doesn’t</em> mean we shouldn’t celebrate such acts of selfless heroism. We definitely should! In fact, we must, because <a href="http://www.meltingasphalt.com/here-be-sermons/">the very act of celebrating good behavior is what makes it more common</a>. We just have to recognize that the behaviors we’re celebrating may not be game-theoretically sustainable. If good people sacrifice too much, the wicked will inherit the earth.</p>
<blockquote><p>Bitter pill #2: Most forms of moral behavior are rooted, ultimately, in self-interest.</p></blockquote>
<p>Sure, I’ll swallow this too, although it’s a bit harder to wash down.</p>
<p>What this means is that empathy, compassion, charity, etc., were all winning strategies for our ancestors. And even though our modern environment is different, similar incentives probably exist today. Thus our brains must calculate when potential actions — including moral actions — are likely to pay off. These calculations are often unconscious and heuristic, of course. But the point is, even when we’re “doing the right thing,” we’re typically doing the right thing <em>for ourselves</em>.</p>
<p>It might help to sketch, very briefly, what this kind of self-interested moral calculus looks like. I don’t have all the mechanics worked out, but I know one important factor is <em>reputation</em>. It’s <a href="https://www.ribbonfarm.com/2016/02/11/minimum-viable-superorganism/">arguably the lynchpin</a> of cooperation outside the family. When other people know you as someone who consistently behaves well, they’re more likely to trust you, team up with you, help you out, etc., etc. In other words, they reward you. And knowing this, we’re all eager to enhance our reputations by a variety of means — e.g., by helping others. In this way, reputation is the alchemical agent that transmutes near-term self-sacrifice into longer-term self-interest.</p>
<p>But — I’ve heard this objection many times — if reputation is so important, why do people often behave well even when nobody’s watching? Doesn’t that smell suspiciously like altruism?</p>
<p>One possible answer is that there was less privacy in the ancestral environment than we have today, so we’re wired to behave <em>as if</em> we’re being watched all the time, even when we aren’t. I think there’s some truth to this — specifically, the EEA <em>was</em> a less private place — but mostly it seems like an excuse to reject the bitter pill. (Also, note that this explanation, like group selection, implies morality is vestigial.⁴)</p>
<p>So why <em>do</em> people behave well even when nobody’s watching? I prefer another answer: that it’s simply a good (self-interested) strategy, because cutting moral corners is risky. If you make a habit of always trying to calculate when an action of yours will or won’t be seen by others, you’ll inevitably slip up. You’ll get caught doing something bad when you thought no one would see it, and the ensuing loss of reputation will offset whatever gains you earned by cutting corners.</p>
<p>It’s not that we never cut corners — of course we do. In fact, we very pointedly use the odds of getting caught in determining whether or when to cheat; why else would transparency be so important? My point is, <em>deciding not to cheat, even when you could probably get away with it</em> is often a good, safe, EV-maximizing move.</p>
<p><strong>A strange gospel</strong></p>
<p>Most of what we’ve discussed today pertains to our <em>innate</em> sense of goodness, our moral instincts. To the extent that morality is a <em>learned</em> behavior, all bets are off.⁵ But there’s a <a href="http://www.nytimes.com/2008/01/13/magazine/13Psychology-t.html">good case to be made</a> that at least some of our moral intuitions come prewired (in the form of tendencies, at any rate), so the question of how they arose remains extremely relevant. And as far as I can tell, the answer seems to be individual selection rather than group selection.</p>
<p>Here, then, is the chain of reasoning I want to endorse:</p>
<ol>
<li>We have prewired moral instincts (probably).</li>
<li>They arose via individual selection (probably).</li>
<li>Therefore: <em>there are conditions familiar to our species in which moral behavior is a winning strategy</em>.</li>
</ol>
<p>This conclusion has the rare property of being both <em>huge if true</em> and also, at the same time, <em>probably true</em>. In other words, it’s huge! (Probably.) And not only that, it’s hugely good. It’s the kind of news that makes me want to buy a bullhorn and take to the roof:</p>
<p><strong><em>BEING GOOD IS </em></strong>(typically)<strong><em> GOOD FOR YOU!<br>
MORAL BEHAVIOR </em></strong>(usually)<strong><em> WINS!</em></strong></p>
<p>Of course I’m hardly the first person to make this kind of claim. It’s the well-known philosophy of <em>enlightened self-interest</em>, the idea that we can “do well for ourselves by doing good for others.” It’s the philosophy described by Alexis de Tocqueville, preached by Adam Smith, and practiced by Benjamin Franklin. It undergirds Dale Carnegie’s <a href="https://en.wikipedia.org/wiki/How_to_Win_Friends_and_Influence_People">famous self-help book</a>. In the biological literature, it’s known as “indirect reciprocity” or “competitive altruism.” So the basic idea is certainly out there. I just find it strange how little emphasis it gets, relative to what it deserves.</p>
<p>But why, exactly? Why is this not a more common gospel?</p>
<p>I think the main problem is that we’re squeamish about self-interest. To explain something pure, like moral behavior, as derived from something dirty, like self-interest, is to create a sacred/profane circuit violation, which is taboo. It also casts suspicion on the people who advance such explanations. If you say, “I do the right thing <em>because it’s the right thing</em>, period, end of story,” you leave no crack in your facade through which a pesky interlocutor might question your motives. However, if you say, “I do the right thing because it’s usually the right thing <em>for me</em>,” you’re practically inviting unwanted speculation: <em>How can you be sure you’ll do the right thing next time? What if you’re tempted to cheat? Can you really be trusted at all??</em></p>
<p>Boy these pills are bitter.</p>
<p>But however uncomfortable all of this makes us, we owe it to each other — and to ourselves, collectively — to acknowledge the good news without flinching away. To do otherwise is to <em>defect</em> when we ought to be <em>cooperating</em>. Because this tower of morality we all inhabit isn’t a steel-girded modern skyscraper. It’s a rickety thing, built from old wood and (for all we know) ridden with termites. And while it has managed to stand for millennia, there’s no guarantee it won’t collapse during the next natural disaster.</p>
<p>If morality is generally a dominant strategy, it’s not an <em>obviously</em> dominant strategy, and certainly not in all circumstances. We — and especially those of us who help build systems — need desperately to study the conditions under which good behavior flourishes, so that we might preserve those conditions, and even enhance them.</p>
<p>This is what I’ve been attempting to do in a lot of my writing over the past few years: to reverse-engineer the tower of morality. (<em>Tower of cooperation</em>? <em>Tower of positive-sum games</em>?) I want to understand how, exactly, it manages to remain standing — sustainably, on its own, without external support or wishful subsidies. I’ve looked at the role of <a href="http://www.meltingasphalt.com/social-status-down-the-rabbit-hole/">prestige</a>, <a href="http://www.meltingasphalt.com/wealth-the-toxic-byproduct/">money</a>, <a href="http://www.meltingasphalt.com/here-be-sermons/">sermons</a>, <a href="http://www.meltingasphalt.com/personhood-a-game-for-two-or-more-players/">personhood</a>, <a href="http://www.meltingasphalt.com/the-more-the-merrier/">network effects</a>, and of course <a href="https://www.ribbonfarm.com/2016/02/11/minimum-viable-superorganism/">reputation</a>. In my <a href="http://elephantinthebrain.com/">upcoming book</a>, I discuss the all-important role of norms and norm enforcement, and touch on the role of religion. Nowhere do I posit untethered instincts that work “for the good of the group.” I attempt to ground everything, as firmly as I can, in the logic of individual advantage. My tentative conclusion is that it really is possible to secure good behavior (if not perfect sainthood) using a structure built entirely on self-interest.</p>
<p>Which brings us back to that quote I started with:</p>
<blockquote><p>“Game theory is asleep, cooperate for no reason.”</p></blockquote>
<p>I love this quote because it hints, playfully, at many of the ideas we’ve just discussed. Taken literally, however, it would be a dangerous fantasy. Game theory never sleeps, and we — the good people of society — can’t just “cooperate for no reason” any more than we can just decide to hover 50 feet off the ground. But we <em>can</em> cooperate, and quite splendidly, so long as we have the right structure for it.</p>
<p>_____</p>
<p>This post was adapted — very loosely — from a conversation with <a href="https://twitter.com/kevinakwok">Kevin Kwok</a>.</p>
<p><strong>Further reading:</strong></p>
<ul>
<li><a href="http://www.meltingasphalt.com/addendum-to-the-leaning-tower/">Addendum for evolution geeks</a>.</li>
<li>This post is in some ways a counterpoint to Scott Alexander’s <em>fantastic</em> post <a href="http://slatestarcodex.com/2014/07/30/meditations-on-moloch/">Meditations on Moloch</a> — the yang to its yin, perhaps? I’m trying to hold both of these ideas in my head simultaneously, and the tension has been very fruitful. Do yourself a favor and go read Scott’s post (or <a href="http://secondenumerations.blogspot.com/2017/06/16-meditations-on-moloch.html">give it a listen</a>).</li>
<li>Steven Pinker, <a href="https://www.edge.org/conversation/steven_pinker-the-false-allure-of-group-selection">The False Allure of Group Selection</a>.</li>
<li>Books: <a href="https://www.amazon.com/SuperCooperators-Altruism-Evolution-Other-Succeed/dp/1451626630"><em>Supercooperators</em></a> by Martin Nowak and Roger Highfield. <a href="https://www.amazon.com/Biology-Systems-Evolutionary-Foundations-Behavior/dp/0202011747"><em>The Biology of Moral Systems</em></a> by Richard Alexander. And of course <a href="https://www.amazon.com/Selfish-Gene-Popular-Science/dp/0192860925"><em>The Selfish Gene</em></a> by Richard Dawkins.</li>
</ul>
<p><strong>Endnotes:</strong></p>
<p>¹ I hope this isn’t a straw man. I realize there are more sophisticated theologies out there. (One that I’m particularly fond of, especially in this context, is Micah Redding’s <a href="http://micahredding.com/blog/minimum-viable-theology-good-wins">Minimum Viable Theology</a>.) But I also think there are plenty of real people who subscribe to something like what I’ve articulated.</p>
<p>² Dan Dennett’s <a href="https://en.wikipedia.org/wiki/Darwin%27s_Dangerous_Idea#Skyhooks_and_cranes">distinction between skyhooks and cranes</a> seems relevant here.</p>
<p>³ But cf. <a href="https://twitter.com/KevinSimler/status/800585631407566849">Michael Crichton’s remarks</a> on the perversity of “consensus science.” Separately: Two notable exceptions who continue to advocate for group selection are David Sloan Wilson and E. O. Wilson (no relation). In fact, E. O. Wilson’s remarks on group selection in his 2012 book <em>The Social Conquest of Earth</em> were a major goad for me to write this post.</p>
<p>⁴ Evolutionary explanations that imply morality is vestigial are actually quite common, once you know to look for them. Just as I was finishing this post, for example, I heard one from the great evolutionist Richard Dawkins (relevant transcript <a href="http://www.meltingasphalt.com/addendum-to-the-leaning-tower/#dawkins">here</a>). The most general objection — to this whole class of explanations — is that humans are plastic enough to adapt to changing environments via learning, rather than having to wait for genetic evolution. (Yes, this is an efficient market–type explanation.) So when a new niche for bad behavior opens as a result of environmental change, it’s quickly filled by moral entrepreneurs. And thus, whatever good behavior remains is likely to be an equilibrium strategy rather than a vestigial instinct.</p>
<p>⁵ Or, rather, a different kind of argument kicks in — one in which reinforcement learning takes on a role similar to individual selection. More <a href="http://www.meltingasphalt.com/addendum-to-the-leaning-tower/#reinforcement">here</a>.</p>
</div></div></div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function () {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>

</body>
</html>