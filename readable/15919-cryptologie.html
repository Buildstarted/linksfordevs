<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Cryptologie -
linksfor.dev(s)
    </title>
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta charset="utf-8">
    <meta name="Description" content="A curated source of links that devs might find interesting. Updated around the clock." />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>
<body>
    <div class="grid">
        
<div class="readable">
    <div id="readOverlay" class="style-ebook"><div id="readInner" class="margin-medium size-medium"><h1>Cryptologie</h1><div><div id="" class=""><article><p>have you heard of <strong>sPAKE</strong> (or <strong>bPAKE</strong>)?</p><p>a sPAKE is first and foremost a <strong>PAKE</strong>, which stands for <strong>Password-Authenticated Key Exchange</strong>.
This simply means that authentication in the key exchange is provided via the knowledge of a password.
The s (resp. b) in front means symmetric (resp. balanced). This indicates that both sides know the password.</p><p><img alt="Alice and Bob trying to use a sPAKE to authenticate a key exchange" src="/upload/Screen_Shot_2020-02-09_at_5.21_.17_PM_.png"></p><p>Other PAKEs where only one side knows the password exist, these are called aPAKE for asymmetric (or augmented) PAKEs.
Yes I know the nomenclature is a bit confusing :)</p><p>The most promising sPAKE scheme currently seems to be <strong>SPAKE2</strong>, which is <a href="https://tools.ietf.org/html/draft-irtf-cfrg-spake2-09">in the process of being standardized here</a>.
There are other sPAKEs, like Dragonfly which is used in WPA3, but they don't seem to provide as strong properties as SPAKE2.</p><p>The trick to a symmetric PAKE is to use the password to blind the key exchange's ephemeral keypairs.</p><p><img alt="The first part of a sPAKE with SPAKE2" src="/upload/Screen_Shot_2020-02-09_at_5.22_.49_PM_.png"></p><p>Note that we can't use the password as is, instead we:</p><ul><li>Pass the password into a memory-hard hash function like Argon2 to obtain <code>w</code>. Can you guess why we do this? (leave a comment if you do!)</li><li>Convert it to a group element. To do this we simply consider <code>w</code> a scalar and do a scalar multiplication with a generator of our subgroup (<code>M</code> or <code>N</code> depending if you're the client or the server, can you guess why we use <a href="https://eprint.iacr.org/2019/1194.pdf">different generators</a>?)</li></ul><blockquote><p>NOTE: If you know BLS or OPAQUE, you might be wondering why we don't use a "hash-to-curve" algorithm, this is because we don't need to obtain a group element with an unknown discrete logarithm in SPAKE2.</p></blockquote><p>Once the blinded (with the password) public keys have been exchanged, both sides can compute a shared group element:</p><ul><li>Alice computes <code>K = h × alice_private_key × (S - w × N)</code></li><li>Bob computes <code>K = h × bob_private_key × (T - w × M)</code></li></ul><p>Spend a bit of your time to understand these equations.
What happens is that both Alice and Bob first unblind the public key they've received, then perform a key exchange with it, then multiply it with the value <code>h</code>. What's this value <code>h</code>? The cofactor, or simply put: the other annoying subgroup.</p><p>Finally Alice and Bob <strong>hash the whole transcript</strong>, which is the concatenation of:</p><ul><li>Alice's identity.</li><li>Bob's identity.</li><li>The message Bob sent <code>S</code>.</li><li>The message Alice sent <code>T</code>.</li><li>The shared group element <code>K</code>.</li><li>The hardened password <code>w</code>.</li></ul><p>The hash of this transcript gives us two things:</p><ul><li>A <strong>shared secret</strong> !</li><li>A key that is further expanded (via a KDF) to obtain two authentication keys.</li></ul><p><img alt="The key derivation of sPAKE" src="/upload/Screen_Shot_2020-02-09_at_5.55_.57_PM_.png"></p><p>These authentication keys sole purpose is to provide <strong>key confirmation</strong> in the last round-trip of messages.
That is to say at this point, if we don't do anything, we don't know if either Alice or Bob truly managed to compute the shared secret.</p><p>Key confirmation is pretty simple, both sides just have to compute an authentication tag with one of the authentication key produced over the transcript.</p><p>The final protocol looks a bit dense, but you should be able to decipher it if you've read this far.</p><p><img alt="Whole SPAKE2 protocol" src="/upload/Screen_Shot_2020-02-09_at_5.56_.36_PM_.png"></p><a href="/article/490/how-symmetric-password-authenticated-key-exchanges-work-spake/#comments" class="comment_link"> comment on this story</a></article><article><p>Authentication is an overloaded word in cryptography.</p><p>In the context of <strong>cryptographic primitives</strong> like message authentication codes (MACs) and authenticated encryption with associated data (AEAD), authentication really refers to authenticity or integrity. And as the <a href="https://dictionary.cambridge.org/us/dictionary/english/authenticity">Cambridge dictionary</a> says:</p><blockquote><p><strong>Authenticity</strong>. the quality of being real or true.<br>The poems are supposed to be by Sappho, but they are actually of doubtful authenticity.<br>The authenticity of her story is beyond doubt.</p></blockquote><p>The proof is in the pudding. When talking about the security properties of primitives like MACs, cryptography talks about <strong>unforgeability</strong>, which does relate to authenticity.</p><p>So whenever you hear things like "<em>is this payload authenticated with HMAC?</em>", think authenticity, think integrity.</p><p>In the context of <strong>protocols</strong> though (e.g. TLS) authentication refers to <strong>identification</strong>: the concept of <strong>proving who you are</strong>.</p><p>So whenever you hear things like "<em>Is the server authenticated?</em>", think "identities are being proven".</p><p>This dual sense really annoys me, but in the end this ambiguity is encompassed in the definition of authentication:</p><blockquote><p>the process or action of proving or showing something to be true, genuine, or valid.</p></blockquote><p><a href="https://twitter.com/dfaranha/status/1221558605259988994">Diego F. Aranha</a> proposes a clever way to disambiguate the two:</p><ul><li><strong>origin/entity authentication</strong>. You're proving that an entity really is who they say they are.</li><li><strong>message authentication</strong>. You're proving that a message is genuine.</li></ul><p>Note that an argument against this distinction is the following: to authenticate a message, you need a key. This key comes from somewhere (it's your context, or your "who"). So when you authenticate a message, you are really authenticating the context. This falls short in scenarios where for example you trust the root hash of a merkle tree, which authenticates all of its leaves.</p><p>The bottom line is, authentication is about proving that something is what it is supposed to be. And that thing can be a person, or a message, or maybe even something else.</p><p>This is not all. In the security world people are confused with authorization vs authentication :)</p><a href="/article/489/authentication-what-the-fuck/#comments" class="comment_link"> comment on this story</a></article><article><p>I've been following the Messaging Layer Security (MLS) standardization a bit.
I really appreciate what the people are doing there, and what they are trying to solve.
I think <strong>group messaging</strong> is currently a huge <strong>mess</strong>, as every application I have seen/audited seemed to invent a new way to implement group chat.
A common standard and guidelines would greatly help.</p><p>MLS' goal is to provide a solution to end-to-end encryption for group chats. A solution that <strong>scales</strong>.</p><p>If you don't know how the MLS protocol works, I advise you to read <a href="https://mrosenberg.pub/cryptography/2019/07/10/molasses.html">Michael Rosenberg's blog post</a> or to watch the Real World Crypto talk on the subject (might not be available at the moment).</p><p>Thinking about the standard, I have two questions:</p><ol><li><strong>Does a group chat loses any notion of privacy/confidentiality after it gets too large?</strong> For example, if you are in a Hong Kong group trying to organize a protest and there are more than 1,000 people in the group, what are the odds that one of them is a <a href="https://www.youtube.com/watch?v=_s5R9cFdRmg">cop</a>?</li><li>Would a group chat protocol targeting groups with small numbers of participant (let's say 50 at most) be able to provide <strong>better security insurances efficiently</strong>?</li></ol><hr><p>For example, here are two security properties (taken from <a href="https://oaklandsok.github.io/papers/unger2014.pdf">SoK: Secure Messaging</a>) that MLS does not provide:</p><blockquote><p><strong>Speaker Consistency</strong>: All participants agree on the sequence of messages sent by each participant.</p></blockquote><p>This means that if Alice (who is part of a group chat with Bob and Eve) colludes with the server, she can send "I like cats" to Bob and "I like dogs" to Eve.</p><blockquote><p><strong>Global Transcript</strong>: All participants see all messages in the same order. Note that this implies speaker consistency</p></blockquote><p>This means that if Alice sends the following messages:</p><p>a server could re-order these messages so that Bob would see them in the same order, but Eve would see:</p><p><img alt="yoda" src="/upload/baby-yoda-3.jpg"></p><hr><p>I have the following open questions:</p><ul><li>Are these attacks important to protect against?</li><li>Is there an efficient protocol to prevent these attacks for groups of reasonable size?</li><li>If we cannot prevent them, can we detect them and warm the users?</li><li>If we are willing to change the protocol when going from 2 participants to 3 participants, would be willing to change the protocol when going from N to N+1 participants (where N is the number of participants threshold where confidentiality/privacy fades away)?</li></ul><a href="/article/488/messaging-layer-security-a-few-thoughts/#comments" class="comment_link"> 2 comments </a></article><article><hr><p>This is were everything starts, we now have an open peer-to-peer protocol that everyone on the internet can use to communicate.</p><hr><ul><li>1991<ul><li>The US government introduces the 1991 Senate Bill 266, which attempts to allow "the Government to obtain the plain text contents of voice, data, and other communications when appropriately authorized by law" from "providers of electronic communications services and manufacturers of electronic communications service equipment". The bill fails to pass into law.</li><li><strong>Pretty Good Privacy (PGP) - released by Phil Zimmermann.</strong></li></ul></li><li>1993 - The US Government launches a criminal investigation against Phil Zimmermann for sharing a cryptographic tool to the world (at the time crypto exporting laws are a thing).</li><li>1995 - Zimmermann publishes PGP's source code in a book via MIT Press, dodging the criminal investigation by using the first ammendment's protection of books.</li></ul><hr><p>That's it, PGP is out there, people now have a weapon to fight government surveillance. As Zimmermann puts it:</p><blockquote><p>PGP empowers people to take their privacy into their own hands. There's a growing social need for it. That's why I wrote it.</p></blockquote><hr><ul><li>1995 - The RSA Data Security company proposes S/MIME as an alternative to PGP.</li><li>1996</li><li>1997 <ul><li><strong>GNU Privacy Guard (GPG)</strong> - version 0.0.0 released by Werner Koch.</li><li>PGP 5 is released.<blockquote><p>The original agreement between Viacrypt and the Zimmermann team had been that Viacrypt would have even-numbered versions and Zimmermann odd-numbered versions. Viacrypt, thus, created a new version (based on PGP 2) that they called PGP 4. To remove confusion about how it could be that PGP 3 was the successor to PGP 4, PGP 3 was renamed and released as PGP 5 in May 1997</p></blockquote></li></ul></li><li>1997 - PGP Inc is acquired by Network Associates</li><li>1998 - <a href="https://www.ietf.org/rfc/rfc2440.txt">RFC 2440 - OpenPGP Message Format</a><blockquote><p>OpenPGP - This is a definition for security software that uses PGP 5.x as a basis.</p></blockquote></li><li>1999<ul><li>GPG version 1.0 released </li><li><strong><a href="https://xmpp.org/">Extensible Messaging and Presence Protocol (XMPP)</a></strong> is developed by the open source community. XMPP is a federated chat protocol (users can run their own servers) that does not have end-to-end encryption and requires communications to be synchronous (both users have to be online).</li></ul></li><li>2002 - PGP Corporation is formed by ex-PGP members and the PGP license/assets are bought back from Network Associates</li><li><strong>2004 - Off-The-Record (OTR) is introduced by Nikita Borisov, Ian Avrum Goldberg, and Eric A. Brewer as an extension of the XMPP chat protocol in "<a href="https://otr.cypherpunks.ca/otr-wpes.pdf">Off-the-Record Communication, or, Why Not To Use PGP</a>"</strong><blockquote><p>We argue that [...] the encryption must provide perfect forward secrecy to protect from future compromises [...] the authentication mechanism must offer repudiation, so that the communications remain personal and unverifiable to third parties</p></blockquote></li></ul><hr><p>We now have an interesting development: messaging (which is seen as a different way of communication for most people) is getting the same security treatment as email.</p><hr><ul><li>2006 - GPG version 2.0 released</li><li>2007 - <a href="https://www.ietf.org/rfc/rfc4880.txt">RFC 4880 - OpenPGP Message Format</a></li><li>2010 - Symantec purchases the rights for PGP for $300 million.</li><li>2011 - <a href="https://en.wikipedia.org/wiki/Cryptocat">Cryptocat</a> is released.</li><li><strong>2013 - The TextSecure (now Signal) application is introduced, built on top of the TextSecure protocol with Axolotl (now the Signal protocol with the double ratchet) as an evolution of OTR and SCIMP. It provides asynchronous communication unlike other messaging protocols, closing the gap between messaging and email.</strong></li><li>2014</li></ul><hr><p>PGP becomes increasingly criticized, as Matt Green puts it in 2014:</p><blockquote><p>It’s time for PGP to die.</p></blockquote><hr><hr><p>Another unexpected development: security professionals are now giving up on encrypted emails, and are moving to secure messaging.
Is messaging going to replace email, even though it feels like a different mean of communication?</p><p>Moxie's quotes are quite interesting:</p><blockquote><p>In the 1990s, I was excited about the future, and I dreamed of a world where everyone would install GPG. Now I’m still excited about the future, but I dream of a world where I can uninstall it. </p></blockquote><blockquote><p>In addition to the design philosophy, the technology itself is also a product of that era. As Matthew Green has noted, “poking through an OpenPGP implementation is like visiting a museum of 1990s crypto.” The protocol reflects layers of cruft built up over the 20 years that it took for cryptography (and software engineering) to really come of age, and the fundamental architecture of PGP also leaves no room for now critical concepts like forward secrecy. </p></blockquote><blockquote><p>In 1997, at the dawn of the internet’s potential, the working hypothesis for privacy enhancing technology was simple: we’d develop really flexible power tools for ourselves, and then teach everyone to be like us. Everyone sending messages to each other would just need to understand the basic principles of cryptography. [...] </p></blockquote><blockquote><p>The GnuPG man page is over sixteen thousand words long; for comparison, the novel Fahrenheit 451 is only 40k words. [...] </p></blockquote><blockquote><p>Worse, it turns out that nobody else found all this stuff to be fascinating. Even though GPG has been around for almost 20 years, there are only ~50,000 keys in the “strong set,” and less than 4 million keys have ever been published to the SKS keyserver pool ever. By today’s standards, that’s a shockingly small user base for a month of activity, much less 20 years.</p></blockquote><hr><ul><li>2018<ul><li>the first draft of <strong>Messaging Layer Security (MLS)</strong> is published, a standard for end-to-end encrypted group chat protocols.</li><li><a href="https://efail.de/">EFAIL</a> releases damaging vulnerabilities against most popular PGP and S/Mime implementations.<blockquote><p>In a nutshell, EFAIL abuses active content of HTML emails, for example externally loaded images or styles, to exfiltrate plaintext through requested URLs. To create these exfiltration channels, the attacker first needs access to the encrypted emails, for example, by eavesdropping on network traffic, compromising email accounts, email servers, backup systems or client computers. The emails could even have been collected years ago.</p></blockquote></li></ul></li><li>2019 - <a href="https://latacora.micro.blog/2019/07/16/the-pgp-problem.html">Latacora - The PGP Problem</a><blockquote><p>Why do people keep telling me to use PGP? The answer is that they shouldn’t be telling you that, because PGP is bad and needs to go away.</p></blockquote></li></ul><hr><p>EFAIL is the straw that broke the camel's back. PGP is officially dead.</p><hr><ul><li>2019<ul><li>Matrix is out of beta and working on making end-to-end encryption the default.</li><li>Moxie gives a <a href="https://peertube.co.uk/videos/watch/12be5396-2a25-4ec8-a92a-674b1cb6b270">controversial talk at CCC</a> arguing that advancements in security, privacy, censorship resistance, etc. are incompatible with slow moving decentralized protocols. Today, most serious end-to-end encrypted messaging apps use the Signal protocol (Signal, Facebook Messenger, WhatsApp, Skype, etc.)</li><li>XMPP's response: <a href="https://blog.jabberhead.tk/2019/12/29/re-the-ecosystem-is-moving/">Re: the ecosystem is moving</a></li><li>Matrix's response: <a href="https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">On privacy versus freedom</a></li></ul></li></ul><blockquote><p>did you like this? This will part of a book on cryptography! <a href="https://www.manning.com/books/real-world-cryptography?a_aid=Realworldcrypto&amp;a_bid=ad500e09">Check it out here</a>.</p></blockquote><a href="/article/487/a-history-of-end-to-end-encryption-and-the-death-of-pgp/#comments" class="comment_link"> 3 comments </a></article><article><p>That title is a mouthful! But so is the field.</p><p>Let me introduce the problem: Alice owns a private key which can sign transactions. The problem is that she has a lot of money, and she is scared that someone will target her to steal all of her funds.</p><p>Cryptography offers some solutions to avoid this being a key management problem.</p><p>The first one is called <strong>Shamir Secret Sharing (SSS)</strong>, which is simply about splitting the signing private key into n shares.
Alice can then split the shares among her friends. When Alice wants to sign a transaction, she would then have to ask her friends to give her back the shares, that she can use to recreate the signing private key. Note that SSS has many many variants, for example VSSS allows participants to <strong>verify</strong> that malicious shares are not being used, and PSSS allows participants to <strong>proactively</strong> rotate their shares.</p><p><img alt="sss" src="/upload/Screen_Shot_2019-12-25_at_9.21_.21_AM_.png"></p><p>This is not great though, as there is a small timeframe in which Alice is the single point of failure again (the moment she holds all the shares).</p><p>A logical next step is to <strong>change the system</strong>, so that Alice cannot sign a transaction by herself.
A <strong>multi-signature</strong> system (or <strong>multisig</strong>) would require n participants to sign the same transaction and send the n signatures to the system.
This is much better, except for the fact that n signatures means that the transaction size increases linearly with the number of signers required.</p><p><img alt="recap" src="/upload/Screen_Shot_2019-12-25_at_9.23_.26_AM_.png"></p><p>We can do better: a multi-signature system with <strong>aggregated signatures</strong>. Signature schemes like <strong>BLS</strong> allow you to compress the n signatures in a single signature. Note that it is currently much slower than popular signature schemes like ECDSA and EdDSA, so there must be a trade off between speed and size.</p><p>We can do even better though!</p><p>So far one still has to maintain a set of n public keys so that a signature can be verified. <strong>Distributed Key Generation (DKG)</strong> allows a set of participant to collaborate on the construction of a key pair, and on signing operations.
This is very similar to SSS, except that there is never a single point of failure. This makes DKG a <strong>Multi-Party Computation (MPC)</strong> algorithm.</p><p>The BLS signature scheme can also aggregate public keys into a single key that will verify their aggregated signatures, which allows the construction of a DKG scheme as well.</p><p>Interestingly, you can do this with schnorr signatures too! The following diagram explains a simplified version of the scheme:</p><p><img alt="schnorr dkg" src="/upload/Screen_Shot_2019-12-25_at_9.12_.32_AM_.png"></p><p>Note two things:</p><ul><li>All these schemes can be augmented to become <strong>threshold schemes</strong>: we don't need n signatures from the n signers anymore, but only a threshold m of n. (Having said that, when people talk about <strong>threshold signatures</strong>, they often mean the threshold version of DKG.) This way if someone loses their keys, or is on holiday, we can still sign.</li><li>Most of these schemes assume that all participants are honest and by default don't tolerate malicious participants. More complicated schemes made to tolerate malicious participants exist.</li></ul><p>Unfortunately all of this is pretty new, and as an active field of study no standard has been decided on one algorithm so far.</p><p>That's the difference!</p><p>One last thing: there's been some recent ideas to use <strong>zero knowledge proofs (ZKP)</strong> to do what aggregated signatures do but for multiple messages (because all the previous solutions all signed the same message). The idea is to release a proof that you have verified all the signatures associated to a set of messages. If the zero knowledge proof is shorter than all the signatures, it did its job!</p><blockquote><p>did you like this? This will part of a book on cryptography! <a href="https://www.manning.com/books/real-world-cryptography?a_aid=Realworldcrypto&amp;a_bid=ad500e09">Check it out here</a>.</p></blockquote><p>EDIT: thanks to <a href="https://www.reddit.com/r/crypto/comments/edqrky/difference_between_shamir_secret_sharing_sss_vs/fbl62rb/">Dowhile and bascule</a> for pointing errors in the post.</p><a href="/article/486/difference-between-shamir-secret-sharing-sss-vs-multisig-vs-aggregated-signatures-bls-vs-distributed-key-generation-dkg-vs-threshold-signatures/#comments" class="comment_link"> 3 comments </a></article><article><p>I am now half-way in the writing of my book (I wrote 8 chapters out of 16) and I am already exhausted.
It doesn't help that I started writing right before accepting a new position for a very challenging (and interesting) project.
But here I am, half-way there, and I think I'm onto something. I can't wait to get there and look at the finished project as a real paper book :)</p><p>To give you some insight into this process, let me share some thoughts.</p><p><strong>Writing is hard</strong>. I have realized that I need at least a full day to write something. It does take time to get into the zone, and writing in the morning before work just doesn't work for me (and writing after work is even worse). As <a href="https://research.kudelskisecurity.com/2017/10/16/the-making-of-serious-cryptography/">JP Aumasson put it (about his process of writing Serious Cryptography)</a>:</p><blockquote><p>I quickly realized that I didn’t know everything about crypto. The book isn’t just a dump of my own knowledge, but rather the fruit of hours of research—sometimes a single page would take me hours of reading before writing a single word.</p></blockquote><p>So when I don't have a full day ahead of me, I use my limited time to read articles and do research in topics that I don't fully understand. This is useful, and I make more progress during the week end once I have time to write.</p><p><strong>Revising is hard</strong>. If writing a chapter takes some effort <code>X</code>, revising a chapter takes effort <code>X^3</code> . After each chapter, several people at Manning, and in my circle, provide feedback. At the same time, I realize that there's much more I want to write about subject Y and I start pilling up articles and papers that I want to read before I revise the chapter. I end up spending a TON of effort revising and re-visiting chapters.</p><p><strong>Getting feedback is hard</strong>. I am lucky, I know a lot of people with different levels of knowledge in cryptography. This is very useful when I want to test how different audiences read different chapters. Unfortunately people are good at providing good feedback, and bad at providing bad feedback. And only the bad feedback ends up being useful feedback. If you want to help, [the first chapters are free to read](<a href="https://www.manning.com/books/real-world-cryptography?a_aid=Realworldcrypto&amp;a_bid=ad500e09">https://www.manning.com/books/real-world-cryptography?a_aid=Realworldcrypto&amp;a_bid=ad500e09</a>
) and I'm ready to buy you a beer for some constructive negative feedback.</p><p><strong>Laying out a chapter is hard</strong>. Writing a blog is relatively easy. It's short, self-contained, and often something I've been thinking about for weeks, months, before I put it into writing. Writing a chapter for a book is more like writing a paper: you want it to be perfect. Knowing a lot about the subject makes this even more difficult: you know you can make something great and not achieving that would be disappointing. One strategy that I wish I would have more time to spend on is the following one: </p><ul><li>create a presentation about the subject of a chapter</li><li>give the presentation and observe what diagrams need revisiting and what parts are hard for an audience to understand</li><li>after many iterations put the slides into writing</li></ul><p>I'm convinced this is the right approach, but I am not sure how I could optimize for this. If you're in SF and wants me to give you a presentation on one of the chapter of the book, leave a comment here :)</p><a href="/article/485/writing-a-book-is-hard/#comments" class="comment_link"> 2 comments </a></article><article><p>There are several cryptocurrencies that are doing really interesting things, Algorand is one of them.
Their breakthrough was to make a leader-based BFT algorithm work in a permissionless setting (and I believe they are the first ones who managed to do this).
At the center of their system lies a <strong>cryptography sortition</strong> algorithm. It's quite interesting, so I made a video to explain it!</p><p>PS: I've been doing these videos for a while, and I still don't have a cool intro, so if you want to make me a cool intro please do :D</p><a href="/article/484/algorands-cryptographic-sortition/#comments" class="comment_link"> 1 comment </a></article><article><p>My colleague <strong>Mesut</strong> asked me if using random identifiers of 128-bit would be enough to avoid collisions.</p><p>I've been asked similar questions, and every time my answer goes something like this: </p><blockquote><p>you need to calculate <strong>the number of outputs</strong> you need to generate in order to get good odds of finding collisions. If that number is impressively large, then it's fine.</p></blockquote><p>The <strong>birthday bound</strong> is often used to calculate this. If you crypto, you must have heard of something like this:</p><blockquote><p>with the SHA-256 hash function, you need to generate at least 2<sup>128</sup> hashes in order to have more than 50% chance of finding collisions.</p></blockquote><p>And you know that usually, you can just divide the exponent of your domain space by two to find out how much output you need to generate to reach such a collision.</p><p>Now, this figure is a bit <strong>deceiving</strong> when it comes to <strong>real world cryptography</strong>. This is because we probably don't want to define "<strong>OK, this is bad</strong>" as someone reaching the point of having 50% chance of finding a collision. Rather, we want to say:</p><blockquote><p>someone reaching <strong>one in a billion</strong> chance (or something much lower) to find a collision would be bad.</p></blockquote><p>In addition, what does it mean for us? How many identifiers are we going to generate per second? How much time are we willing to keep this thing secure?</p><p>To truly answer this question, one needs to plug in the correct numbers and play with the birthday bound formula. Since this is not the first time I had to do this, I thought to myself "why don't I create an app for this?" and <a href="https://www.davidwong.fr/whatsmybirthday">voila</a>.</p><p><img alt="birthday bound" src="/upload/Screen_Shot_2019-09-20_at_10.50_.46_PM_.png"></p><p><a href="https://www.davidwong.fr/whatsmybirthday">You can play with it here</a>.</p><p>Thanks to my tool, I can now answer Mesut's question:</p><blockquote><p>If you generate one million identifiers per second, in 26 years you will have one in a billion chance to generate a collision. Is this enough?
If this is not adversary-controlled, or it is rate-limited, you will probably not generate millions of identifiers per second though, but rather thousands, in this case it will take 265 centuries to get these odds.</p></blockquote><a href="/article/483/whats-my-birthday/#comments" class="comment_link"> 3 comments </a></article><article><p>Manning Publications reached out to me last year with an opportunity for a book. I had been thinking of a book for quite some time, as I felt that the landscape lacked a book targeted to developers, students and engineers who did not want to learn about the history of cryptography, or have to sort through too many technical details and mathematic formulas, and wanted an up to date survey of modern applied cryptography. In addition, I love diagrams. I don’t understand why most books underuse them. When you think of AES-CTR what do you think about? I bet the excellent diagrams from Wikipedia just flash in your mind. </p><p>The book <strong>Real World Cryptography</strong> was released today in <a href="https://www.manning.com/books/real-world-cryptography?a_aid=Realworldcrypto&amp;a_bid=ad500e09">pre-access</a>. This means you’ll be able to read new chapters as I write them, and be able to provide feedback on topics you wished I would include and questions you wish I would answer. </p><a href="/article/481/my-book-real-world-cryptography-is-out-in-pre-access/#comments" class="comment_link"> 4 comments </a></article><article><p><img alt="libra" src="/upload/libra.jpg"></p><p>At 2am this morning <a href="https://libra.org/en-US/">Libra</a> was released.</p><p>and it seems to have broken the internet (sorry about that ^.^")</p><p>I've never worked on something this big, and I'm overwhelmed by all this reception. This is honestly pretty surreal from where I'm standing.</p><p>Libra is a <strong>cryptocurrency</strong>, which is on-par with other state-of-the-art blockchains. Meaning that it attempts to solve a lot of the problems Bitcoin originally had:</p><ul><li><strong>Energy Waste</strong>. The biggest reproach that people have on Bitcoin, is that it wastes a lot of our electricity. Indeed, because of the <strong>proof of work</strong> mechanism people constantly use machines to hash useless data in order to find new blocks. Newer cryptocurrencies, including Libra, make use of <strong>Byzantine Fault Tolerance (BFT) consensus protocols</strong>, which are pretty green by definition.</li><li><strong>Efficiency</strong>. Bitcoin is notably slow, with a block being mined every 10 minutes, and a minimum confirmation time of one hour. BFT allows us to "mine" a new block every 3 seconds (in reality it can even go much faster).</li><li><strong>Safety</strong>. Another problem with Bitcoin (or proof of work-based cryptocurrencies) is that it forks, constantly, and then re-organize itself around the "main chain". This is why one must wait several blocks to confirm that their transaction has been included. This concept is not great at all, as we've seen with Ethereum Classic which was forked (not so long ago) with more than <a href="https://blog.coinbase.com/ethereum-classic-etc-is-currently-being-51-attacked-33be13ce32de">100 block in the past</a>! BFT protocols never fork once they commit a block. What you see on the chain, is the final chain always. This is why it is so fast (and so sexy).</li><li><strong>Stability</strong>. This one is pretty self-explanatory. Bitcoin's price has been anything but stable. Gamblers actually strive on that. But for a global currency to be useful, it has to keep a certain rate for people to use it safely. Libra uses a reserve of <strong>real assets</strong> to back the currency. This is the most conservative way to achieve stability, and it is probably the most contentious point about Libra, but one needs to remember that this is all in order to achieve stability. Stability is required if we want this to be useful for everyone.</li><li><strong>Adoption</strong>. This final point is the most important in my opinion, and this is the reason I've joined Facebook on this journey. Adoption is the largest problem to all cryptocurrencies right now, even though you hear about them in the news very few people use them to actually transact (and most people use them to speculate instead). The mere size of the association (which is planned to reach 100 members from all around the world) and the user-base of Facebook is going to be a big factor in adoption. That's the most exciting thing about the project.</li></ul><p>On top of that, it is probably one of the most interesting projects in cryptography right now. The codebase is in Rust, it uses the Noise Protocol Framework, it will include BLS signatures and formally verified smart contracts. And there's a bunch of other exciting stuff to discover!</p><p>If you're interested you should definitely check the many papers we've published:</p><p>I've read many comments about this project, and here's how I would summarize my point of view: this is a crazy and world-scale project. There are not many projects with such an impact, and we'll have to be very careful about how we walk towards that goal. How will it change the world? Like a lot of global projects, it will have its ups and downs, but I believe that this is a positive net worth project for the world (if it works). We're in a unique position to change the status quo for the better. It's going to be exciting :)</p><p>If you're having trouble understanding why this could work, think about it this way. You currently can't transact money easily as soon as you're crossing a border, and actually, for a lot of countries (like the US) even intra-border money transfers are a pain. Currently the best banks in the world are probably Monzo and Revolut, and they're not available everywhere. Why? Because the banking system is very complex. By using a cryptocurrency, you are skipping decades of progress and setting up a <strong>interoperable</strong> network. Any banks and custody wallets can now use this network. You literally get the same thing you would get with your normal bank (same privacy, same usability, etc.) except that now banks themselves have access to a cheap and global network. The cherry on top is that normal users can bypass banks and use it directly, and you can monitor the total amount of money on the network. No more random printing of money.</p><p>A friend compared this project to nuclear energy: you can debate about it long and large, but there's no doubt it has advanced humanity. I feel the same way about this one. This is a clear improvement. </p><a href="/article/480/libra-a-usable-cryptocurrency/#comments" class="comment_link"> 2 comments </a></article><article><p>I've started writing a book on applied cryptography at the beginning of 2019, and I will soon release a <strong>pre-access version</strong>. I will talk about that soon on this blog!</p><p><img alt="Alice and Bob" src="/upload/alice_and_bob.png"></p><small>(picture taken from the book)</small><hr><p>The book's audience is for students, developers, product managers, engineers, security consultants, curious people, etc. It tries to avoid the history of cryptography (which seems to be unavoidable in any book about cryptography these days), and shy away from mathematical formulas. Instead, it relies heavily on diagrams! A lot of them! As such, it is a broad introduction to what is useful in cryptography and how one can use the different primitives if seen as <strong>black boxes</strong>. It attempts to also serve the right amount of details, to satisfy the reader's curiosity. I'm hopping for it to be a good book for quickly getting introduced to different concepts going from TLS to PAKE. It will also include more modern topics like post-quantum cryptography and cryptocurrencies.</p><p>I don't think there's anything like this yet. the classic <strong>Applied Cryptography</strong> is quite old now and did not do much to encourage best practices or discourage rolling your own. The excellent <strong>Serious Cryptography</strong> is more technical and has more depth than what I'm aiming for. My book will rather be something in between, or something that would (hopefully) look like <a href="https://blog.cryptographyengineering.com/">Matthew Green's blog</a> if it was a book (minus a lot of the humor, because I suck at making jokes).</p><p>More to come!</p><a href="/article/479/a-book-in-preparation/#comments" class="comment_link"> comment on this story</a></article><article><p>Have you ever wondered why byzantine agreement protocols seem to all start with the assumptions that less than a third of the participants can be malicious?</p><p>This axiom is useful down the line when you want to prove <strong>safety</strong>, or in other words that <strong>your protocol can't fork</strong>. I made a diagram to show that, an instance of the protocol that forks (2 proposals have been committed with 2f+1 votes from the participants) is absurd.</p><p><img alt="2f+1 byzantine agreement" src="/upload/Screen_Shot_2019-05-11_at_9.54_.07_AM_.png"></p><a href="/article/478/why-2f1/#comments" class="comment_link"> comment on this story</a></article><article><p>As I'm transitioning to the Blockchain team of Facebook, I decided it would be a good time to give this place a bit of a refresh :)</p><p>I've started blogging here in 2013:</p><p><img alt="2013" src="/upload/Screen_Shot_2019-04-14_at_1.08_.50_PM_.png"></p><p>I quickly found out a layout I liked and sticked with it. In 2014 it looked like this:</p><p><img alt="2014" src="/upload/Screen_Shot_2019-04-14_at_1.10_.36_PM_.png"></p><p>In 2018 it looked a bit different:</p><p><img alt="2018" src="/upload/Screen_Shot_2019-04-14_at_12.59_.23_PM_.png"></p><p>And finally the new re-design which should be brighter: </p><p><img alt="2019" src="/upload/Screen_Shot_2019-04-14_at_12.57_.37_PM_.png"></p><p>Hope you like it :)</p><a href="/article/477/new-job-new-design/#comments" class="comment_link"> 1 comment </a></article><article><p>I already wrote a lot about Disco:</p><p>Today, I released the white paper that introduces the construction. <a href="https://eprint.iacr.org/2019/180">Check it out on ePrint</a>.</p><p><img alt="disco paper" src="/upload/Screen_Shot_2019-05-08_at_4.36_.52_PM_.png"></p><p>It's a combination of everything I've talked about, plus:</p><ul><li>some experimental results on embedded devices done by Matteo Bocchi and Ruggero Susella</li><li>some preliminary results on formal verification with <a href="https://www.cryptologie.net/article/404/tamarin-prover-introduction/">Tamarin Prover</a></li></ul><p>I unfortunately did not have the time to complete the formal verification of several important lemmas. But I am hopping that I can achieve this in a later paper. <a href="https://github.com/mimoo/disco-formal-verification/blob/master/disco_IK.spthy">The formal verification code is on github</a> and anybody is welcome to help :)</p><a href="/article/475/disco-whitepaper/#comments" class="comment_link"> comment on this story</a></article><article><h2>1. Bits and Their Encoding</h2><p>Imagine that I generate a key to encrypt with AES. I use AES-128, instead of AES-256, so I need a 128-bit key.</p><p>I use whatever mechanism my OS gives me to generate a <strong>long string of bits</strong>. For example in python:</p><pre><code class="language-py">&gt;&gt;&gt; import os;
&gt;&gt;&gt; random_number = os.urandom(16)
&gt;&gt;&gt; print(bin(int(random_number, 16))[2:])
11111010110001111100010010101111110101101111111011100001110000001000010100001000000010001001000110111000000111101101000000101011</code></pre><p>These bits, can be interpreted as a large number in base 2. Exactly how you would interpret <code>18</code> as "eighteen" in base 10.</p><p>This is the large number in base 10:</p><pre><code class="language-py">&gt;&gt;&gt; print(int(random_number, 16))
333344255304826079991460895939740225579</code></pre><p>According to <a href="https://www.wolframalpha.com/input/?i=333344255304826079991460895939740225579">wolframalpha</a> it reads like so in english:</p><blockquote><p><em>333 undecillion 344 decillion 255 nonillion 304 octillion 826 septillion 79 sextillion 991 quintillion 460 quadrillion 895 trillion 939 billion 740 million 225 thousand 579</em>.</p></blockquote><p>This number can be quite large sometimes, and we can make use of letters to shorten it into something more human readable. Let's try base 16 which is <strong>hexadecimal</strong>:</p><pre><code class="language-py">&gt;&gt;&gt; print(random_number.encode('hex'))
fac7c4afd6fee1c085080891b81ed02b</code></pre><p>You often see this method of displaying binary strings to a more human readable format. Another popular one is <strong>base64</strong> which is using, you guessed it, base 64:</p><pre><code>&gt;&gt;&gt; import base64
&gt;&gt;&gt; print(base64.b64encode(random_number))
+sfEr9b+4cCFCAiRuB7QKw==</code></pre><p>And as you can see, the bigger the base, the shorter the string we get. That is quite useful to keep something human readable and short.</p><h2>2. Bytes and Bit-wise Operations</h2><p>Let's go back to our bitstring</p><pre><code>11111010110001111100010010101111110101101111111011100001110000001000010100001000000010001001000110111000000111101101000000101011</code></pre><p>this is quite a lot of bits, and we need to find a way to store that in our computer memory.</p><p>The most common way, is to pack these bits into <a href="https://en.wikipedia.org/wiki/Byte">bytes</a> of 8 bits (also called <a href="https://en.wikipedia.org/wiki/Octet_(computing)">one octet</a>):</p><pre><code>11111010 11000111 11000100 10101111 11010110 11111110 11100001 11000000 10000101 00001000 00001000 10010001 10111000 00011110 11010000 00101011</code></pre><p>As you can see, we just split things every 8 bits. In each bundle of 8 bits, we keep the <a href="https://en.wikipedia.org/wiki/Bit_numbering">bit-numbering</a> with the most significant bit (MSB) first. We could have had the least significant bit (LSB) first instead, but since our larger binary string already had MSB first, it makes sense to keep it this way. It's also more "human" as we are used to read numbers from left to right (at least in English, French, Chinese, etc.)</p><p>Most programming languages let you access octets instead of bits directly. For example in Golang:</p><pre><code class="language-go">a := []byte{98, 99} // an array of bytes
b := a[0] // the byte represented by the base 10 number '98'</code></pre><p>To act on a specific bit, it's a bit more effort as we need to segregate it via <a href="https://en.wikipedia.org/wiki/Bitwise_operation">bitwise operations</a> like NOT, AND, OR, XOR, SHIFTs, ROTATIONs, etc. </p><p>For example in <a href="https://play.golang.org/p/4REqapFQnlx">Golang</a>:</p><pre><code class="language-go">a := byte(98)
firstBit := a &gt;&gt; 7 // shifting 7 bits to the right, leaving the MSB intact and zero'ing the others</code></pre><p>So far, all of these things can be learned and anchored in your brain by writing code for something like <a href="https://cryptopals.com/">cryptopals</a> for example.</p><h2>3. Memory</h2><p>OK. How do we store these octets in memory? Unfortunately, because of historical reasons, we have two ways of doing this:</p><ol><li><strong>Big-Endian</strong>: from low memory address (00000....) to high memory address (999999...) in that order.</li><li><strong>Little-Endian</strong>: from high memory address (9999999...) to lower memory address (0000000...) in that order.</li></ol><p>We call this <a href="https://en.wikipedia.org/wiki/Endianness">Endianness</a>.</p><p>I'm sorry, but to understand the rest of this article, you are going to have to parse this small snippet of C first:</p><pre><code class="language-c">#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdint.h&gt;

int main(){
  uint8_t a[] = {1, 255};         // storing [1, 255]
  printf("%p: x\n", a, *a);       // 0x7ffdc5e78a70: 01
  printf("%p: x\n", a+1, *(a+1)); // 0x7ffdc5e78a71: ff
}</code></pre><p>As we can see, everything works as expected: </p><ul><li><code>a</code> points to an address in memory (<code>0x7ffdc5e78a70</code>) containing $1$</li><li>the next address (<code>0x7ffdc5e78a71</code>) points to the value $255$ (displayed in hexadecimal)</li></ul><p>The number <code>0x01ff</code> (the <code>0x</code> is a nice way to indicate that it is hexadecimal) represents the number $1 \times 16^2 + 15 \times 16^1 + 15 \times 16^0 = 511$ (remember, <code>f</code> represents the number 15 in hexadecimal).</p><p>So let's try to store that number in a different way in C:</p><pre><code class="language-c">#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdint.h&gt;

int main(){
  uint16_t b = 0x01ff;               // storing [1, 255] ?
//uint16_t b = 511                   // these two lines are equivalent

  uint8_t *a = (uint8_t*)&amp;b;         // getting octet pointer on b
  printf("%p: x\n", a, *a);       // 0x7ffd78106986: ff
  printf("%p: x\n", a+1, *(a+1)); // 0x7ffd78106987: 01
}</code></pre><p>Wait what? Why is the order of <code>01</code> and <code>ff</code> reversed?</p><p>This is because the machine I used to run this uses <strong>little-endianness</strong> to map values to memory (like most machines nowadays).</p><p>If you didn't know about this, it should freak you out.</p><p>But relax, <strong>this weirdness almost NEVER matters</strong>. Because:</p><ol><li>in most languages, you do not do pointer arithmetic (what I just did when I incremented <code>a</code>)</li><li>in most scenarios, you do not convert back and forth between bytestrings and number types (like <code>int</code> or <code>uint16_t</code>).</li></ol><p>And this is pretty much why most systems don't care too much about using little-endian instead of big-endian.</p><h2>4. Network</h2><p>Networking is usually the first challenge someone unfamiliar with endianness encounters.</p><p>When receiving bytes from a TCP socket, one usually stores them into an array. Here is a simple example in C where we receive a string from the network:</p><pre><code class="language-go">char *a = readFromNetwork() // [104, 101, 108, 108, 111, 0]
printf("%s\n", a);          // hello</code></pre><p>Notice that we do not necessarily know in which order (endianness) the bytes were sent, but protocols usually agree to use <a href="https://en.wikipedia.org/wiki/Endianness#Networking">network byte order</a> which is <strong>big-endian</strong>. This works pretty well for strings, but when it comes to number larger than 8-bit, you need to know how to re-assemble it in memory depending on your machine. </p><p>Let's see why this is a problem. Imagine that we want to transmit the number $511$. We need two bytes: <code>0x01</code> and <code>0x0ff</code>. We transmit them in this order since it is big-endian which is the prefered <strong>network-byte order</strong>. On the other side, here is how we can receive the two bytes, and convert them back into a number type:</p><pre><code class="language-c">uint8_t a1[] = {1, 255};      // storing the received octets as-is (from left to right)
uint8_t a2[] = {255, 1};      // storing the octets from right to left after reversing them
uint16_t *b1 = (uint16_t*)a1;
uint16_t *b2 = (uint16_t*)a2;
printf("%"PRIu16"\n", *b1);    // 65281
printf("%"PRIu16"\n", *b2);    // 511</code></pre><p>In this case, we see that to collect the correct number $511$ on the other end of the connection, we had to reverse the order of the bytes in memory. This is because our machine is little-endian.</p><p><strong>This is what confuses most people!</strong></p><p>In reality, it shouldn't. And this should re-assure you, because trying to figure out the endianness of your machine before converting a series of bytes received from the network into a number can be daunting.</p><p><strong>Instead, we can rely on bitwise operations that are always emulating big-endianness!</strong> Let's take a deep look at this short snippet of code:</p><pre><code class="language-c">uint8_t* a[] = {1, 255};          // the number 511 encoded in network byte-order
uint16_t b = (a[0] &lt;&lt; 8) | a[1];
printf("%"PRIu16"\n", b);         // 511</code></pre><p>Here, we placed the received big-endian numbers in the correct big-endian order via the <a href="https://en.wikipedia.org/wiki/Bitwise_operation#Arithmetic_shift">left shift operation</a>. This code works on any machine. It is the key to understanding why endianness doesn't matter in most cases: <strong>bit-wise operations are endianness-independent</strong>.</p><p>Unless your job is to implement low-level stuff like cryptogaphy, you do not care about endianness. This is because you will almost never convert a series of bytes to a number, or a number to a series of bytes. </p><p>If you do, because of networking perhaps, you use the built-in functions of the language (see <a href="https://golang.org/pkg/encoding/binary/#pkg-variables">Golang</a> or <a href="https://linux.die.net/man/3/htons">C</a> for example) and endianness-independent operations (like left shift), but never pointer arithmetic.</p><a href="/article/474/bits-and-bytes-ordering-in-5-minutes/#comments" class="comment_link"> 3 comments </a></article></div></div></div></div>
</div>
    </div>
    <footer>
        <div>created by buildstarted &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
    </footer>
    
    <script>
        (function () {
            var COLLECT_URL = "https://dna.buildstarted.com/t";
            var SITE_ID = "linksfor.devs";
            var GLOBAL_VAR_NAME = "__DNA__";

            window[GLOBAL_VAR_NAME] = {};

            window[GLOBAL_VAR_NAME].sendPageView = function () {
                var path = location.pathname;
                var referrer = document.referrer;

                var url = COLLECT_URL + "?siteid=" + SITE_ID + "&p=" + encodeURIComponent(path) + "&r=" + encodeURIComponent(referrer);

                try { fetch(url, { method: "GET" }); } catch (e) { }
            };

            window[GLOBAL_VAR_NAME].sendPageView();
        })();
    </script>
</body>
</html>