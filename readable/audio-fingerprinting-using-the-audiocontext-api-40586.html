<!DOCTYPE html>
<html lang="en">
<head>
    <title>
Audio Fingerprinting using the AudioContext API - linksfor.dev(s)    </title>
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Linksfor.dev(s) feed" href="https://linksfor.dev/feed.rss" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google" value="notranslate">
    <link rel="stylesheet" type="text/css" href="/style.css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/favicon.ico" type="image/x-icon">
    <meta property="og:title" content="Audio Fingerprinting using the AudioContext API - linksfor.dev(s)"/>
    <meta property="article:author" content="OpenGenus Foundation"/>
    <meta property="og:description" content="Audio fingerprinting takes advantage of device performance specs to build up an identifying fingerprint of a user. It uses the AudioContext API for this"/>
    <meta property="og:type" content="website"/>
    <meta property="og:url" content="https://iq.opengenus.org/audio-fingerprinting/"/>

<meta property="og:site_name" content="linksfor.dev(s)" />
</head>
<body>
    <div class="devring" style="background: #222">
        <div style="text-align:center">Explore other dev related sites in this ring. If you would like to join this ring <a href="https://devring.club">click here</a>.</div>
        <div class="grid">
            <div style="display: grid; grid-template-columns: .5fr 1fr 1fr 1fr; text-align: center;">
                <span class="devring-title"><a href="https://devring.club/">devring.club</a></span>
                <a href="https://devring.club/sites/1/prev" class="devring-previous">Previous</a>
                <a href="https://devring.club/random" class="devring-random">Random</a>
                <a href="https://devring.club/sites/1/next" class="devring-next">Next</a>
            </div>
        </div>
    </div>
    <div class="grid">
        <h1>
<a href="/" style="color:inherit">linksfor.dev(s)</a>
        </h1>
        <title>linksfor.dev(s) - Audio Fingerprinting using the AudioContext API</title>
<div class="readable">
        <h1>Audio Fingerprinting using the AudioContext API</h1>
            <div>by OpenGenus Foundation</div>
            <div>Reading time: 7-8 minutes</div>
        <div>Posted here: 04 Nov 2019</div>
        <p><a href="https://iq.opengenus.org/audio-fingerprinting/">https://iq.opengenus.org/audio-fingerprinting/</a></p>
        <hr/>
<div id="readability-page-1" class="page"><section>

        <div>
<p id="time">Reading time: 30 minutes | Coding time: 10 minutes</p>
<p>Fingerprinting as introduced in <a href="https://iq.opengenus.org/canvas-fingerprinting/"><strong>this article</strong></a> is a way of identifying users based on one or more set of unique device characteristics. Along with Canvas fingerprinting, <strong>Audio fingerprinting</strong> takes advantage of device performance specs to build up an identifying fingerprint of a user. The problem is it does not need to take any <strong>permission</strong> from the users and works on all browsers and can be used to <mark><strong>track users</strong></mark> across browsers.</p>
<p>It has the same basic process of doing this as canvas fingerprinting. Assign a task to the browser, record how it is executed, and use such data to build the fingerprint.</p>
<p>Recently, several sites have been found to be using such techniques to track activity across browsers on a device.</p>
<h3 id="moredetails">More details</h3>
<p>In the case of audio fingerprinting, the fingerprinting is based on the <strong>device's audio stack</strong>. Just as canvas fingerprinting takes advantage of the Canvas API, the technology that makes audio fingerprinting possible is an API called the <strong>AudioContext API</strong>. It is an <strong>interface of the Web Audio API</strong> that is a part of most modern browsers.</p>
<p>The browser is assigned the task of <strong>generating an audio signal</strong> and it's processed based on the device's audio setting and audio hardware installed on it.</p>
<p>A website uses the <strong>AudioContext API</strong> to send a low frequency audio through the browser to the computer. It then measures how the computer processes this sent data. Based on how this signal is processed, the results from the AudioContext API can help identify the same user across different browsers.</p>
<p>This process <strong>doesn't require access to the device permissions</strong> like microphone or speakers. No audio is recorded, collected or played by any means. It gathers the audio signature of a user's device and uses it to create an identifier to track that user. It simply relies on the difference in the way these generated signals are processed on each device.</p>
<p>Since this technique utilizes the <strong>device's (hardware) capability differences</strong> and not just the browser's â€” it can be used to <strong>track users across different browsers</strong> as long as they're on the same device. Browser compartmentalization (a method where a person uses two or more dedicated browsers for different Internet activities) can be used to escape cookies set by different trackers.</p>
<p><strong>Firefox's multi-account containers</strong> add-on offers the same type of functionality and can be used to separate various web tasks into containers which are kept apart from each other. Cookies have become a less effective technique to these and various other prevention methods. However, methods like audio fingerprinting make it possible to identify users despite the fact that they are using different browsers.</p>
<p>Consider this code snippet:</p>
<pre><code>    <span>console</span><span>.</span><span>log</span><span>(</span><span><span>new</span></span> <span>AudioContext</span><span>(</span><span>)</span><span>)</span><span>;</span>
    
    
    
    <span>{</span>
        <span><span>"baseLatency"</span></span><span>:</span> <span><span>0</span></span><span>,</span>
        <span><span>"outputLatency"</span></span><span>:</span> <span><span>0</span></span><span>,</span>
        <span><span>"sampleRate"</span></span><span>:</span> <span><span>48000</span></span><span>,</span>
        <span><span>"state"</span></span><span>:</span> <span><span>"suspended"</span></span><span>,</span>
        <span><span>"maxChannelCount"</span></span><span>:</span> <span><span>2</span></span><span>,</span>
        <span><span>"numberOfInputs"</span></span><span>:</span> <span><span>1</span></span><span>,</span>
        <span><span>"numberOfOutputs"</span></span><span>:</span> <span><span>1</span></span><span>,</span>
        <span><span>"channelCount"</span></span><span>:</span> <span><span>1</span></span><span>,</span>
        <span><span>"channelCountMode"</span></span><span>:</span> <span><span>"max"</span></span><span>,</span>
        <span><span>"channelInterpretation"</span></span><span>:</span> <span><span>"speakers"</span></span><span>,</span>
        <span><span>"fftSize"</span></span><span>:</span> <span><span>2048</span></span><span>,</span>
        <span><span>"frequencyBinCount"</span></span><span>:</span> <span><span>1024</span></span><span>,</span>
        <span><span>"minDecibels"</span></span><span>:</span> <span><span>-</span></span><span><span>100</span></span><span>,</span>
        <span><span>"maxDecibels"</span></span><span>:</span> <span><span>-</span></span><span><span>30</span></span><span>,</span>
        <span><span>"smoothingTimeConstant"</span></span><span>:</span> <span><span>0.8</span></span>
    <span>}</span>
</code></pre>
<p>Using methods such as <code>createAnalyser()</code>, <code>createDynamicsCompressor()</code> and <code>createOscillator()</code> can be used to further develop unique device information. Other fingerprinting methods can be used in conjunction with this one to get an even more accurate identifier. All the information collected is passed onto a hash function to make up the fingerprint.</p>
<ul>
<li><code>createAnalyser()</code>: can be used to reveal time and frequency data of the audio and create data visualizations through a node created called <code>AnalyserNode</code>.</li>
<li><code>createDynamicsCompressor()</code>: can be used to compress an audio signal through the <code>DynamicsCompressorNode</code>.</li>
<li><code>createOscillator()</code>: results in the creation of a given frequency of a given periodic wave to be created through <code>OscillatorNode</code>.</li>
<li><code>createGain()</code>: creates a <code>GainNode</code> which is responsible for detecting the change in volume.</li>
</ul>
<p>This piece of code performs fingerprint as found in <a href="https://www.cdn-net.com/cc.js">cc.js of CDN-NET</a> and <a href="https://audiofingerprint.openwpm.com/">OpenWPM</a></p>
<ol>
<li>First, we need to create an array to store frequency values.</li>
</ol>
<pre><code>    <span><span>let</span></span> freq_data <span>=</span> <span>[</span><span>]</span><span>;</span>
</code></pre>
<ol start="2">
<li>We create an AudioContext object and create the various nodes needed to generate signal and collect the information using the built-in methods of the AudioContext object.</li>
</ol>
<pre><code>    
   <span><span>const</span></span> ctx <span>=</span> <span><span>new</span></span> <span>AudioContext</span><span>(</span><span>)</span><span>;</span> 
   <span><span>const</span></span> oscillator <span>=</span> ctx<span>.</span><span>createOscillator</span><span>(</span><span>)</span><span>;</span> 
   <span><span>const</span></span> analyser <span>=</span> ctx<span>.</span><span>createAnalyser</span><span>(</span><span>)</span><span>;</span> 
   <span><span>const</span></span> gain <span>=</span> ctx<span>.</span><span>createGain</span><span>(</span><span>)</span><span>;</span> 
   <span><span>const</span></span> scriptProcessor <span>=</span> ctx<span>.</span><span>createScriptProcessor</span><span>(</span><span><span>4096</span></span><span>,</span> <span><span>1</span></span><span>,</span> <span><span>1</span></span><span>)</span><span>;</span> 
</code></pre>
<ol start="3">
<li>We disable the volume and connect the nodes with each other.</li>
</ol>
<pre><code>    
   gain<span>.</span>gain<span>.</span>value <span>=</span> <span><span>0</span></span><span>;</span>
   
   
   oscillator<span>.</span><span>connect</span><span>(</span>analyser<span>)</span><span>;</span>
   
   analyser<span>.</span><span>connect</span><span>(</span>scriptProcessor<span>)</span><span>;</span>
   
   scriptProcessor<span>.</span><span>connect</span><span>(</span>gain<span>)</span><span>;</span>
   
   gain<span>.</span><span>connect</span><span>(</span>ctx<span>.</span>destination<span>)</span><span>;</span>
</code></pre>
<ol start="4">
<li>Using the <code>ScriptProcessorNode</code>, we create a function that collects frequency data while the audio is being processed.</li>
</ol>
<ul>
<li>The function creates a <code>Float32Array</code> typed array with a length that equals the number of (frequency) data values in the <code>AnalyserNode</code> and then populates it with the values.</li>
<li>These values are then copied to the array we created earlier (<code>freq_data</code>) so we can log them easily to an output.</li>
<li>We disconnect the nodes and log the output.</li>
</ul>
<pre><code>   scriptProcessor<span>.</span><span>onaudioprocess</span> <span>=</span> <span><span><span>function</span></span></span><span><span>(</span></span><span><span>bins</span></span><span><span>)</span></span><span> </span><span>{</span>
      
      bins <span>=</span> <span><span>new</span></span> <span><span>Float32Array</span></span><span>(</span>analyser<span>.</span>frequencyBinCount<span>)</span><span>;</span>
      
      analyser<span>.</span><span>getFloatFrequencyData</span><span>(</span>bins<span>)</span><span>;</span>
      
      
      <span><span>for</span></span> <span>(</span><span><span>var</span></span> i <span>=</span> <span><span>0</span></span><span>;</span> i <span>&lt;</span> bins<span>.</span>length<span>;</span> i <span>=</span> i <span>+</span> <span><span>1</span></span><span>)</span> <span>{</span>
          freq_data<span>.</span><span>push</span><span>(</span>bins<span>[</span>i<span>]</span><span>)</span><span>;</span>
      <span>}</span>
      
      
      analyser<span>.</span><span>disconnect</span><span>(</span><span>)</span><span>;</span>
      scriptProcessor<span>.</span><span>disconnect</span><span>(</span><span>)</span><span>;</span>
      gain<span>.</span><span>disconnect</span><span>(</span><span>)</span><span>;</span>
      
      
      <span>console</span><span>.</span><span>log</span><span>(</span>freq_data<span>)</span><span>;</span>
   <span>}</span><span>;</span> 
</code></pre>
<ol start="5">
<li>We start playing the tone so the audio is generated and processed in accordance with the function.</li>
</ol>
<pre><code>   
   oscillator<span>.</span><span>start</span><span>(</span><span><span>0</span></span><span>)</span><span>;</span>
</code></pre>
<p>We get an output like the one displayed below. The values are a lot longer than 10 values. This is for the sake of simplification.</p>
<pre><code>   
</code></pre>
<p>A combination of all these audio data values can be processed through a hash function to create a unique fingerprint. Values passed from other methods of fingerprinting can also be aggregated to be hashed and produce a fingerprint of a device.</p>
<p>Some possible defenses against this tracking method work by adding a small noise to the actual fingerprint to generate a random fake value and reporting it as such. This is seen in add-ons like <a href="https://addons.mozilla.org/en-US/firefox/addon/audioctx-fingerprint-defender/">AudioContext Fingerprint Defender</a>. The TOR browser is by far the only browser that blocks these types of tracking methods by default.</p>
<h3 id="references">References</h3>
<p><a href="https://iq.opengenus.org/canvas-fingerprinting/"><strong>Canvas fingerprinting</strong></a><br>
<a href="https://iq.opengenus.org/methods-to-track-user-on-web/"><strong>Methods to track users on the Web</strong></a><br>
<a href="https://audiofingerprint.openwpm.com/">OpenWPM</a><br>
<a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext">AudioContext API</a><br>
<a href="https://yinzhicao.org/TrackingFree/crossbrowsertracking_NDSS17.pdf">(Cross-)Browser Fingerprinting via OS and Hardware Level Features</a></p>
</div>
      </section></div></div>
    </div>
    <footer>
        <div>created by <a href="https://buildstarted.com">buildstarted</a> &copy; 2020 <a href="/about">about</a></div>
        <div>Share this page on social media: copy and paste this url https://linksfor.dev/</div>
        <div>If you prefer RSS: <a href="https://linksfor.dev/feed.xml">https://linksfor.dev/feed.xml</a></div>
        <div>Customer satisfaction guaranteed to be optional.</div>
    </footer>
    
    <script async defer>
        _dna = window._dna || {};
        _dna.siteId = "linksfor.devs";
        _dna.outlink = true;

        (function() {
            let dna = document.createElement('script');
            dna.type = 'text/javascript';
            dna.async = true;
            dna.src = '//dna.buildstarted.com/t.js';
            let s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(dna, s);
        })();
    </script>
    <noscript><img src="//dna.buildstarted.com/g?siteId=linksfor.devs"/></noscript>
</body>
</html>